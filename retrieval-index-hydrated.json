{
  "metadata": {
    "title": "AI for IA - Comprehensive Retrieval Index",
    "version": "2.0-expanded",
    "created": "2025-11-29",
    "totalEntities": 1030,
    "modules": 11,
    "description": "Complete entity registry with IDs, types, definitions, cross-module references, and retrieval questions extracted from all 11 ontology audit files"
  },
  "modules": {
    "1-1-ai-fundamentals": {
      "file": "1-1-ai-fundamentals.mdx",
      "focus": "Foundation knowledge about how LLMs work and their application to Information Architecture work",
      "entityCount": 67,
      "entities": {
        "concepts": [
          {
            "id": "ai-for-ia-course",
            "title": "AI for IA (Course Overview)",
            "type": "root_concept",
            "definition": "A comprehensive course on applying Artificial Intelligence to Information Architecture, focusing on the partnership between human judgment and AI capabilities.",
            "retrievalQuestions": [
              "What is AI for IA?",
              "What does AI for IA mean?",
              "What is this course about?",
              "Introduction to AI for IA"
            ],
            "content": "**AI for IA** is a specialized curriculum designed to help Information Architects integrate Large Language Models (LLMs) into their workflow.\n\n**Core Philosophy:**\n- **AI Amplifies, Not Replaces:** AI is a tool for scale and pattern recognition; humans provide strategy and empathy.\n- **Prediction, Not Retrieval:** Understanding that LLMs generate text based on probability, not knowledge lookup.\n- **Validation is Mandatory:** Because AI can hallucinate, a robust validation framework is essential.\n\n**Key Modules:**\n1. **AI Fundamentals:** How LLMs work (tokens, context windows, embeddings).\n2. **AI-Human Partnership:** The decision framework for delegating tasks.\n3. **Prompt Engineering:** Techniques for getting consistent IA outputs.\n4. **Ontology & Taxonomy:** Using AI to structure information.\n\nThis course moves beyond basic prompting to deep structural application of AI in information science."
          }
        ],
        "frameworks": [
          {
            "id": "llm-capability-model",
            "title": "LLM Capability Model",
            "type": "framework",
            "definition": "Framework defining what AI can do well for IA work, including pattern recognition, content generation, classification, and analysis",
            "contains": [
              "pattern-recognition-scale",
              "content-generation-variation",
              "classification-organization",
              "analysis-synthesis"
            ],
            "lines": "96-209",
            "crossModule": true,
            "retrievalQuestions": [
              "What can AI do well for IA work?",
              "What are LLM capabilities?",
              "How can AI help with content audits?"
            ],
            "content": "### 2.1 Pattern Recognition at Scale\n\n**What LLMs Excel At:**\n- Finding inconsistencies across large content sets\n- Identifying duplicate or overlapping content\n- Detecting naming convention variations\n- Spotting structural patterns\n\n**IA Application Example:**\n\n<CodeGroup>\n\n```text Task\nAnalyze 250 documentation pages for inconsistent terminology.\nFind all variations of \"authentication\" terms used across the site.\n```\n\n```text AI Capability\nCan process all 250 pages in minutes and identify:\n- \"login\" (45 instances)\n- \"sign in\" (32 instances)\n- \"log in\" (28 instances)\n- \"authentication\" (67 instances)\n- \"auth\" (23 instances)\n\nFlags recommendation: Standardize on one term\n```\n\n</CodeGroup>\n\n**Human Role:** Decide which term to standardize on based on:\n- User research\n- Brand voice\n- SEO considerations\n- Accessibility\n\n---\n\n### 2.2 Content Generation and Variation\n\n**What LLMs Excel At:**\n- Generating multiple options quickly\n- Creating variations for A/B testing\n- Drafting initial taxonomies\n- Producing navigation label alternatives\n\n**IA Application Example:**\n\n<CodeGroup>\n\n```text Prompt\nGenerate 10 different top-level category labels for developer documentation covering:\n- Getting started guides\n- API reference\n- SDK documentation\n- Best practices\n- Troubleshooting\n\nRequirements:\n- Each label under 20 characters\n- Action-oriented where possible\n- Clear for junior developers\n```\n\n```text AI Output\n1. Get Started\n2. API Reference\n3. SDKs & Tools\n4. Best Practices\n5. Troubleshoot\n6. Quick Start\n7. API Docs\n8. Developer Tools\n9. Help & Support\n10. Reference Guide\n```\n\n</CodeGroup>\n\n**Human Role:** Select and test options with users\n\n---\n\n### 2.3 Classification and Organization\n\n**What LLMs Excel At:**\n- Categorizing content by type\n- Applying consistent taxonomy\n- Organizing unstructured content\n- Identifying themes\n\n**IA Application Example:**\n\n<CodeGroup>\n\n```text Prompt\nClassify these documentation pages using the Di\u00e1taxis framework:\n- \"Building Your First App\" \u2192 ?\n- \"API Endpoint Reference\" \u2192 ?\n- \"Understanding Authentication Flows\" \u2192 ?\n- \"How to Reset a Password\" \u2192 ?\n- \"Error Code Reference\" \u2192 ?\n\nCategories: Tutorial (learning-oriented), How-to Guide (task-oriented), \nReference (information-oriented), Explanation (understanding-oriented)\n```\n\n```text AI Classification\n- \"Building Your First App\" \u2192 Tutorial (step-by-step learning)\n- \"API Endpoint Reference\" \u2192 Reference (technical lookup)\n- \"Understanding Authentication Flows\" \u2192 Explanation (conceptual understanding)\n- \"How to Reset a Password\" \u2192 How-to Guide (specific task solution)\n- \"Error Code Reference\" \u2192 Reference (information lookup)\n```\n\n</CodeGroup>\n\n**Human Role:** Validate classifications against content goals and user needs\n\n---\n\n### 2.4 Analysis and Synthesis\n\n**What LLMs Excel At:**\n- Summarizing large datasets\n- Finding themes in qualitative data\n- Synthesizing research findings\n- Generating insights from patterns\n\n**IA Application Example:**\n\n<CodeGroup>\n\n```text Task\nAnalyze 30 card sorting results to identify consensus groupings.\nEach of 30 participants sorted 40 cards into their own categories.\n```\n\n```text AI Capability\nProcess all 30 \u00d7 40 = 1,200 placements to find:\n- Cards grouped together by 80%+ of participants (high consensus)\n- Cards with no clear grouping pattern (conflicts)\n- Most common category names participants created\n- Suggested taxonomy based on consensus patterns\n\nTime: Minutes (vs. hours manually)\n```\n\n</CodeGroup>\n\n**Human Role:** Interpret findings in user context, resolve conflicts, make final IA decisions\n\n---",
            "hydration_source_header": "2. AI Capabilities in IA Work",
            "hydration_method": "line_proximity"
          },
          {
            "id": "llm-limitation-model",
            "title": "LLM Limitation Model",
            "type": "framework",
            "definition": "Framework defining AI limitations including hallucination, consistency challenges, and context window constraints",
            "contains": [
              "hallucination-problem",
              "consistency-challenges",
              "context-window-limitations"
            ],
            "lines": "211-390",
            "crossModule": true,
            "retrievalQuestions": [
              "What are the limitations of using AI in information architecture?",
              "What should I watch out for with AI?",
              "Why can't I trust AI outputs directly?"
            ],
            "content": "**What LLMs Excel At:**\n- Summarizing large datasets\n- Finding themes in qualitative data\n- Synthesizing research findings\n- Generating insights from patterns\n\n**IA Application Example:**\n\n<CodeGroup>\n\n```text Task\nAnalyze 30 card sorting results to identify consensus groupings.\nEach of 30 participants sorted 40 cards into their own categories.\n```\n\n```text AI Capability\nProcess all 30 \u00d7 40 = 1,200 placements to find:\n- Cards grouped together by 80%+ of participants (high consensus)\n- Cards with no clear grouping pattern (conflicts)\n- Most common category names participants created\n- Suggested taxonomy based on consensus patterns\n\nTime: Minutes (vs. hours manually)\n```\n\n</CodeGroup>\n\n**Human Role:** Interpret findings in user context, resolve conflicts, make final IA decisions\n\n---",
            "hydration_source_header": "2.4 Analysis and Synthesis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "ethical-use-framework",
            "title": "Ethical Use Guidelines for IA",
            "type": "framework",
            "definition": "Framework for ethical AI use in IA including transparency, validation, privacy, and accessibility principles",
            "contains": [
              "transparency-principle",
              "validation-principle",
              "privacy-principle",
              "accessibility-principle"
            ],
            "lines": "570-602",
            "crossModule": true,
            "retrievalQuestions": [
              "How should I ethically use AI in my IA practice?",
              "What ethical principles should guide my AI use?",
              "Is it ethical to use AI for IA?"
            ],
            "content": "#### Transparency\n\n<Card title=\"Be Transparent About AI Use\" icon=\"eye\">\n  - Tell stakeholders when AI assisted with IA decisions\n  - Document AI-generated options vs. human choices\n  - Don't present AI outputs as your own analysis without validation\n  - Explain how AI was used in your process\n</Card>\n\n#### Validation\n\n<Card title=\"Always Validate AI Outputs\" icon=\"check-double\">\n  - Check facts and citations\n  - Test with real users when possible\n  - Apply your expertise and judgment\n  - Don't outsource critical thinking to AI\n  - Verify against primary sources\n</Card>\n\n#### Privacy\n\n<Card title=\"Protect Sensitive Information\" icon=\"shield-halved\">\n  - Don't input confidential content into public AI tools\n  - Be aware of data retention policies\n  - Use enterprise or private AI instances when handling proprietary information\n  - Sanitize data before analysis\n  - Consider user privacy in any data shared with AI\n</Card>\n\n#### Accessibility\n\n<Card title=\"Center Accessibility\" icon=\"universal-access\">\n  - Don't trust AI's accessibility judgments\n  - Apply WCAG guidelines yourself\n  - Test with assistive technologies\n  - Consider cognitive and reading accessibility\n  - Involve users with disabilities in validation\n</Card>\n\n---",
            "hydration_source_header": "4.3 Ethical Use Guidelines for IA",
            "hydration_method": "title_match"
          }
        ],
        "principles": [
          {
            "id": "prediction-not-retrieval",
            "title": "Prediction Not Retrieval",
            "type": "principle",
            "definition": "LLMs predict the next token based on patterns, they don't retrieve facts from a database",
            "partOf": "llm-fundamentals",
            "lines": "21-31, 58-86",
            "crossModule": true,
            "retrievalQuestions": [
              "How do LLMs actually work?",
              "What's the difference between AI prediction and retrieval?"
            ],
            "content": "**The Generation Process:**\n\n1. **Input Processing:** Your prompt is converted to tokens\n2. **Pattern Matching:** The model identifies patterns similar to what it learned\n3. **Probability Calculation:** For each possible next token, it calculates probability\n4. **Selection:** It picks the most likely token (with some randomness for creativity)\n5. **Repetition:** This process continues token by token until the response is complete\n\n**Why This Matters for IA:**\n\n```text Example\nYou: \"Organize these topics: Login, Password Reset, 2FA, Account Security\"\n\nWhat the LLM does:\n1. Recognizes this looks like security-related features\n2. Recalls patterns from documentation it has seen\n3. Predicts logical groupings based on those patterns\n4. Generates: \"Authentication\" category with subcategories\n\nWhat the LLM does NOT do:\n- Look up \"the correct\" way to organize security features\n- Remember what it suggested for similar prompts before\n- Understand what 2FA means beyond its statistical relationship to security terms\n```\n\n<Warning>\n  **Critical Insight:** The LLM generates plausible-sounding text, not guaranteed-accurate text. Always validate outputs.\n</Warning>\n\n---",
            "hydration_source_header": "1.3 How LLMs Generate Text (Prediction, Not Retrieval)",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "pattern-not-knowledge",
            "title": "Pattern-Based, Not Knowledge-Based",
            "type": "principle",
            "definition": "LLMs work through pattern matching, not true understanding or knowledge",
            "partOf": "llm-fundamentals",
            "lines": "21-31",
            "crossModule": true,
            "retrievalQuestions": [
              "Does AI actually understand content?",
              "How do LLMs process information?"
            ],
            "content": "### 1.1 What is a Large Language Model?\n\nThink of an LLM as a sophisticated pattern-matching system trained on billions of text examples. Unlike a database that retrieves exact information, an LLM predicts the most likely next words based on patterns it learned during training.\n\n**Key Concept:** LLMs don't \"know\" things\u2014they predict text based on statistical patterns.\n\n#### How This Relates to IA Work\n\nAs an information architect, you organize information for humans to find and understand. LLMs can help because they:\n- Recognize patterns in how information is structured\n- Generate labels and descriptions that follow natural language conventions\n- Identify relationships between concepts\n- Process large amounts of unstructured content quickly\n\n**Example in Documentation IA:**\nWhen you ask an LLM to \"organize these API endpoints into logical groups,\" it recognizes patterns from thousands of API documentation examples it's seen and suggests groupings that match common industry practices.\n\n---\n\n### 1.2 The Token-Based Processing Model\n\nLLMs break text into \"tokens\" (roughly words or word parts). This matters for IA work because:\n\n**Token limits affect:**\n- How much content you can analyze at once\n- The cost of using API-based tools\n- How you structure prompts for complex IA tasks\n\n**Practical Implication for IAs:**\nWhen conducting a content audit of 200 documentation pages, you can't feed all 200 pages into an LLM at once. You'll need to:\n- Process in batches\n- Create summaries first, then analyze\n- Design prompts that work within constraints\n\n**Example Token Counts (approximate):**\n- 1 token \u2248 4 characters\n- Average word \u2248 1.3 tokens\n- A documentation page (1,000 words) \u2248 1,300 tokens\n- Claude's context window \u2248 200,000 tokens (but practical use is less)\n\n---\n\n### 1.3 How LLMs Generate Text (Prediction, Not Retrieval)\n\n**The Generation Process:**\n\n1. **Input Processing:** Your prompt is converted to tokens\n2. **Pattern Matching:** The model identifies patterns similar to what it learned\n3. **Probability Calculation:** For each possible next token, it calculates probability\n4. **Selection:** It picks the most likely token (with some randomness for creativity)\n5. **Repetition:** This process continues token by token until the response is complete\n\n**Why This Matters for IA:**\n\n```text Example\nYou: \"Organize these topics: Login, Password Reset, 2FA, Account Security\"\n\nWhat the LLM does:\n1. Recognizes this looks like security-related features\n2. Recalls patterns from documentation it has seen\n3. Predicts logical groupings based on those patterns\n4. Generates: \"Authentication\" category with subcategories\n\nWhat the LLM does NOT do:\n- Look up \"the correct\" way to organize security features\n- Remember what it suggested for similar prompts before\n- Understand what 2FA means beyond its statistical relationship to security terms\n```\n\n<Warning>\n  **Critical Insight:** The LLM generates plausible-sounding text, not guaranteed-accurate text. Always validate outputs.\n</Warning>\n\n---",
            "hydration_source_header": "1. How LLMs Process and Generate Information",
            "hydration_method": "line_proximity"
          },
          {
            "id": "validate-all-outputs",
            "title": "Always Validate AI Outputs",
            "type": "principle",
            "definition": "All AI outputs should be treated as suggestions requiring human validation",
            "partOf": "ethical-use-framework",
            "lines": "247-253, 582-588",
            "crossModule": true,
            "retrievalQuestions": [
              "Should I trust AI outputs?",
              "Why do I need to validate AI work?"
            ],
            "content": "### 3.1 The Hallucination Problem\n\n**What is Hallucination?**\nWhen AI generates confident-sounding but factually incorrect information.\n\n**Common IA Hallucinations:**\n\n<Accordion title=\"Example 1: Made-Up Statistics\">\n**AI Output:**\n\"Studies show that 73% of users prefer task-based navigation over alphabetical organization.\"\n\n**Problem:**\nNo such study exists. The percentage sounds authoritative but is fabricated.\n\n**How to Avoid:**\nNever trust statistics without verification. Ask for sources. Verify citations.\n</Accordion>\n\n<Accordion title=\"Example 2: Incorrect Best Practices\">\n**AI Output:**\n\"ISO 25964 recommends a maximum taxonomy depth of 5 levels for optimal usability.\"\n\n**Problem:**\nThe standard doesn't specify this exact number.\n\n**How to Avoid:**\nCheck primary sources. Verify standards directly. Don't assume AI knows current standards.\n</Accordion>\n\n<Accordion title=\"Example 3: Fabricated Examples\">\n**AI Output:**\n\"Stripe's API documentation uses a 7-level hierarchy organized by HTTP method.\"\n\n**Problem:**\nStripe actually uses ~3 levels organized by resource type, not HTTP method.\n\n**How to Avoid:**\nVerify examples against real-world sources. Visit the actual sites AI mentions.\n</Accordion>\n\n<Warning>\n  **Golden Rule:** Treat AI outputs as suggestions, not facts. Always validate against:\n  - Primary sources\n  - Your own expertise\n  - Real-world data\n  - User research\n</Warning>\n\n---\n\n### 3.2 Consistency Challenges\n\n**The Problem:**\nLLMs don't maintain perfect consistency across:\n- Multiple prompts in a session\n- Regenerated outputs\n- Different ways of asking the same question\n\n**Consistency Issues in IA Work:**\n\n<Tabs>\n  <Tab title=\"Classification Drift\">\n```text First Prompt\n\"Classify this content as Tutorial, Reference, or Guide\"\nResult: \"Tutorial\"\n```\n\n```text Same Content, Rephrased\n\"What content type is this: Tutorial, Reference, or How-to?\"\nResult: \"How-to\"\n```\n\n**Why:** Slight prompt variations affect pattern matching\n  </Tab>\n  \n  <Tab title=\"Taxonomy Changes\">\n```text Session 1\nGenerate taxonomy \u2192 8 top-level categories\n```\n\n```text Session 2 (Next Day)\nRefine same taxonomy \u2192 Suggests 6 categories, some renamed\n```\n\n**Why:** No persistent memory between sessions, built-in randomness\n  </Tab>\n</Tabs>\n\n#### How to Maintain Consistency\n\n**Strategy 1: Single-Session Processing**\nComplete related tasks in one session rather than across multiple sessions.\n\n**Strategy 2: Explicit Context Preservation**\n\n<CodeGroup>\n\n```text Preserving Context\n\"In our previous conversation, you generated this taxonomy: \n[paste taxonomy]. \n\nNow, using the SAME category names and structure, add subcategories \nto the 'API Reference' section.\"\n```\n\n</CodeGroup>\n\n**Strategy 3: Document Your Prompts**\nKeep a record of exact prompts that produced good results, so you can replicate them.\n\n**Strategy 4: Use Explicit Rules**\n\n<CodeGroup>\n\n```text Explicit Rules\n\"When classifying content, always use these exact terms: \nTutorial, How-to Guide, Reference, Explanation. \nNever use synonyms or variations.\"\n```\n\n</CodeGroup>\n\n---\n\n### 3.3 Context Window Limitations\n\n**What Is a Context Window?**\nThe amount of text an LLM can \"remember\" in a single conversation. Think of it as working memory.\n\n**Why This Matters for IA:**\nMany IA tasks involve large amounts of content:\n- Content inventories with hundreds of pages\n- Complete sitemaps\n- Full documentation sets\n- Extensive user research transcripts\n\nYou can't always feed everything to the LLM at once.\n\n#### Practical Implications for IA Work\n\n**Limitation Example:**\n\n```text The Problem\nYou have: 500-page documentation site audit\nContext window: ~200,000 tokens (about 150,000 words)\nEach page: ~1,000 words\n\nYou can only process ~150 pages at a time.\n```\n\n**Workaround Strategies:**\n\n<Accordion title=\"Strategy 1: Batch Processing\">\n1. Divide content into logical chunks (e.g., by section)\n2. Process each chunk separately\n3. Synthesize results manually or with a final prompt\n\n**Example:**\n- Batch 1: Process pages 1-50\n- Batch 2: Process pages 51-100\n- Batch 3: Process pages 101-150\n- Final: Synthesize findings across all batches\n</Accordion>\n\n<Accordion title=\"Strategy 2: Hierarchical Analysis\">\n1. First pass: Analyze page titles and summaries only\n2. Second pass: Deep dive into specific sections identified as problematic\n3. Third pass: Detailed analysis of priority pages\n\n**Example:**\n- Level 1: Classify all 500 pages by title (fast)\n- Level 2: Analyze 50 pages flagged as problematic\n- Level 3: Deep dive on 10 highest-priority issues\n</Accordion>\n\n<Accordion title=\"Strategy 3: Summarize Then Analyze\">\n1. Use AI to create summaries of large content sets\n2. Analyze the summaries (much smaller)\n3. Drill down into specifics only where needed\n\n**Example:**\n- Create 1-sentence summary per page (500 pages \u2192 500 sentences)\n- Analyze patterns in the 500 summaries\n- Deep-dive specific pages based on summary analysis\n</Accordion>\n\n**Example Workflow for Large Content Audit:**\n\n```text Step-by-Step\nStep 1: Generate 1-sentence summary per page (AI)\nStep 2: Classify all pages by content type using summaries (AI)\nStep 3: Identify top 20 problematic pages (AI)\nStep 4: Deep analysis of those 20 pages (AI + human)\nStep 5: Generate recommendations (AI + human)\n```\n\n#### Context Window Best Practices\n\n<CardGroup cols={2}>\n  <Card title=\"Do\" icon=\"check\">\n    - Start with high-level overviews, then zoom in\n    - Use pagination or batching for large datasets\n    - Keep prompts focused on one task at a time\n    - Store important context outside the conversation\n  </Card>\n  \n  <Card title=\"Don't\" icon=\"xmark\">\n    - Assume the LLM remembers everything from start\n    - Try to analyze entire large websites in one prompt\n    - Expect consistency across very long conversations\n    - Mix multiple unrelated tasks in one session\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "3. AI Limitations in IA Work",
            "hydration_method": "line_proximity"
          },
          {
            "id": "ai-amplifies-not-replaces",
            "title": "AI Amplifies, Not Replaces",
            "type": "principle",
            "definition": "AI should augment human capabilities, not replace human judgment",
            "partOf": "ia-ai-partnership",
            "lines": "856-858",
            "crossModule": true,
            "retrievalQuestions": [
              "Will AI replace IA professionals?",
              "What's the relationship between AI and human work?"
            ],
            "content": "In the next module, you'll learn exactly **when to use AI vs. human judgment** through a practical decision framework, and discover how to validate AI outputs systematically.\n\nYou'll master:\n- The IA Decision Framework (AI-First, Human-First, Collaborative tasks)\n- The Validation Pyramid (catching errors at each level)\n- Real-world case studies showing successful AI-human partnerships\n\n<CardGroup cols={2}>\n  <Card title=\"\u2190 Prerequisites\" icon=\"arrow-left\" href=\"/prerequisites\">\n    Review course prerequisites\n  </Card>\n  <Card title=\"Module 1.2 \u2192\" icon=\"arrow-right\" href=\"/1-2-ai-human-partnership\">\n    The AI-Human Partnership in IA\n  </Card>\n</CardGroup>\n\n---\n\n**Estimated Time to Complete:** 60 minutes  \n**Prerequisites:** None\u2014this is the starting point!  \n**Next Module:** [Module 1.2: The AI-Human Partnership in IA \u2192](1-2-ai-human-partnership)",
            "hydration_source_header": "What's Next",
            "hydration_method": "line_proximity"
          },
          {
            "id": "transparency-principle",
            "title": "Transparency About AI Use",
            "type": "principle",
            "definition": "Be transparent about when and how AI is used in IA work",
            "partOf": "ethical-use-framework",
            "lines": "570-578",
            "crossModule": false,
            "retrievalQuestions": [
              "Should I disclose AI use?",
              "How transparent should I be about using AI?"
            ],
            "content": "<Card title=\"Be Transparent About AI Use\" icon=\"eye\">\n  - Tell stakeholders when AI assisted with IA decisions\n  - Document AI-generated options vs. human choices\n  - Don't present AI outputs as your own analysis without validation\n  - Explain how AI was used in your process\n</Card>",
            "hydration_source_header": "Transparency",
            "hydration_method": "title_match"
          },
          {
            "id": "privacy-principle",
            "title": "Protect Sensitive Information",
            "type": "principle",
            "definition": "Never share sensitive or proprietary information with AI systems",
            "partOf": "ethical-use-framework",
            "lines": "590-596",
            "crossModule": false,
            "retrievalQuestions": [
              "Can I share client data with AI?",
              "What data should I avoid putting in AI?"
            ],
            "content": "#### Transparency\n\n<Card title=\"Be Transparent About AI Use\" icon=\"eye\">\n  - Tell stakeholders when AI assisted with IA decisions\n  - Document AI-generated options vs. human choices\n  - Don't present AI outputs as your own analysis without validation\n  - Explain how AI was used in your process\n</Card>\n\n#### Validation\n\n<Card title=\"Always Validate AI Outputs\" icon=\"check-double\">\n  - Check facts and citations\n  - Test with real users when possible\n  - Apply your expertise and judgment\n  - Don't outsource critical thinking to AI\n  - Verify against primary sources\n</Card>\n\n#### Privacy\n\n<Card title=\"Protect Sensitive Information\" icon=\"shield-halved\">\n  - Don't input confidential content into public AI tools\n  - Be aware of data retention policies\n  - Use enterprise or private AI instances when handling proprietary information\n  - Sanitize data before analysis\n  - Consider user privacy in any data shared with AI\n</Card>\n\n#### Accessibility\n\n<Card title=\"Center Accessibility\" icon=\"universal-access\">\n  - Don't trust AI's accessibility judgments\n  - Apply WCAG guidelines yourself\n  - Test with assistive technologies\n  - Consider cognitive and reading accessibility\n  - Involve users with disabilities in validation\n</Card>\n\n---",
            "hydration_source_header": "4.3 Ethical Use Guidelines for IA",
            "hydration_method": "line_proximity"
          },
          {
            "id": "accessibility-principle",
            "title": "Center Accessibility",
            "type": "principle",
            "definition": "Always center accessibility in AI-assisted IA work",
            "partOf": "ethical-use-framework",
            "lines": "598-604",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I ensure AI outputs are accessible?",
              "What about accessibility with AI?"
            ],
            "content": "<Card title=\"Center Accessibility\" icon=\"universal-access\">\n  - Don't trust AI's accessibility judgments\n  - Apply WCAG guidelines yourself\n  - Test with assistive technologies\n  - Consider cognitive and reading accessibility\n  - Involve users with disabilities in validation\n</Card>\n\n---",
            "hydration_source_header": "Accessibility",
            "hydration_method": "title_match"
          }
        ],
        "concepts": [
          {
            "id": "llm-fundamentals",
            "title": "What is a Large Language Model?",
            "type": "concept",
            "definition": "Sophisticated pattern-matching system trained on billions of text examples that predicts text based on statistical patterns",
            "domain": "ai-basics",
            "lines": "21-31",
            "crossModule": true,
            "retrievalQuestions": [
              "What is an LLM?",
              "How do large language models work?"
            ],
            "content": "Think of an LLM as a sophisticated pattern-matching system trained on billions of text examples. Unlike a database that retrieves exact information, an LLM predicts the most likely next words based on patterns it learned during training.\n\n**Key Concept:** LLMs don't \"know\" things\u2014they predict text based on statistical patterns.\n\n#### How This Relates to IA Work\n\nAs an information architect, you organize information for humans to find and understand. LLMs can help because they:\n- Recognize patterns in how information is structured\n- Generate labels and descriptions that follow natural language conventions\n- Identify relationships between concepts\n- Process large amounts of unstructured content quickly\n\n**Example in Documentation IA:**\nWhen you ask an LLM to \"organize these API endpoints into logical groups,\" it recognizes patterns from thousands of API documentation examples it's seen and suggests groupings that match common industry practices.\n\n---",
            "hydration_source_header": "1.1 What is a Large Language Model?",
            "hydration_method": "title_match"
          },
          {
            "id": "token-processing",
            "title": "Token-Based Processing Model",
            "type": "concept",
            "definition": "LLMs process text as tokens (approximately 4 characters or 1.3 tokens per word)",
            "domain": "ai-basics",
            "lines": "37-56",
            "crossModule": true,
            "retrievalQuestions": [
              "What are tokens?",
              "How does tokenization work?"
            ],
            "content": "LLMs break text into \"tokens\" (roughly words or word parts). This matters for IA work because:\n\n**Token limits affect:**\n- How much content you can analyze at once\n- The cost of using API-based tools\n- How you structure prompts for complex IA tasks\n\n**Practical Implication for IAs:**\nWhen conducting a content audit of 200 documentation pages, you can't feed all 200 pages into an LLM at once. You'll need to:\n- Process in batches\n- Create summaries first, then analyze\n- Design prompts that work within constraints\n\n**Example Token Counts (approximate):**\n- 1 token \u2248 4 characters\n- Average word \u2248 1.3 tokens\n- A documentation page (1,000 words) \u2248 1,300 tokens\n- Claude's context window \u2248 200,000 tokens (but practical use is less)\n\n---",
            "hydration_source_header": "1.2 The Token-Based Processing Model",
            "hydration_method": "title_match"
          },
          {
            "id": "text-generation-process",
            "title": "How LLMs Generate Text",
            "type": "concept",
            "definition": "The process by which LLMs predict and generate text output",
            "domain": "ai-basics",
            "lines": "58-86",
            "crossModule": true,
            "retrievalQuestions": [
              "How does AI generate text?",
              "What happens when AI writes?"
            ],
            "content": "**The Generation Process:**\n\n1. **Input Processing:** Your prompt is converted to tokens\n2. **Pattern Matching:** The model identifies patterns similar to what it learned\n3. **Probability Calculation:** For each possible next token, it calculates probability\n4. **Selection:** It picks the most likely token (with some randomness for creativity)\n5. **Repetition:** This process continues token by token until the response is complete\n\n**Why This Matters for IA:**\n\n```text Example\nYou: \"Organize these topics: Login, Password Reset, 2FA, Account Security\"\n\nWhat the LLM does:\n1. Recognizes this looks like security-related features\n2. Recalls patterns from documentation it has seen\n3. Predicts logical groupings based on those patterns\n4. Generates: \"Authentication\" category with subcategories\n\nWhat the LLM does NOT do:\n- Look up \"the correct\" way to organize security features\n- Remember what it suggested for similar prompts before\n- Understand what 2FA means beyond its statistical relationship to security terms\n```\n\n<Warning>\n  **Critical Insight:** The LLM generates plausible-sounding text, not guaranteed-accurate text. Always validate outputs.\n</Warning>\n\n---",
            "hydration_source_header": "1.3 How LLMs Generate Text (Prediction, Not Retrieval)",
            "hydration_method": "title_match"
          },
          {
            "id": "context-window",
            "title": "Context Window Concept",
            "type": "concept",
            "definition": "The amount of text an LLM can 'remember' in a single conversation, measured in tokens",
            "domain": "ai-basics",
            "lines": "303-390",
            "crossModule": true,
            "retrievalQuestions": [
              "What is a context window?",
              "How much can AI remember?",
              "What are context limits?"
            ],
            "content": "<CardGroup cols={2}>\n  <Card title=\"Do\" icon=\"check\">\n    - Start with high-level overviews, then zoom in\n    - Use pagination or batching for large datasets\n    - Keep prompts focused on one task at a time\n    - Store important context outside the conversation\n  </Card>\n  \n  <Card title=\"Don't\" icon=\"xmark\">\n    - Assume the LLM remembers everything from start\n    - Try to analyze entire large websites in one prompt\n    - Expect consistency across very long conversations\n    - Mix multiple unrelated tasks in one session\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Context Window Best Practices",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "ai-hallucination",
            "title": "The Hallucination Problem",
            "type": "concept",
            "definition": "When AI generates confident-sounding but factually incorrect information",
            "domain": "ai-limitations",
            "lines": "215-253",
            "crossModule": true,
            "retrievalQuestions": [
              "What is AI hallucination?",
              "Why does AI make things up?",
              "How do I detect AI hallucinations?"
            ],
            "content": "**What is Hallucination?**\nWhen AI generates confident-sounding but factually incorrect information.\n\n**Common IA Hallucinations:**\n\n<Accordion title=\"Example 1: Made-Up Statistics\">\n**AI Output:**\n\"Studies show that 73% of users prefer task-based navigation over alphabetical organization.\"\n\n**Problem:**\nNo such study exists. The percentage sounds authoritative but is fabricated.\n\n**How to Avoid:**\nNever trust statistics without verification. Ask for sources. Verify citations.\n</Accordion>\n\n<Accordion title=\"Example 2: Incorrect Best Practices\">\n**AI Output:**\n\"ISO 25964 recommends a maximum taxonomy depth of 5 levels for optimal usability.\"\n\n**Problem:**\nThe standard doesn't specify this exact number.\n\n**How to Avoid:**\nCheck primary sources. Verify standards directly. Don't assume AI knows current standards.\n</Accordion>\n\n<Accordion title=\"Example 3: Fabricated Examples\">\n**AI Output:**\n\"Stripe's API documentation uses a 7-level hierarchy organized by HTTP method.\"\n\n**Problem:**\nStripe actually uses ~3 levels organized by resource type, not HTTP method.\n\n**How to Avoid:**\nVerify examples against real-world sources. Visit the actual sites AI mentions.\n</Accordion>\n\n<Warning>\n  **Golden Rule:** Treat AI outputs as suggestions, not facts. Always validate against:\n  - Primary sources\n  - Your own expertise\n  - Real-world data\n  - User research\n</Warning>\n\n---",
            "hydration_source_header": "3.1 The Hallucination Problem",
            "hydration_method": "title_match"
          },
          {
            "id": "consistency-challenges",
            "title": "Consistency Challenges",
            "type": "concept",
            "definition": "AI may give different answers to the same question across sessions",
            "domain": "ai-limitations",
            "lines": "257-301",
            "crossModule": true,
            "retrievalQuestions": [
              "Why does AI give inconsistent answers?",
              "How do I get consistent results from AI?"
            ],
            "content": "**The Problem:**\nLLMs don't maintain perfect consistency across:\n- Multiple prompts in a session\n- Regenerated outputs\n- Different ways of asking the same question\n\n**Consistency Issues in IA Work:**\n\n<Tabs>\n  <Tab title=\"Classification Drift\">\n```text First Prompt\n\"Classify this content as Tutorial, Reference, or Guide\"\nResult: \"Tutorial\"\n```\n\n```text Same Content, Rephrased\n\"What content type is this: Tutorial, Reference, or How-to?\"\nResult: \"How-to\"\n```\n\n**Why:** Slight prompt variations affect pattern matching\n  </Tab>\n  \n  <Tab title=\"Taxonomy Changes\">\n```text Session 1\nGenerate taxonomy \u2192 8 top-level categories\n```\n\n```text Session 2 (Next Day)\nRefine same taxonomy \u2192 Suggests 6 categories, some renamed\n```\n\n**Why:** No persistent memory between sessions, built-in randomness\n  </Tab>\n</Tabs>\n\n#### How to Maintain Consistency\n\n**Strategy 1: Single-Session Processing**\nComplete related tasks in one session rather than across multiple sessions.\n\n**Strategy 2: Explicit Context Preservation**\n\n<CodeGroup>\n\n```text Preserving Context\n\"In our previous conversation, you generated this taxonomy: \n[paste taxonomy]. \n\nNow, using the SAME category names and structure, add subcategories \nto the 'API Reference' section.\"\n```\n\n</CodeGroup>\n\n**Strategy 3: Document Your Prompts**\nKeep a record of exact prompts that produced good results, so you can replicate them.\n\n**Strategy 4: Use Explicit Rules**\n\n<CodeGroup>\n\n```text Explicit Rules\n\"When classifying content, always use these exact terms: \nTutorial, How-to Guide, Reference, Explanation. \nNever use synonyms or variations.\"\n```\n\n</CodeGroup>\n\n---",
            "hydration_source_header": "3.2 Consistency Challenges",
            "hydration_method": "title_match"
          },
          {
            "id": "llm-bias",
            "title": "Bias in LLMs",
            "type": "concept",
            "definition": "Systematic biases in AI outputs reflecting training data limitations",
            "domain": "ethics",
            "lines": "398-476",
            "crossModule": true,
            "retrievalQuestions": [
              "What biases exist in AI?",
              "Is AI biased?",
              "How do I account for AI bias?"
            ],
            "content": "**What Is Bias in This Context?**\nLLMs learn patterns from their training data. If that data contains biases (and it does\u2014it's human-created content from the internet), the LLM will reflect those biases.\n\n**Types of Bias Relevant to IA Work:**\n\n#### A. Language and Cultural Bias\n\n- LLMs are typically strongest in English\n- They may reflect Western/US-centric organizational patterns\n- Cultural differences in information seeking behavior may not be reflected\n\n**IA Impact Example:**\n\n```text Potential Issue\nPrompt: \"Create a taxonomy for HR documentation\"\n\nPotential Bias: Generated categories might reflect US corporate structures \nand terminology, missing important categories for international audiences.\n\nExample: \"401(k) Plans\" (US-specific) vs. \"Retirement Benefits\" (universal)\n```\n\n<Tip>\n  **Mitigation:** Explicitly state your audience geography and cultural context in prompts. Review outputs for regional assumptions.\n</Tip>\n\n#### B. Technical Documentation Bias\n\n- Tech documentation is overrepresented in training data\n- Other domains may have less accurate outputs\n- Documentation patterns may skew toward developer-focused content\n\n**IA Impact Example:**\n\n```text Potential Issue\nPrompt: \"Classify this healthcare documentation\"\n\nRisk: AI may apply developer documentation patterns inappropriately.\nHealthcare IA may need different organization (by patient journey, condition, etc.)\n```\n\n#### C. Representation and Demographic Bias\n\n- Training data reflects historical biases\n- May not represent diverse user populations\n- Can reinforce existing structural inequities\n\n**IA Impact Example:**\n\n```text Potential Issue\nPrompt: \"Create user personas for this product\"\n\nRisk: Generated personas might over-represent certain demographics or \nperpetuate stereotypes seen in training data.\n```\n\n---",
            "hydration_source_header": "4.1 Understanding Bias in LLMs",
            "hydration_method": "title_match"
          },
          {
            "id": "language-cultural-bias",
            "title": "Language and Cultural Bias",
            "type": "concept",
            "definition": "AI tends toward English-centric, Western cultural perspectives",
            "domain": "bias",
            "lines": "407-428",
            "crossModule": false,
            "retrievalQuestions": [
              "Is AI culturally biased?",
              "How does AI handle non-English content?"
            ],
            "content": "- LLMs are typically strongest in English\n- They may reflect Western/US-centric organizational patterns\n- Cultural differences in information seeking behavior may not be reflected\n\n**IA Impact Example:**\n\n```text Potential Issue\nPrompt: \"Create a taxonomy for HR documentation\"\n\nPotential Bias: Generated categories might reflect US corporate structures \nand terminology, missing important categories for international audiences.\n\nExample: \"401(k) Plans\" (US-specific) vs. \"Retirement Benefits\" (universal)\n```\n\n<Tip>\n  **Mitigation:** Explicitly state your audience geography and cultural context in prompts. Review outputs for regional assumptions.\n</Tip>",
            "hydration_source_header": "A. Language and Cultural Bias",
            "hydration_method": "title_match"
          },
          {
            "id": "technical-documentation-bias",
            "title": "Technical Documentation Bias",
            "type": "concept",
            "definition": "AI over-represents certain technical domains based on training data",
            "domain": "bias",
            "lines": "430-444",
            "crossModule": false,
            "retrievalQuestions": [
              "Is AI biased toward certain tech stacks?"
            ],
            "content": "- Tech documentation is overrepresented in training data\n- Other domains may have less accurate outputs\n- Documentation patterns may skew toward developer-focused content\n\n**IA Impact Example:**\n\n```text Potential Issue\nPrompt: \"Classify this healthcare documentation\"\n\nRisk: AI may apply developer documentation patterns inappropriately.\nHealthcare IA may need different organization (by patient journey, condition, etc.)\n```",
            "hydration_source_header": "B. Technical Documentation Bias",
            "hydration_method": "title_match"
          },
          {
            "id": "representation-demographic-bias",
            "title": "Representation and Demographic Bias",
            "type": "concept",
            "definition": "AI may perpetuate demographic stereotypes in generated content",
            "domain": "bias",
            "lines": "446-460",
            "crossModule": false,
            "retrievalQuestions": [
              "Does AI have demographic bias?",
              "How do I avoid stereotypes in AI output?"
            ],
            "content": "- Training data reflects historical biases\n- May not represent diverse user populations\n- Can reinforce existing structural inequities\n\n**IA Impact Example:**\n\n```text Potential Issue\nPrompt: \"Create user personas for this product\"\n\nRisk: Generated personas might over-represent certain demographics or \nperpetuate stereotypes seen in training data.\n```\n\n---",
            "hydration_source_header": "C. Representation and Demographic Bias",
            "hydration_method": "title_match"
          }
        ],
        "capabilities": [
          {
            "id": "pattern-recognition-scale",
            "title": "Pattern Recognition at Scale",
            "type": "capability",
            "definition": "AI can identify patterns across large volumes of content quickly",
            "taskType": "analysis",
            "lines": "98-128",
            "crossModule": true,
            "retrievalQuestions": [
              "How can AI help find patterns?",
              "What is AI good at analyzing?"
            ],
            "content": "**What LLMs Excel At:**\n- Finding inconsistencies across large content sets\n- Identifying duplicate or overlapping content\n- Detecting naming convention variations\n- Spotting structural patterns\n\n**IA Application Example:**\n\n<CodeGroup>\n\n```text Task\nAnalyze 250 documentation pages for inconsistent terminology.\nFind all variations of \"authentication\" terms used across the site.\n```\n\n```text AI Capability\nCan process all 250 pages in minutes and identify:\n- \"login\" (45 instances)\n- \"sign in\" (32 instances)\n- \"log in\" (28 instances)\n- \"authentication\" (67 instances)\n- \"auth\" (23 instances)\n\nFlags recommendation: Standardize on one term\n```\n\n</CodeGroup>\n\n**Human Role:** Decide which term to standardize on based on:\n- User research\n- Brand voice\n- SEO considerations\n- Accessibility\n\n---",
            "hydration_source_header": "2.1 Pattern Recognition at Scale",
            "hydration_method": "title_match"
          },
          {
            "id": "content-generation-variation",
            "title": "Content Generation and Variation",
            "type": "capability",
            "definition": "AI can generate multiple variations of content quickly",
            "taskType": "generation",
            "lines": "132-166",
            "crossModule": true,
            "retrievalQuestions": [
              "Can AI generate content variations?",
              "How can AI help with content creation?"
            ],
            "content": "**What LLMs Excel At:**\n- Generating multiple options quickly\n- Creating variations for A/B testing\n- Drafting initial taxonomies\n- Producing navigation label alternatives\n\n**IA Application Example:**\n\n<CodeGroup>\n\n```text Prompt\nGenerate 10 different top-level category labels for developer documentation covering:\n- Getting started guides\n- API reference\n- SDK documentation\n- Best practices\n- Troubleshooting\n\nRequirements:\n- Each label under 20 characters\n- Action-oriented where possible\n- Clear for junior developers\n```\n\n```text AI Output\n1. Get Started\n2. API Reference\n3. SDKs & Tools\n4. Best Practices\n5. Troubleshoot\n6. Quick Start\n7. API Docs\n8. Developer Tools\n9. Help & Support\n10. Reference Guide\n```\n\n</CodeGroup>\n\n**Human Role:** Select and test options with users\n\n---",
            "hydration_source_header": "2.2 Content Generation and Variation",
            "hydration_method": "title_match"
          },
          {
            "id": "classification-organization",
            "title": "Classification and Organization",
            "type": "capability",
            "definition": "AI can categorize and organize content according to frameworks",
            "taskType": "classification",
            "lines": "170-197",
            "crossModule": true,
            "retrievalQuestions": [
              "How does AI help with classification?",
              "Can AI organize content?"
            ],
            "content": "**What LLMs Excel At:**\n- Categorizing content by type\n- Applying consistent taxonomy\n- Organizing unstructured content\n- Identifying themes\n\n**IA Application Example:**\n\n<CodeGroup>\n\n```text Prompt\nClassify these documentation pages using the Di\u00e1taxis framework:\n- \"Building Your First App\" \u2192 ?\n- \"API Endpoint Reference\" \u2192 ?\n- \"Understanding Authentication Flows\" \u2192 ?\n- \"How to Reset a Password\" \u2192 ?\n- \"Error Code Reference\" \u2192 ?\n\nCategories: Tutorial (learning-oriented), How-to Guide (task-oriented), \nReference (information-oriented), Explanation (understanding-oriented)\n```\n\n```text AI Classification\n- \"Building Your First App\" \u2192 Tutorial (step-by-step learning)\n- \"API Endpoint Reference\" \u2192 Reference (technical lookup)\n- \"Understanding Authentication Flows\" \u2192 Explanation (conceptual understanding)\n- \"How to Reset a Password\" \u2192 How-to Guide (specific task solution)\n- \"Error Code Reference\" \u2192 Reference (information lookup)\n```\n\n</CodeGroup>\n\n**Human Role:** Validate classifications against content goals and user needs\n\n---",
            "hydration_source_header": "2.3 Classification and Organization",
            "hydration_method": "title_match"
          },
          {
            "id": "analysis-synthesis",
            "title": "Analysis and Synthesis",
            "type": "capability",
            "definition": "AI can analyze data and synthesize findings",
            "taskType": "analysis",
            "lines": "201-227",
            "crossModule": true,
            "retrievalQuestions": [
              "How can AI help with analysis?",
              "Can AI synthesize research findings?"
            ],
            "content": "**What LLMs Excel At:**\n- Summarizing large datasets\n- Finding themes in qualitative data\n- Synthesizing research findings\n- Generating insights from patterns\n\n**IA Application Example:**\n\n<CodeGroup>\n\n```text Task\nAnalyze 30 card sorting results to identify consensus groupings.\nEach of 30 participants sorted 40 cards into their own categories.\n```\n\n```text AI Capability\nProcess all 30 \u00d7 40 = 1,200 placements to find:\n- Cards grouped together by 80%+ of participants (high consensus)\n- Cards with no clear grouping pattern (conflicts)\n- Most common category names participants created\n- Suggested taxonomy based on consensus patterns\n\nTime: Minutes (vs. hours manually)\n```\n\n</CodeGroup>\n\n**Human Role:** Interpret findings in user context, resolve conflicts, make final IA decisions\n\n---",
            "hydration_source_header": "2.4 Analysis and Synthesis",
            "hydration_method": "title_match"
          }
        ],
        "examples": [
          {
            "id": "terminology-inconsistency-example",
            "title": "Terminology Inconsistency Analysis",
            "demonstrates": "pattern-recognition-scale",
            "domain": "content-audit",
            "lines": "108-128",
            "retrievalQuestions": [
              "Show me an example of terminology analysis"
            ],
            "content": "**What LLMs Excel At:**\n- Finding inconsistencies across large content sets\n- Identifying duplicate or overlapping content\n- Detecting naming convention variations\n- Spotting structural patterns\n\n**IA Application Example:**\n\n<CodeGroup>\n\n```text Task\nAnalyze 250 documentation pages for inconsistent terminology.\nFind all variations of \"authentication\" terms used across the site.\n```\n\n```text AI Capability\nCan process all 250 pages in minutes and identify:\n- \"login\" (45 instances)\n- \"sign in\" (32 instances)\n- \"log in\" (28 instances)\n- \"authentication\" (67 instances)\n- \"auth\" (23 instances)\n\nFlags recommendation: Standardize on one term\n```\n\n</CodeGroup>\n\n**Human Role:** Decide which term to standardize on based on:\n- User research\n- Brand voice\n- SEO considerations\n- Accessibility\n\n---",
            "hydration_source_header": "2.1 Pattern Recognition at Scale",
            "hydration_method": "line_proximity"
          },
          {
            "id": "navigation-label-generation",
            "title": "Navigation Label Generation",
            "demonstrates": "content-generation-variation",
            "domain": "labeling",
            "lines": "140-166",
            "retrievalQuestions": [
              "Example of AI-generated navigation labels"
            ],
            "content": "**What LLMs Excel At:**\n- Generating multiple options quickly\n- Creating variations for A/B testing\n- Drafting initial taxonomies\n- Producing navigation label alternatives\n\n**IA Application Example:**\n\n<CodeGroup>\n\n```text Prompt\nGenerate 10 different top-level category labels for developer documentation covering:\n- Getting started guides\n- API reference\n- SDK documentation\n- Best practices\n- Troubleshooting\n\nRequirements:\n- Each label under 20 characters\n- Action-oriented where possible\n- Clear for junior developers\n```\n\n```text AI Output\n1. Get Started\n2. API Reference\n3. SDKs & Tools\n4. Best Practices\n5. Troubleshoot\n6. Quick Start\n7. API Docs\n8. Developer Tools\n9. Help & Support\n10. Reference Guide\n```\n\n</CodeGroup>\n\n**Human Role:** Select and test options with users\n\n---",
            "hydration_source_header": "2.2 Content Generation and Variation",
            "hydration_method": "line_proximity"
          },
          {
            "id": "diataxis-classification",
            "title": "Di\u00e1taxis Classification Example",
            "demonstrates": "classification-organization",
            "domain": "content-types",
            "lines": "175-197",
            "retrievalQuestions": [
              "Example of Di\u00e1taxis classification"
            ],
            "content": "**What LLMs Excel At:**\n- Categorizing content by type\n- Applying consistent taxonomy\n- Organizing unstructured content\n- Identifying themes\n\n**IA Application Example:**\n\n<CodeGroup>\n\n```text Prompt\nClassify these documentation pages using the Di\u00e1taxis framework:\n- \"Building Your First App\" \u2192 ?\n- \"API Endpoint Reference\" \u2192 ?\n- \"Understanding Authentication Flows\" \u2192 ?\n- \"How to Reset a Password\" \u2192 ?\n- \"Error Code Reference\" \u2192 ?\n\nCategories: Tutorial (learning-oriented), How-to Guide (task-oriented), \nReference (information-oriented), Explanation (understanding-oriented)\n```\n\n```text AI Classification\n- \"Building Your First App\" \u2192 Tutorial (step-by-step learning)\n- \"API Endpoint Reference\" \u2192 Reference (technical lookup)\n- \"Understanding Authentication Flows\" \u2192 Explanation (conceptual understanding)\n- \"How to Reset a Password\" \u2192 How-to Guide (specific task solution)\n- \"Error Code Reference\" \u2192 Reference (information lookup)\n```\n\n</CodeGroup>\n\n**Human Role:** Validate classifications against content goals and user needs\n\n---",
            "hydration_source_header": "2.3 Classification and Organization",
            "hydration_method": "line_proximity"
          },
          {
            "id": "card-sorting-analysis",
            "title": "Card Sorting Analysis",
            "demonstrates": "analysis-synthesis",
            "domain": "user-research",
            "lines": "207-227",
            "retrievalQuestions": [
              "Example of AI card sort analysis"
            ],
            "content": "**What LLMs Excel At:**\n- Summarizing large datasets\n- Finding themes in qualitative data\n- Synthesizing research findings\n- Generating insights from patterns\n\n**IA Application Example:**\n\n<CodeGroup>\n\n```text Task\nAnalyze 30 card sorting results to identify consensus groupings.\nEach of 30 participants sorted 40 cards into their own categories.\n```\n\n```text AI Capability\nProcess all 30 \u00d7 40 = 1,200 placements to find:\n- Cards grouped together by 80%+ of participants (high consensus)\n- Cards with no clear grouping pattern (conflicts)\n- Most common category names participants created\n- Suggested taxonomy based on consensus patterns\n\nTime: Minutes (vs. hours manually)\n```\n\n</CodeGroup>\n\n**Human Role:** Interpret findings in user context, resolve conflicts, make final IA decisions\n\n---",
            "hydration_source_header": "2.4 Analysis and Synthesis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "hallucination-statistics",
            "title": "Made-Up Statistics Hallucination",
            "demonstrates": "hallucination-problem",
            "domain": "validation",
            "lines": "221-227",
            "retrievalQuestions": [
              "Show me an example of AI hallucination",
              "Example of made-up statistics"
            ],
            "content": "**What LLMs Excel At:**\n- Summarizing large datasets\n- Finding themes in qualitative data\n- Synthesizing research findings\n- Generating insights from patterns\n\n**IA Application Example:**\n\n<CodeGroup>\n\n```text Task\nAnalyze 30 card sorting results to identify consensus groupings.\nEach of 30 participants sorted 40 cards into their own categories.\n```\n\n```text AI Capability\nProcess all 30 \u00d7 40 = 1,200 placements to find:\n- Cards grouped together by 80%+ of participants (high consensus)\n- Cards with no clear grouping pattern (conflicts)\n- Most common category names participants created\n- Suggested taxonomy based on consensus patterns\n\nTime: Minutes (vs. hours manually)\n```\n\n</CodeGroup>\n\n**Human Role:** Interpret findings in user context, resolve conflicts, make final IA decisions\n\n---",
            "hydration_source_header": "2.4 Analysis and Synthesis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "hallucination-best-practices",
            "title": "Incorrect Best Practices Hallucination",
            "demonstrates": "hallucination-problem",
            "domain": "validation",
            "lines": "229-237",
            "retrievalQuestions": [
              "Example of incorrect best practices from AI"
            ],
            "content": "**What LLMs Excel At:**\n- Summarizing large datasets\n- Finding themes in qualitative data\n- Synthesizing research findings\n- Generating insights from patterns\n\n**IA Application Example:**\n\n<CodeGroup>\n\n```text Task\nAnalyze 30 card sorting results to identify consensus groupings.\nEach of 30 participants sorted 40 cards into their own categories.\n```\n\n```text AI Capability\nProcess all 30 \u00d7 40 = 1,200 placements to find:\n- Cards grouped together by 80%+ of participants (high consensus)\n- Cards with no clear grouping pattern (conflicts)\n- Most common category names participants created\n- Suggested taxonomy based on consensus patterns\n\nTime: Minutes (vs. hours manually)\n```\n\n</CodeGroup>\n\n**Human Role:** Interpret findings in user context, resolve conflicts, make final IA decisions\n\n---",
            "hydration_source_header": "2.4 Analysis and Synthesis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "hallucination-fabricated",
            "title": "Fabricated Examples Hallucination",
            "demonstrates": "hallucination-problem",
            "domain": "validation",
            "lines": "239-247",
            "retrievalQuestions": [
              "Example of AI fabricating information"
            ],
            "content": "### 3.1 The Hallucination Problem\n\n**What is Hallucination?**\nWhen AI generates confident-sounding but factually incorrect information.\n\n**Common IA Hallucinations:**\n\n<Accordion title=\"Example 1: Made-Up Statistics\">\n**AI Output:**\n\"Studies show that 73% of users prefer task-based navigation over alphabetical organization.\"\n\n**Problem:**\nNo such study exists. The percentage sounds authoritative but is fabricated.\n\n**How to Avoid:**\nNever trust statistics without verification. Ask for sources. Verify citations.\n</Accordion>\n\n<Accordion title=\"Example 2: Incorrect Best Practices\">\n**AI Output:**\n\"ISO 25964 recommends a maximum taxonomy depth of 5 levels for optimal usability.\"\n\n**Problem:**\nThe standard doesn't specify this exact number.\n\n**How to Avoid:**\nCheck primary sources. Verify standards directly. Don't assume AI knows current standards.\n</Accordion>\n\n<Accordion title=\"Example 3: Fabricated Examples\">\n**AI Output:**\n\"Stripe's API documentation uses a 7-level hierarchy organized by HTTP method.\"\n\n**Problem:**\nStripe actually uses ~3 levels organized by resource type, not HTTP method.\n\n**How to Avoid:**\nVerify examples against real-world sources. Visit the actual sites AI mentions.\n</Accordion>\n\n<Warning>\n  **Golden Rule:** Treat AI outputs as suggestions, not facts. Always validate against:\n  - Primary sources\n  - Your own expertise\n  - Real-world data\n  - User research\n</Warning>\n\n---\n\n### 3.2 Consistency Challenges\n\n**The Problem:**\nLLMs don't maintain perfect consistency across:\n- Multiple prompts in a session\n- Regenerated outputs\n- Different ways of asking the same question\n\n**Consistency Issues in IA Work:**\n\n<Tabs>\n  <Tab title=\"Classification Drift\">\n```text First Prompt\n\"Classify this content as Tutorial, Reference, or Guide\"\nResult: \"Tutorial\"\n```\n\n```text Same Content, Rephrased\n\"What content type is this: Tutorial, Reference, or How-to?\"\nResult: \"How-to\"\n```\n\n**Why:** Slight prompt variations affect pattern matching\n  </Tab>\n  \n  <Tab title=\"Taxonomy Changes\">\n```text Session 1\nGenerate taxonomy \u2192 8 top-level categories\n```\n\n```text Session 2 (Next Day)\nRefine same taxonomy \u2192 Suggests 6 categories, some renamed\n```\n\n**Why:** No persistent memory between sessions, built-in randomness\n  </Tab>\n</Tabs>\n\n#### How to Maintain Consistency\n\n**Strategy 1: Single-Session Processing**\nComplete related tasks in one session rather than across multiple sessions.\n\n**Strategy 2: Explicit Context Preservation**\n\n<CodeGroup>\n\n```text Preserving Context\n\"In our previous conversation, you generated this taxonomy: \n[paste taxonomy]. \n\nNow, using the SAME category names and structure, add subcategories \nto the 'API Reference' section.\"\n```\n\n</CodeGroup>\n\n**Strategy 3: Document Your Prompts**\nKeep a record of exact prompts that produced good results, so you can replicate them.\n\n**Strategy 4: Use Explicit Rules**\n\n<CodeGroup>\n\n```text Explicit Rules\n\"When classifying content, always use these exact terms: \nTutorial, How-to Guide, Reference, Explanation. \nNever use synonyms or variations.\"\n```\n\n</CodeGroup>\n\n---\n\n### 3.3 Context Window Limitations\n\n**What Is a Context Window?**\nThe amount of text an LLM can \"remember\" in a single conversation. Think of it as working memory.\n\n**Why This Matters for IA:**\nMany IA tasks involve large amounts of content:\n- Content inventories with hundreds of pages\n- Complete sitemaps\n- Full documentation sets\n- Extensive user research transcripts\n\nYou can't always feed everything to the LLM at once.\n\n#### Practical Implications for IA Work\n\n**Limitation Example:**\n\n```text The Problem\nYou have: 500-page documentation site audit\nContext window: ~200,000 tokens (about 150,000 words)\nEach page: ~1,000 words\n\nYou can only process ~150 pages at a time.\n```\n\n**Workaround Strategies:**\n\n<Accordion title=\"Strategy 1: Batch Processing\">\n1. Divide content into logical chunks (e.g., by section)\n2. Process each chunk separately\n3. Synthesize results manually or with a final prompt\n\n**Example:**\n- Batch 1: Process pages 1-50\n- Batch 2: Process pages 51-100\n- Batch 3: Process pages 101-150\n- Final: Synthesize findings across all batches\n</Accordion>\n\n<Accordion title=\"Strategy 2: Hierarchical Analysis\">\n1. First pass: Analyze page titles and summaries only\n2. Second pass: Deep dive into specific sections identified as problematic\n3. Third pass: Detailed analysis of priority pages\n\n**Example:**\n- Level 1: Classify all 500 pages by title (fast)\n- Level 2: Analyze 50 pages flagged as problematic\n- Level 3: Deep dive on 10 highest-priority issues\n</Accordion>\n\n<Accordion title=\"Strategy 3: Summarize Then Analyze\">\n1. Use AI to create summaries of large content sets\n2. Analyze the summaries (much smaller)\n3. Drill down into specifics only where needed\n\n**Example:**\n- Create 1-sentence summary per page (500 pages \u2192 500 sentences)\n- Analyze patterns in the 500 summaries\n- Deep-dive specific pages based on summary analysis\n</Accordion>\n\n**Example Workflow for Large Content Audit:**\n\n```text Step-by-Step\nStep 1: Generate 1-sentence summary per page (AI)\nStep 2: Classify all pages by content type using summaries (AI)\nStep 3: Identify top 20 problematic pages (AI)\nStep 4: Deep analysis of those 20 pages (AI + human)\nStep 5: Generate recommendations (AI + human)\n```\n\n#### Context Window Best Practices\n\n<CardGroup cols={2}>\n  <Card title=\"Do\" icon=\"check\">\n    - Start with high-level overviews, then zoom in\n    - Use pagination or batching for large datasets\n    - Keep prompts focused on one task at a time\n    - Store important context outside the conversation\n  </Card>\n  \n  <Card title=\"Don't\" icon=\"xmark\">\n    - Assume the LLM remembers everything from start\n    - Try to analyze entire large websites in one prompt\n    - Expect consistency across very long conversations\n    - Mix multiple unrelated tasks in one session\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "3. AI Limitations in IA Work",
            "hydration_method": "line_proximity"
          },
          {
            "id": "classification-drift",
            "title": "Classification Drift Example",
            "demonstrates": "consistency-challenges",
            "domain": "validation",
            "lines": "265-279",
            "retrievalQuestions": [
              "How does classification drift happen?",
              "Example of inconsistent AI classification"
            ],
            "content": "**What is Hallucination?**\nWhen AI generates confident-sounding but factually incorrect information.\n\n**Common IA Hallucinations:**\n\n<Accordion title=\"Example 1: Made-Up Statistics\">\n**AI Output:**\n\"Studies show that 73% of users prefer task-based navigation over alphabetical organization.\"\n\n**Problem:**\nNo such study exists. The percentage sounds authoritative but is fabricated.\n\n**How to Avoid:**\nNever trust statistics without verification. Ask for sources. Verify citations.\n</Accordion>\n\n<Accordion title=\"Example 2: Incorrect Best Practices\">\n**AI Output:**\n\"ISO 25964 recommends a maximum taxonomy depth of 5 levels for optimal usability.\"\n\n**Problem:**\nThe standard doesn't specify this exact number.\n\n**How to Avoid:**\nCheck primary sources. Verify standards directly. Don't assume AI knows current standards.\n</Accordion>\n\n<Accordion title=\"Example 3: Fabricated Examples\">\n**AI Output:**\n\"Stripe's API documentation uses a 7-level hierarchy organized by HTTP method.\"\n\n**Problem:**\nStripe actually uses ~3 levels organized by resource type, not HTTP method.\n\n**How to Avoid:**\nVerify examples against real-world sources. Visit the actual sites AI mentions.\n</Accordion>\n\n<Warning>\n  **Golden Rule:** Treat AI outputs as suggestions, not facts. Always validate against:\n  - Primary sources\n  - Your own expertise\n  - Real-world data\n  - User research\n</Warning>\n\n---",
            "hydration_source_header": "3.1 The Hallucination Problem",
            "hydration_method": "line_proximity"
          },
          {
            "id": "taxonomy-session-changes",
            "title": "Taxonomy Changes Across Sessions",
            "demonstrates": "consistency-challenges",
            "domain": "validation",
            "lines": "281-291",
            "retrievalQuestions": [
              "Why does AI give different answers across sessions?"
            ],
            "content": "**The Problem:**\nLLMs don't maintain perfect consistency across:\n- Multiple prompts in a session\n- Regenerated outputs\n- Different ways of asking the same question\n\n**Consistency Issues in IA Work:**\n\n<Tabs>\n  <Tab title=\"Classification Drift\">\n```text First Prompt\n\"Classify this content as Tutorial, Reference, or Guide\"\nResult: \"Tutorial\"\n```\n\n```text Same Content, Rephrased\n\"What content type is this: Tutorial, Reference, or How-to?\"\nResult: \"How-to\"\n```\n\n**Why:** Slight prompt variations affect pattern matching\n  </Tab>\n  \n  <Tab title=\"Taxonomy Changes\">\n```text Session 1\nGenerate taxonomy \u2192 8 top-level categories\n```\n\n```text Session 2 (Next Day)\nRefine same taxonomy \u2192 Suggests 6 categories, some renamed\n```\n\n**Why:** No persistent memory between sessions, built-in randomness\n  </Tab>\n</Tabs>\n\n#### How to Maintain Consistency\n\n**Strategy 1: Single-Session Processing**\nComplete related tasks in one session rather than across multiple sessions.\n\n**Strategy 2: Explicit Context Preservation**\n\n<CodeGroup>\n\n```text Preserving Context\n\"In our previous conversation, you generated this taxonomy: \n[paste taxonomy]. \n\nNow, using the SAME category names and structure, add subcategories \nto the 'API Reference' section.\"\n```\n\n</CodeGroup>\n\n**Strategy 3: Document Your Prompts**\nKeep a record of exact prompts that produced good results, so you can replicate them.\n\n**Strategy 4: Use Explicit Rules**\n\n<CodeGroup>\n\n```text Explicit Rules\n\"When classifying content, always use these exact terms: \nTutorial, How-to Guide, Reference, Explanation. \nNever use synonyms or variations.\"\n```\n\n</CodeGroup>\n\n---",
            "hydration_source_header": "3.2 Consistency Challenges",
            "hydration_method": "line_proximity"
          },
          {
            "id": "context-window-calculation",
            "title": "Context Window Calculation",
            "demonstrates": "context-window-limitations",
            "domain": "practical",
            "lines": "337-345",
            "retrievalQuestions": [
              "How do I calculate context window usage?"
            ],
            "content": "**What Is a Context Window?**\nThe amount of text an LLM can \"remember\" in a single conversation. Think of it as working memory.\n\n**Why This Matters for IA:**\nMany IA tasks involve large amounts of content:\n- Content inventories with hundreds of pages\n- Complete sitemaps\n- Full documentation sets\n- Extensive user research transcripts\n\nYou can't always feed everything to the LLM at once.\n\n#### Practical Implications for IA Work\n\n**Limitation Example:**\n\n```text The Problem\nYou have: 500-page documentation site audit\nContext window: ~200,000 tokens (about 150,000 words)\nEach page: ~1,000 words\n\nYou can only process ~150 pages at a time.\n```\n\n**Workaround Strategies:**\n\n<Accordion title=\"Strategy 1: Batch Processing\">\n1. Divide content into logical chunks (e.g., by section)\n2. Process each chunk separately\n3. Synthesize results manually or with a final prompt\n\n**Example:**\n- Batch 1: Process pages 1-50\n- Batch 2: Process pages 51-100\n- Batch 3: Process pages 101-150\n- Final: Synthesize findings across all batches\n</Accordion>\n\n<Accordion title=\"Strategy 2: Hierarchical Analysis\">\n1. First pass: Analyze page titles and summaries only\n2. Second pass: Deep dive into specific sections identified as problematic\n3. Third pass: Detailed analysis of priority pages\n\n**Example:**\n- Level 1: Classify all 500 pages by title (fast)\n- Level 2: Analyze 50 pages flagged as problematic\n- Level 3: Deep dive on 10 highest-priority issues\n</Accordion>\n\n<Accordion title=\"Strategy 3: Summarize Then Analyze\">\n1. Use AI to create summaries of large content sets\n2. Analyze the summaries (much smaller)\n3. Drill down into specifics only where needed\n\n**Example:**\n- Create 1-sentence summary per page (500 pages \u2192 500 sentences)\n- Analyze patterns in the 500 summaries\n- Deep-dive specific pages based on summary analysis\n</Accordion>\n\n**Example Workflow for Large Content Audit:**\n\n```text Step-by-Step\nStep 1: Generate 1-sentence summary per page (AI)\nStep 2: Classify all pages by content type using summaries (AI)\nStep 3: Identify top 20 problematic pages (AI)\nStep 4: Deep analysis of those 20 pages (AI + human)\nStep 5: Generate recommendations (AI + human)\n```\n\n#### Context Window Best Practices\n\n<CardGroup cols={2}>\n  <Card title=\"Do\" icon=\"check\">\n    - Start with high-level overviews, then zoom in\n    - Use pagination or batching for large datasets\n    - Keep prompts focused on one task at a time\n    - Store important context outside the conversation\n  </Card>\n  \n  <Card title=\"Don't\" icon=\"xmark\">\n    - Assume the LLM remembers everything from start\n    - Try to analyze entire large websites in one prompt\n    - Expect consistency across very long conversations\n    - Mix multiple unrelated tasks in one session\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "3.3 Context Window Limitations",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "cultural-bias-hr-taxonomy",
            "title": "HR Taxonomy Cultural Bias",
            "demonstrates": "language-cultural-bias",
            "domain": "bias",
            "lines": "414-428",
            "retrievalQuestions": [
              "What's an example of cultural bias in AI?"
            ],
            "content": "- LLMs are typically strongest in English\n- They may reflect Western/US-centric organizational patterns\n- Cultural differences in information seeking behavior may not be reflected\n\n**IA Impact Example:**\n\n```text Potential Issue\nPrompt: \"Create a taxonomy for HR documentation\"\n\nPotential Bias: Generated categories might reflect US corporate structures \nand terminology, missing important categories for international audiences.\n\nExample: \"401(k) Plans\" (US-specific) vs. \"Retirement Benefits\" (universal)\n```\n\n<Tip>\n  **Mitigation:** Explicitly state your audience geography and cultural context in prompts. Review outputs for regional assumptions.\n</Tip>",
            "hydration_source_header": "A. Language and Cultural Bias",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "healthcare-docs-bias",
            "title": "Healthcare Documentation Bias",
            "demonstrates": "technical-documentation-bias",
            "domain": "bias",
            "lines": "438-444",
            "retrievalQuestions": [
              "Example of technical documentation bias"
            ],
            "content": "- Tech documentation is overrepresented in training data\n- Other domains may have less accurate outputs\n- Documentation patterns may skew toward developer-focused content\n\n**IA Impact Example:**\n\n```text Potential Issue\nPrompt: \"Classify this healthcare documentation\"\n\nRisk: AI may apply developer documentation patterns inappropriately.\nHealthcare IA may need different organization (by patient journey, condition, etc.)\n```",
            "hydration_source_header": "B. Technical Documentation Bias",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "persona-bias",
            "title": "User Persona Generation Bias",
            "demonstrates": "representation-demographic-bias",
            "domain": "bias",
            "lines": "452-460",
            "retrievalQuestions": [
              "Example of demographic bias in AI personas"
            ],
            "content": "<CardGroup cols={2}>\n  <Card title=\"Do\" icon=\"check\">\n    - Start with high-level overviews, then zoom in\n    - Use pagination or batching for large datasets\n    - Keep prompts focused on one task at a time\n    - Store important context outside the conversation\n  </Card>\n  \n  <Card title=\"Don't\" icon=\"xmark\">\n    - Assume the LLM remembers everything from start\n    - Try to analyze entire large websites in one prompt\n    - Expect consistency across very long conversations\n    - Mix multiple unrelated tasks in one session\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Context Window Best Practices",
            "hydration_method": "line_proximity"
          },
          {
            "id": "accessibility-jargon",
            "title": "Technical Jargon Accessibility Failure",
            "demonstrates": "accessibility-limitations",
            "domain": "accessibility",
            "lines": "496-520",
            "retrievalQuestions": [
              "Example of accessibility problems with AI-generated content"
            ],
            "content": "<Card title=\"Center Accessibility\" icon=\"universal-access\">\n  - Don't trust AI's accessibility judgments\n  - Apply WCAG guidelines yourself\n  - Test with assistive technologies\n  - Consider cognitive and reading accessibility\n  - Involve users with disabilities in validation\n</Card>\n\n---",
            "hydration_source_header": "Accessibility",
            "hydration_method": "title_match"
          }
        ],
        "warnings": [
          {
            "id": "validate-not-trust",
            "title": "Treat AI Outputs as Suggestions Not Facts",
            "prevents": "hallucination-acceptance",
            "lines": "249-253",
            "retrievalQuestions": [
              "What should I never trust AI for?"
            ],
            "content": "### 3.1 The Hallucination Problem\n\n**What is Hallucination?**\nWhen AI generates confident-sounding but factually incorrect information.\n\n**Common IA Hallucinations:**\n\n<Accordion title=\"Example 1: Made-Up Statistics\">\n**AI Output:**\n\"Studies show that 73% of users prefer task-based navigation over alphabetical organization.\"\n\n**Problem:**\nNo such study exists. The percentage sounds authoritative but is fabricated.\n\n**How to Avoid:**\nNever trust statistics without verification. Ask for sources. Verify citations.\n</Accordion>\n\n<Accordion title=\"Example 2: Incorrect Best Practices\">\n**AI Output:**\n\"ISO 25964 recommends a maximum taxonomy depth of 5 levels for optimal usability.\"\n\n**Problem:**\nThe standard doesn't specify this exact number.\n\n**How to Avoid:**\nCheck primary sources. Verify standards directly. Don't assume AI knows current standards.\n</Accordion>\n\n<Accordion title=\"Example 3: Fabricated Examples\">\n**AI Output:**\n\"Stripe's API documentation uses a 7-level hierarchy organized by HTTP method.\"\n\n**Problem:**\nStripe actually uses ~3 levels organized by resource type, not HTTP method.\n\n**How to Avoid:**\nVerify examples against real-world sources. Visit the actual sites AI mentions.\n</Accordion>\n\n<Warning>\n  **Golden Rule:** Treat AI outputs as suggestions, not facts. Always validate against:\n  - Primary sources\n  - Your own expertise\n  - Real-world data\n  - User research\n</Warning>\n\n---\n\n### 3.2 Consistency Challenges\n\n**The Problem:**\nLLMs don't maintain perfect consistency across:\n- Multiple prompts in a session\n- Regenerated outputs\n- Different ways of asking the same question\n\n**Consistency Issues in IA Work:**\n\n<Tabs>\n  <Tab title=\"Classification Drift\">\n```text First Prompt\n\"Classify this content as Tutorial, Reference, or Guide\"\nResult: \"Tutorial\"\n```\n\n```text Same Content, Rephrased\n\"What content type is this: Tutorial, Reference, or How-to?\"\nResult: \"How-to\"\n```\n\n**Why:** Slight prompt variations affect pattern matching\n  </Tab>\n  \n  <Tab title=\"Taxonomy Changes\">\n```text Session 1\nGenerate taxonomy \u2192 8 top-level categories\n```\n\n```text Session 2 (Next Day)\nRefine same taxonomy \u2192 Suggests 6 categories, some renamed\n```\n\n**Why:** No persistent memory between sessions, built-in randomness\n  </Tab>\n</Tabs>\n\n#### How to Maintain Consistency\n\n**Strategy 1: Single-Session Processing**\nComplete related tasks in one session rather than across multiple sessions.\n\n**Strategy 2: Explicit Context Preservation**\n\n<CodeGroup>\n\n```text Preserving Context\n\"In our previous conversation, you generated this taxonomy: \n[paste taxonomy]. \n\nNow, using the SAME category names and structure, add subcategories \nto the 'API Reference' section.\"\n```\n\n</CodeGroup>\n\n**Strategy 3: Document Your Prompts**\nKeep a record of exact prompts that produced good results, so you can replicate them.\n\n**Strategy 4: Use Explicit Rules**\n\n<CodeGroup>\n\n```text Explicit Rules\n\"When classifying content, always use these exact terms: \nTutorial, How-to Guide, Reference, Explanation. \nNever use synonyms or variations.\"\n```\n\n</CodeGroup>\n\n---\n\n### 3.3 Context Window Limitations\n\n**What Is a Context Window?**\nThe amount of text an LLM can \"remember\" in a single conversation. Think of it as working memory.\n\n**Why This Matters for IA:**\nMany IA tasks involve large amounts of content:\n- Content inventories with hundreds of pages\n- Complete sitemaps\n- Full documentation sets\n- Extensive user research transcripts\n\nYou can't always feed everything to the LLM at once.\n\n#### Practical Implications for IA Work\n\n**Limitation Example:**\n\n```text The Problem\nYou have: 500-page documentation site audit\nContext window: ~200,000 tokens (about 150,000 words)\nEach page: ~1,000 words\n\nYou can only process ~150 pages at a time.\n```\n\n**Workaround Strategies:**\n\n<Accordion title=\"Strategy 1: Batch Processing\">\n1. Divide content into logical chunks (e.g., by section)\n2. Process each chunk separately\n3. Synthesize results manually or with a final prompt\n\n**Example:**\n- Batch 1: Process pages 1-50\n- Batch 2: Process pages 51-100\n- Batch 3: Process pages 101-150\n- Final: Synthesize findings across all batches\n</Accordion>\n\n<Accordion title=\"Strategy 2: Hierarchical Analysis\">\n1. First pass: Analyze page titles and summaries only\n2. Second pass: Deep dive into specific sections identified as problematic\n3. Third pass: Detailed analysis of priority pages\n\n**Example:**\n- Level 1: Classify all 500 pages by title (fast)\n- Level 2: Analyze 50 pages flagged as problematic\n- Level 3: Deep dive on 10 highest-priority issues\n</Accordion>\n\n<Accordion title=\"Strategy 3: Summarize Then Analyze\">\n1. Use AI to create summaries of large content sets\n2. Analyze the summaries (much smaller)\n3. Drill down into specifics only where needed\n\n**Example:**\n- Create 1-sentence summary per page (500 pages \u2192 500 sentences)\n- Analyze patterns in the 500 summaries\n- Deep-dive specific pages based on summary analysis\n</Accordion>\n\n**Example Workflow for Large Content Audit:**\n\n```text Step-by-Step\nStep 1: Generate 1-sentence summary per page (AI)\nStep 2: Classify all pages by content type using summaries (AI)\nStep 3: Identify top 20 problematic pages (AI)\nStep 4: Deep analysis of those 20 pages (AI + human)\nStep 5: Generate recommendations (AI + human)\n```\n\n#### Context Window Best Practices\n\n<CardGroup cols={2}>\n  <Card title=\"Do\" icon=\"check\">\n    - Start with high-level overviews, then zoom in\n    - Use pagination or batching for large datasets\n    - Keep prompts focused on one task at a time\n    - Store important context outside the conversation\n  </Card>\n  \n  <Card title=\"Don't\" icon=\"xmark\">\n    - Assume the LLM remembers everything from start\n    - Try to analyze entire large websites in one prompt\n    - Expect consistency across very long conversations\n    - Mix multiple unrelated tasks in one session\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "3. AI Limitations in IA Work",
            "hydration_method": "line_proximity"
          },
          {
            "id": "accessibility-judgment-warning",
            "title": "Never Trust AI Accessibility Judgments",
            "prevents": "accessibility-failures",
            "lines": "522-524",
            "retrievalQuestions": [
              "Can AI assess accessibility?"
            ],
            "content": "<Card title=\"Center Accessibility\" icon=\"universal-access\">\n  - Don't trust AI's accessibility judgments\n  - Apply WCAG guidelines yourself\n  - Test with assistive technologies\n  - Consider cognitive and reading accessibility\n  - Involve users with disabilities in validation\n</Card>\n\n---",
            "hydration_source_header": "Accessibility",
            "hydration_method": "title_match"
          },
          {
            "id": "statistics-verification",
            "title": "Never Trust Statistics Without Verification",
            "prevents": "citation-hallucinations",
            "lines": "225-227",
            "retrievalQuestions": [
              "Should I trust AI statistics?"
            ],
            "content": "**What LLMs Excel At:**\n- Summarizing large datasets\n- Finding themes in qualitative data\n- Synthesizing research findings\n- Generating insights from patterns\n\n**IA Application Example:**\n\n<CodeGroup>\n\n```text Task\nAnalyze 30 card sorting results to identify consensus groupings.\nEach of 30 participants sorted 40 cards into their own categories.\n```\n\n```text AI Capability\nProcess all 30 \u00d7 40 = 1,200 placements to find:\n- Cards grouped together by 80%+ of participants (high consensus)\n- Cards with no clear grouping pattern (conflicts)\n- Most common category names participants created\n- Suggested taxonomy based on consensus patterns\n\nTime: Minutes (vs. hours manually)\n```\n\n</CodeGroup>\n\n**Human Role:** Interpret findings in user context, resolve conflicts, make final IA decisions\n\n---",
            "hydration_source_header": "2.4 Analysis and Synthesis",
            "hydration_method": "line_proximity"
          }
        ],
        "strategies": [
          {
            "id": "batch-processing",
            "title": "Batch Processing Strategy",
            "addresses": "context-window-limitations",
            "lines": "349-358",
            "retrievalQuestions": [
              "How do I process large content sets with AI?"
            ],
            "content": "**Strategy 1: Single-Session Processing**\nComplete related tasks in one session rather than across multiple sessions.\n\n**Strategy 2: Explicit Context Preservation**\n\n<CodeGroup>\n\n```text Preserving Context\n\"In our previous conversation, you generated this taxonomy: \n[paste taxonomy]. \n\nNow, using the SAME category names and structure, add subcategories \nto the 'API Reference' section.\"\n```\n\n</CodeGroup>\n\n**Strategy 3: Document Your Prompts**\nKeep a record of exact prompts that produced good results, so you can replicate them.\n\n**Strategy 4: Use Explicit Rules**\n\n<CodeGroup>\n\n```text Explicit Rules\n\"When classifying content, always use these exact terms: \nTutorial, How-to Guide, Reference, Explanation. \nNever use synonyms or variations.\"\n```\n\n</CodeGroup>\n\n---",
            "hydration_source_header": "How to Maintain Consistency",
            "hydration_method": "line_proximity"
          },
          {
            "id": "hierarchical-analysis",
            "title": "Hierarchical Analysis Strategy",
            "addresses": "context-window-limitations",
            "lines": "360-370",
            "retrievalQuestions": [
              "How do I analyze hierarchies with AI?"
            ],
            "content": "**Strategy 1: Single-Session Processing**\nComplete related tasks in one session rather than across multiple sessions.\n\n**Strategy 2: Explicit Context Preservation**\n\n<CodeGroup>\n\n```text Preserving Context\n\"In our previous conversation, you generated this taxonomy: \n[paste taxonomy]. \n\nNow, using the SAME category names and structure, add subcategories \nto the 'API Reference' section.\"\n```\n\n</CodeGroup>\n\n**Strategy 3: Document Your Prompts**\nKeep a record of exact prompts that produced good results, so you can replicate them.\n\n**Strategy 4: Use Explicit Rules**\n\n<CodeGroup>\n\n```text Explicit Rules\n\"When classifying content, always use these exact terms: \nTutorial, How-to Guide, Reference, Explanation. \nNever use synonyms or variations.\"\n```\n\n</CodeGroup>\n\n---",
            "hydration_source_header": "How to Maintain Consistency",
            "hydration_method": "line_proximity"
          },
          {
            "id": "summarize-then-analyze",
            "title": "Summarize Then Analyze Strategy",
            "addresses": "context-window-limitations",
            "lines": "372-382",
            "retrievalQuestions": [
              "What's the summarize-then-analyze approach?"
            ],
            "content": "**What Is a Context Window?**\nThe amount of text an LLM can \"remember\" in a single conversation. Think of it as working memory.\n\n**Why This Matters for IA:**\nMany IA tasks involve large amounts of content:\n- Content inventories with hundreds of pages\n- Complete sitemaps\n- Full documentation sets\n- Extensive user research transcripts\n\nYou can't always feed everything to the LLM at once.\n\n#### Practical Implications for IA Work\n\n**Limitation Example:**\n\n```text The Problem\nYou have: 500-page documentation site audit\nContext window: ~200,000 tokens (about 150,000 words)\nEach page: ~1,000 words\n\nYou can only process ~150 pages at a time.\n```\n\n**Workaround Strategies:**\n\n<Accordion title=\"Strategy 1: Batch Processing\">\n1. Divide content into logical chunks (e.g., by section)\n2. Process each chunk separately\n3. Synthesize results manually or with a final prompt\n\n**Example:**\n- Batch 1: Process pages 1-50\n- Batch 2: Process pages 51-100\n- Batch 3: Process pages 101-150\n- Final: Synthesize findings across all batches\n</Accordion>\n\n<Accordion title=\"Strategy 2: Hierarchical Analysis\">\n1. First pass: Analyze page titles and summaries only\n2. Second pass: Deep dive into specific sections identified as problematic\n3. Third pass: Detailed analysis of priority pages\n\n**Example:**\n- Level 1: Classify all 500 pages by title (fast)\n- Level 2: Analyze 50 pages flagged as problematic\n- Level 3: Deep dive on 10 highest-priority issues\n</Accordion>\n\n<Accordion title=\"Strategy 3: Summarize Then Analyze\">\n1. Use AI to create summaries of large content sets\n2. Analyze the summaries (much smaller)\n3. Drill down into specifics only where needed\n\n**Example:**\n- Create 1-sentence summary per page (500 pages \u2192 500 sentences)\n- Analyze patterns in the 500 summaries\n- Deep-dive specific pages based on summary analysis\n</Accordion>\n\n**Example Workflow for Large Content Audit:**\n\n```text Step-by-Step\nStep 1: Generate 1-sentence summary per page (AI)\nStep 2: Classify all pages by content type using summaries (AI)\nStep 3: Identify top 20 problematic pages (AI)\nStep 4: Deep analysis of those 20 pages (AI + human)\nStep 5: Generate recommendations (AI + human)\n```\n\n#### Context Window Best Practices\n\n<CardGroup cols={2}>\n  <Card title=\"Do\" icon=\"check\">\n    - Start with high-level overviews, then zoom in\n    - Use pagination or batching for large datasets\n    - Keep prompts focused on one task at a time\n    - Store important context outside the conversation\n  </Card>\n  \n  <Card title=\"Don't\" icon=\"xmark\">\n    - Assume the LLM remembers everything from start\n    - Try to analyze entire large websites in one prompt\n    - Expect consistency across very long conversations\n    - Mix multiple unrelated tasks in one session\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "3.3 Context Window Limitations",
            "hydration_method": "line_proximity"
          },
          {
            "id": "single-session-processing",
            "title": "Single-Session Processing",
            "addresses": "consistency-challenges",
            "lines": "293",
            "retrievalQuestions": [
              "How do I maintain consistency with AI?"
            ],
            "content": "**The Problem:**\nLLMs don't maintain perfect consistency across:\n- Multiple prompts in a session\n- Regenerated outputs\n- Different ways of asking the same question\n\n**Consistency Issues in IA Work:**\n\n<Tabs>\n  <Tab title=\"Classification Drift\">\n```text First Prompt\n\"Classify this content as Tutorial, Reference, or Guide\"\nResult: \"Tutorial\"\n```\n\n```text Same Content, Rephrased\n\"What content type is this: Tutorial, Reference, or How-to?\"\nResult: \"How-to\"\n```\n\n**Why:** Slight prompt variations affect pattern matching\n  </Tab>\n  \n  <Tab title=\"Taxonomy Changes\">\n```text Session 1\nGenerate taxonomy \u2192 8 top-level categories\n```\n\n```text Session 2 (Next Day)\nRefine same taxonomy \u2192 Suggests 6 categories, some renamed\n```\n\n**Why:** No persistent memory between sessions, built-in randomness\n  </Tab>\n</Tabs>\n\n#### How to Maintain Consistency\n\n**Strategy 1: Single-Session Processing**\nComplete related tasks in one session rather than across multiple sessions.\n\n**Strategy 2: Explicit Context Preservation**\n\n<CodeGroup>\n\n```text Preserving Context\n\"In our previous conversation, you generated this taxonomy: \n[paste taxonomy]. \n\nNow, using the SAME category names and structure, add subcategories \nto the 'API Reference' section.\"\n```\n\n</CodeGroup>\n\n**Strategy 3: Document Your Prompts**\nKeep a record of exact prompts that produced good results, so you can replicate them.\n\n**Strategy 4: Use Explicit Rules**\n\n<CodeGroup>\n\n```text Explicit Rules\n\"When classifying content, always use these exact terms: \nTutorial, How-to Guide, Reference, Explanation. \nNever use synonyms or variations.\"\n```\n\n</CodeGroup>\n\n---",
            "hydration_source_header": "3.2 Consistency Challenges",
            "hydration_method": "line_proximity"
          },
          {
            "id": "explicit-context-preservation",
            "title": "Explicit Context Preservation",
            "addresses": "consistency-challenges",
            "lines": "295-299",
            "retrievalQuestions": [
              "How do I preserve context across AI sessions?"
            ],
            "content": "**The Problem:**\nLLMs don't maintain perfect consistency across:\n- Multiple prompts in a session\n- Regenerated outputs\n- Different ways of asking the same question\n\n**Consistency Issues in IA Work:**\n\n<Tabs>\n  <Tab title=\"Classification Drift\">\n```text First Prompt\n\"Classify this content as Tutorial, Reference, or Guide\"\nResult: \"Tutorial\"\n```\n\n```text Same Content, Rephrased\n\"What content type is this: Tutorial, Reference, or How-to?\"\nResult: \"How-to\"\n```\n\n**Why:** Slight prompt variations affect pattern matching\n  </Tab>\n  \n  <Tab title=\"Taxonomy Changes\">\n```text Session 1\nGenerate taxonomy \u2192 8 top-level categories\n```\n\n```text Session 2 (Next Day)\nRefine same taxonomy \u2192 Suggests 6 categories, some renamed\n```\n\n**Why:** No persistent memory between sessions, built-in randomness\n  </Tab>\n</Tabs>\n\n#### How to Maintain Consistency\n\n**Strategy 1: Single-Session Processing**\nComplete related tasks in one session rather than across multiple sessions.\n\n**Strategy 2: Explicit Context Preservation**\n\n<CodeGroup>\n\n```text Preserving Context\n\"In our previous conversation, you generated this taxonomy: \n[paste taxonomy]. \n\nNow, using the SAME category names and structure, add subcategories \nto the 'API Reference' section.\"\n```\n\n</CodeGroup>\n\n**Strategy 3: Document Your Prompts**\nKeep a record of exact prompts that produced good results, so you can replicate them.\n\n**Strategy 4: Use Explicit Rules**\n\n<CodeGroup>\n\n```text Explicit Rules\n\"When classifying content, always use these exact terms: \nTutorial, How-to Guide, Reference, Explanation. \nNever use synonyms or variations.\"\n```\n\n</CodeGroup>\n\n---",
            "hydration_source_header": "3.2 Consistency Challenges",
            "hydration_method": "line_proximity"
          },
          {
            "id": "document-prompts",
            "title": "Document Your Prompts",
            "addresses": "consistency-challenges",
            "lines": "299",
            "retrievalQuestions": [
              "Should I save my prompts?"
            ],
            "content": "**The Problem:**\nLLMs don't maintain perfect consistency across:\n- Multiple prompts in a session\n- Regenerated outputs\n- Different ways of asking the same question\n\n**Consistency Issues in IA Work:**\n\n<Tabs>\n  <Tab title=\"Classification Drift\">\n```text First Prompt\n\"Classify this content as Tutorial, Reference, or Guide\"\nResult: \"Tutorial\"\n```\n\n```text Same Content, Rephrased\n\"What content type is this: Tutorial, Reference, or How-to?\"\nResult: \"How-to\"\n```\n\n**Why:** Slight prompt variations affect pattern matching\n  </Tab>\n  \n  <Tab title=\"Taxonomy Changes\">\n```text Session 1\nGenerate taxonomy \u2192 8 top-level categories\n```\n\n```text Session 2 (Next Day)\nRefine same taxonomy \u2192 Suggests 6 categories, some renamed\n```\n\n**Why:** No persistent memory between sessions, built-in randomness\n  </Tab>\n</Tabs>\n\n#### How to Maintain Consistency\n\n**Strategy 1: Single-Session Processing**\nComplete related tasks in one session rather than across multiple sessions.\n\n**Strategy 2: Explicit Context Preservation**\n\n<CodeGroup>\n\n```text Preserving Context\n\"In our previous conversation, you generated this taxonomy: \n[paste taxonomy]. \n\nNow, using the SAME category names and structure, add subcategories \nto the 'API Reference' section.\"\n```\n\n</CodeGroup>\n\n**Strategy 3: Document Your Prompts**\nKeep a record of exact prompts that produced good results, so you can replicate them.\n\n**Strategy 4: Use Explicit Rules**\n\n<CodeGroup>\n\n```text Explicit Rules\n\"When classifying content, always use these exact terms: \nTutorial, How-to Guide, Reference, Explanation. \nNever use synonyms or variations.\"\n```\n\n</CodeGroup>\n\n---",
            "hydration_source_header": "3.2 Consistency Challenges",
            "hydration_method": "line_proximity"
          },
          {
            "id": "use-explicit-rules",
            "title": "Use Explicit Rules",
            "addresses": "consistency-challenges",
            "lines": "301",
            "retrievalQuestions": [
              "How do I get consistent AI behavior?"
            ],
            "content": "**The Problem:**\nLLMs don't maintain perfect consistency across:\n- Multiple prompts in a session\n- Regenerated outputs\n- Different ways of asking the same question\n\n**Consistency Issues in IA Work:**\n\n<Tabs>\n  <Tab title=\"Classification Drift\">\n```text First Prompt\n\"Classify this content as Tutorial, Reference, or Guide\"\nResult: \"Tutorial\"\n```\n\n```text Same Content, Rephrased\n\"What content type is this: Tutorial, Reference, or How-to?\"\nResult: \"How-to\"\n```\n\n**Why:** Slight prompt variations affect pattern matching\n  </Tab>\n  \n  <Tab title=\"Taxonomy Changes\">\n```text Session 1\nGenerate taxonomy \u2192 8 top-level categories\n```\n\n```text Session 2 (Next Day)\nRefine same taxonomy \u2192 Suggests 6 categories, some renamed\n```\n\n**Why:** No persistent memory between sessions, built-in randomness\n  </Tab>\n</Tabs>\n\n#### How to Maintain Consistency\n\n**Strategy 1: Single-Session Processing**\nComplete related tasks in one session rather than across multiple sessions.\n\n**Strategy 2: Explicit Context Preservation**\n\n<CodeGroup>\n\n```text Preserving Context\n\"In our previous conversation, you generated this taxonomy: \n[paste taxonomy]. \n\nNow, using the SAME category names and structure, add subcategories \nto the 'API Reference' section.\"\n```\n\n</CodeGroup>\n\n**Strategy 3: Document Your Prompts**\nKeep a record of exact prompts that produced good results, so you can replicate them.\n\n**Strategy 4: Use Explicit Rules**\n\n<CodeGroup>\n\n```text Explicit Rules\n\"When classifying content, always use these exact terms: \nTutorial, How-to Guide, Reference, Explanation. \nNever use synonyms or variations.\"\n```\n\n</CodeGroup>\n\n---",
            "hydration_source_header": "3.2 Consistency Challenges",
            "hydration_method": "line_proximity"
          }
        ],
        "terms": [
          {
            "id": "llm-definition",
            "term": "Large Language Model (LLM)",
            "definition": "Sophisticated pattern-matching system trained on billions of text examples that predicts text based on statistical patterns",
            "lines": "21-25",
            "retrievalQuestions": [
              "What is an LLM?",
              "Definition of large language model"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "token-definition",
            "term": "Token",
            "definition": "Basic unit of text processing, approximately 4 characters or 1.3 tokens per word",
            "lines": "39-41",
            "retrievalQuestions": [
              "What is a token?",
              "How are tokens counted?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "context-window-definition",
            "term": "Context Window",
            "definition": "Amount of text an LLM can remember in a single conversation",
            "lines": "303-305",
            "retrievalQuestions": [
              "What is a context window?",
              "Definition of context window"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "hallucination-definition",
            "term": "Hallucination",
            "definition": "When AI generates confident-sounding but factually incorrect information",
            "lines": "217-218",
            "retrievalQuestions": [
              "What is AI hallucination?",
              "Definition of hallucination in AI"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "embedding-definition",
            "term": "Embeddings",
            "definition": "Numerical representations of words where similar concepts have similar representations",
            "lines": "618-620",
            "retrievalQuestions": [
              "What are embeddings?",
              "How do embeddings work?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "attention-mechanism-definition",
            "term": "Attention Mechanism",
            "definition": "Allows model to focus on relevant parts of input and handle long-range dependencies",
            "lines": "614-617",
            "retrievalQuestions": [
              "What is the attention mechanism?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "rlhf-definition",
            "term": "RLHF",
            "definition": "Reinforcement Learning from Human Feedback - process to align model with human preferences",
            "lines": "628",
            "retrievalQuestions": [
              "What is RLHF?",
              "How is AI aligned with human preferences?"
            ],
            "hydration_status": "skipped_unknown"
          }
        ],
        "deepDives": [
          {
            "id": "transformer-architecture",
            "title": "Transformer Architecture",
            "audience": "advanced",
            "lines": "608-638",
            "retrievalQuestions": [
              "How do transformers work?"
            ],
            "content": "<Card title=\"Protect Sensitive Information\" icon=\"shield-halved\">\n  - Don't input confidential content into public AI tools\n  - Be aware of data retention policies\n  - Use enterprise or private AI instances when handling proprietary information\n  - Sanitize data before analysis\n  - Consider user privacy in any data shared with AI\n</Card>",
            "hydration_source_header": "Privacy",
            "hydration_method": "line_proximity"
          },
          {
            "id": "tokenization-deep-dive",
            "title": "Tokenization Deep Dive",
            "audience": "advanced",
            "lines": "640-678",
            "retrievalQuestions": [
              "How does tokenization affect my prompts?"
            ],
            "content": "**Key Components:**\n\n**1. Attention Mechanism**\n- Allows the model to focus on relevant parts of input\n- Handles long-range dependencies between words\n- Example: In \"The architect who designed the building retired,\" attention helps link \"who\" back to \"architect\"\n\n**2. Embeddings**\n- Convert words/tokens to numerical representations\n- Similar concepts have similar representations\n- \"taxonomy\" and \"classification\" would be close in embedding space\n\n**3. Layers**\n- Multiple processing layers refine understanding\n- Early layers: basic patterns\n- Deep layers: complex relationships and context\n\n**4. Training Process**\n- **Pre-training:** Learn general language patterns from massive text corpus\n- **Fine-tuning:** Refine for specific tasks or behaviors\n- **RLHF (Reinforcement Learning from Human Feedback):** Align with human preferences",
            "hydration_source_header": "How Transformers Work",
            "hydration_method": "line_proximity"
          },
          {
            "id": "training-affects-output",
            "title": "How Training Affects Output",
            "audience": "advanced",
            "lines": "680-718",
            "retrievalQuestions": [
              "How does AI training affect output?"
            ],
            "content": "**Common Tokenization Patterns:**\n\n```text Example\n\"information architecture\" might tokenize as:\n- \"inform\" + \"ation\" + \" architect\" + \"ure\" = 4 tokens\n\n\"API\" might be:\n- \"API\" = 1 token (common term, kept whole)\n\n\"Di\u00e1taxis\" might be:\n- \"Di\" + \"\u00e1t\" + \"axis\" = 3 tokens (uncommon term, broken up)\n```\n\n**Token Efficiency Tips:**\n\n```text Inefficient\n\"Let me provide you with a comprehensive and detailed analysis of \nthe following documentation pages, examining each one carefully...\"\n\nTokens: ~25\n\nEfficient  \n\"Analyze these documentation pages:\"\n\nTokens: ~6\n\nSame meaning, 75% fewer tokens\n```\n\n**Special Characters and Formatting:**\n\n```text Comparison\nPlain text: 100 tokens\nSame content with markdown formatting: 120 tokens\nSame content with JSON structure: 110 tokens\n\nFor bulk processing, strip unnecessary formatting.\n```\n\n</Accordion>\n\n<Accordion title=\"How Training Affects Output (Advanced)\">",
            "hydration_source_header": "How Tokenization Affects Your Work",
            "hydration_method": "line_proximity"
          }
        ],
        "checklists": [
          {
            "id": "context-window-dos",
            "title": "Context Window Best Practices - Do",
            "validates": "context-window-usage",
            "lines": "388-392",
            "retrievalQuestions": [
              "What should I do with context windows?",
              "Context window best practices"
            ],
            "content": "<CardGroup cols={2}>\n  <Card title=\"Do\" icon=\"check\">\n    - Start with high-level overviews, then zoom in\n    - Use pagination or batching for large datasets\n    - Keep prompts focused on one task at a time\n    - Store important context outside the conversation\n  </Card>\n  \n  <Card title=\"Don't\" icon=\"xmark\">\n    - Assume the LLM remembers everything from start\n    - Try to analyze entire large websites in one prompt\n    - Expect consistency across very long conversations\n    - Mix multiple unrelated tasks in one session\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Context Window Best Practices",
            "hydration_method": "title_match"
          },
          {
            "id": "context-window-donts",
            "title": "Context Window Best Practices - Don't",
            "validates": "context-window-usage",
            "lines": "388-392",
            "retrievalQuestions": [
              "What should I not do with context windows?"
            ],
            "content": "<CardGroup cols={2}>\n  <Card title=\"Do\" icon=\"check\">\n    - Start with high-level overviews, then zoom in\n    - Use pagination or batching for large datasets\n    - Keep prompts focused on one task at a time\n    - Store important context outside the conversation\n  </Card>\n  \n  <Card title=\"Don't\" icon=\"xmark\">\n    - Assume the LLM remembers everything from start\n    - Try to analyze entire large websites in one prompt\n    - Expect consistency across very long conversations\n    - Mix multiple unrelated tasks in one session\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Context Window Best Practices",
            "hydration_method": "title_match"
          },
          {
            "id": "accessibility-limitations",
            "title": "What AI Cannot Evaluate for Accessibility",
            "validates": "accessibility-validation",
            "lines": "478-494",
            "retrievalQuestions": [
              "What can't AI evaluate for accessibility?",
              "AI limitations for accessibility"
            ],
            "content": "<Card title=\"Center Accessibility\" icon=\"universal-access\">\n  - Don't trust AI's accessibility judgments\n  - Apply WCAG guidelines yourself\n  - Test with assistive technologies\n  - Consider cognitive and reading accessibility\n  - Involve users with disabilities in validation\n</Card>\n\n---",
            "hydration_source_header": "Accessibility",
            "hydration_method": "title_match"
          }
        ]
      }
    },
    "1-2-ai-human-partnership": {
      "file": "1-2-ai-human-partnership.mdx",
      "focus": "Decision framework for when to use AI vs. human judgment in IA work, plus systematic validation approach",
      "entityCount": 88,
      "entities": {
        "frameworks": [
          {
            "id": "ia-decision-framework",
            "title": "IA Decision Framework",
            "type": "framework",
            "definition": "Framework for deciding when AI should lead, when humans should lead, and when to collaborate",
            "contains": [
              "ai-first-zone",
              "human-first-zone",
              "collaborative-zone"
            ],
            "lines": "37-600",
            "crossModule": true,
            "retrievalQuestions": [
              "When should I use AI vs. do it myself?",
              "How do I decide if AI or human should lead a task?"
            ],
            "content": "The IA Decision Framework helps you quickly categorize any IA task into three zones:\n\n1. **AI-First Zone:** Tasks where AI excels (you review outputs)\n2. **Human-First Zone:** Tasks requiring human judgment (AI might assist)\n3. **Collaborative Zone:** Tasks requiring tight AI-human iteration\n\n<CardGroup cols={3}>\n  <Card title=\"AI-First Zone\" icon=\"robot\">\n    Tasks where AI excels\n    \n    You provide direction, AI generates, you validate\n  </Card>\n  \n  <Card title=\"Human-First Zone\" icon=\"user\">\n    Tasks requiring human judgment\n    \n    AI might assist, but humans lead\n  </Card>\n  \n  <Card title=\"Collaborative Zone\" icon=\"users\">\n    Tasks requiring iteration\n    \n    Tight AI-human back-and-forth\n  </Card>\n</CardGroup>\n\n---\n\n### 1.1 AI-First Zone: Tasks Best for AI\n\nThese are tasks where AI provides the most value with minimal human input upfront. You provide direction, AI generates, you validate.\n\n#### A. Generation Tasks\n\n**What This Means:**\nCreating initial drafts, variations, or options that you'll refine.\n\n**Why AI Excels:**\n- Generates quickly at scale\n- Pulls from vast pattern library\n- No fatigue or creative blocks\n- Produces multiple variations easily\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **Taxonomy Generation** | Create initial hierarchical structure | \"Generate a 3-level taxonomy for e-commerce documentation with these 50 page titles\" |\n| **Navigation Label Variations** | Produce 10+ alternatives for testing | \"Create 15 different labels for the 'Developer Resources' section\" |\n| **Metadata Attributes** | List potential attributes for content types | \"What metadata fields should a tutorial page include?\" |\n| **Content Descriptions** | Write summaries for sitemap pages | \"Create 50-character descriptions for each of these navigation items\" |\n| **Search Synonyms** | Generate keyword variations | \"List 20 terms users might search for instead of 'API Authentication'\" |\n\n**Example Workflow: Navigation Label Generation**\n\n```text Step 1 (Human): Define context and constraints\n\"I need navigation labels for a section about API security. \nTarget audience: Junior developers. \nConstraint: Labels must be under 20 characters.\"\n```\n\n```text Step 2 (AI): Generate variations\nOutput:\n- API Security\n- Secure Your API\n- Security Guide\n- Auth & Security\n- Keep APIs Safe\n- Security Basics\n- Protect Your API\n- Security Best Practices\n- API Protection\n- Safe Integration\n```\n\n```text Step 3 (Human): Select and refine\nChoose top 3, test with users, select winner.\n```\n\n**When to Use AI-First for Generation:**\n- \u2705 You need volume (multiple options)\n- \u2705 Speed matters more than perfection\n- \u2705 You have clear validation criteria\n- \u2705 The task is pattern-based, not deeply strategic\n\n**When NOT to Use AI-First:**\n- \u274c The first draft needs to be nearly perfect\n- \u274c Highly specialized domain knowledge required\n- \u274c Strategic positioning or brand voice is critical\n- \u274c Legal or compliance considerations\n\n---\n\n#### B. Pattern Finding Tasks\n\n**What This Means:**\nIdentifying trends, inconsistencies, or structures in existing content.\n\n**Why AI Excels:**\n- Processes large volumes quickly\n- Doesn't miss patterns due to fatigue\n- No confirmation bias\n- Consistent classification criteria\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **Content Classification** | Categorize pages by type | \"Classify these 200 pages as Tutorial, Reference, Guide, or Concept\" |\n| **Inconsistency Detection** | Find naming variations | \"Identify inconsistent terminology across these documentation pages\" |\n| **Structure Pattern Analysis** | Recognize organizational approaches | \"What structural patterns appear in these 50 page titles?\" |\n| **Gap Identification** | Spot missing content areas | \"What topics are missing from this documentation set?\" |\n| **Redundancy Detection** | Find duplicate or overlapping content | \"Identify pages covering the same topics\" |\n\n**Example Workflow: Content Classification**\n\n```text Context\nYou have 300 documentation pages to classify using Di\u00e1taxis framework\n```\n\n```text Step 1 (Human): Prepare data and provide classification rules\nExport: Page titles + first 100 words of each page\nRules: Define each category clearly with examples\n```\n\n<CodeGroup>\n\n```text Step 2 (AI): Classify all pages\nPrompt: \"Classify each page as Tutorial (learning-oriented), \nHow-to Guide (task-oriented), Reference (information-oriented), \nor Explanation (understanding-oriented). \nProvide classification + brief reasoning.\"\n```\n\n```text Step 3 (Human): Spot-check results\nValidate ~20% randomly selected pages\nCheck edge cases manually\nReview AI's reasoning for uncertain classifications\n```\n\n```text Step 4 (Human + AI): Refine misclassifications\nAddress systematic errors in prompt\nReclassify problematic pages with more context\n```\n\n</CodeGroup>\n\n**Real Example Output:**\n\n```text AI Classifications\nPage: \"Getting Started with Authentication\"\nClassification: Tutorial\nReasoning: Step-by-step learning journey, assumes no prior knowledge, \nteaches by doing\n\nPage: \"Authentication Endpoint Reference\"  \nClassification: Reference\nReasoning: Technical specifications, lists all endpoints, \ndescribes what each does\n\nPage: \"How to Implement OAuth 2.0\"\nClassification: How-to Guide\nReasoning: Task-oriented, assumes some knowledge, \nfocuses on achieving specific goal\n\nPage: \"Understanding Token Expiration\"\nClassification: Explanation\nReasoning: Conceptual explanation, background knowledge, \nhelps understand why something works\n```\n\n<Tip>\n  **When to Use AI-First for Pattern Finding:**\n  - \u2705 Large content volumes (100+ items)\n  - \u2705 Repetitive classification criteria\n  - \u2705 Objective patterns (not subjective interpretation)\n  - \u2705 Speed is valuable\n</Tip>\n\n<Warning>\n  **When NOT to Use AI-First:**\n  - \u274c Nuanced interpretation required\n  - \u274c Small dataset (easier to do manually)\n  - \u274c Complex, multifaceted categorization\n  - \u274c Deep domain expertise needed per item\n</Warning>\n\n---\n\n#### C. Variation Creation Tasks\n\n**What This Means:**\nGenerating multiple versions of the same concept for testing or exploration.\n\n**Why AI Excels:**\n- Creates variations without creativity fatigue\n- Produces systematically different approaches\n- Generates quickly in bulk\n- Offers perspectives you might not consider\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **A/B Testing Options** | Create variations for testing | \"Generate 5 different ways to structure this navigation\" |\n| **Perspective Shifting** | View problem from different angles | \"How would a novice vs. expert organize this content?\" |\n| **Label Testing** | Produce terminology variations | \"Create synonyms for each of these technical terms\" |\n| **Organizational Approaches** | Try different IA models | \"Organize this content by: task, role, product, and topic\" |\n\n**Example Workflow: Navigation Structure Variations**\n\n<CodeGroup>\n\n```text Step 1 (Human): Define the scope\nContent inventory: 75 documentation pages\nUser types: Developers, product managers, support staff\nBusiness goal: Reduce time-to-answer\n```\n\n```text Step 2 (AI): Generate 4 different structures\nPrompt: \"Create 4 different navigation structures for this documentation:\n1. Task-based (organized by what users want to do)\n2. Role-based (organized by user type)  \n3. Product-feature-based (organized by product components)\n4. Journey-based (organized by user maturity: beginner \u2192 advanced)\n\nFor each, provide the top 2 levels of hierarchy.\"\n```\n\n</CodeGroup>\n\n```text Step 3 (AI Output)\n1. TASK-BASED:\n   \u251c\u2500\u2500 Get Started\n   \u251c\u2500\u2500 Integrate\n   \u251c\u2500\u2500 Configure\n   \u251c\u2500\u2500 Monitor\n   \u2514\u2500\u2500 Troubleshoot\n\n2. ROLE-BASED:\n   \u251c\u2500\u2500 For Developers\n   \u251c\u2500\u2500 For Product Managers\n   \u251c\u2500\u2500 For Support Staff\n   \u2514\u2500\u2500 For Administrators\n\n3. PRODUCT-FEATURE-BASED:\n   \u251c\u2500\u2500 Authentication\n   \u251c\u2500\u2500 Data Management\n   \u251c\u2500\u2500 APIs\n   \u2514\u2500\u2500 Reporting\n\n4. JOURNEY-BASED:\n   \u251c\u2500\u2500 Beginner (First Steps)\n   \u251c\u2500\u2500 Intermediate (Common Tasks)\n   \u251c\u2500\u2500 Advanced (Optimization)\n   \u2514\u2500\u2500 Expert (Architecture)\n```\n\n```text Step 4 (Human): Evaluate and test\n- Which aligns with user research?\n- Which scales best with future features?\n- Test top 2 options with users\n- Select final approach\n```\n\n<Tip>\n  **Pro Tip:** When generating variations, ask AI to explain the trade-offs of each approach. This helps you understand implications before testing.\n</Tip>\n\n---\n\n### 1.2 Human-First Zone: Tasks Best for Humans\n\nThese tasks require human judgment, empathy, or strategic thinking. AI might provide supporting information, but humans must lead.\n\n#### A. Strategic Decisions\n\n**What This Means:**\nHigh-level choices that shape the entire IA direction and align with business goals.\n\n**Why Humans Must Lead:**\n- Requires business context AI doesn't have\n- Involves trade-offs AI can't evaluate\n- Connects to broader organizational strategy\n- Has long-term implications beyond immediate task\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **IA Approach Selection** | Choose task-based vs. topic-based structure | Requires understanding user mental models from research |\n| **Scope Definition** | Decide what content to include/exclude | Requires business priorities and resource constraints |\n| **Stakeholder Alignment** | Get buy-in from product, engineering, marketing | Requires negotiation and relationship management |\n| **Governance Model** | Define who maintains what content | Requires org structure knowledge |\n| **Success Metrics** | Define what \"good IA\" means for your context | Requires business goal alignment |\n\n**Example: Strategic IA Decision**\n\n<Accordion title=\"Scenario: Organizing API Documentation\">\n\n**Question:** Should you organize by endpoint or by use case?\n\n**AI Can Help:**\n- Generate both structures for comparison\n- List pros/cons of each approach  \n- Show examples from similar products\n- Identify potential issues with each\n\n**Humans Must Decide Based On:**\n- \u2705 User research: How do YOUR users think about the product?\n- \u2705 Business goals: Are you selling solutions or technical features?\n- \u2705 Competitive positioning: How do competitors organize (and should you differ)?\n- \u2705 Product roadmap: Which structure scales better with planned features?\n- \u2705 Resource constraints: Which is more maintainable with your team?\n- \u2705 Technical constraints: What does your CMS support?\n\n**The Decision:** Humans synthesize these factors (which AI can't access or weigh)\n\n</Accordion>\n\n<Warning>\n  **Red Flags That This Is Human-First:**\n  - The phrase \"it depends\" applies heavily\n  - Multiple stakeholders have different preferences\n  - Trade-offs involve business strategy\n  - Decision has multi-year implications\n  - Requires knowledge of internal constraints\n</Warning>\n\n---\n\n#### B. User Empathy and Research Interpretation\n\n**What This Means:**\nUnderstanding user needs, behaviors, emotions, and mental models through research.\n\n**Why Humans Must Lead:**\n- Empathy requires human connection\n- Context and nuance matter enormously\n- Research uncovers unexpected insights\n- Follow-up questions are critical\n- Non-verbal cues inform understanding\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **User Interviews** | Conduct interviews, probe deeper | Requires empathy, reading between lines, following unexpected threads |\n| **Mental Model Mapping** | Understand how users conceptualize information | Requires synthesis of behavior + stated preferences + context |\n| **Usability Testing** | Observe users interacting with IA | Requires noting frustration, confusion, surprise |\n| **Card Sorting Interpretation** | Understand why users grouped content | Requires understanding reasoning, not just patterns |\n| **Research Synthesis** | Turn findings into IA principles | Requires weighing contradictions, identifying priorities |\n\n**Example: Card Sorting Analysis**\n\n**What AI Can Do:**\n\nAI Can Help:\n- Identify most common groupings\n- Calculate similarity matrices  \n- Cluster related cards\n- Generate initial category suggestions\n- Find outlier groupings\n\n**What Humans Must Do:**\n\nHumans Must Interpret:\n- \u2705 Why did 8 participants create an \"Advanced\" category but define it differently?\n- \u2705 What does it mean that 12 participants couldn't categorize \"Webhooks\"?\n- \u2705 When participants wrote notes like \"I'm not sure where this goes,\" what does that tell us?\n- \u2705 How do contradictions in sorting reflect different user roles or expertise?\n- \u2705 Which patterns reflect actual mental models vs. exposure to competitors?\n\n<Tip>\n**The Insight:** The confusion around \"Webhooks\" reveals a fundamental education gap, not just a categorization problem. (AI would miss this insight.)\n</Tip>\n\n**Example: Interview Analysis**\n\n<CodeGroup>\n\n```text Participant Quote\n\"I usually just search for what I need, but half the time \nI can't find it even though I know it exists.\"\n```\n\n```text AI Analysis (Surface Level)\nUser prefers search. Search functionality needs improvement.\n```\n\n```text Human Interpretation (Deep)\n\u2705 Why is search failing? (Labels don't match user language?)\n\u2705 What does \"even though I know it exists\" reveal? \n   (Findability problem, not availability)\n\u2705 What emotion is expressed? (Frustration\u2014indicates high-priority problem)\n\u2705 What's the underlying need? (Confidence in search results, not just better algorithm)\n\u2705 Follow-up questions needed: \"Tell me about the last time this happened...\"\n```\n\n</CodeGroup>\n\n<Tip>\n  **The Pattern:** AI can identify what users said; humans understand what users meant and felt.\n</Tip>\n\n---\n\n#### C. Ethical Judgment and Responsibility\n\n**What This Means:**\nMaking decisions that affect user wellbeing, accessibility, inclusivity, and fairness.\n\n**Why Humans Must Lead:**\n- Requires values and moral reasoning\n- Involves considering harm and benefit\n- Needs understanding of social context\n- Must account for diverse user needs\n- Requires legal/compliance knowledge\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **Accessibility Design** | Ensure IA works for users with disabilities | Requires understanding WCAG, testing with assistive tech, empathy for diverse needs |\n| **Plain Language** | Make complex content understandable | Requires knowing your users' reading levels, cultural context, domain knowledge |\n| **Content Sensitivity** | Handle sensitive topics appropriately | Requires cultural awareness, understanding potential harm, legal knowledge |\n| **Inclusive Terminology** | Choose language that doesn't exclude | Requires awareness of marginalized groups, evolving language norms |\n| **Privacy Considerations** | Protect user data in IA decisions | Requires understanding privacy laws, data ethics, consent |\n\n**Example: Accessibility Decisions**\n\n<CodeGroup>\n\n```text AI Suggestion\nNavigation labels:\n- \"Authenticate Programmatically\"\n- \"Implement Authorization Logic\"\n- \"Configure OAuth Flows\"\n\nAI evaluation: \"Clear and descriptive\" (based on length and keywords)\n```\n\n```text Human Accessibility Analysis\nProblems:\n- Technical jargon assumes expert knowledge\n- Not clear to screen reader users\n- Cognitive load too high for beginners\n- Doesn't use plain language\n\nBetter:\n- \"Sign In to Your App\"\n- \"Control Access to Features\"  \n- \"Set Up Login with OAuth\"\n\nHuman ensures: Screen reader friendly, cognitively accessible, plain language\n```\n\n</CodeGroup>\n\n**Example: Ethical Content Organization**\n\n<Accordion title=\"Scenario: Organizing Health Information\">\n\n**Question:** How should you categorize content about medical conditions?\n\n**AI Suggestion:**\n- Organize alphabetically by condition name\n- Group by severity (minor, moderate, severe)\n- Sort by body system (cardiovascular, respiratory, etc.)\n\n**Ethical Considerations (Human):**\n- \u2705 Will organizing by \"severity\" cause anxiety for users seeking information?\n- \u2705 Does alphabetical grouping make emergency information hard to find?\n- \u2705 Are we using person-first language throughout?\n- \u2705 Do category names avoid stigmatizing conditions?\n- \u2705 Is mental health treated with equal prominence to physical health?\n- \u2705 Are we providing equal depth for conditions affecting marginalized groups?\n\n**The Decision:** Humans weigh these ethical implications, which require values and understanding of social impact.\n\n</Accordion>\n\n<Warning>\n  **Red Flags That This Is Human-First:**\n  - \"Should we\" questions (not just \"can we\")\n  - Impacts on vulnerable populations\n  - Legal or compliance requirements\n  - Potential for harm or discrimination\n  - Values-based trade-offs\n</Warning>\n\n---\n\n### 1.3 Collaborative Zone: Tasks Requiring Iteration\n\nThese tasks benefit from tight back-and-forth between AI and human. Neither can do it alone efficiently.\n\n#### A. Iterative Refinement\n\n**What This Means:**\nStarting with AI generation, then refining through multiple rounds of human feedback and AI regeneration.\n\n**Why Collaboration Works:**\n- AI provides fast first drafts\n- Humans identify issues\n- AI incorporates feedback quickly\n- Humans validate improvements\n- Repeat until satisfactory\n\n**IA Applications:**\n\n| Task | Collaboration Pattern | Example |\n|------|----------------------|---------|\n| **Taxonomy Refinement** | AI generates \u2192 Human critiques \u2192 AI adjusts | \"Flatten this level, merge these categories, split that one\" |\n| **Label Optimization** | AI suggests \u2192 Human tests \u2192 AI revises | \"Too technical, make it plainer\" \u2192 AI rewrites \u2192 test again |\n| **Content Model Development** | AI proposes attributes \u2192 Human adds constraints \u2192 AI regenerates | \"Add required vs. optional flags, include character limits\" |\n| **Navigation Hierarchy** | AI builds structure \u2192 Human identifies gaps \u2192 AI fills | \"What about troubleshooting content?\" \u2192 AI adds category |\n\n**Example Workflow: Taxonomy Refinement**\n\n<CodeGroup>\n\n```text Round 1 (AI): Generate initial taxonomy\nPrompt: \"Create a 3-level taxonomy for 100 API documentation pages covering \nauthentication, payments, webhooks, and analytics.\"\n\nOutput:\n\u251c\u2500\u2500 Authentication (25 pages)\n\u2502   \u251c\u2500\u2500 Methods\n\u2502   \u251c\u2500\u2500 OAuth\n\u2502   \u2514\u2500\u2500 Security\n\u251c\u2500\u2500 Payments (35 pages)\n\u2502   \u251c\u2500\u2500 Processing\n\u2502   \u251c\u2500\u2500 Subscriptions\n\u2502   \u2514\u2500\u2500 Refunds\n\u251c\u2500\u2500 Webhooks (20 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u251c\u2500\u2500 Events\n\u2502   \u2514\u2500\u2500 Troubleshooting\n\u2514\u2500\u2500 Analytics (20 pages)\n    \u251c\u2500\u2500 Tracking\n    \u251c\u2500\u2500 Reports\n    \u2514\u2500\u2500 Dashboards\n```\n\n```text Round 2 (Human): Critique\nIssues identified:\n1. \"Payments\" at 35% is unbalanced\n2. \"Analytics\" feels like it should be under \"Webhooks\" \n   (webhook events generate analytics)\n3. Missing \"Getting Started\" section\n4. \"Security\" could be its own top-level (cross-cutting concern)\n```\n\n```text Round 3 (AI): Refine based on feedback\nPrompt: \"Adjust the taxonomy:\n1. Split 'Payments' into 'Payments' and 'Subscriptions' at top level\n2. Move 'Analytics' under 'Webhooks'\n3. Add 'Getting Started' as first top-level category\n4. Promote 'Security' to top level, covering auth security, payment security\"\n\nOutput:\n\u251c\u2500\u2500 Getting Started (8 pages)\n\u2502   \u251c\u2500\u2500 Quick Start\n\u2502   \u2514\u2500\u2500 Core Concepts\n\u251c\u2500\u2500 Authentication (18 pages)\n\u2502   \u251c\u2500\u2500 Methods\n\u2502   \u2514\u2500\u2500 OAuth\n\u251c\u2500\u2500 Payments (22 pages)\n\u2502   \u251c\u2500\u2500 Processing\n\u2502   \u2514\u2500\u2500 Refunds\n\u251c\u2500\u2500 Subscriptions (13 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u2514\u2500\u2500 Management\n\u251c\u2500\u2500 Webhooks (20 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u251c\u2500\u2500 Events\n\u2502   \u251c\u2500\u2500 Analytics\n\u2502   \u2514\u2500\u2500 Troubleshooting\n\u2514\u2500\u2500 Security (19 pages)\n    \u251c\u2500\u2500 Authentication Security\n    \u251c\u2500\u2500 Payment Security\n    \u2514\u2500\u2500 Best Practices\n```\n\n```text Round 4 (Human): Validate\nMuch better! Balanced (no category >25%), logical structure.\nFinal check: Test with 3 users navigating to common tasks.\n```\n\n</CodeGroup>\n\n<Tip>\n  **Iteration Best Practices:**\n  1. **Be specific in critiques:** Not \"this doesn't work\" but \"this is too vague for beginners\"\n  2. **Iterate in chunks:** Don't try to fix everything at once\n  3. **Set a stopping point:** Know when \"good enough\" is sufficient\n  4. **Document your prompts:** Save the winning prompt for future use\n</Tip>\n\n---\n\n#### B. Validation and Quality Assurance\n\n**What This Means:**\nAI generates, humans validate systematically, AI fixes identified issues.\n\n**Why Collaboration Works:**\n- AI produces volume quickly\n- Humans catch errors AI can't see\n- AI fixes errors quickly at scale\n- Humans verify fixes\n\n**IA Applications:**\n\n| Task | Collaboration Pattern | Example |\n|------|----------------------|---------|\n| **Consistency Checking** | AI identifies inconsistencies \u2192 Human confirms \u2192 AI standardizes | \"Fix all instances of 'log in' vs 'login'\" |\n| **Completeness Validation** | AI checks structure \u2192 Human adds missing elements \u2192 AI regenerates | \"Every category needs a landing page description\" |\n| **Link Relationship Mapping** | AI suggests relationships \u2192 Human validates relevance \u2192 AI builds map | \"Should 'OAuth Guide' link to 'Token Management'?\" |\n| **Metadata Validation** | AI checks schema adherence \u2192 Human fixes edge cases \u2192 AI revalidates | \"This page is missing required metadata\" |\n\n**Example Workflow: Metadata Validation**\n\n<Accordion title=\"Complete Workflow Example\">\n\n**Context:** You've defined a metadata schema for 200 documentation pages.\n\n**Required fields:** title, description, content_type, audience, last_updated  \n**Optional fields:** related_pages, prerequisites, estimated_time\n\n**Step 1 (AI): Validate all pages against schema**\n\n```text Prompt\n\"Check each page for required metadata. List any missing fields.\"\n```\n\n```text Output\nPages missing required metadata:\n- Page 47: Missing 'audience'\n- Page 89: Missing 'content_type' and 'description'  \n- Page 102: Missing 'last_updated'\n- Page 134: Missing 'content_type'\n[15 more pages with issues...]\n```\n\n**Step 2 (Human): Review and triage**\n- Most missing \"audience\" can be inferred from content\n- Missing \"content_type\" needs human judgment (Tutorial vs. Guide vs. Reference)\n- Missing \"last_updated\" can be pulled from CMS\n\n**Step 3 (AI): Fill in what it can**\n\n```text Prompt\n\"For pages missing 'audience', analyze content and suggest appropriate audience \n(developers, product managers, or support staff). For pages missing 'description', \ngenerate 150-character summaries.\"\n```\n\n**Step 4 (Human): Handle what AI can't**\nManually classify pages by content_type (requires understanding Di\u00e1taxis framework nuances)\n\n**Step 5 (AI): Final validation**\n\n```text Prompt\n\"Recheck all 200 pages. Confirm all required fields are now present.\"\n```\n\n</Accordion>\n\n<Tip>\n  **When to Use Collaborative Validation:**\n  - \u2705 Large datasets where manual checking is slow\n  - \u2705 Clear validation rules exist\n  - \u2705 Some cases need judgment, others don't\n  - \u2705 Iterative improvement is acceptable\n</Tip>\n\n---\n\n#### C. Complex Problem Solving\n\n**What This Means:**\nBreaking down complex IA problems into steps, using AI for some steps and human judgment for others.\n\n**Why Collaboration Works:**\n- Humans decompose the problem strategically\n- AI handles analytical/repetitive substeps\n- Humans synthesize findings\n- AI helps scale the solution\n\n**Example: Complete Documentation IA Audit**\n\n<Accordion title=\"Full Case Study: Software Documentation IA Audit\">\n\n**Context:** 250-page developer documentation site with known findability issues.\n\n**Goal:** Audit content, identify problems, recommend improvements.\n\n#### Phase 1: Content Audit\n\n| Task | Owner | Why |\n|------|-------|-----|\n| Extract all page titles, URLs, metadata | **AI** | Mechanical data collection |\n| Classify pages by content type (Di\u00e1taxis) | **AI** | Pattern recognition at scale |\n| Identify duplicate/redundant content | **AI** | Pattern matching |\n| Calculate content freshness | **AI** | Date analysis |\n| Review audit results for accuracy | **Human** | Validation, context |\n| Identify strategic content gaps | **Human** | Requires domain knowledge |\n| Prioritize which gaps to fill | **Human** | Business strategy |\n\n**What AI Did Well:**\n```\nAI Analysis Output:\n- 250 pages classified:\n  * 45 Tutorials\n  * 82 How-to Guides  \n  * 98 Reference pages\n  * 25 Explanations\n- Identified 18 pairs of redundant content\n- Found 45 pages not updated in 2+ years\n- Detected inconsistent terminology (12 variations of \"authentication\")\n```\n\n**What AI Missed (Human Caught):**\n- AI classified \"Troubleshooting Webhooks\" as How-to Guide\n  Human: Actually a Reference (lists error codes)\n- AI flagged \"Intro to REST\" and \"REST API Basics\" as redundant\n  Human: Different audiences (beginners vs. experienced)\n- AI said content is \"outdated\" based on dates alone\n  Human: Some reference content is timeless; tutorials need updates\n\n**Outcome:** AI accelerated audit from 2 weeks \u2192 3 days, but human validation was essential.\n\n#### Phase 2: Navigation Analysis\n\n| Task | Owner | Why |\n|------|-------|-----|\n| Map current navigation structure | **AI** | Data extraction |\n| Identify navigation inconsistencies | **AI** | Pattern detection |\n| Calculate navigation depth metrics | **AI** | Quantitative analysis |\n| Analyze user search queries | **AI** | Pattern analysis at scale |\n| Compare navigation to user mental models | **Human** | Requires user research interpretation |\n| Identify navigation-search gaps | **Human** | Strategic insight |\n| Recommend navigation changes | **Human** | Strategic decision |\n\n**What AI Did Well:**\n```\n- Current structure: 7 top-level categories, max depth 5 levels\n- Found 23 pages buried 4+ levels deep (low discoverability)\n- Identified 45 search queries with 0 results despite relevant pages existing\n- Detected 8 pages accessible via multiple paths (ambiguous placement)\n```\n\n**What Human Decided:**\n- Reduce to 5 top-level categories (based on user research)\n- Flatten hierarchy to max 3 levels\n- Reorganize from feature-based to task-based structure\n- Create cross-links for genuinely multi-purpose content\n\n#### Phase 3: Recommendations\n\n| Task | Owner | Why |\n|------|-------|-----|\n| Generate initial recommendations | **AI** | Based on patterns found |\n| Estimate effort for each recommendation | **AI** | Pattern-based estimates |\n| Prioritize by impact vs. effort | **Human** | Strategic prioritization |\n| Create implementation plan | **Human** | Requires resource knowledge |\n| Draft executive summary | **AI** | Synthesis of findings |\n| Finalize executive summary | **Human** | Messaging for stakeholders |\n\n**Final Deliverable (Collaborative):**\n- 12-page audit report (AI drafted, human refined)\n- Prioritized action plan with 23 recommendations\n- Quick wins (3 items, less than 1 week each)\n- High-impact changes (5 items, 2-4 weeks each)\n- Strategic initiatives (4 items, multi-month)\n\n**Time Saved:**\nTraditional audit: 3-4 weeks\nAI-assisted audit: 1 week\n**Savings: 66-75%**\n\n</Accordion>\n\n<Tip>\n  **The Pattern for Complex Problems:**\n  1. Human: Decompose into steps\n  2. AI: Handle analytical/scale-dependent steps\n  3. Human: Validate AI outputs at each step\n  4. AI: Synthesize findings\n  5. Human: Make strategic decisions\n  6. AI: Scale the solution\n</Tip>\n\n---",
            "hydration_source_header": "1. The IA Decision Framework",
            "hydration_method": "title_match"
          },
          {
            "id": "validation-pyramid",
            "title": "Validation Pyramid",
            "type": "framework",
            "definition": "Four-level system for validating AI outputs from quick checks to user testing",
            "contains": [
              "level-1-quick-checks",
              "level-2-structural",
              "level-3-semantic",
              "level-4-user-validation"
            ],
            "lines": "602-820",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I validate AI outputs?",
              "What's the validation pyramid?",
              "How do I systematically check AI-generated content?"
            ],
            "content": "AI outputs need validation. But not all validation is equal. The Validation Pyramid provides a systematic approach.\n\n```mermaid\ngraph TD\n    A[Level 4: User Validation<br/>Hours-Days]\n    B[Level 3: Semantic Validation<br/>30-60 min]\n    C[Level 2: Structural Validation<br/>15-30 min]\n    D[Level 1: Quick Checks<br/>Minutes]\n    \n    A --> B\n    B --> C\n    C --> D\n    \n    style A fill:#ffcccc\n    style B fill:#ffe6cc\n    style C fill:#ffffcc\n    style D fill:#ccffcc\n```\n\n**The principle:** Start with fast, easy checks. Only invest in deeper validation if earlier levels pass.\n\n---\n\n### Level 1: Quick Checks (Minutes)\n\n**Purpose:** Catch obvious errors fast\n\n**What to Check:**\n- \u2705 Format is correct (expected structure)\n- \u2705 Completeness (all requested parts present)\n- \u2705 Obvious factual errors\n- \u2705 Nonsensical outputs\n\n**Example Quick Checks:**\n\n### Example 1: Taxonomy Check\n\n**AI Generated Taxonomy:**\n```\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 API Reference\n\u251c\u2500\u2500 SDKs & Tools\n\u251c\u2500\u2500 Get Started\n\u2514\u2500\u2500 Troubleshooting\n```\n\n**Quick Check Findings:**\n- \u274c \"Get Started\" appears twice (obvious error)\n- \u2705 Format is correct (tree structure)\n- \u2705 All categories present\n- \u2705 No nonsensical content\n\n**Action:** Fix immediately, no deep analysis needed\n\n---\n\n### Example 2: Label Check\n\n**AI Generated Labels:**\n```\n- Authentication Guide\n- Authenticate Your Users\n- API Security\n- Secure Your API\n- OAuth Implementation\n```\n\n**Quick Check Findings:**\n- \u2705 All labels under 30 characters (format requirement met)\n- \u2705 No typos or obvious errors\n- \u26a0\ufe0f Possible redundancy (\"Authentication\" vs \"Authenticate\")\n\n**Action:** Passes Level 1, proceed to Level 2 for deeper check\n\n<Tip>\n  **Time Investment:** 2-5 minutes. Don't skip this\u2014it catches embarrassing errors before you invest more time.\n</Tip>\n\n---\n\n### Level 2: Structural Validation (15-30 min)\n\n**Purpose:** Verify logical structure and relationships\n\n**What to Check:**\n- \u2705 Hierarchy logic (parent-child relationships make sense)\n- \u2705 Parallel structure (items at same level have similar specificity)\n- \u2705 Balance (no category drastically larger than others)\n- \u2705 Completeness (no major gaps)\n- \u2705 Mutual exclusivity (clear boundaries)\n\n**Example Structural Validation:**\n\n<Accordion title=\"Taxonomy Structure Check\">\n\n**AI Generated Taxonomy:**\n```\nDocumentation (85 pages)\n\u251c\u2500\u2500 Getting Started (12 pages, 14%)\n\u2502   \u251c\u2500\u2500 Installation\n\u2502   \u251c\u2500\u2500 Quick Start\n\u2502   \u2514\u2500\u2500 Core Concepts\n\u251c\u2500\u2500 Authentication (25 pages, 29%)\n\u2502   \u251c\u2500\u2500 OAuth 2.0\n\u2502   \u251c\u2500\u2500 API Keys\n\u2502   \u2514\u2500\u2500 JWT Tokens\n\u251c\u2500\u2500 API Endpoints (30 pages, 35%)\n\u2502   \u251c\u2500\u2500 Users\n\u2502   \u251c\u2500\u2500 Posts\n\u2502   \u2514\u2500\u2500 Comments\n\u2514\u2500\u2500 Troubleshooting (18 pages, 21%)\n    \u251c\u2500\u2500 Common Errors\n    \u251c\u2500\u2500 Debug Mode\n    \u2514\u2500\u2500 Support\n```\n\n**Structural Validation:**\n\n**1. Hierarchy Logic:**\n- \u2705 Top level represents user tasks/features\n- \u2705 Second level breaks down appropriately\n- \u26a0\ufe0f \"JWT Tokens\" under \"Authentication\" but also relates to \"API Endpoints\"\n\n**2. Parallel Structure:**\n- \u274c \"Getting Started\" (process) vs \"Authentication\" (topic) vs \"API Endpoints\" (reference) vs \"Troubleshooting\" (process)\n- Issue: Mixing organizational principles\n\n**3. Balance:**\n- \u2705 Reasonable distribution (14%, 29%, 35%, 21%)\n- \u26a0\ufe0f \"API Endpoints\" at 35% is borderline high\n\n**4. Completeness:**\n- \u2705 Covers major user needs\n- \u26a0\ufe0f Where does \"Rate Limiting\" go? \"Webhooks\"? Missing?\n\n**5. Mutual Exclusivity:**\n- \u26a0\ufe0f JWT Tokens could fit under Authentication OR API Endpoints\n\n**Action:** Needs refinement before proceeding to Level 3\n\n</Accordion>\n\n<Tip>\n  **Time Investment:** 15-30 minutes. This is where you catch structural issues that would confuse users.\n</Tip>\n\n---\n\n### Level 3: Semantic Validation (30-60 min)\n\n**Purpose:** Verify meaning, accuracy, and appropriateness\n\n**What to Check:**\n- \u2705 Terminology is accurate and appropriate\n- \u2705 Labels match user vocabulary\n- \u2705 Content appropriateness for audience\n- \u2705 Domain accuracy (no misinformation)\n- \u2705 Cultural sensitivity and inclusivity\n\n#### A. Terminology Accuracy\n\n**Example: Navigation Labels**\n\n<CodeGroup>\n\n```text AI Generated Labels\n\u251c\u2500\u2500 Authentication & Authorization\n\u2502   \u251c\u2500\u2500 User Authentication\n\u2502   \u251c\u2500\u2500 API Authorization\n\u2502   \u251c\u2500\u2500 Login Methods\n\u2502   \u251c\u2500\u2500 Access Tokens\n\u2502   \u251c\u2500\u2500 Password Security\n\u2502   \u2514\u2500\u2500 Permission Levels\n```\n\n```text Semantic Issues Found\n1. \"User Authentication\" vs. \"API Authorization\" - these concepts overlap in OAuth\n   - Authentication = proving identity\n   - Authorization = granting permissions\n   - OAuth does BOTH, so where does it belong?\n\n2. \"Login Methods\" is user-facing language\n   \"Access Tokens\" is developer-facing language\n   - Inconsistent audience targeting\n\n3. \"Password Security\" under Authentication (correct)\n   \"Permission Levels\" under Authorization (correct)\n   - But what about API Keys? They're auth AND authz\n```\n\n```text Corrected Structure\n\u251c\u2500\u2500 Authentication (Proving Identity)\n\u2502   \u251c\u2500\u2500 Username & Password\n\u2502   \u251c\u2500\u2500 API Keys\n\u2502   \u2514\u2500\u2500 Multi-Factor Authentication\n\u251c\u2500\u2500 Authorization (Granting Permissions)\n\u2502   \u251c\u2500\u2500 OAuth 2.0\n\u2502   \u251c\u2500\u2500 Access Control\n\u2502   \u2514\u2500\u2500 Scopes & Permissions\n```\n\n</CodeGroup>\n\n**Common Semantic Problems:**\n- Mixing similar but distinct concepts\n- Using colloquial terms where technical precision needed\n- Terms that mean different things in different contexts\n- Outdated terminology\n\n---\n\n#### B. Content Appropriateness\n\nIs the content appropriate for the stated purpose and audience?\n\n**Checklist:**\n- \u2610 Complexity matches audience level\n- \u2610 Scope aligns with user needs\n- \u2610 Tone is appropriate\n- \u2610 Examples are relevant\n- \u2610 No inappropriate content\n\n**Example: Audience Appropriateness Check**\n\n<CodeGroup>\n\n```text Context: Documentation for junior developers\n\nAI-Generated Navigation Labels:\n\u251c\u2500\u2500 Fundamentals\n\u2502   \u251c\u2500\u2500 RESTful Architecture Principles\n\u2502   \u251c\u2500\u2500 HTTP Methods & Status Codes\n\u2502   \u2514\u2500\u2500 JSON Schema Validation\n\u251c\u2500\u2500 Implementation\n\u2502   \u251c\u2500\u2500 Dependency Injection Patterns\n\u2502   \u251c\u2500\u2500 Async/Await Best Practices\n\u2502   \u2514\u2500\u2500 Error Handling Strategies\n```\n\n```text Appropriateness Issues\n\u2717 \"RESTful Architecture Principles\" - Too abstract for beginners\n\u2717 \"Dependency Injection Patterns\" - Advanced concept, assumes experience\n\u2717 Assumes knowledge of architectural patterns\n```\n\n```text Better for Junior Developers\n\u251c\u2500\u2500 Getting Started\n\u2502   \u251c\u2500\u2500 What is a REST API?\n\u2502   \u251c\u2500\u2500 Making Your First API Call\n\u2502   \u2514\u2500\u2500 Understanding API Responses\n\u251c\u2500\u2500 Common Tasks\n\u2502   \u251c\u2500\u2500 Authenticating Requests\n\u2502   \u251c\u2500\u2500 Handling Errors\n\u2502   \u2514\u2500\u2500 Working with Async Code\n```\n\n</CodeGroup>\n\n<Warning>\n  **Red Flags:**\n  - Labels use jargon audience won't know\n  - Assumes prerequisite knowledge not stated\n  - Complexity doesn't match stated user level\n  - Content too advanced or too basic\n</Warning>\n\n---\n\n#### C. Domain Accuracy\n\nIs the content factually correct for the domain?\n\n**Checklist:**\n- \u2610 Technical accuracy (no false information)\n- \u2610 Best practices are actually best practices\n- \u2610 Standards are cited correctly\n- \u2610 No outdated information\n- \u2610 Domain-specific nuances are respected\n\n**Example: Domain Accuracy Check**\n\n<Accordion title=\"API Documentation Taxonomy Review\">\n\n**AI-Generated Category Descriptions:**\n\n```text\n\"Rate Limiting: Controls how many requests users can make per minute. \nStandard practice is 100 requests/minute.\"\n```\n\n**Domain Accuracy Issues:**\n- \u274c \"Standard practice is 100 requests/minute\" - This is NOT a universal standard\n- Reality: Rate limits vary widely (GitHub: 5000/hour, Twitter: varies by endpoint)\n- Should say: \"varies by service\" or provide YOUR API's specific limits\n\n**Corrected:**\n```text\n\"Rate Limiting: Controls how many API requests can be made within a time period. \nOur API allows 1000 requests per hour per API key.\"\n```\n\n</Accordion>\n\n<Tip>\n  **Time Investment:** 30-60 minutes. This is where domain expertise matters most.\n</Tip>\n\n---\n\n### Level 4: User Validation (Hours-Days)\n\n**Purpose:** Test with real users to validate findability and usability\n\n**What to Test:**\n- \u2705 Can users find what they need?\n- \u2705 Do labels match user mental models?\n- \u2705 Does hierarchy make intuitive sense?\n- \u2705 Are navigation paths efficient?\n- \u2705 Does the IA reduce friction?\n\n**Validation Methods:**\n\n<CardGroup cols={2}>\n  <Card title=\"Tree Testing\" icon=\"sitemap\">\n    Users find items in the proposed structure\n    \n    **Time:** 20-30 min per participant\n    **Participants:** 8-12 users\n    **Cost:** Low (remote, unmoderated)\n  </Card>\n  \n  <Card title=\"First Click Testing\" icon=\"hand-pointer\">\n    Where do users click first to find X?\n    \n    **Time:** 5-10 min per participant\n    **Participants:** 15-20 users\n    **Cost:** Very low\n  </Card>\n  \n  <Card title=\"Usability Testing\" icon=\"user-check\">\n    Watch users navigate actual interface\n    \n    **Time:** 60 min per participant\n    **Participants:** 5-8 users\n    **Cost:** Higher (moderated, recordings)\n  </Card>\n  \n  <Card title=\"A/B Testing\" icon=\"flask\">\n    Compare two IA approaches with analytics\n    \n    **Time:** 1-2 weeks minimum\n    **Participants:** Hundreds (live traffic)\n    **Cost:** Medium (implementation time)\n  </Card>\n</CardGroup>\n\n**Example Tree Test Results:**\n\n```text Task: Find how to reset a user's password\n\nProposed Structure:\n\u251c\u2500\u2500 Authentication\n\u2502   \u251c\u2500\u2500 User Management\n\u2502   \u2502   \u2514\u2500\u2500 Password Reset \u2190 Target\n\u2502   \u2514\u2500\u2500 OAuth Setup\n\u251c\u2500\u2500 API Reference\n\u2514\u2500\u2500 Troubleshooting\n\nResults:\n- 15 participants tested\n- 60% found it directly under Authentication > User Management\n- 27% looked in Troubleshooting first (makes sense!)\n- 13% looked in API Reference\n- Average time: 45 seconds (acceptable)\n\nConclusion: \n\u2705 Structure works for most users\n\u26a0\ufe0f Consider cross-link from Troubleshooting\n```\n\n<Tip>\n  **When to Use Level 4:**\n  - High-impact changes (site-wide navigation)\n  - Uncertainty about user mental models\n  - Contradictory findings in earlier validation\n  - Stakeholder buy-in requires evidence\n</Tip>\n\n<Warning>\n  **Don't Skip Earlier Levels:**\n  \n  User testing is expensive. Don't waste users' time testing AI outputs with obvious structural or semantic flaws. Use Levels 1-3 first.\n</Warning>\n\n---",
            "hydration_source_header": "2. The Validation Pyramid",
            "hydration_method": "title_match"
          }
        ],
        "principles": [
          {
            "id": "partnership-mindset",
            "title": "AI as Specialized Team Member",
            "partOf": "introduction",
            "lines": "25-35",
            "crossModule": true,
            "retrievalQuestions": [
              "What's the right mindset for working with AI?"
            ],
            "content": "In Module 1.1, you learned what AI can and cannot do. Now comes the critical question every IA faces: **\"Should I use AI for this task, or do it myself?\"**\n\n**The Core Principle:**\nAI is not a replacement for you\u2014it's a specialized team member with specific strengths and limitations. Like any team collaboration, success depends on assigning the right tasks to the right \"team member.\"\n\n**What This Module Teaches:**\n- A systematic framework for making AI vs. human decisions\n- A validation approach that catches errors before they cause problems\n- Real examples of where AI shines and where it fails\n\nLet's start with the decision framework.\n\n---",
            "hydration_source_header": "Introduction: The Partnership Mindset",
            "hydration_method": "line_proximity"
          },
          {
            "id": "ai-accelerates-humans-decide",
            "title": "AI Accelerates, Humans Decide",
            "partOf": "core-principles",
            "lines": "1295-1296",
            "crossModule": true,
            "retrievalQuestions": [
              "What role should AI play in decisions?"
            ],
            "content": "**Decision:** AI-First (Generation) \u2192 Human Strategic Selection\n\n<CodeGroup>\n\n```text Prompt\n\"Given this content inventory, generate 3 different IA approaches:\n\n1. Task-based: Organize by what users want to accomplish\n2. Feature-based: Organize by CloudStore features\n3. Audience-based: Organize by user role (developer/product manager/support)\n\nFor each approach:\n- Provide 2-level hierarchy\n- Distribute 85 pages across categories\n- Show page counts and percentages\n- List 3 pros and 3 cons\n```\n\n```text AI Output (summary)\nAPPROACH 1: TASK-BASED\n\u251c\u2500\u2500 Get Started (12 pages, 14%)\n\u251c\u2500\u2500 Authenticate & Secure (15 pages, 18%)\n\u251c\u2500\u2500 Store & Manage Files (28 pages, 33%)\n\u251c\u2500\u2500 Integrate Webhooks (12 pages, 14%)\n\u2514\u2500\u2500 Monitor & Troubleshoot (18 pages, 21%)\n\nPros: Matches user goals, supports progressive disclosure, scalable\nCons: Some features span categories, requires more cross-links\n\nAPPROACH 2: FEATURE-BASED\n\u251c\u2500\u2500 Authentication (22 pages, 26%)\n\u251c\u2500\u2500 File Storage (35 pages, 41%)\n\u251c\u2500\u2500 Webhooks (15 pages, 18%)\n\u2514\u2500\u2500 Analytics (13 pages, 15%)\n\nPros: Mirrors product structure, familiar to internal team, simple\nCons: Doesn't match user tasks, \"File Storage\" too large, learning curve\n\nAPPROACH 3: AUDIENCE-BASED\n\u251c\u2500\u2500 For Backend Developers (45 pages, 53%)\n\u251c\u2500\u2500 For Frontend Developers (25 pages, 29%)\n\u2514\u2500\u2500 For Support Staff (15 pages, 18%)\n\nPros: Targeted content, clear audience signals\nCons: Duplicates content, hard to maintain, doesn't scale with roles\n```\n\n```text Human Decision (Strategic)\nSelected: APPROACH 1 (Task-Based)\n\nReasoning:\n\u2705 User research shows users think in tasks (\"I want to upload a file\")\n\u2705 Aligns with business goal (reduce support tickets via better findability)\n\u2705 Scales with product roadmap (new features fit existing task categories)\n\u2705 Competitor analysis: Best-practice pattern in API docs\n\u2705 No organizational constraints blocking this approach\n```\n\n</CodeGroup>\n\n**Time:** AI generation: 5 minutes | Human analysis & decision: 45 minutes | **Total: 50 minutes**\n\n---",
            "hydration_source_header": "Step 2: Generate IA Options",
            "hydration_method": "line_proximity"
          },
          {
            "id": "always-validate",
            "title": "Always Validate AI Outputs",
            "partOf": "core-principles",
            "lines": "1297",
            "crossModule": true,
            "retrievalQuestions": [
              "Must I always validate AI?"
            ],
            "content": "**Decision:** AI-First (Generation) \u2192 Human Strategic Selection\n\n<CodeGroup>\n\n```text Prompt\n\"Given this content inventory, generate 3 different IA approaches:\n\n1. Task-based: Organize by what users want to accomplish\n2. Feature-based: Organize by CloudStore features\n3. Audience-based: Organize by user role (developer/product manager/support)\n\nFor each approach:\n- Provide 2-level hierarchy\n- Distribute 85 pages across categories\n- Show page counts and percentages\n- List 3 pros and 3 cons\n```\n\n```text AI Output (summary)\nAPPROACH 1: TASK-BASED\n\u251c\u2500\u2500 Get Started (12 pages, 14%)\n\u251c\u2500\u2500 Authenticate & Secure (15 pages, 18%)\n\u251c\u2500\u2500 Store & Manage Files (28 pages, 33%)\n\u251c\u2500\u2500 Integrate Webhooks (12 pages, 14%)\n\u2514\u2500\u2500 Monitor & Troubleshoot (18 pages, 21%)\n\nPros: Matches user goals, supports progressive disclosure, scalable\nCons: Some features span categories, requires more cross-links\n\nAPPROACH 2: FEATURE-BASED\n\u251c\u2500\u2500 Authentication (22 pages, 26%)\n\u251c\u2500\u2500 File Storage (35 pages, 41%)\n\u251c\u2500\u2500 Webhooks (15 pages, 18%)\n\u2514\u2500\u2500 Analytics (13 pages, 15%)\n\nPros: Mirrors product structure, familiar to internal team, simple\nCons: Doesn't match user tasks, \"File Storage\" too large, learning curve\n\nAPPROACH 3: AUDIENCE-BASED\n\u251c\u2500\u2500 For Backend Developers (45 pages, 53%)\n\u251c\u2500\u2500 For Frontend Developers (25 pages, 29%)\n\u2514\u2500\u2500 For Support Staff (15 pages, 18%)\n\nPros: Targeted content, clear audience signals\nCons: Duplicates content, hard to maintain, doesn't scale with roles\n```\n\n```text Human Decision (Strategic)\nSelected: APPROACH 1 (Task-Based)\n\nReasoning:\n\u2705 User research shows users think in tasks (\"I want to upload a file\")\n\u2705 Aligns with business goal (reduce support tickets via better findability)\n\u2705 Scales with product roadmap (new features fit existing task categories)\n\u2705 Competitor analysis: Best-practice pattern in API docs\n\u2705 No organizational constraints blocking this approach\n```\n\n</CodeGroup>\n\n**Time:** AI generation: 5 minutes | Human analysis & decision: 45 minutes | **Total: 50 minutes**\n\n---",
            "hydration_source_header": "Step 2: Generate IA Options",
            "hydration_method": "line_proximity"
          },
          {
            "id": "iterate-tightly",
            "title": "Iterate Tightly for Best Results",
            "partOf": "core-principles",
            "lines": "1298",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I iterate with AI?"
            ],
            "content": "**Decision:** AI-First (Generation) \u2192 Human Strategic Selection\n\n<CodeGroup>\n\n```text Prompt\n\"Given this content inventory, generate 3 different IA approaches:\n\n1. Task-based: Organize by what users want to accomplish\n2. Feature-based: Organize by CloudStore features\n3. Audience-based: Organize by user role (developer/product manager/support)\n\nFor each approach:\n- Provide 2-level hierarchy\n- Distribute 85 pages across categories\n- Show page counts and percentages\n- List 3 pros and 3 cons\n```\n\n```text AI Output (summary)\nAPPROACH 1: TASK-BASED\n\u251c\u2500\u2500 Get Started (12 pages, 14%)\n\u251c\u2500\u2500 Authenticate & Secure (15 pages, 18%)\n\u251c\u2500\u2500 Store & Manage Files (28 pages, 33%)\n\u251c\u2500\u2500 Integrate Webhooks (12 pages, 14%)\n\u2514\u2500\u2500 Monitor & Troubleshoot (18 pages, 21%)\n\nPros: Matches user goals, supports progressive disclosure, scalable\nCons: Some features span categories, requires more cross-links\n\nAPPROACH 2: FEATURE-BASED\n\u251c\u2500\u2500 Authentication (22 pages, 26%)\n\u251c\u2500\u2500 File Storage (35 pages, 41%)\n\u251c\u2500\u2500 Webhooks (15 pages, 18%)\n\u2514\u2500\u2500 Analytics (13 pages, 15%)\n\nPros: Mirrors product structure, familiar to internal team, simple\nCons: Doesn't match user tasks, \"File Storage\" too large, learning curve\n\nAPPROACH 3: AUDIENCE-BASED\n\u251c\u2500\u2500 For Backend Developers (45 pages, 53%)\n\u251c\u2500\u2500 For Frontend Developers (25 pages, 29%)\n\u2514\u2500\u2500 For Support Staff (15 pages, 18%)\n\nPros: Targeted content, clear audience signals\nCons: Duplicates content, hard to maintain, doesn't scale with roles\n```\n\n```text Human Decision (Strategic)\nSelected: APPROACH 1 (Task-Based)\n\nReasoning:\n\u2705 User research shows users think in tasks (\"I want to upload a file\")\n\u2705 Aligns with business goal (reduce support tickets via better findability)\n\u2705 Scales with product roadmap (new features fit existing task categories)\n\u2705 Competitor analysis: Best-practice pattern in API docs\n\u2705 No organizational constraints blocking this approach\n```\n\n</CodeGroup>\n\n**Time:** AI generation: 5 minutes | Human analysis & decision: 45 minutes | **Total: 50 minutes**\n\n---",
            "hydration_source_header": "Step 2: Generate IA Options",
            "hydration_method": "line_proximity"
          },
          {
            "id": "know-your-strengths",
            "title": "Leverage What Each Does Best",
            "partOf": "core-principles",
            "lines": "1299",
            "crossModule": true,
            "retrievalQuestions": [
              "What is AI best at vs humans?"
            ],
            "content": "**Decision:** AI-First (Generation) \u2192 Human Strategic Selection\n\n<CodeGroup>\n\n```text Prompt\n\"Given this content inventory, generate 3 different IA approaches:\n\n1. Task-based: Organize by what users want to accomplish\n2. Feature-based: Organize by CloudStore features\n3. Audience-based: Organize by user role (developer/product manager/support)\n\nFor each approach:\n- Provide 2-level hierarchy\n- Distribute 85 pages across categories\n- Show page counts and percentages\n- List 3 pros and 3 cons\n```\n\n```text AI Output (summary)\nAPPROACH 1: TASK-BASED\n\u251c\u2500\u2500 Get Started (12 pages, 14%)\n\u251c\u2500\u2500 Authenticate & Secure (15 pages, 18%)\n\u251c\u2500\u2500 Store & Manage Files (28 pages, 33%)\n\u251c\u2500\u2500 Integrate Webhooks (12 pages, 14%)\n\u2514\u2500\u2500 Monitor & Troubleshoot (18 pages, 21%)\n\nPros: Matches user goals, supports progressive disclosure, scalable\nCons: Some features span categories, requires more cross-links\n\nAPPROACH 2: FEATURE-BASED\n\u251c\u2500\u2500 Authentication (22 pages, 26%)\n\u251c\u2500\u2500 File Storage (35 pages, 41%)\n\u251c\u2500\u2500 Webhooks (15 pages, 18%)\n\u2514\u2500\u2500 Analytics (13 pages, 15%)\n\nPros: Mirrors product structure, familiar to internal team, simple\nCons: Doesn't match user tasks, \"File Storage\" too large, learning curve\n\nAPPROACH 3: AUDIENCE-BASED\n\u251c\u2500\u2500 For Backend Developers (45 pages, 53%)\n\u251c\u2500\u2500 For Frontend Developers (25 pages, 29%)\n\u2514\u2500\u2500 For Support Staff (15 pages, 18%)\n\nPros: Targeted content, clear audience signals\nCons: Duplicates content, hard to maintain, doesn't scale with roles\n```\n\n```text Human Decision (Strategic)\nSelected: APPROACH 1 (Task-Based)\n\nReasoning:\n\u2705 User research shows users think in tasks (\"I want to upload a file\")\n\u2705 Aligns with business goal (reduce support tickets via better findability)\n\u2705 Scales with product roadmap (new features fit existing task categories)\n\u2705 Competitor analysis: Best-practice pattern in API docs\n\u2705 No organizational constraints blocking this approach\n```\n\n</CodeGroup>\n\n**Time:** AI generation: 5 minutes | Human analysis & decision: 45 minutes | **Total: 50 minutes**\n\n---",
            "hydration_source_header": "Step 2: Generate IA Options",
            "hydration_method": "line_proximity"
          },
          {
            "id": "start-fast-validate-systematically",
            "title": "Start Fast, Validate Systematically",
            "partOf": "core-principles",
            "lines": "1300",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I balance speed and quality with AI?"
            ],
            "content": "**Decision:** AI-First (Generation) \u2192 Human Strategic Selection\n\n<CodeGroup>\n\n```text Prompt\n\"Given this content inventory, generate 3 different IA approaches:\n\n1. Task-based: Organize by what users want to accomplish\n2. Feature-based: Organize by CloudStore features\n3. Audience-based: Organize by user role (developer/product manager/support)\n\nFor each approach:\n- Provide 2-level hierarchy\n- Distribute 85 pages across categories\n- Show page counts and percentages\n- List 3 pros and 3 cons\n```\n\n```text AI Output (summary)\nAPPROACH 1: TASK-BASED\n\u251c\u2500\u2500 Get Started (12 pages, 14%)\n\u251c\u2500\u2500 Authenticate & Secure (15 pages, 18%)\n\u251c\u2500\u2500 Store & Manage Files (28 pages, 33%)\n\u251c\u2500\u2500 Integrate Webhooks (12 pages, 14%)\n\u2514\u2500\u2500 Monitor & Troubleshoot (18 pages, 21%)\n\nPros: Matches user goals, supports progressive disclosure, scalable\nCons: Some features span categories, requires more cross-links\n\nAPPROACH 2: FEATURE-BASED\n\u251c\u2500\u2500 Authentication (22 pages, 26%)\n\u251c\u2500\u2500 File Storage (35 pages, 41%)\n\u251c\u2500\u2500 Webhooks (15 pages, 18%)\n\u2514\u2500\u2500 Analytics (13 pages, 15%)\n\nPros: Mirrors product structure, familiar to internal team, simple\nCons: Doesn't match user tasks, \"File Storage\" too large, learning curve\n\nAPPROACH 3: AUDIENCE-BASED\n\u251c\u2500\u2500 For Backend Developers (45 pages, 53%)\n\u251c\u2500\u2500 For Frontend Developers (25 pages, 29%)\n\u2514\u2500\u2500 For Support Staff (15 pages, 18%)\n\nPros: Targeted content, clear audience signals\nCons: Duplicates content, hard to maintain, doesn't scale with roles\n```\n\n```text Human Decision (Strategic)\nSelected: APPROACH 1 (Task-Based)\n\nReasoning:\n\u2705 User research shows users think in tasks (\"I want to upload a file\")\n\u2705 Aligns with business goal (reduce support tickets via better findability)\n\u2705 Scales with product roadmap (new features fit existing task categories)\n\u2705 Competitor analysis: Best-practice pattern in API docs\n\u2705 No organizational constraints blocking this approach\n```\n\n</CodeGroup>\n\n**Time:** AI generation: 5 minutes | Human analysis & decision: 45 minutes | **Total: 50 minutes**\n\n---",
            "hydration_source_header": "Step 2: Generate IA Options",
            "hydration_method": "line_proximity"
          }
        ],
        "zones": [
          {
            "id": "ai-first-zone",
            "title": "AI-First Zone",
            "type": "zone",
            "definition": "Tasks where AI should lead with human validation",
            "contains": [
              "generation-tasks",
              "pattern-finding-tasks",
              "variation-creation-tasks"
            ],
            "lines": "47-260",
            "crossModule": true,
            "retrievalQuestions": [
              "What tasks should AI lead?",
              "What's in the AI-first zone?"
            ],
            "content": "These are tasks where AI provides the most value with minimal human input upfront. You provide direction, AI generates, you validate.\n\n#### A. Generation Tasks\n\n**What This Means:**\nCreating initial drafts, variations, or options that you'll refine.\n\n**Why AI Excels:**\n- Generates quickly at scale\n- Pulls from vast pattern library\n- No fatigue or creative blocks\n- Produces multiple variations easily\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **Taxonomy Generation** | Create initial hierarchical structure | \"Generate a 3-level taxonomy for e-commerce documentation with these 50 page titles\" |\n| **Navigation Label Variations** | Produce 10+ alternatives for testing | \"Create 15 different labels for the 'Developer Resources' section\" |\n| **Metadata Attributes** | List potential attributes for content types | \"What metadata fields should a tutorial page include?\" |\n| **Content Descriptions** | Write summaries for sitemap pages | \"Create 50-character descriptions for each of these navigation items\" |\n| **Search Synonyms** | Generate keyword variations | \"List 20 terms users might search for instead of 'API Authentication'\" |\n\n**Example Workflow: Navigation Label Generation**\n\n```text Step 1 (Human): Define context and constraints\n\"I need navigation labels for a section about API security. \nTarget audience: Junior developers. \nConstraint: Labels must be under 20 characters.\"\n```\n\n```text Step 2 (AI): Generate variations\nOutput:\n- API Security\n- Secure Your API\n- Security Guide\n- Auth & Security\n- Keep APIs Safe\n- Security Basics\n- Protect Your API\n- Security Best Practices\n- API Protection\n- Safe Integration\n```\n\n```text Step 3 (Human): Select and refine\nChoose top 3, test with users, select winner.\n```\n\n**When to Use AI-First for Generation:**\n- \u2705 You need volume (multiple options)\n- \u2705 Speed matters more than perfection\n- \u2705 You have clear validation criteria\n- \u2705 The task is pattern-based, not deeply strategic\n\n**When NOT to Use AI-First:**\n- \u274c The first draft needs to be nearly perfect\n- \u274c Highly specialized domain knowledge required\n- \u274c Strategic positioning or brand voice is critical\n- \u274c Legal or compliance considerations\n\n---\n\n#### B. Pattern Finding Tasks\n\n**What This Means:**\nIdentifying trends, inconsistencies, or structures in existing content.\n\n**Why AI Excels:**\n- Processes large volumes quickly\n- Doesn't miss patterns due to fatigue\n- No confirmation bias\n- Consistent classification criteria\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **Content Classification** | Categorize pages by type | \"Classify these 200 pages as Tutorial, Reference, Guide, or Concept\" |\n| **Inconsistency Detection** | Find naming variations | \"Identify inconsistent terminology across these documentation pages\" |\n| **Structure Pattern Analysis** | Recognize organizational approaches | \"What structural patterns appear in these 50 page titles?\" |\n| **Gap Identification** | Spot missing content areas | \"What topics are missing from this documentation set?\" |\n| **Redundancy Detection** | Find duplicate or overlapping content | \"Identify pages covering the same topics\" |\n\n**Example Workflow: Content Classification**\n\n```text Context\nYou have 300 documentation pages to classify using Di\u00e1taxis framework\n```\n\n```text Step 1 (Human): Prepare data and provide classification rules\nExport: Page titles + first 100 words of each page\nRules: Define each category clearly with examples\n```\n\n<CodeGroup>\n\n```text Step 2 (AI): Classify all pages\nPrompt: \"Classify each page as Tutorial (learning-oriented), \nHow-to Guide (task-oriented), Reference (information-oriented), \nor Explanation (understanding-oriented). \nProvide classification + brief reasoning.\"\n```\n\n```text Step 3 (Human): Spot-check results\nValidate ~20% randomly selected pages\nCheck edge cases manually\nReview AI's reasoning for uncertain classifications\n```\n\n```text Step 4 (Human + AI): Refine misclassifications\nAddress systematic errors in prompt\nReclassify problematic pages with more context\n```\n\n</CodeGroup>\n\n**Real Example Output:**\n\n```text AI Classifications\nPage: \"Getting Started with Authentication\"\nClassification: Tutorial\nReasoning: Step-by-step learning journey, assumes no prior knowledge, \nteaches by doing\n\nPage: \"Authentication Endpoint Reference\"  \nClassification: Reference\nReasoning: Technical specifications, lists all endpoints, \ndescribes what each does\n\nPage: \"How to Implement OAuth 2.0\"\nClassification: How-to Guide\nReasoning: Task-oriented, assumes some knowledge, \nfocuses on achieving specific goal\n\nPage: \"Understanding Token Expiration\"\nClassification: Explanation\nReasoning: Conceptual explanation, background knowledge, \nhelps understand why something works\n```\n\n<Tip>\n  **When to Use AI-First for Pattern Finding:**\n  - \u2705 Large content volumes (100+ items)\n  - \u2705 Repetitive classification criteria\n  - \u2705 Objective patterns (not subjective interpretation)\n  - \u2705 Speed is valuable\n</Tip>\n\n<Warning>\n  **When NOT to Use AI-First:**\n  - \u274c Nuanced interpretation required\n  - \u274c Small dataset (easier to do manually)\n  - \u274c Complex, multifaceted categorization\n  - \u274c Deep domain expertise needed per item\n</Warning>\n\n---\n\n#### C. Variation Creation Tasks\n\n**What This Means:**\nGenerating multiple versions of the same concept for testing or exploration.\n\n**Why AI Excels:**\n- Creates variations without creativity fatigue\n- Produces systematically different approaches\n- Generates quickly in bulk\n- Offers perspectives you might not consider\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **A/B Testing Options** | Create variations for testing | \"Generate 5 different ways to structure this navigation\" |\n| **Perspective Shifting** | View problem from different angles | \"How would a novice vs. expert organize this content?\" |\n| **Label Testing** | Produce terminology variations | \"Create synonyms for each of these technical terms\" |\n| **Organizational Approaches** | Try different IA models | \"Organize this content by: task, role, product, and topic\" |\n\n**Example Workflow: Navigation Structure Variations**\n\n<CodeGroup>\n\n```text Step 1 (Human): Define the scope\nContent inventory: 75 documentation pages\nUser types: Developers, product managers, support staff\nBusiness goal: Reduce time-to-answer\n```\n\n```text Step 2 (AI): Generate 4 different structures\nPrompt: \"Create 4 different navigation structures for this documentation:\n1. Task-based (organized by what users want to do)\n2. Role-based (organized by user type)  \n3. Product-feature-based (organized by product components)\n4. Journey-based (organized by user maturity: beginner \u2192 advanced)\n\nFor each, provide the top 2 levels of hierarchy.\"\n```\n\n</CodeGroup>\n\n```text Step 3 (AI Output)\n1. TASK-BASED:\n   \u251c\u2500\u2500 Get Started\n   \u251c\u2500\u2500 Integrate\n   \u251c\u2500\u2500 Configure\n   \u251c\u2500\u2500 Monitor\n   \u2514\u2500\u2500 Troubleshoot\n\n2. ROLE-BASED:\n   \u251c\u2500\u2500 For Developers\n   \u251c\u2500\u2500 For Product Managers\n   \u251c\u2500\u2500 For Support Staff\n   \u2514\u2500\u2500 For Administrators\n\n3. PRODUCT-FEATURE-BASED:\n   \u251c\u2500\u2500 Authentication\n   \u251c\u2500\u2500 Data Management\n   \u251c\u2500\u2500 APIs\n   \u2514\u2500\u2500 Reporting\n\n4. JOURNEY-BASED:\n   \u251c\u2500\u2500 Beginner (First Steps)\n   \u251c\u2500\u2500 Intermediate (Common Tasks)\n   \u251c\u2500\u2500 Advanced (Optimization)\n   \u2514\u2500\u2500 Expert (Architecture)\n```\n\n```text Step 4 (Human): Evaluate and test\n- Which aligns with user research?\n- Which scales best with future features?\n- Test top 2 options with users\n- Select final approach\n```\n\n<Tip>\n  **Pro Tip:** When generating variations, ask AI to explain the trade-offs of each approach. This helps you understand implications before testing.\n</Tip>\n\n---",
            "hydration_source_header": "1.1 AI-First Zone: Tasks Best for AI",
            "hydration_method": "title_match"
          },
          {
            "id": "human-first-zone",
            "title": "Human-First Zone",
            "type": "zone",
            "definition": "Tasks requiring human judgment, empathy, or ethical consideration",
            "contains": [
              "strategic-decisions",
              "user-empathy-research",
              "ethical-judgment"
            ],
            "lines": "262-450",
            "crossModule": true,
            "retrievalQuestions": [
              "What tasks should humans lead?",
              "When should I NOT use AI?"
            ],
            "content": "These tasks require human judgment, empathy, or strategic thinking. AI might provide supporting information, but humans must lead.\n\n#### A. Strategic Decisions\n\n**What This Means:**\nHigh-level choices that shape the entire IA direction and align with business goals.\n\n**Why Humans Must Lead:**\n- Requires business context AI doesn't have\n- Involves trade-offs AI can't evaluate\n- Connects to broader organizational strategy\n- Has long-term implications beyond immediate task\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **IA Approach Selection** | Choose task-based vs. topic-based structure | Requires understanding user mental models from research |\n| **Scope Definition** | Decide what content to include/exclude | Requires business priorities and resource constraints |\n| **Stakeholder Alignment** | Get buy-in from product, engineering, marketing | Requires negotiation and relationship management |\n| **Governance Model** | Define who maintains what content | Requires org structure knowledge |\n| **Success Metrics** | Define what \"good IA\" means for your context | Requires business goal alignment |\n\n**Example: Strategic IA Decision**\n\n<Accordion title=\"Scenario: Organizing API Documentation\">\n\n**Question:** Should you organize by endpoint or by use case?\n\n**AI Can Help:**\n- Generate both structures for comparison\n- List pros/cons of each approach  \n- Show examples from similar products\n- Identify potential issues with each\n\n**Humans Must Decide Based On:**\n- \u2705 User research: How do YOUR users think about the product?\n- \u2705 Business goals: Are you selling solutions or technical features?\n- \u2705 Competitive positioning: How do competitors organize (and should you differ)?\n- \u2705 Product roadmap: Which structure scales better with planned features?\n- \u2705 Resource constraints: Which is more maintainable with your team?\n- \u2705 Technical constraints: What does your CMS support?\n\n**The Decision:** Humans synthesize these factors (which AI can't access or weigh)\n\n</Accordion>\n\n<Warning>\n  **Red Flags That This Is Human-First:**\n  - The phrase \"it depends\" applies heavily\n  - Multiple stakeholders have different preferences\n  - Trade-offs involve business strategy\n  - Decision has multi-year implications\n  - Requires knowledge of internal constraints\n</Warning>\n\n---\n\n#### B. User Empathy and Research Interpretation\n\n**What This Means:**\nUnderstanding user needs, behaviors, emotions, and mental models through research.\n\n**Why Humans Must Lead:**\n- Empathy requires human connection\n- Context and nuance matter enormously\n- Research uncovers unexpected insights\n- Follow-up questions are critical\n- Non-verbal cues inform understanding\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **User Interviews** | Conduct interviews, probe deeper | Requires empathy, reading between lines, following unexpected threads |\n| **Mental Model Mapping** | Understand how users conceptualize information | Requires synthesis of behavior + stated preferences + context |\n| **Usability Testing** | Observe users interacting with IA | Requires noting frustration, confusion, surprise |\n| **Card Sorting Interpretation** | Understand why users grouped content | Requires understanding reasoning, not just patterns |\n| **Research Synthesis** | Turn findings into IA principles | Requires weighing contradictions, identifying priorities |\n\n**Example: Card Sorting Analysis**\n\n**What AI Can Do:**\n\nAI Can Help:\n- Identify most common groupings\n- Calculate similarity matrices  \n- Cluster related cards\n- Generate initial category suggestions\n- Find outlier groupings\n\n**What Humans Must Do:**\n\nHumans Must Interpret:\n- \u2705 Why did 8 participants create an \"Advanced\" category but define it differently?\n- \u2705 What does it mean that 12 participants couldn't categorize \"Webhooks\"?\n- \u2705 When participants wrote notes like \"I'm not sure where this goes,\" what does that tell us?\n- \u2705 How do contradictions in sorting reflect different user roles or expertise?\n- \u2705 Which patterns reflect actual mental models vs. exposure to competitors?\n\n<Tip>\n**The Insight:** The confusion around \"Webhooks\" reveals a fundamental education gap, not just a categorization problem. (AI would miss this insight.)\n</Tip>\n\n**Example: Interview Analysis**\n\n<CodeGroup>\n\n```text Participant Quote\n\"I usually just search for what I need, but half the time \nI can't find it even though I know it exists.\"\n```\n\n```text AI Analysis (Surface Level)\nUser prefers search. Search functionality needs improvement.\n```\n\n```text Human Interpretation (Deep)\n\u2705 Why is search failing? (Labels don't match user language?)\n\u2705 What does \"even though I know it exists\" reveal? \n   (Findability problem, not availability)\n\u2705 What emotion is expressed? (Frustration\u2014indicates high-priority problem)\n\u2705 What's the underlying need? (Confidence in search results, not just better algorithm)\n\u2705 Follow-up questions needed: \"Tell me about the last time this happened...\"\n```\n\n</CodeGroup>\n\n<Tip>\n  **The Pattern:** AI can identify what users said; humans understand what users meant and felt.\n</Tip>\n\n---\n\n#### C. Ethical Judgment and Responsibility\n\n**What This Means:**\nMaking decisions that affect user wellbeing, accessibility, inclusivity, and fairness.\n\n**Why Humans Must Lead:**\n- Requires values and moral reasoning\n- Involves considering harm and benefit\n- Needs understanding of social context\n- Must account for diverse user needs\n- Requires legal/compliance knowledge\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **Accessibility Design** | Ensure IA works for users with disabilities | Requires understanding WCAG, testing with assistive tech, empathy for diverse needs |\n| **Plain Language** | Make complex content understandable | Requires knowing your users' reading levels, cultural context, domain knowledge |\n| **Content Sensitivity** | Handle sensitive topics appropriately | Requires cultural awareness, understanding potential harm, legal knowledge |\n| **Inclusive Terminology** | Choose language that doesn't exclude | Requires awareness of marginalized groups, evolving language norms |\n| **Privacy Considerations** | Protect user data in IA decisions | Requires understanding privacy laws, data ethics, consent |\n\n**Example: Accessibility Decisions**\n\n<CodeGroup>\n\n```text AI Suggestion\nNavigation labels:\n- \"Authenticate Programmatically\"\n- \"Implement Authorization Logic\"\n- \"Configure OAuth Flows\"\n\nAI evaluation: \"Clear and descriptive\" (based on length and keywords)\n```\n\n```text Human Accessibility Analysis\nProblems:\n- Technical jargon assumes expert knowledge\n- Not clear to screen reader users\n- Cognitive load too high for beginners\n- Doesn't use plain language\n\nBetter:\n- \"Sign In to Your App\"\n- \"Control Access to Features\"  \n- \"Set Up Login with OAuth\"\n\nHuman ensures: Screen reader friendly, cognitively accessible, plain language\n```\n\n</CodeGroup>\n\n**Example: Ethical Content Organization**\n\n<Accordion title=\"Scenario: Organizing Health Information\">\n\n**Question:** How should you categorize content about medical conditions?\n\n**AI Suggestion:**\n- Organize alphabetically by condition name\n- Group by severity (minor, moderate, severe)\n- Sort by body system (cardiovascular, respiratory, etc.)\n\n**Ethical Considerations (Human):**\n- \u2705 Will organizing by \"severity\" cause anxiety for users seeking information?\n- \u2705 Does alphabetical grouping make emergency information hard to find?\n- \u2705 Are we using person-first language throughout?\n- \u2705 Do category names avoid stigmatizing conditions?\n- \u2705 Is mental health treated with equal prominence to physical health?\n- \u2705 Are we providing equal depth for conditions affecting marginalized groups?\n\n**The Decision:** Humans weigh these ethical implications, which require values and understanding of social impact.\n\n</Accordion>\n\n<Warning>\n  **Red Flags That This Is Human-First:**\n  - \"Should we\" questions (not just \"can we\")\n  - Impacts on vulnerable populations\n  - Legal or compliance requirements\n  - Potential for harm or discrimination\n  - Values-based trade-offs\n</Warning>\n\n---",
            "hydration_source_header": "1.2 Human-First Zone: Tasks Best for Humans",
            "hydration_method": "title_match"
          },
          {
            "id": "collaborative-zone",
            "title": "Collaborative Zone",
            "type": "zone",
            "definition": "Tasks best done through AI-human iteration",
            "contains": [
              "iterative-refinement",
              "validation-qa",
              "complex-problem-solving"
            ],
            "lines": "452-600",
            "crossModule": true,
            "retrievalQuestions": [
              "When do I need AI-human collaboration?",
              "What tasks require iteration?"
            ],
            "content": "These tasks benefit from tight back-and-forth between AI and human. Neither can do it alone efficiently.\n\n#### A. Iterative Refinement\n\n**What This Means:**\nStarting with AI generation, then refining through multiple rounds of human feedback and AI regeneration.\n\n**Why Collaboration Works:**\n- AI provides fast first drafts\n- Humans identify issues\n- AI incorporates feedback quickly\n- Humans validate improvements\n- Repeat until satisfactory\n\n**IA Applications:**\n\n| Task | Collaboration Pattern | Example |\n|------|----------------------|---------|\n| **Taxonomy Refinement** | AI generates \u2192 Human critiques \u2192 AI adjusts | \"Flatten this level, merge these categories, split that one\" |\n| **Label Optimization** | AI suggests \u2192 Human tests \u2192 AI revises | \"Too technical, make it plainer\" \u2192 AI rewrites \u2192 test again |\n| **Content Model Development** | AI proposes attributes \u2192 Human adds constraints \u2192 AI regenerates | \"Add required vs. optional flags, include character limits\" |\n| **Navigation Hierarchy** | AI builds structure \u2192 Human identifies gaps \u2192 AI fills | \"What about troubleshooting content?\" \u2192 AI adds category |\n\n**Example Workflow: Taxonomy Refinement**\n\n<CodeGroup>\n\n```text Round 1 (AI): Generate initial taxonomy\nPrompt: \"Create a 3-level taxonomy for 100 API documentation pages covering \nauthentication, payments, webhooks, and analytics.\"\n\nOutput:\n\u251c\u2500\u2500 Authentication (25 pages)\n\u2502   \u251c\u2500\u2500 Methods\n\u2502   \u251c\u2500\u2500 OAuth\n\u2502   \u2514\u2500\u2500 Security\n\u251c\u2500\u2500 Payments (35 pages)\n\u2502   \u251c\u2500\u2500 Processing\n\u2502   \u251c\u2500\u2500 Subscriptions\n\u2502   \u2514\u2500\u2500 Refunds\n\u251c\u2500\u2500 Webhooks (20 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u251c\u2500\u2500 Events\n\u2502   \u2514\u2500\u2500 Troubleshooting\n\u2514\u2500\u2500 Analytics (20 pages)\n    \u251c\u2500\u2500 Tracking\n    \u251c\u2500\u2500 Reports\n    \u2514\u2500\u2500 Dashboards\n```\n\n```text Round 2 (Human): Critique\nIssues identified:\n1. \"Payments\" at 35% is unbalanced\n2. \"Analytics\" feels like it should be under \"Webhooks\" \n   (webhook events generate analytics)\n3. Missing \"Getting Started\" section\n4. \"Security\" could be its own top-level (cross-cutting concern)\n```\n\n```text Round 3 (AI): Refine based on feedback\nPrompt: \"Adjust the taxonomy:\n1. Split 'Payments' into 'Payments' and 'Subscriptions' at top level\n2. Move 'Analytics' under 'Webhooks'\n3. Add 'Getting Started' as first top-level category\n4. Promote 'Security' to top level, covering auth security, payment security\"\n\nOutput:\n\u251c\u2500\u2500 Getting Started (8 pages)\n\u2502   \u251c\u2500\u2500 Quick Start\n\u2502   \u2514\u2500\u2500 Core Concepts\n\u251c\u2500\u2500 Authentication (18 pages)\n\u2502   \u251c\u2500\u2500 Methods\n\u2502   \u2514\u2500\u2500 OAuth\n\u251c\u2500\u2500 Payments (22 pages)\n\u2502   \u251c\u2500\u2500 Processing\n\u2502   \u2514\u2500\u2500 Refunds\n\u251c\u2500\u2500 Subscriptions (13 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u2514\u2500\u2500 Management\n\u251c\u2500\u2500 Webhooks (20 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u251c\u2500\u2500 Events\n\u2502   \u251c\u2500\u2500 Analytics\n\u2502   \u2514\u2500\u2500 Troubleshooting\n\u2514\u2500\u2500 Security (19 pages)\n    \u251c\u2500\u2500 Authentication Security\n    \u251c\u2500\u2500 Payment Security\n    \u2514\u2500\u2500 Best Practices\n```\n\n```text Round 4 (Human): Validate\nMuch better! Balanced (no category >25%), logical structure.\nFinal check: Test with 3 users navigating to common tasks.\n```\n\n</CodeGroup>\n\n<Tip>\n  **Iteration Best Practices:**\n  1. **Be specific in critiques:** Not \"this doesn't work\" but \"this is too vague for beginners\"\n  2. **Iterate in chunks:** Don't try to fix everything at once\n  3. **Set a stopping point:** Know when \"good enough\" is sufficient\n  4. **Document your prompts:** Save the winning prompt for future use\n</Tip>\n\n---\n\n#### B. Validation and Quality Assurance\n\n**What This Means:**\nAI generates, humans validate systematically, AI fixes identified issues.\n\n**Why Collaboration Works:**\n- AI produces volume quickly\n- Humans catch errors AI can't see\n- AI fixes errors quickly at scale\n- Humans verify fixes\n\n**IA Applications:**\n\n| Task | Collaboration Pattern | Example |\n|------|----------------------|---------|\n| **Consistency Checking** | AI identifies inconsistencies \u2192 Human confirms \u2192 AI standardizes | \"Fix all instances of 'log in' vs 'login'\" |\n| **Completeness Validation** | AI checks structure \u2192 Human adds missing elements \u2192 AI regenerates | \"Every category needs a landing page description\" |\n| **Link Relationship Mapping** | AI suggests relationships \u2192 Human validates relevance \u2192 AI builds map | \"Should 'OAuth Guide' link to 'Token Management'?\" |\n| **Metadata Validation** | AI checks schema adherence \u2192 Human fixes edge cases \u2192 AI revalidates | \"This page is missing required metadata\" |\n\n**Example Workflow: Metadata Validation**\n\n<Accordion title=\"Complete Workflow Example\">\n\n**Context:** You've defined a metadata schema for 200 documentation pages.\n\n**Required fields:** title, description, content_type, audience, last_updated  \n**Optional fields:** related_pages, prerequisites, estimated_time\n\n**Step 1 (AI): Validate all pages against schema**\n\n```text Prompt\n\"Check each page for required metadata. List any missing fields.\"\n```\n\n```text Output\nPages missing required metadata:\n- Page 47: Missing 'audience'\n- Page 89: Missing 'content_type' and 'description'  \n- Page 102: Missing 'last_updated'\n- Page 134: Missing 'content_type'\n[15 more pages with issues...]\n```\n\n**Step 2 (Human): Review and triage**\n- Most missing \"audience\" can be inferred from content\n- Missing \"content_type\" needs human judgment (Tutorial vs. Guide vs. Reference)\n- Missing \"last_updated\" can be pulled from CMS\n\n**Step 3 (AI): Fill in what it can**\n\n```text Prompt\n\"For pages missing 'audience', analyze content and suggest appropriate audience \n(developers, product managers, or support staff). For pages missing 'description', \ngenerate 150-character summaries.\"\n```\n\n**Step 4 (Human): Handle what AI can't**\nManually classify pages by content_type (requires understanding Di\u00e1taxis framework nuances)\n\n**Step 5 (AI): Final validation**\n\n```text Prompt\n\"Recheck all 200 pages. Confirm all required fields are now present.\"\n```\n\n</Accordion>\n\n<Tip>\n  **When to Use Collaborative Validation:**\n  - \u2705 Large datasets where manual checking is slow\n  - \u2705 Clear validation rules exist\n  - \u2705 Some cases need judgment, others don't\n  - \u2705 Iterative improvement is acceptable\n</Tip>\n\n---\n\n#### C. Complex Problem Solving\n\n**What This Means:**\nBreaking down complex IA problems into steps, using AI for some steps and human judgment for others.\n\n**Why Collaboration Works:**\n- Humans decompose the problem strategically\n- AI handles analytical/repetitive substeps\n- Humans synthesize findings\n- AI helps scale the solution\n\n**Example: Complete Documentation IA Audit**\n\n<Accordion title=\"Full Case Study: Software Documentation IA Audit\">\n\n**Context:** 250-page developer documentation site with known findability issues.\n\n**Goal:** Audit content, identify problems, recommend improvements.\n\n#### Phase 1: Content Audit\n\n| Task | Owner | Why |\n|------|-------|-----|\n| Extract all page titles, URLs, metadata | **AI** | Mechanical data collection |\n| Classify pages by content type (Di\u00e1taxis) | **AI** | Pattern recognition at scale |\n| Identify duplicate/redundant content | **AI** | Pattern matching |\n| Calculate content freshness | **AI** | Date analysis |\n| Review audit results for accuracy | **Human** | Validation, context |\n| Identify strategic content gaps | **Human** | Requires domain knowledge |\n| Prioritize which gaps to fill | **Human** | Business strategy |\n\n**What AI Did Well:**\n```\nAI Analysis Output:\n- 250 pages classified:\n  * 45 Tutorials\n  * 82 How-to Guides  \n  * 98 Reference pages\n  * 25 Explanations\n- Identified 18 pairs of redundant content\n- Found 45 pages not updated in 2+ years\n- Detected inconsistent terminology (12 variations of \"authentication\")\n```\n\n**What AI Missed (Human Caught):**\n- AI classified \"Troubleshooting Webhooks\" as How-to Guide\n  Human: Actually a Reference (lists error codes)\n- AI flagged \"Intro to REST\" and \"REST API Basics\" as redundant\n  Human: Different audiences (beginners vs. experienced)\n- AI said content is \"outdated\" based on dates alone\n  Human: Some reference content is timeless; tutorials need updates\n\n**Outcome:** AI accelerated audit from 2 weeks \u2192 3 days, but human validation was essential.\n\n#### Phase 2: Navigation Analysis\n\n| Task | Owner | Why |\n|------|-------|-----|\n| Map current navigation structure | **AI** | Data extraction |\n| Identify navigation inconsistencies | **AI** | Pattern detection |\n| Calculate navigation depth metrics | **AI** | Quantitative analysis |\n| Analyze user search queries | **AI** | Pattern analysis at scale |\n| Compare navigation to user mental models | **Human** | Requires user research interpretation |\n| Identify navigation-search gaps | **Human** | Strategic insight |\n| Recommend navigation changes | **Human** | Strategic decision |\n\n**What AI Did Well:**\n```\n- Current structure: 7 top-level categories, max depth 5 levels\n- Found 23 pages buried 4+ levels deep (low discoverability)\n- Identified 45 search queries with 0 results despite relevant pages existing\n- Detected 8 pages accessible via multiple paths (ambiguous placement)\n```\n\n**What Human Decided:**\n- Reduce to 5 top-level categories (based on user research)\n- Flatten hierarchy to max 3 levels\n- Reorganize from feature-based to task-based structure\n- Create cross-links for genuinely multi-purpose content\n\n#### Phase 3: Recommendations\n\n| Task | Owner | Why |\n|------|-------|-----|\n| Generate initial recommendations | **AI** | Based on patterns found |\n| Estimate effort for each recommendation | **AI** | Pattern-based estimates |\n| Prioritize by impact vs. effort | **Human** | Strategic prioritization |\n| Create implementation plan | **Human** | Requires resource knowledge |\n| Draft executive summary | **AI** | Synthesis of findings |\n| Finalize executive summary | **Human** | Messaging for stakeholders |\n\n**Final Deliverable (Collaborative):**\n- 12-page audit report (AI drafted, human refined)\n- Prioritized action plan with 23 recommendations\n- Quick wins (3 items, less than 1 week each)\n- High-impact changes (5 items, 2-4 weeks each)\n- Strategic initiatives (4 items, multi-month)\n\n**Time Saved:**\nTraditional audit: 3-4 weeks\nAI-assisted audit: 1 week\n**Savings: 66-75%**\n\n</Accordion>\n\n<Tip>\n  **The Pattern for Complex Problems:**\n  1. Human: Decompose into steps\n  2. AI: Handle analytical/scale-dependent steps\n  3. Human: Validate AI outputs at each step\n  4. AI: Synthesize findings\n  5. Human: Make strategic decisions\n  6. AI: Scale the solution\n</Tip>\n\n---",
            "hydration_source_header": "1.3 Collaborative Zone: Tasks Requiring Iteration",
            "hydration_method": "title_match"
          }
        ],
        "taskCategories": [
          {
            "id": "generation-tasks",
            "title": "Generation Tasks",
            "zone": "ai-first-zone",
            "lines": "55-115",
            "crossModule": true,
            "retrievalQuestions": [
              "What generation tasks can AI do?"
            ],
            "content": "**What This Means:**\nCreating initial drafts, variations, or options that you'll refine.\n\n**Why AI Excels:**\n- Generates quickly at scale\n- Pulls from vast pattern library\n- No fatigue or creative blocks\n- Produces multiple variations easily\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **Taxonomy Generation** | Create initial hierarchical structure | \"Generate a 3-level taxonomy for e-commerce documentation with these 50 page titles\" |\n| **Navigation Label Variations** | Produce 10+ alternatives for testing | \"Create 15 different labels for the 'Developer Resources' section\" |\n| **Metadata Attributes** | List potential attributes for content types | \"What metadata fields should a tutorial page include?\" |\n| **Content Descriptions** | Write summaries for sitemap pages | \"Create 50-character descriptions for each of these navigation items\" |\n| **Search Synonyms** | Generate keyword variations | \"List 20 terms users might search for instead of 'API Authentication'\" |\n\n**Example Workflow: Navigation Label Generation**\n\n```text Step 1 (Human): Define context and constraints\n\"I need navigation labels for a section about API security. \nTarget audience: Junior developers. \nConstraint: Labels must be under 20 characters.\"\n```\n\n```text Step 2 (AI): Generate variations\nOutput:\n- API Security\n- Secure Your API\n- Security Guide\n- Auth & Security\n- Keep APIs Safe\n- Security Basics\n- Protect Your API\n- Security Best Practices\n- API Protection\n- Safe Integration\n```\n\n```text Step 3 (Human): Select and refine\nChoose top 3, test with users, select winner.\n```\n\n**When to Use AI-First for Generation:**\n- \u2705 You need volume (multiple options)\n- \u2705 Speed matters more than perfection\n- \u2705 You have clear validation criteria\n- \u2705 The task is pattern-based, not deeply strategic\n\n**When NOT to Use AI-First:**\n- \u274c The first draft needs to be nearly perfect\n- \u274c Highly specialized domain knowledge required\n- \u274c Strategic positioning or brand voice is critical\n- \u274c Legal or compliance considerations\n\n---",
            "hydration_source_header": "A. Generation Tasks",
            "hydration_method": "title_match"
          },
          {
            "id": "pattern-finding-tasks",
            "title": "Pattern Finding Tasks",
            "zone": "ai-first-zone",
            "lines": "117-190",
            "crossModule": true,
            "retrievalQuestions": [
              "How can AI find patterns?"
            ],
            "content": "**What This Means:**\nIdentifying trends, inconsistencies, or structures in existing content.\n\n**Why AI Excels:**\n- Processes large volumes quickly\n- Doesn't miss patterns due to fatigue\n- No confirmation bias\n- Consistent classification criteria\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **Content Classification** | Categorize pages by type | \"Classify these 200 pages as Tutorial, Reference, Guide, or Concept\" |\n| **Inconsistency Detection** | Find naming variations | \"Identify inconsistent terminology across these documentation pages\" |\n| **Structure Pattern Analysis** | Recognize organizational approaches | \"What structural patterns appear in these 50 page titles?\" |\n| **Gap Identification** | Spot missing content areas | \"What topics are missing from this documentation set?\" |\n| **Redundancy Detection** | Find duplicate or overlapping content | \"Identify pages covering the same topics\" |\n\n**Example Workflow: Content Classification**\n\n```text Context\nYou have 300 documentation pages to classify using Di\u00e1taxis framework\n```\n\n```text Step 1 (Human): Prepare data and provide classification rules\nExport: Page titles + first 100 words of each page\nRules: Define each category clearly with examples\n```\n\n<CodeGroup>\n\n```text Step 2 (AI): Classify all pages\nPrompt: \"Classify each page as Tutorial (learning-oriented), \nHow-to Guide (task-oriented), Reference (information-oriented), \nor Explanation (understanding-oriented). \nProvide classification + brief reasoning.\"\n```\n\n```text Step 3 (Human): Spot-check results\nValidate ~20% randomly selected pages\nCheck edge cases manually\nReview AI's reasoning for uncertain classifications\n```\n\n```text Step 4 (Human + AI): Refine misclassifications\nAddress systematic errors in prompt\nReclassify problematic pages with more context\n```\n\n</CodeGroup>\n\n**Real Example Output:**\n\n```text AI Classifications\nPage: \"Getting Started with Authentication\"\nClassification: Tutorial\nReasoning: Step-by-step learning journey, assumes no prior knowledge, \nteaches by doing\n\nPage: \"Authentication Endpoint Reference\"  \nClassification: Reference\nReasoning: Technical specifications, lists all endpoints, \ndescribes what each does\n\nPage: \"How to Implement OAuth 2.0\"\nClassification: How-to Guide\nReasoning: Task-oriented, assumes some knowledge, \nfocuses on achieving specific goal\n\nPage: \"Understanding Token Expiration\"\nClassification: Explanation\nReasoning: Conceptual explanation, background knowledge, \nhelps understand why something works\n```\n\n<Tip>\n  **When to Use AI-First for Pattern Finding:**\n  - \u2705 Large content volumes (100+ items)\n  - \u2705 Repetitive classification criteria\n  - \u2705 Objective patterns (not subjective interpretation)\n  - \u2705 Speed is valuable\n</Tip>\n\n<Warning>\n  **When NOT to Use AI-First:**\n  - \u274c Nuanced interpretation required\n  - \u274c Small dataset (easier to do manually)\n  - \u274c Complex, multifaceted categorization\n  - \u274c Deep domain expertise needed per item\n</Warning>\n\n---",
            "hydration_source_header": "B. Pattern Finding Tasks",
            "hydration_method": "title_match"
          },
          {
            "id": "variation-creation-tasks",
            "title": "Variation Creation Tasks",
            "zone": "ai-first-zone",
            "lines": "192-260",
            "crossModule": true,
            "retrievalQuestions": [
              "Can AI create variations?"
            ],
            "content": "**What This Means:**\nGenerating multiple versions of the same concept for testing or exploration.\n\n**Why AI Excels:**\n- Creates variations without creativity fatigue\n- Produces systematically different approaches\n- Generates quickly in bulk\n- Offers perspectives you might not consider\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **A/B Testing Options** | Create variations for testing | \"Generate 5 different ways to structure this navigation\" |\n| **Perspective Shifting** | View problem from different angles | \"How would a novice vs. expert organize this content?\" |\n| **Label Testing** | Produce terminology variations | \"Create synonyms for each of these technical terms\" |\n| **Organizational Approaches** | Try different IA models | \"Organize this content by: task, role, product, and topic\" |\n\n**Example Workflow: Navigation Structure Variations**\n\n<CodeGroup>\n\n```text Step 1 (Human): Define the scope\nContent inventory: 75 documentation pages\nUser types: Developers, product managers, support staff\nBusiness goal: Reduce time-to-answer\n```\n\n```text Step 2 (AI): Generate 4 different structures\nPrompt: \"Create 4 different navigation structures for this documentation:\n1. Task-based (organized by what users want to do)\n2. Role-based (organized by user type)  \n3. Product-feature-based (organized by product components)\n4. Journey-based (organized by user maturity: beginner \u2192 advanced)\n\nFor each, provide the top 2 levels of hierarchy.\"\n```\n\n</CodeGroup>\n\n```text Step 3 (AI Output)\n1. TASK-BASED:\n   \u251c\u2500\u2500 Get Started\n   \u251c\u2500\u2500 Integrate\n   \u251c\u2500\u2500 Configure\n   \u251c\u2500\u2500 Monitor\n   \u2514\u2500\u2500 Troubleshoot\n\n2. ROLE-BASED:\n   \u251c\u2500\u2500 For Developers\n   \u251c\u2500\u2500 For Product Managers\n   \u251c\u2500\u2500 For Support Staff\n   \u2514\u2500\u2500 For Administrators\n\n3. PRODUCT-FEATURE-BASED:\n   \u251c\u2500\u2500 Authentication\n   \u251c\u2500\u2500 Data Management\n   \u251c\u2500\u2500 APIs\n   \u2514\u2500\u2500 Reporting\n\n4. JOURNEY-BASED:\n   \u251c\u2500\u2500 Beginner (First Steps)\n   \u251c\u2500\u2500 Intermediate (Common Tasks)\n   \u251c\u2500\u2500 Advanced (Optimization)\n   \u2514\u2500\u2500 Expert (Architecture)\n```\n\n```text Step 4 (Human): Evaluate and test\n- Which aligns with user research?\n- Which scales best with future features?\n- Test top 2 options with users\n- Select final approach\n```\n\n<Tip>\n  **Pro Tip:** When generating variations, ask AI to explain the trade-offs of each approach. This helps you understand implications before testing.\n</Tip>\n\n---",
            "hydration_source_header": "C. Variation Creation Tasks",
            "hydration_method": "title_match"
          },
          {
            "id": "strategic-decisions",
            "title": "Strategic Decisions",
            "zone": "human-first-zone",
            "lines": "268-330",
            "crossModule": true,
            "retrievalQuestions": [
              "What strategic decisions require humans?"
            ],
            "content": "**What This Means:**\nHigh-level choices that shape the entire IA direction and align with business goals.\n\n**Why Humans Must Lead:**\n- Requires business context AI doesn't have\n- Involves trade-offs AI can't evaluate\n- Connects to broader organizational strategy\n- Has long-term implications beyond immediate task\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **IA Approach Selection** | Choose task-based vs. topic-based structure | Requires understanding user mental models from research |\n| **Scope Definition** | Decide what content to include/exclude | Requires business priorities and resource constraints |\n| **Stakeholder Alignment** | Get buy-in from product, engineering, marketing | Requires negotiation and relationship management |\n| **Governance Model** | Define who maintains what content | Requires org structure knowledge |\n| **Success Metrics** | Define what \"good IA\" means for your context | Requires business goal alignment |\n\n**Example: Strategic IA Decision**\n\n<Accordion title=\"Scenario: Organizing API Documentation\">\n\n**Question:** Should you organize by endpoint or by use case?\n\n**AI Can Help:**\n- Generate both structures for comparison\n- List pros/cons of each approach  \n- Show examples from similar products\n- Identify potential issues with each\n\n**Humans Must Decide Based On:**\n- \u2705 User research: How do YOUR users think about the product?\n- \u2705 Business goals: Are you selling solutions or technical features?\n- \u2705 Competitive positioning: How do competitors organize (and should you differ)?\n- \u2705 Product roadmap: Which structure scales better with planned features?\n- \u2705 Resource constraints: Which is more maintainable with your team?\n- \u2705 Technical constraints: What does your CMS support?\n\n**The Decision:** Humans synthesize these factors (which AI can't access or weigh)\n\n</Accordion>\n\n<Warning>\n  **Red Flags That This Is Human-First:**\n  - The phrase \"it depends\" applies heavily\n  - Multiple stakeholders have different preferences\n  - Trade-offs involve business strategy\n  - Decision has multi-year implications\n  - Requires knowledge of internal constraints\n</Warning>\n\n---",
            "hydration_source_header": "A. Strategic Decisions",
            "hydration_method": "title_match"
          },
          {
            "id": "user-empathy-research",
            "title": "User Empathy and Research Interpretation",
            "zone": "human-first-zone",
            "lines": "332-400",
            "crossModule": true,
            "retrievalQuestions": [
              "Why can't AI interpret user research alone?"
            ],
            "content": "**What This Means:**\nUnderstanding user needs, behaviors, emotions, and mental models through research.\n\n**Why Humans Must Lead:**\n- Empathy requires human connection\n- Context and nuance matter enormously\n- Research uncovers unexpected insights\n- Follow-up questions are critical\n- Non-verbal cues inform understanding\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **User Interviews** | Conduct interviews, probe deeper | Requires empathy, reading between lines, following unexpected threads |\n| **Mental Model Mapping** | Understand how users conceptualize information | Requires synthesis of behavior + stated preferences + context |\n| **Usability Testing** | Observe users interacting with IA | Requires noting frustration, confusion, surprise |\n| **Card Sorting Interpretation** | Understand why users grouped content | Requires understanding reasoning, not just patterns |\n| **Research Synthesis** | Turn findings into IA principles | Requires weighing contradictions, identifying priorities |\n\n**Example: Card Sorting Analysis**\n\n**What AI Can Do:**\n\nAI Can Help:\n- Identify most common groupings\n- Calculate similarity matrices  \n- Cluster related cards\n- Generate initial category suggestions\n- Find outlier groupings\n\n**What Humans Must Do:**\n\nHumans Must Interpret:\n- \u2705 Why did 8 participants create an \"Advanced\" category but define it differently?\n- \u2705 What does it mean that 12 participants couldn't categorize \"Webhooks\"?\n- \u2705 When participants wrote notes like \"I'm not sure where this goes,\" what does that tell us?\n- \u2705 How do contradictions in sorting reflect different user roles or expertise?\n- \u2705 Which patterns reflect actual mental models vs. exposure to competitors?\n\n<Tip>\n**The Insight:** The confusion around \"Webhooks\" reveals a fundamental education gap, not just a categorization problem. (AI would miss this insight.)\n</Tip>\n\n**Example: Interview Analysis**\n\n<CodeGroup>\n\n```text Participant Quote\n\"I usually just search for what I need, but half the time \nI can't find it even though I know it exists.\"\n```\n\n```text AI Analysis (Surface Level)\nUser prefers search. Search functionality needs improvement.\n```\n\n```text Human Interpretation (Deep)\n\u2705 Why is search failing? (Labels don't match user language?)\n\u2705 What does \"even though I know it exists\" reveal? \n   (Findability problem, not availability)\n\u2705 What emotion is expressed? (Frustration\u2014indicates high-priority problem)\n\u2705 What's the underlying need? (Confidence in search results, not just better algorithm)\n\u2705 Follow-up questions needed: \"Tell me about the last time this happened...\"\n```\n\n</CodeGroup>\n\n<Tip>\n  **The Pattern:** AI can identify what users said; humans understand what users meant and felt.\n</Tip>\n\n---",
            "hydration_source_header": "B. User Empathy and Research Interpretation",
            "hydration_method": "title_match"
          },
          {
            "id": "ethical-judgment",
            "title": "Ethical Judgment and Responsibility",
            "zone": "human-first-zone",
            "lines": "402-450",
            "crossModule": true,
            "retrievalQuestions": [
              "What ethical decisions require humans?"
            ],
            "content": "**What This Means:**\nMaking decisions that affect user wellbeing, accessibility, inclusivity, and fairness.\n\n**Why Humans Must Lead:**\n- Requires values and moral reasoning\n- Involves considering harm and benefit\n- Needs understanding of social context\n- Must account for diverse user needs\n- Requires legal/compliance knowledge\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **Accessibility Design** | Ensure IA works for users with disabilities | Requires understanding WCAG, testing with assistive tech, empathy for diverse needs |\n| **Plain Language** | Make complex content understandable | Requires knowing your users' reading levels, cultural context, domain knowledge |\n| **Content Sensitivity** | Handle sensitive topics appropriately | Requires cultural awareness, understanding potential harm, legal knowledge |\n| **Inclusive Terminology** | Choose language that doesn't exclude | Requires awareness of marginalized groups, evolving language norms |\n| **Privacy Considerations** | Protect user data in IA decisions | Requires understanding privacy laws, data ethics, consent |\n\n**Example: Accessibility Decisions**\n\n<CodeGroup>\n\n```text AI Suggestion\nNavigation labels:\n- \"Authenticate Programmatically\"\n- \"Implement Authorization Logic\"\n- \"Configure OAuth Flows\"\n\nAI evaluation: \"Clear and descriptive\" (based on length and keywords)\n```\n\n```text Human Accessibility Analysis\nProblems:\n- Technical jargon assumes expert knowledge\n- Not clear to screen reader users\n- Cognitive load too high for beginners\n- Doesn't use plain language\n\nBetter:\n- \"Sign In to Your App\"\n- \"Control Access to Features\"  \n- \"Set Up Login with OAuth\"\n\nHuman ensures: Screen reader friendly, cognitively accessible, plain language\n```\n\n</CodeGroup>\n\n**Example: Ethical Content Organization**\n\n<Accordion title=\"Scenario: Organizing Health Information\">\n\n**Question:** How should you categorize content about medical conditions?\n\n**AI Suggestion:**\n- Organize alphabetically by condition name\n- Group by severity (minor, moderate, severe)\n- Sort by body system (cardiovascular, respiratory, etc.)\n\n**Ethical Considerations (Human):**\n- \u2705 Will organizing by \"severity\" cause anxiety for users seeking information?\n- \u2705 Does alphabetical grouping make emergency information hard to find?\n- \u2705 Are we using person-first language throughout?\n- \u2705 Do category names avoid stigmatizing conditions?\n- \u2705 Is mental health treated with equal prominence to physical health?\n- \u2705 Are we providing equal depth for conditions affecting marginalized groups?\n\n**The Decision:** Humans weigh these ethical implications, which require values and understanding of social impact.\n\n</Accordion>\n\n<Warning>\n  **Red Flags That This Is Human-First:**\n  - \"Should we\" questions (not just \"can we\")\n  - Impacts on vulnerable populations\n  - Legal or compliance requirements\n  - Potential for harm or discrimination\n  - Values-based trade-offs\n</Warning>\n\n---",
            "hydration_source_header": "C. Ethical Judgment and Responsibility",
            "hydration_method": "title_match"
          },
          {
            "id": "iterative-refinement",
            "title": "Iterative Refinement",
            "zone": "collaborative-zone",
            "lines": "458-530",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I refine AI outputs?"
            ],
            "content": "**What This Means:**\nStarting with AI generation, then refining through multiple rounds of human feedback and AI regeneration.\n\n**Why Collaboration Works:**\n- AI provides fast first drafts\n- Humans identify issues\n- AI incorporates feedback quickly\n- Humans validate improvements\n- Repeat until satisfactory\n\n**IA Applications:**\n\n| Task | Collaboration Pattern | Example |\n|------|----------------------|---------|\n| **Taxonomy Refinement** | AI generates \u2192 Human critiques \u2192 AI adjusts | \"Flatten this level, merge these categories, split that one\" |\n| **Label Optimization** | AI suggests \u2192 Human tests \u2192 AI revises | \"Too technical, make it plainer\" \u2192 AI rewrites \u2192 test again |\n| **Content Model Development** | AI proposes attributes \u2192 Human adds constraints \u2192 AI regenerates | \"Add required vs. optional flags, include character limits\" |\n| **Navigation Hierarchy** | AI builds structure \u2192 Human identifies gaps \u2192 AI fills | \"What about troubleshooting content?\" \u2192 AI adds category |\n\n**Example Workflow: Taxonomy Refinement**\n\n<CodeGroup>\n\n```text Round 1 (AI): Generate initial taxonomy\nPrompt: \"Create a 3-level taxonomy for 100 API documentation pages covering \nauthentication, payments, webhooks, and analytics.\"\n\nOutput:\n\u251c\u2500\u2500 Authentication (25 pages)\n\u2502   \u251c\u2500\u2500 Methods\n\u2502   \u251c\u2500\u2500 OAuth\n\u2502   \u2514\u2500\u2500 Security\n\u251c\u2500\u2500 Payments (35 pages)\n\u2502   \u251c\u2500\u2500 Processing\n\u2502   \u251c\u2500\u2500 Subscriptions\n\u2502   \u2514\u2500\u2500 Refunds\n\u251c\u2500\u2500 Webhooks (20 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u251c\u2500\u2500 Events\n\u2502   \u2514\u2500\u2500 Troubleshooting\n\u2514\u2500\u2500 Analytics (20 pages)\n    \u251c\u2500\u2500 Tracking\n    \u251c\u2500\u2500 Reports\n    \u2514\u2500\u2500 Dashboards\n```\n\n```text Round 2 (Human): Critique\nIssues identified:\n1. \"Payments\" at 35% is unbalanced\n2. \"Analytics\" feels like it should be under \"Webhooks\" \n   (webhook events generate analytics)\n3. Missing \"Getting Started\" section\n4. \"Security\" could be its own top-level (cross-cutting concern)\n```\n\n```text Round 3 (AI): Refine based on feedback\nPrompt: \"Adjust the taxonomy:\n1. Split 'Payments' into 'Payments' and 'Subscriptions' at top level\n2. Move 'Analytics' under 'Webhooks'\n3. Add 'Getting Started' as first top-level category\n4. Promote 'Security' to top level, covering auth security, payment security\"\n\nOutput:\n\u251c\u2500\u2500 Getting Started (8 pages)\n\u2502   \u251c\u2500\u2500 Quick Start\n\u2502   \u2514\u2500\u2500 Core Concepts\n\u251c\u2500\u2500 Authentication (18 pages)\n\u2502   \u251c\u2500\u2500 Methods\n\u2502   \u2514\u2500\u2500 OAuth\n\u251c\u2500\u2500 Payments (22 pages)\n\u2502   \u251c\u2500\u2500 Processing\n\u2502   \u2514\u2500\u2500 Refunds\n\u251c\u2500\u2500 Subscriptions (13 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u2514\u2500\u2500 Management\n\u251c\u2500\u2500 Webhooks (20 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u251c\u2500\u2500 Events\n\u2502   \u251c\u2500\u2500 Analytics\n\u2502   \u2514\u2500\u2500 Troubleshooting\n\u2514\u2500\u2500 Security (19 pages)\n    \u251c\u2500\u2500 Authentication Security\n    \u251c\u2500\u2500 Payment Security\n    \u2514\u2500\u2500 Best Practices\n```\n\n```text Round 4 (Human): Validate\nMuch better! Balanced (no category >25%), logical structure.\nFinal check: Test with 3 users navigating to common tasks.\n```\n\n</CodeGroup>\n\n<Tip>\n  **Iteration Best Practices:**\n  1. **Be specific in critiques:** Not \"this doesn't work\" but \"this is too vague for beginners\"\n  2. **Iterate in chunks:** Don't try to fix everything at once\n  3. **Set a stopping point:** Know when \"good enough\" is sufficient\n  4. **Document your prompts:** Save the winning prompt for future use\n</Tip>\n\n---",
            "hydration_source_header": "A. Iterative Refinement",
            "hydration_method": "title_match"
          },
          {
            "id": "validation-qa",
            "title": "Validation and Quality Assurance",
            "zone": "collaborative-zone",
            "lines": "532-575",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I QA AI work?"
            ],
            "content": "**What This Means:**\nAI generates, humans validate systematically, AI fixes identified issues.\n\n**Why Collaboration Works:**\n- AI produces volume quickly\n- Humans catch errors AI can't see\n- AI fixes errors quickly at scale\n- Humans verify fixes\n\n**IA Applications:**\n\n| Task | Collaboration Pattern | Example |\n|------|----------------------|---------|\n| **Consistency Checking** | AI identifies inconsistencies \u2192 Human confirms \u2192 AI standardizes | \"Fix all instances of 'log in' vs 'login'\" |\n| **Completeness Validation** | AI checks structure \u2192 Human adds missing elements \u2192 AI regenerates | \"Every category needs a landing page description\" |\n| **Link Relationship Mapping** | AI suggests relationships \u2192 Human validates relevance \u2192 AI builds map | \"Should 'OAuth Guide' link to 'Token Management'?\" |\n| **Metadata Validation** | AI checks schema adherence \u2192 Human fixes edge cases \u2192 AI revalidates | \"This page is missing required metadata\" |\n\n**Example Workflow: Metadata Validation**\n\n<Accordion title=\"Complete Workflow Example\">\n\n**Context:** You've defined a metadata schema for 200 documentation pages.\n\n**Required fields:** title, description, content_type, audience, last_updated  \n**Optional fields:** related_pages, prerequisites, estimated_time\n\n**Step 1 (AI): Validate all pages against schema**\n\n```text Prompt\n\"Check each page for required metadata. List any missing fields.\"\n```\n\n```text Output\nPages missing required metadata:\n- Page 47: Missing 'audience'\n- Page 89: Missing 'content_type' and 'description'  \n- Page 102: Missing 'last_updated'\n- Page 134: Missing 'content_type'\n[15 more pages with issues...]\n```\n\n**Step 2 (Human): Review and triage**\n- Most missing \"audience\" can be inferred from content\n- Missing \"content_type\" needs human judgment (Tutorial vs. Guide vs. Reference)\n- Missing \"last_updated\" can be pulled from CMS\n\n**Step 3 (AI): Fill in what it can**\n\n```text Prompt\n\"For pages missing 'audience', analyze content and suggest appropriate audience \n(developers, product managers, or support staff). For pages missing 'description', \ngenerate 150-character summaries.\"\n```\n\n**Step 4 (Human): Handle what AI can't**\nManually classify pages by content_type (requires understanding Di\u00e1taxis framework nuances)\n\n**Step 5 (AI): Final validation**\n\n```text Prompt\n\"Recheck all 200 pages. Confirm all required fields are now present.\"\n```\n\n</Accordion>\n\n<Tip>\n  **When to Use Collaborative Validation:**\n  - \u2705 Large datasets where manual checking is slow\n  - \u2705 Clear validation rules exist\n  - \u2705 Some cases need judgment, others don't\n  - \u2705 Iterative improvement is acceptable\n</Tip>\n\n---",
            "hydration_source_header": "B. Validation and Quality Assurance",
            "hydration_method": "title_match"
          },
          {
            "id": "complex-problem-solving",
            "title": "Complex Problem Solving",
            "zone": "collaborative-zone",
            "lines": "577-600",
            "crossModule": true,
            "retrievalQuestions": [
              "How do AI and humans solve complex problems together?"
            ],
            "content": "**What This Means:**\nBreaking down complex IA problems into steps, using AI for some steps and human judgment for others.\n\n**Why Collaboration Works:**\n- Humans decompose the problem strategically\n- AI handles analytical/repetitive substeps\n- Humans synthesize findings\n- AI helps scale the solution\n\n**Example: Complete Documentation IA Audit**\n\n<Accordion title=\"Full Case Study: Software Documentation IA Audit\">\n\n**Context:** 250-page developer documentation site with known findability issues.\n\n**Goal:** Audit content, identify problems, recommend improvements.",
            "hydration_source_header": "C. Complex Problem Solving",
            "hydration_method": "title_match"
          }
        ],
        "validationLevels": [
          {
            "id": "level-1-quick-checks",
            "title": "Level 1: Quick Checks",
            "timeInvestment": "Minutes",
            "lines": "630-680",
            "crossModule": true,
            "retrievalQuestions": [
              "What are quick checks for AI output?"
            ],
            "content": "**Purpose:** Catch obvious errors fast\n\n**What to Check:**\n- \u2705 Format is correct (expected structure)\n- \u2705 Completeness (all requested parts present)\n- \u2705 Obvious factual errors\n- \u2705 Nonsensical outputs\n\n**Example Quick Checks:**",
            "hydration_source_header": "Level 1: Quick Checks (Minutes)",
            "hydration_method": "title_match"
          },
          {
            "id": "level-2-structural",
            "title": "Level 2: Structural Validation",
            "timeInvestment": "15-30 min",
            "lines": "682-745",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I validate taxonomy structure?"
            ],
            "content": "**Purpose:** Verify logical structure and relationships\n\n**What to Check:**\n- \u2705 Hierarchy logic (parent-child relationships make sense)\n- \u2705 Parallel structure (items at same level have similar specificity)\n- \u2705 Balance (no category drastically larger than others)\n- \u2705 Completeness (no major gaps)\n- \u2705 Mutual exclusivity (clear boundaries)\n\n**Example Structural Validation:**\n\n<Accordion title=\"Taxonomy Structure Check\">\n\n**AI Generated Taxonomy:**\n```\nDocumentation (85 pages)\n\u251c\u2500\u2500 Getting Started (12 pages, 14%)\n\u2502   \u251c\u2500\u2500 Installation\n\u2502   \u251c\u2500\u2500 Quick Start\n\u2502   \u2514\u2500\u2500 Core Concepts\n\u251c\u2500\u2500 Authentication (25 pages, 29%)\n\u2502   \u251c\u2500\u2500 OAuth 2.0\n\u2502   \u251c\u2500\u2500 API Keys\n\u2502   \u2514\u2500\u2500 JWT Tokens\n\u251c\u2500\u2500 API Endpoints (30 pages, 35%)\n\u2502   \u251c\u2500\u2500 Users\n\u2502   \u251c\u2500\u2500 Posts\n\u2502   \u2514\u2500\u2500 Comments\n\u2514\u2500\u2500 Troubleshooting (18 pages, 21%)\n    \u251c\u2500\u2500 Common Errors\n    \u251c\u2500\u2500 Debug Mode\n    \u2514\u2500\u2500 Support\n```\n\n**Structural Validation:**\n\n**1. Hierarchy Logic:**\n- \u2705 Top level represents user tasks/features\n- \u2705 Second level breaks down appropriately\n- \u26a0\ufe0f \"JWT Tokens\" under \"Authentication\" but also relates to \"API Endpoints\"\n\n**2. Parallel Structure:**\n- \u274c \"Getting Started\" (process) vs \"Authentication\" (topic) vs \"API Endpoints\" (reference) vs \"Troubleshooting\" (process)\n- Issue: Mixing organizational principles\n\n**3. Balance:**\n- \u2705 Reasonable distribution (14%, 29%, 35%, 21%)\n- \u26a0\ufe0f \"API Endpoints\" at 35% is borderline high\n\n**4. Completeness:**\n- \u2705 Covers major user needs\n- \u26a0\ufe0f Where does \"Rate Limiting\" go? \"Webhooks\"? Missing?\n\n**5. Mutual Exclusivity:**\n- \u26a0\ufe0f JWT Tokens could fit under Authentication OR API Endpoints\n\n**Action:** Needs refinement before proceeding to Level 3\n\n</Accordion>\n\n<Tip>\n  **Time Investment:** 15-30 minutes. This is where you catch structural issues that would confuse users.\n</Tip>\n\n---",
            "hydration_source_header": "Level 2: Structural Validation (15-30 min)",
            "hydration_method": "title_match"
          },
          {
            "id": "level-3-semantic",
            "title": "Level 3: Semantic Validation",
            "timeInvestment": "30-60 min",
            "lines": "747-820",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I check if terminology is correct?"
            ],
            "content": "**Purpose:** Verify meaning, accuracy, and appropriateness\n\n**What to Check:**\n- \u2705 Terminology is accurate and appropriate\n- \u2705 Labels match user vocabulary\n- \u2705 Content appropriateness for audience\n- \u2705 Domain accuracy (no misinformation)\n- \u2705 Cultural sensitivity and inclusivity\n\n#### A. Terminology Accuracy\n\n**Example: Navigation Labels**\n\n<CodeGroup>\n\n```text AI Generated Labels\n\u251c\u2500\u2500 Authentication & Authorization\n\u2502   \u251c\u2500\u2500 User Authentication\n\u2502   \u251c\u2500\u2500 API Authorization\n\u2502   \u251c\u2500\u2500 Login Methods\n\u2502   \u251c\u2500\u2500 Access Tokens\n\u2502   \u251c\u2500\u2500 Password Security\n\u2502   \u2514\u2500\u2500 Permission Levels\n```\n\n```text Semantic Issues Found\n1. \"User Authentication\" vs. \"API Authorization\" - these concepts overlap in OAuth\n   - Authentication = proving identity\n   - Authorization = granting permissions\n   - OAuth does BOTH, so where does it belong?\n\n2. \"Login Methods\" is user-facing language\n   \"Access Tokens\" is developer-facing language\n   - Inconsistent audience targeting\n\n3. \"Password Security\" under Authentication (correct)\n   \"Permission Levels\" under Authorization (correct)\n   - But what about API Keys? They're auth AND authz\n```\n\n```text Corrected Structure\n\u251c\u2500\u2500 Authentication (Proving Identity)\n\u2502   \u251c\u2500\u2500 Username & Password\n\u2502   \u251c\u2500\u2500 API Keys\n\u2502   \u2514\u2500\u2500 Multi-Factor Authentication\n\u251c\u2500\u2500 Authorization (Granting Permissions)\n\u2502   \u251c\u2500\u2500 OAuth 2.0\n\u2502   \u251c\u2500\u2500 Access Control\n\u2502   \u2514\u2500\u2500 Scopes & Permissions\n```\n\n</CodeGroup>\n\n**Common Semantic Problems:**\n- Mixing similar but distinct concepts\n- Using colloquial terms where technical precision needed\n- Terms that mean different things in different contexts\n- Outdated terminology\n\n---\n\n#### B. Content Appropriateness\n\nIs the content appropriate for the stated purpose and audience?\n\n**Checklist:**\n- \u2610 Complexity matches audience level\n- \u2610 Scope aligns with user needs\n- \u2610 Tone is appropriate\n- \u2610 Examples are relevant\n- \u2610 No inappropriate content\n\n**Example: Audience Appropriateness Check**\n\n<CodeGroup>\n\n```text Context: Documentation for junior developers\n\nAI-Generated Navigation Labels:\n\u251c\u2500\u2500 Fundamentals\n\u2502   \u251c\u2500\u2500 RESTful Architecture Principles\n\u2502   \u251c\u2500\u2500 HTTP Methods & Status Codes\n\u2502   \u2514\u2500\u2500 JSON Schema Validation\n\u251c\u2500\u2500 Implementation\n\u2502   \u251c\u2500\u2500 Dependency Injection Patterns\n\u2502   \u251c\u2500\u2500 Async/Await Best Practices\n\u2502   \u2514\u2500\u2500 Error Handling Strategies\n```\n\n```text Appropriateness Issues\n\u2717 \"RESTful Architecture Principles\" - Too abstract for beginners\n\u2717 \"Dependency Injection Patterns\" - Advanced concept, assumes experience\n\u2717 Assumes knowledge of architectural patterns\n```\n\n```text Better for Junior Developers\n\u251c\u2500\u2500 Getting Started\n\u2502   \u251c\u2500\u2500 What is a REST API?\n\u2502   \u251c\u2500\u2500 Making Your First API Call\n\u2502   \u2514\u2500\u2500 Understanding API Responses\n\u251c\u2500\u2500 Common Tasks\n\u2502   \u251c\u2500\u2500 Authenticating Requests\n\u2502   \u251c\u2500\u2500 Handling Errors\n\u2502   \u2514\u2500\u2500 Working with Async Code\n```\n\n</CodeGroup>\n\n<Warning>\n  **Red Flags:**\n  - Labels use jargon audience won't know\n  - Assumes prerequisite knowledge not stated\n  - Complexity doesn't match stated user level\n  - Content too advanced or too basic\n</Warning>\n\n---\n\n#### C. Domain Accuracy\n\nIs the content factually correct for the domain?\n\n**Checklist:**\n- \u2610 Technical accuracy (no false information)\n- \u2610 Best practices are actually best practices\n- \u2610 Standards are cited correctly\n- \u2610 No outdated information\n- \u2610 Domain-specific nuances are respected\n\n**Example: Domain Accuracy Check**\n\n<Accordion title=\"API Documentation Taxonomy Review\">\n\n**AI-Generated Category Descriptions:**\n\n```text\n\"Rate Limiting: Controls how many requests users can make per minute. \nStandard practice is 100 requests/minute.\"\n```\n\n**Domain Accuracy Issues:**\n- \u274c \"Standard practice is 100 requests/minute\" - This is NOT a universal standard\n- Reality: Rate limits vary widely (GitHub: 5000/hour, Twitter: varies by endpoint)\n- Should say: \"varies by service\" or provide YOUR API's specific limits\n\n**Corrected:**\n```text\n\"Rate Limiting: Controls how many API requests can be made within a time period. \nOur API allows 1000 requests per hour per API key.\"\n```\n\n</Accordion>\n\n<Tip>\n  **Time Investment:** 30-60 minutes. This is where domain expertise matters most.\n</Tip>\n\n---",
            "hydration_source_header": "Level 3: Semantic Validation (30-60 min)",
            "hydration_method": "title_match"
          },
          {
            "id": "level-4-user-validation",
            "title": "Level 4: User Validation",
            "timeInvestment": "Hours-Days",
            "lines": "822-890",
            "crossModule": true,
            "retrievalQuestions": [
              "When should I test with users?"
            ],
            "content": "**Purpose:** Test with real users to validate findability and usability\n\n**What to Test:**\n- \u2705 Can users find what they need?\n- \u2705 Do labels match user mental models?\n- \u2705 Does hierarchy make intuitive sense?\n- \u2705 Are navigation paths efficient?\n- \u2705 Does the IA reduce friction?\n\n**Validation Methods:**\n\n<CardGroup cols={2}>\n  <Card title=\"Tree Testing\" icon=\"sitemap\">\n    Users find items in the proposed structure\n    \n    **Time:** 20-30 min per participant\n    **Participants:** 8-12 users\n    **Cost:** Low (remote, unmoderated)\n  </Card>\n  \n  <Card title=\"First Click Testing\" icon=\"hand-pointer\">\n    Where do users click first to find X?\n    \n    **Time:** 5-10 min per participant\n    **Participants:** 15-20 users\n    **Cost:** Very low\n  </Card>\n  \n  <Card title=\"Usability Testing\" icon=\"user-check\">\n    Watch users navigate actual interface\n    \n    **Time:** 60 min per participant\n    **Participants:** 5-8 users\n    **Cost:** Higher (moderated, recordings)\n  </Card>\n  \n  <Card title=\"A/B Testing\" icon=\"flask\">\n    Compare two IA approaches with analytics\n    \n    **Time:** 1-2 weeks minimum\n    **Participants:** Hundreds (live traffic)\n    **Cost:** Medium (implementation time)\n  </Card>\n</CardGroup>\n\n**Example Tree Test Results:**\n\n```text Task: Find how to reset a user's password\n\nProposed Structure:\n\u251c\u2500\u2500 Authentication\n\u2502   \u251c\u2500\u2500 User Management\n\u2502   \u2502   \u2514\u2500\u2500 Password Reset \u2190 Target\n\u2502   \u2514\u2500\u2500 OAuth Setup\n\u251c\u2500\u2500 API Reference\n\u2514\u2500\u2500 Troubleshooting\n\nResults:\n- 15 participants tested\n- 60% found it directly under Authentication > User Management\n- 27% looked in Troubleshooting first (makes sense!)\n- 13% looked in API Reference\n- Average time: 45 seconds (acceptable)\n\nConclusion: \n\u2705 Structure works for most users\n\u26a0\ufe0f Consider cross-link from Troubleshooting\n```\n\n<Tip>\n  **When to Use Level 4:**\n  - High-impact changes (site-wide navigation)\n  - Uncertainty about user mental models\n  - Contradictory findings in earlier validation\n  - Stakeholder buy-in requires evidence\n</Tip>\n\n<Warning>\n  **Don't Skip Earlier Levels:**\n  \n  User testing is expensive. Don't waste users' time testing AI outputs with obvious structural or semantic flaws. Use Levels 1-3 first.\n</Warning>\n\n---",
            "hydration_source_header": "Level 4: User Validation (Hours-Days)",
            "hydration_method": "title_match"
          }
        ],
        "checklists": [
          {
            "id": "quick-checks-checklist",
            "title": "Quick Checks Checklist",
            "validates": "any-ai-output",
            "time": "2-5 min",
            "lines": "635-640",
            "retrievalQuestions": [
              "What should I check first for AI output?",
              "Quick checks checklist"
            ],
            "content": "- \u2610 Part 1: Task mapping table completed with reasoning\n- \u2610 Part 2: Taxonomy generation with full validation\n- \u2610 Part 3: Iteration log showing refinements\n- \u2610 Part 4: Reflection on experience",
            "hydration_source_header": "Submission Checklist",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "structural-validation-checklist",
            "title": "Structural Validation Checklist",
            "validates": "taxonomy-hierarchy",
            "time": "15-30 min",
            "lines": "690-698",
            "retrievalQuestions": [
              "Checklist for validating taxonomy structure"
            ],
            "content": "**Purpose:** Verify logical structure and relationships\n\n**What to Check:**\n- \u2705 Hierarchy logic (parent-child relationships make sense)\n- \u2705 Parallel structure (items at same level have similar specificity)\n- \u2705 Balance (no category drastically larger than others)\n- \u2705 Completeness (no major gaps)\n- \u2705 Mutual exclusivity (clear boundaries)\n\n**Example Structural Validation:**\n\n<Accordion title=\"Taxonomy Structure Check\">\n\n**AI Generated Taxonomy:**\n```\nDocumentation (85 pages)\n\u251c\u2500\u2500 Getting Started (12 pages, 14%)\n\u2502   \u251c\u2500\u2500 Installation\n\u2502   \u251c\u2500\u2500 Quick Start\n\u2502   \u2514\u2500\u2500 Core Concepts\n\u251c\u2500\u2500 Authentication (25 pages, 29%)\n\u2502   \u251c\u2500\u2500 OAuth 2.0\n\u2502   \u251c\u2500\u2500 API Keys\n\u2502   \u2514\u2500\u2500 JWT Tokens\n\u251c\u2500\u2500 API Endpoints (30 pages, 35%)\n\u2502   \u251c\u2500\u2500 Users\n\u2502   \u251c\u2500\u2500 Posts\n\u2502   \u2514\u2500\u2500 Comments\n\u2514\u2500\u2500 Troubleshooting (18 pages, 21%)\n    \u251c\u2500\u2500 Common Errors\n    \u251c\u2500\u2500 Debug Mode\n    \u2514\u2500\u2500 Support\n```\n\n**Structural Validation:**\n\n**1. Hierarchy Logic:**\n- \u2705 Top level represents user tasks/features\n- \u2705 Second level breaks down appropriately\n- \u26a0\ufe0f \"JWT Tokens\" under \"Authentication\" but also relates to \"API Endpoints\"\n\n**2. Parallel Structure:**\n- \u274c \"Getting Started\" (process) vs \"Authentication\" (topic) vs \"API Endpoints\" (reference) vs \"Troubleshooting\" (process)\n- Issue: Mixing organizational principles\n\n**3. Balance:**\n- \u2705 Reasonable distribution (14%, 29%, 35%, 21%)\n- \u26a0\ufe0f \"API Endpoints\" at 35% is borderline high\n\n**4. Completeness:**\n- \u2705 Covers major user needs\n- \u26a0\ufe0f Where does \"Rate Limiting\" go? \"Webhooks\"? Missing?\n\n**5. Mutual Exclusivity:**\n- \u26a0\ufe0f JWT Tokens could fit under Authentication OR API Endpoints\n\n**Action:** Needs refinement before proceeding to Level 3\n\n</Accordion>\n\n<Tip>\n  **Time Investment:** 15-30 minutes. This is where you catch structural issues that would confuse users.\n</Tip>\n\n---",
            "hydration_source_header": "Level 2: Structural Validation (15-30 min)",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "semantic-terminology-checklist",
            "title": "Terminology Accuracy Checklist",
            "validates": "labels-terminology",
            "time": "30 min",
            "lines": "755-760",
            "retrievalQuestions": [
              "Checklist for semantic validation",
              "How do I check terminology accuracy?"
            ],
            "content": "**Example: Navigation Labels**\n\n<CodeGroup>\n\n```text AI Generated Labels\n\u251c\u2500\u2500 Authentication & Authorization\n\u2502   \u251c\u2500\u2500 User Authentication\n\u2502   \u251c\u2500\u2500 API Authorization\n\u2502   \u251c\u2500\u2500 Login Methods\n\u2502   \u251c\u2500\u2500 Access Tokens\n\u2502   \u251c\u2500\u2500 Password Security\n\u2502   \u2514\u2500\u2500 Permission Levels\n```\n\n```text Semantic Issues Found\n1. \"User Authentication\" vs. \"API Authorization\" - these concepts overlap in OAuth\n   - Authentication = proving identity\n   - Authorization = granting permissions\n   - OAuth does BOTH, so where does it belong?\n\n2. \"Login Methods\" is user-facing language\n   \"Access Tokens\" is developer-facing language\n   - Inconsistent audience targeting\n\n3. \"Password Security\" under Authentication (correct)\n   \"Permission Levels\" under Authorization (correct)\n   - But what about API Keys? They're auth AND authz\n```\n\n```text Corrected Structure\n\u251c\u2500\u2500 Authentication (Proving Identity)\n\u2502   \u251c\u2500\u2500 Username & Password\n\u2502   \u251c\u2500\u2500 API Keys\n\u2502   \u2514\u2500\u2500 Multi-Factor Authentication\n\u251c\u2500\u2500 Authorization (Granting Permissions)\n\u2502   \u251c\u2500\u2500 OAuth 2.0\n\u2502   \u251c\u2500\u2500 Access Control\n\u2502   \u2514\u2500\u2500 Scopes & Permissions\n```\n\n</CodeGroup>\n\n**Common Semantic Problems:**\n- Mixing similar but distinct concepts\n- Using colloquial terms where technical precision needed\n- Terms that mean different things in different contexts\n- Outdated terminology\n\n---",
            "hydration_source_header": "A. Terminology Accuracy",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "content-appropriateness-checklist",
            "title": "Content Appropriateness Checklist",
            "validates": "audience-fit",
            "time": "15 min",
            "lines": "780-788",
            "retrievalQuestions": [
              "How do I check content is appropriate for audience?"
            ],
            "content": "Is the content appropriate for the stated purpose and audience?\n\n**Checklist:**\n- \u2610 Complexity matches audience level\n- \u2610 Scope aligns with user needs\n- \u2610 Tone is appropriate\n- \u2610 Examples are relevant\n- \u2610 No inappropriate content\n\n**Example: Audience Appropriateness Check**\n\n<CodeGroup>\n\n```text Context: Documentation for junior developers\n\nAI-Generated Navigation Labels:\n\u251c\u2500\u2500 Fundamentals\n\u2502   \u251c\u2500\u2500 RESTful Architecture Principles\n\u2502   \u251c\u2500\u2500 HTTP Methods & Status Codes\n\u2502   \u2514\u2500\u2500 JSON Schema Validation\n\u251c\u2500\u2500 Implementation\n\u2502   \u251c\u2500\u2500 Dependency Injection Patterns\n\u2502   \u251c\u2500\u2500 Async/Await Best Practices\n\u2502   \u2514\u2500\u2500 Error Handling Strategies\n```\n\n```text Appropriateness Issues\n\u2717 \"RESTful Architecture Principles\" - Too abstract for beginners\n\u2717 \"Dependency Injection Patterns\" - Advanced concept, assumes experience\n\u2717 Assumes knowledge of architectural patterns\n```\n\n```text Better for Junior Developers\n\u251c\u2500\u2500 Getting Started\n\u2502   \u251c\u2500\u2500 What is a REST API?\n\u2502   \u251c\u2500\u2500 Making Your First API Call\n\u2502   \u2514\u2500\u2500 Understanding API Responses\n\u251c\u2500\u2500 Common Tasks\n\u2502   \u251c\u2500\u2500 Authenticating Requests\n\u2502   \u251c\u2500\u2500 Handling Errors\n\u2502   \u2514\u2500\u2500 Working with Async Code\n```\n\n</CodeGroup>\n\n<Warning>\n  **Red Flags:**\n  - Labels use jargon audience won't know\n  - Assumes prerequisite knowledge not stated\n  - Complexity doesn't match stated user level\n  - Content too advanced or too basic\n</Warning>\n\n---",
            "hydration_source_header": "B. Content Appropriateness",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "domain-accuracy-checklist",
            "title": "Domain Accuracy Checklist",
            "validates": "factual-correctness",
            "time": "20 min",
            "lines": "800-808",
            "retrievalQuestions": [
              "How do I validate domain accuracy?"
            ],
            "content": "Is the content factually correct for the domain?\n\n**Checklist:**\n- \u2610 Technical accuracy (no false information)\n- \u2610 Best practices are actually best practices\n- \u2610 Standards are cited correctly\n- \u2610 No outdated information\n- \u2610 Domain-specific nuances are respected\n\n**Example: Domain Accuracy Check**\n\n<Accordion title=\"API Documentation Taxonomy Review\">\n\n**AI-Generated Category Descriptions:**\n\n```text\n\"Rate Limiting: Controls how many requests users can make per minute. \nStandard practice is 100 requests/minute.\"\n```\n\n**Domain Accuracy Issues:**\n- \u274c \"Standard practice is 100 requests/minute\" - This is NOT a universal standard\n- Reality: Rate limits vary widely (GitHub: 5000/hour, Twitter: varies by endpoint)\n- Should say: \"varies by service\" or provide YOUR API's specific limits\n\n**Corrected:**\n```text\n\"Rate Limiting: Controls how many API requests can be made within a time period. \nOur API allows 1000 requests per hour per API key.\"\n```\n\n</Accordion>\n\n<Tip>\n  **Time Investment:** 30-60 minutes. This is where domain expertise matters most.\n</Tip>\n\n---",
            "hydration_source_header": "C. Domain Accuracy",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "ai-first-when-to-use",
            "title": "When to Use AI-First for Generation",
            "validates": "task-assignment",
            "time": "5 min",
            "lines": "108-115",
            "retrievalQuestions": [
              "When should I use AI-first approach?"
            ],
            "content": "**What This Means:**\nIdentifying trends, inconsistencies, or structures in existing content.\n\n**Why AI Excels:**\n- Processes large volumes quickly\n- Doesn't miss patterns due to fatigue\n- No confirmation bias\n- Consistent classification criteria\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **Content Classification** | Categorize pages by type | \"Classify these 200 pages as Tutorial, Reference, Guide, or Concept\" |\n| **Inconsistency Detection** | Find naming variations | \"Identify inconsistent terminology across these documentation pages\" |\n| **Structure Pattern Analysis** | Recognize organizational approaches | \"What structural patterns appear in these 50 page titles?\" |\n| **Gap Identification** | Spot missing content areas | \"What topics are missing from this documentation set?\" |\n| **Redundancy Detection** | Find duplicate or overlapping content | \"Identify pages covering the same topics\" |\n\n**Example Workflow: Content Classification**\n\n```text Context\nYou have 300 documentation pages to classify using Di\u00e1taxis framework\n```\n\n```text Step 1 (Human): Prepare data and provide classification rules\nExport: Page titles + first 100 words of each page\nRules: Define each category clearly with examples\n```\n\n<CodeGroup>\n\n```text Step 2 (AI): Classify all pages\nPrompt: \"Classify each page as Tutorial (learning-oriented), \nHow-to Guide (task-oriented), Reference (information-oriented), \nor Explanation (understanding-oriented). \nProvide classification + brief reasoning.\"\n```\n\n```text Step 3 (Human): Spot-check results\nValidate ~20% randomly selected pages\nCheck edge cases manually\nReview AI's reasoning for uncertain classifications\n```\n\n```text Step 4 (Human + AI): Refine misclassifications\nAddress systematic errors in prompt\nReclassify problematic pages with more context\n```\n\n</CodeGroup>\n\n**Real Example Output:**\n\n```text AI Classifications\nPage: \"Getting Started with Authentication\"\nClassification: Tutorial\nReasoning: Step-by-step learning journey, assumes no prior knowledge, \nteaches by doing\n\nPage: \"Authentication Endpoint Reference\"  \nClassification: Reference\nReasoning: Technical specifications, lists all endpoints, \ndescribes what each does\n\nPage: \"How to Implement OAuth 2.0\"\nClassification: How-to Guide\nReasoning: Task-oriented, assumes some knowledge, \nfocuses on achieving specific goal\n\nPage: \"Understanding Token Expiration\"\nClassification: Explanation\nReasoning: Conceptual explanation, background knowledge, \nhelps understand why something works\n```\n\n<Tip>\n  **When to Use AI-First for Pattern Finding:**\n  - \u2705 Large content volumes (100+ items)\n  - \u2705 Repetitive classification criteria\n  - \u2705 Objective patterns (not subjective interpretation)\n  - \u2705 Speed is valuable\n</Tip>\n\n<Warning>\n  **When NOT to Use AI-First:**\n  - \u274c Nuanced interpretation required\n  - \u274c Small dataset (easier to do manually)\n  - \u274c Complex, multifaceted categorization\n  - \u274c Deep domain expertise needed per item\n</Warning>\n\n---",
            "hydration_source_header": "B. Pattern Finding Tasks",
            "hydration_method": "line_proximity"
          },
          {
            "id": "ai-first-when-not",
            "title": "When NOT to Use AI-First",
            "validates": "task-assignment",
            "time": "5 min",
            "lines": "108-115",
            "retrievalQuestions": [
              "When should I NOT use AI?"
            ],
            "content": "**What This Means:**\nIdentifying trends, inconsistencies, or structures in existing content.\n\n**Why AI Excels:**\n- Processes large volumes quickly\n- Doesn't miss patterns due to fatigue\n- No confirmation bias\n- Consistent classification criteria\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **Content Classification** | Categorize pages by type | \"Classify these 200 pages as Tutorial, Reference, Guide, or Concept\" |\n| **Inconsistency Detection** | Find naming variations | \"Identify inconsistent terminology across these documentation pages\" |\n| **Structure Pattern Analysis** | Recognize organizational approaches | \"What structural patterns appear in these 50 page titles?\" |\n| **Gap Identification** | Spot missing content areas | \"What topics are missing from this documentation set?\" |\n| **Redundancy Detection** | Find duplicate or overlapping content | \"Identify pages covering the same topics\" |\n\n**Example Workflow: Content Classification**\n\n```text Context\nYou have 300 documentation pages to classify using Di\u00e1taxis framework\n```\n\n```text Step 1 (Human): Prepare data and provide classification rules\nExport: Page titles + first 100 words of each page\nRules: Define each category clearly with examples\n```\n\n<CodeGroup>\n\n```text Step 2 (AI): Classify all pages\nPrompt: \"Classify each page as Tutorial (learning-oriented), \nHow-to Guide (task-oriented), Reference (information-oriented), \nor Explanation (understanding-oriented). \nProvide classification + brief reasoning.\"\n```\n\n```text Step 3 (Human): Spot-check results\nValidate ~20% randomly selected pages\nCheck edge cases manually\nReview AI's reasoning for uncertain classifications\n```\n\n```text Step 4 (Human + AI): Refine misclassifications\nAddress systematic errors in prompt\nReclassify problematic pages with more context\n```\n\n</CodeGroup>\n\n**Real Example Output:**\n\n```text AI Classifications\nPage: \"Getting Started with Authentication\"\nClassification: Tutorial\nReasoning: Step-by-step learning journey, assumes no prior knowledge, \nteaches by doing\n\nPage: \"Authentication Endpoint Reference\"  \nClassification: Reference\nReasoning: Technical specifications, lists all endpoints, \ndescribes what each does\n\nPage: \"How to Implement OAuth 2.0\"\nClassification: How-to Guide\nReasoning: Task-oriented, assumes some knowledge, \nfocuses on achieving specific goal\n\nPage: \"Understanding Token Expiration\"\nClassification: Explanation\nReasoning: Conceptual explanation, background knowledge, \nhelps understand why something works\n```\n\n<Tip>\n  **When to Use AI-First for Pattern Finding:**\n  - \u2705 Large content volumes (100+ items)\n  - \u2705 Repetitive classification criteria\n  - \u2705 Objective patterns (not subjective interpretation)\n  - \u2705 Speed is valuable\n</Tip>\n\n<Warning>\n  **When NOT to Use AI-First:**\n  - \u274c Nuanced interpretation required\n  - \u274c Small dataset (easier to do manually)\n  - \u274c Complex, multifaceted categorization\n  - \u274c Deep domain expertise needed per item\n</Warning>\n\n---",
            "hydration_source_header": "B. Pattern Finding Tasks",
            "hydration_method": "line_proximity"
          },
          {
            "id": "pattern-finding-when-to-use",
            "title": "When to Use AI-First for Pattern Finding",
            "validates": "task-assignment",
            "time": "5 min",
            "lines": "185-190",
            "retrievalQuestions": [
              "When can AI find patterns?"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "human-first-red-flags",
            "title": "Human-First Red Flags",
            "validates": "task-assignment",
            "time": "5 min",
            "lines": "325-330, 445-450",
            "retrievalQuestions": [
              "Red flags that a task is human-first",
              "When should I NOT use AI?"
            ],
            "content": "**What This Means:**\nHigh-level choices that shape the entire IA direction and align with business goals.\n\n**Why Humans Must Lead:**\n- Requires business context AI doesn't have\n- Involves trade-offs AI can't evaluate\n- Connects to broader organizational strategy\n- Has long-term implications beyond immediate task\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **IA Approach Selection** | Choose task-based vs. topic-based structure | Requires understanding user mental models from research |\n| **Scope Definition** | Decide what content to include/exclude | Requires business priorities and resource constraints |\n| **Stakeholder Alignment** | Get buy-in from product, engineering, marketing | Requires negotiation and relationship management |\n| **Governance Model** | Define who maintains what content | Requires org structure knowledge |\n| **Success Metrics** | Define what \"good IA\" means for your context | Requires business goal alignment |\n\n**Example: Strategic IA Decision**\n\n<Accordion title=\"Scenario: Organizing API Documentation\">\n\n**Question:** Should you organize by endpoint or by use case?\n\n**AI Can Help:**\n- Generate both structures for comparison\n- List pros/cons of each approach  \n- Show examples from similar products\n- Identify potential issues with each\n\n**Humans Must Decide Based On:**\n- \u2705 User research: How do YOUR users think about the product?\n- \u2705 Business goals: Are you selling solutions or technical features?\n- \u2705 Competitive positioning: How do competitors organize (and should you differ)?\n- \u2705 Product roadmap: Which structure scales better with planned features?\n- \u2705 Resource constraints: Which is more maintainable with your team?\n- \u2705 Technical constraints: What does your CMS support?\n\n**The Decision:** Humans synthesize these factors (which AI can't access or weigh)\n\n</Accordion>\n\n<Warning>\n  **Red Flags That This Is Human-First:**\n  - The phrase \"it depends\" applies heavily\n  - Multiple stakeholders have different preferences\n  - Trade-offs involve business strategy\n  - Decision has multi-year implications\n  - Requires knowledge of internal constraints\n</Warning>\n\n---",
            "hydration_source_header": "A. Strategic Decisions",
            "hydration_method": "line_proximity"
          }
        ],
        "workflows": [
          {
            "id": "navigation-label-generation-workflow",
            "title": "Navigation Label Generation",
            "steps": 3,
            "uses": "generation-tasks",
            "lines": "85-105",
            "retrievalQuestions": [
              "How do I generate navigation labels with AI?"
            ],
            "content": "**What This Means:**\nCreating initial drafts, variations, or options that you'll refine.\n\n**Why AI Excels:**\n- Generates quickly at scale\n- Pulls from vast pattern library\n- No fatigue or creative blocks\n- Produces multiple variations easily\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **Taxonomy Generation** | Create initial hierarchical structure | \"Generate a 3-level taxonomy for e-commerce documentation with these 50 page titles\" |\n| **Navigation Label Variations** | Produce 10+ alternatives for testing | \"Create 15 different labels for the 'Developer Resources' section\" |\n| **Metadata Attributes** | List potential attributes for content types | \"What metadata fields should a tutorial page include?\" |\n| **Content Descriptions** | Write summaries for sitemap pages | \"Create 50-character descriptions for each of these navigation items\" |\n| **Search Synonyms** | Generate keyword variations | \"List 20 terms users might search for instead of 'API Authentication'\" |\n\n**Example Workflow: Navigation Label Generation**\n\n```text Step 1 (Human): Define context and constraints\n\"I need navigation labels for a section about API security. \nTarget audience: Junior developers. \nConstraint: Labels must be under 20 characters.\"\n```\n\n```text Step 2 (AI): Generate variations\nOutput:\n- API Security\n- Secure Your API\n- Security Guide\n- Auth & Security\n- Keep APIs Safe\n- Security Basics\n- Protect Your API\n- Security Best Practices\n- API Protection\n- Safe Integration\n```\n\n```text Step 3 (Human): Select and refine\nChoose top 3, test with users, select winner.\n```\n\n**When to Use AI-First for Generation:**\n- \u2705 You need volume (multiple options)\n- \u2705 Speed matters more than perfection\n- \u2705 You have clear validation criteria\n- \u2705 The task is pattern-based, not deeply strategic\n\n**When NOT to Use AI-First:**\n- \u274c The first draft needs to be nearly perfect\n- \u274c Highly specialized domain knowledge required\n- \u274c Strategic positioning or brand voice is critical\n- \u274c Legal or compliance considerations\n\n---",
            "hydration_source_header": "A. Generation Tasks",
            "hydration_method": "line_proximity"
          },
          {
            "id": "content-classification-workflow",
            "title": "Content Classification Workflow",
            "steps": 4,
            "uses": "pattern-finding-tasks",
            "lines": "140-175",
            "retrievalQuestions": [
              "Workflow for content classification"
            ],
            "content": "**Decision:** AI-First (Pattern Finding)\n\n<CodeGroup>\n\n```text Prompt\n\"Analyze these 85 documentation pages. For each:\n1. Classify as Tutorial, How-to Guide, Reference, or Explanation (Di\u00e1taxis)\n2. Identify primary topic\n3. Note target audience level (beginner/intermediate/advanced)\n4. Estimate word count category\n\nProvide as structured table.\"\n```\n\n```text AI Output (excerpt)\n| Page | Type | Topic | Audience | Length |\n|------|------|-------|----------|--------|\n| \"Getting Started with Auth\" | Tutorial | Authentication | Beginner | 1200 words |\n| \"OAuth 2.0 Implementation\" | How-to | Authentication | Intermediate | 800 words |\n| \"Token Endpoint Reference\" | Reference | Authentication | All levels | 600 words |\n[...85 rows total...]\n```\n\n```text Validation (Level 1-2)\n\u2705 Format correct\n\u2705 All 85 pages classified\n\u26a0\ufe0f Spot-check 15 pages: 2 misclassified\n\u274c \"Troubleshooting OAuth\" marked as How-to, should be Reference\n\nAction: Rerun classification with refined criteria\n```\n\n</CodeGroup>\n\n**Time:** AI analysis: 3 minutes | Human validation: 20 minutes | **Total: 23 minutes**\n\n---",
            "hydration_source_header": "Step 1: Content Inventory & Classification",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "navigation-structure-variations-workflow",
            "title": "Navigation Structure Variations",
            "steps": 4,
            "uses": "variation-creation-tasks",
            "lines": "215-255",
            "retrievalQuestions": [
              "How do I generate navigation structure options?"
            ],
            "content": "**What This Means:**\nGenerating multiple versions of the same concept for testing or exploration.\n\n**Why AI Excels:**\n- Creates variations without creativity fatigue\n- Produces systematically different approaches\n- Generates quickly in bulk\n- Offers perspectives you might not consider\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **A/B Testing Options** | Create variations for testing | \"Generate 5 different ways to structure this navigation\" |\n| **Perspective Shifting** | View problem from different angles | \"How would a novice vs. expert organize this content?\" |\n| **Label Testing** | Produce terminology variations | \"Create synonyms for each of these technical terms\" |\n| **Organizational Approaches** | Try different IA models | \"Organize this content by: task, role, product, and topic\" |\n\n**Example Workflow: Navigation Structure Variations**\n\n<CodeGroup>\n\n```text Step 1 (Human): Define the scope\nContent inventory: 75 documentation pages\nUser types: Developers, product managers, support staff\nBusiness goal: Reduce time-to-answer\n```\n\n```text Step 2 (AI): Generate 4 different structures\nPrompt: \"Create 4 different navigation structures for this documentation:\n1. Task-based (organized by what users want to do)\n2. Role-based (organized by user type)  \n3. Product-feature-based (organized by product components)\n4. Journey-based (organized by user maturity: beginner \u2192 advanced)\n\nFor each, provide the top 2 levels of hierarchy.\"\n```\n\n</CodeGroup>\n\n```text Step 3 (AI Output)\n1. TASK-BASED:\n   \u251c\u2500\u2500 Get Started\n   \u251c\u2500\u2500 Integrate\n   \u251c\u2500\u2500 Configure\n   \u251c\u2500\u2500 Monitor\n   \u2514\u2500\u2500 Troubleshoot\n\n2. ROLE-BASED:\n   \u251c\u2500\u2500 For Developers\n   \u251c\u2500\u2500 For Product Managers\n   \u251c\u2500\u2500 For Support Staff\n   \u2514\u2500\u2500 For Administrators\n\n3. PRODUCT-FEATURE-BASED:\n   \u251c\u2500\u2500 Authentication\n   \u251c\u2500\u2500 Data Management\n   \u251c\u2500\u2500 APIs\n   \u2514\u2500\u2500 Reporting\n\n4. JOURNEY-BASED:\n   \u251c\u2500\u2500 Beginner (First Steps)\n   \u251c\u2500\u2500 Intermediate (Common Tasks)\n   \u251c\u2500\u2500 Advanced (Optimization)\n   \u2514\u2500\u2500 Expert (Architecture)\n```\n\n```text Step 4 (Human): Evaluate and test\n- Which aligns with user research?\n- Which scales best with future features?\n- Test top 2 options with users\n- Select final approach\n```\n\n<Tip>\n  **Pro Tip:** When generating variations, ask AI to explain the trade-offs of each approach. This helps you understand implications before testing.\n</Tip>\n\n---",
            "hydration_source_header": "C. Variation Creation Tasks",
            "hydration_method": "line_proximity"
          },
          {
            "id": "taxonomy-refinement-workflow",
            "title": "Taxonomy Refinement Workflow",
            "steps": "4 rounds",
            "uses": "iterative-refinement",
            "lines": "475-530",
            "retrievalQuestions": [
              "How do I refine a taxonomy iteratively?"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "metadata-validation-workflow",
            "title": "Metadata Validation Workflow",
            "steps": 5,
            "uses": "validation-qa",
            "lines": "545-575",
            "retrievalQuestions": [
              "How do I validate metadata with AI?"
            ],
            "content": "**What This Means:**\nStarting with AI generation, then refining through multiple rounds of human feedback and AI regeneration.\n\n**Why Collaboration Works:**\n- AI provides fast first drafts\n- Humans identify issues\n- AI incorporates feedback quickly\n- Humans validate improvements\n- Repeat until satisfactory\n\n**IA Applications:**\n\n| Task | Collaboration Pattern | Example |\n|------|----------------------|---------|\n| **Taxonomy Refinement** | AI generates \u2192 Human critiques \u2192 AI adjusts | \"Flatten this level, merge these categories, split that one\" |\n| **Label Optimization** | AI suggests \u2192 Human tests \u2192 AI revises | \"Too technical, make it plainer\" \u2192 AI rewrites \u2192 test again |\n| **Content Model Development** | AI proposes attributes \u2192 Human adds constraints \u2192 AI regenerates | \"Add required vs. optional flags, include character limits\" |\n| **Navigation Hierarchy** | AI builds structure \u2192 Human identifies gaps \u2192 AI fills | \"What about troubleshooting content?\" \u2192 AI adds category |\n\n**Example Workflow: Taxonomy Refinement**\n\n<CodeGroup>\n\n```text Round 1 (AI): Generate initial taxonomy\nPrompt: \"Create a 3-level taxonomy for 100 API documentation pages covering \nauthentication, payments, webhooks, and analytics.\"\n\nOutput:\n\u251c\u2500\u2500 Authentication (25 pages)\n\u2502   \u251c\u2500\u2500 Methods\n\u2502   \u251c\u2500\u2500 OAuth\n\u2502   \u2514\u2500\u2500 Security\n\u251c\u2500\u2500 Payments (35 pages)\n\u2502   \u251c\u2500\u2500 Processing\n\u2502   \u251c\u2500\u2500 Subscriptions\n\u2502   \u2514\u2500\u2500 Refunds\n\u251c\u2500\u2500 Webhooks (20 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u251c\u2500\u2500 Events\n\u2502   \u2514\u2500\u2500 Troubleshooting\n\u2514\u2500\u2500 Analytics (20 pages)\n    \u251c\u2500\u2500 Tracking\n    \u251c\u2500\u2500 Reports\n    \u2514\u2500\u2500 Dashboards\n```\n\n```text Round 2 (Human): Critique\nIssues identified:\n1. \"Payments\" at 35% is unbalanced\n2. \"Analytics\" feels like it should be under \"Webhooks\" \n   (webhook events generate analytics)\n3. Missing \"Getting Started\" section\n4. \"Security\" could be its own top-level (cross-cutting concern)\n```\n\n```text Round 3 (AI): Refine based on feedback\nPrompt: \"Adjust the taxonomy:\n1. Split 'Payments' into 'Payments' and 'Subscriptions' at top level\n2. Move 'Analytics' under 'Webhooks'\n3. Add 'Getting Started' as first top-level category\n4. Promote 'Security' to top level, covering auth security, payment security\"\n\nOutput:\n\u251c\u2500\u2500 Getting Started (8 pages)\n\u2502   \u251c\u2500\u2500 Quick Start\n\u2502   \u2514\u2500\u2500 Core Concepts\n\u251c\u2500\u2500 Authentication (18 pages)\n\u2502   \u251c\u2500\u2500 Methods\n\u2502   \u2514\u2500\u2500 OAuth\n\u251c\u2500\u2500 Payments (22 pages)\n\u2502   \u251c\u2500\u2500 Processing\n\u2502   \u2514\u2500\u2500 Refunds\n\u251c\u2500\u2500 Subscriptions (13 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u2514\u2500\u2500 Management\n\u251c\u2500\u2500 Webhooks (20 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u251c\u2500\u2500 Events\n\u2502   \u251c\u2500\u2500 Analytics\n\u2502   \u2514\u2500\u2500 Troubleshooting\n\u2514\u2500\u2500 Security (19 pages)\n    \u251c\u2500\u2500 Authentication Security\n    \u251c\u2500\u2500 Payment Security\n    \u2514\u2500\u2500 Best Practices\n```\n\n```text Round 4 (Human): Validate\nMuch better! Balanced (no category >25%), logical structure.\nFinal check: Test with 3 users navigating to common tasks.\n```\n\n</CodeGroup>\n\n<Tip>\n  **Iteration Best Practices:**\n  1. **Be specific in critiques:** Not \"this doesn't work\" but \"this is too vague for beginners\"\n  2. **Iterate in chunks:** Don't try to fix everything at once\n  3. **Set a stopping point:** Know when \"good enough\" is sufficient\n  4. **Document your prompts:** Save the winning prompt for future use\n</Tip>\n\n---",
            "hydration_source_header": "A. Iterative Refinement",
            "hydration_method": "line_proximity"
          },
          {
            "id": "documentation-ia-audit-workflow",
            "title": "Complete Documentation IA Audit",
            "steps": "3 phases",
            "uses": "complex-problem-solving",
            "lines": "580-600",
            "retrievalQuestions": [
              "Complete workflow for documentation audit"
            ],
            "hydration_status": "failed"
          }
        ],
        "examples": [
          {
            "id": "taxonomy-generation-example",
            "title": "Taxonomy Generation Example",
            "demonstrates": "generation-tasks",
            "domain": "api-docs",
            "lines": "70-80",
            "retrievalQuestions": [
              "Show me a taxonomy generation example"
            ],
            "content": "**What This Means:**\nCreating initial drafts, variations, or options that you'll refine.\n\n**Why AI Excels:**\n- Generates quickly at scale\n- Pulls from vast pattern library\n- No fatigue or creative blocks\n- Produces multiple variations easily\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **Taxonomy Generation** | Create initial hierarchical structure | \"Generate a 3-level taxonomy for e-commerce documentation with these 50 page titles\" |\n| **Navigation Label Variations** | Produce 10+ alternatives for testing | \"Create 15 different labels for the 'Developer Resources' section\" |\n| **Metadata Attributes** | List potential attributes for content types | \"What metadata fields should a tutorial page include?\" |\n| **Content Descriptions** | Write summaries for sitemap pages | \"Create 50-character descriptions for each of these navigation items\" |\n| **Search Synonyms** | Generate keyword variations | \"List 20 terms users might search for instead of 'API Authentication'\" |\n\n**Example Workflow: Navigation Label Generation**\n\n```text Step 1 (Human): Define context and constraints\n\"I need navigation labels for a section about API security. \nTarget audience: Junior developers. \nConstraint: Labels must be under 20 characters.\"\n```\n\n```text Step 2 (AI): Generate variations\nOutput:\n- API Security\n- Secure Your API\n- Security Guide\n- Auth & Security\n- Keep APIs Safe\n- Security Basics\n- Protect Your API\n- Security Best Practices\n- API Protection\n- Safe Integration\n```\n\n```text Step 3 (Human): Select and refine\nChoose top 3, test with users, select winner.\n```\n\n**When to Use AI-First for Generation:**\n- \u2705 You need volume (multiple options)\n- \u2705 Speed matters more than perfection\n- \u2705 You have clear validation criteria\n- \u2705 The task is pattern-based, not deeply strategic\n\n**When NOT to Use AI-First:**\n- \u274c The first draft needs to be nearly perfect\n- \u274c Highly specialized domain knowledge required\n- \u274c Strategic positioning or brand voice is critical\n- \u274c Legal or compliance considerations\n\n---",
            "hydration_source_header": "A. Generation Tasks",
            "hydration_method": "line_proximity"
          },
          {
            "id": "label-generation-example",
            "title": "Navigation Label Generation Example",
            "demonstrates": "generation-tasks",
            "domain": "navigation",
            "lines": "85-105",
            "retrievalQuestions": [
              "Example of AI-generated navigation labels"
            ],
            "content": "**What This Means:**\nCreating initial drafts, variations, or options that you'll refine.\n\n**Why AI Excels:**\n- Generates quickly at scale\n- Pulls from vast pattern library\n- No fatigue or creative blocks\n- Produces multiple variations easily\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **Taxonomy Generation** | Create initial hierarchical structure | \"Generate a 3-level taxonomy for e-commerce documentation with these 50 page titles\" |\n| **Navigation Label Variations** | Produce 10+ alternatives for testing | \"Create 15 different labels for the 'Developer Resources' section\" |\n| **Metadata Attributes** | List potential attributes for content types | \"What metadata fields should a tutorial page include?\" |\n| **Content Descriptions** | Write summaries for sitemap pages | \"Create 50-character descriptions for each of these navigation items\" |\n| **Search Synonyms** | Generate keyword variations | \"List 20 terms users might search for instead of 'API Authentication'\" |\n\n**Example Workflow: Navigation Label Generation**\n\n```text Step 1 (Human): Define context and constraints\n\"I need navigation labels for a section about API security. \nTarget audience: Junior developers. \nConstraint: Labels must be under 20 characters.\"\n```\n\n```text Step 2 (AI): Generate variations\nOutput:\n- API Security\n- Secure Your API\n- Security Guide\n- Auth & Security\n- Keep APIs Safe\n- Security Basics\n- Protect Your API\n- Security Best Practices\n- API Protection\n- Safe Integration\n```\n\n```text Step 3 (Human): Select and refine\nChoose top 3, test with users, select winner.\n```\n\n**When to Use AI-First for Generation:**\n- \u2705 You need volume (multiple options)\n- \u2705 Speed matters more than perfection\n- \u2705 You have clear validation criteria\n- \u2705 The task is pattern-based, not deeply strategic\n\n**When NOT to Use AI-First:**\n- \u274c The first draft needs to be nearly perfect\n- \u274c Highly specialized domain knowledge required\n- \u274c Strategic positioning or brand voice is critical\n- \u274c Legal or compliance considerations\n\n---",
            "hydration_source_header": "A. Generation Tasks",
            "hydration_method": "line_proximity"
          },
          {
            "id": "terminology-analysis-example",
            "title": "Terminology Inconsistency Analysis",
            "demonstrates": "pattern-finding-tasks",
            "domain": "content-audit",
            "lines": "125-135",
            "retrievalQuestions": [
              "Example of terminology analysis"
            ],
            "content": "**What This Means:**\nIdentifying trends, inconsistencies, or structures in existing content.\n\n**Why AI Excels:**\n- Processes large volumes quickly\n- Doesn't miss patterns due to fatigue\n- No confirmation bias\n- Consistent classification criteria\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **Content Classification** | Categorize pages by type | \"Classify these 200 pages as Tutorial, Reference, Guide, or Concept\" |\n| **Inconsistency Detection** | Find naming variations | \"Identify inconsistent terminology across these documentation pages\" |\n| **Structure Pattern Analysis** | Recognize organizational approaches | \"What structural patterns appear in these 50 page titles?\" |\n| **Gap Identification** | Spot missing content areas | \"What topics are missing from this documentation set?\" |\n| **Redundancy Detection** | Find duplicate or overlapping content | \"Identify pages covering the same topics\" |\n\n**Example Workflow: Content Classification**\n\n```text Context\nYou have 300 documentation pages to classify using Di\u00e1taxis framework\n```\n\n```text Step 1 (Human): Prepare data and provide classification rules\nExport: Page titles + first 100 words of each page\nRules: Define each category clearly with examples\n```\n\n<CodeGroup>\n\n```text Step 2 (AI): Classify all pages\nPrompt: \"Classify each page as Tutorial (learning-oriented), \nHow-to Guide (task-oriented), Reference (information-oriented), \nor Explanation (understanding-oriented). \nProvide classification + brief reasoning.\"\n```\n\n```text Step 3 (Human): Spot-check results\nValidate ~20% randomly selected pages\nCheck edge cases manually\nReview AI's reasoning for uncertain classifications\n```\n\n```text Step 4 (Human + AI): Refine misclassifications\nAddress systematic errors in prompt\nReclassify problematic pages with more context\n```\n\n</CodeGroup>\n\n**Real Example Output:**\n\n```text AI Classifications\nPage: \"Getting Started with Authentication\"\nClassification: Tutorial\nReasoning: Step-by-step learning journey, assumes no prior knowledge, \nteaches by doing\n\nPage: \"Authentication Endpoint Reference\"  \nClassification: Reference\nReasoning: Technical specifications, lists all endpoints, \ndescribes what each does\n\nPage: \"How to Implement OAuth 2.0\"\nClassification: How-to Guide\nReasoning: Task-oriented, assumes some knowledge, \nfocuses on achieving specific goal\n\nPage: \"Understanding Token Expiration\"\nClassification: Explanation\nReasoning: Conceptual explanation, background knowledge, \nhelps understand why something works\n```\n\n<Tip>\n  **When to Use AI-First for Pattern Finding:**\n  - \u2705 Large content volumes (100+ items)\n  - \u2705 Repetitive classification criteria\n  - \u2705 Objective patterns (not subjective interpretation)\n  - \u2705 Speed is valuable\n</Tip>\n\n<Warning>\n  **When NOT to Use AI-First:**\n  - \u274c Nuanced interpretation required\n  - \u274c Small dataset (easier to do manually)\n  - \u274c Complex, multifaceted categorization\n  - \u274c Deep domain expertise needed per item\n</Warning>\n\n---",
            "hydration_source_header": "B. Pattern Finding Tasks",
            "hydration_method": "line_proximity"
          },
          {
            "id": "diataxis-classification-example",
            "title": "Di\u00e1taxis Classification Example",
            "demonstrates": "pattern-finding-tasks",
            "domain": "content-types",
            "lines": "155-175",
            "retrievalQuestions": [
              "Example of Di\u00e1taxis classification"
            ],
            "content": "**What This Means:**\nIdentifying trends, inconsistencies, or structures in existing content.\n\n**Why AI Excels:**\n- Processes large volumes quickly\n- Doesn't miss patterns due to fatigue\n- No confirmation bias\n- Consistent classification criteria\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **Content Classification** | Categorize pages by type | \"Classify these 200 pages as Tutorial, Reference, Guide, or Concept\" |\n| **Inconsistency Detection** | Find naming variations | \"Identify inconsistent terminology across these documentation pages\" |\n| **Structure Pattern Analysis** | Recognize organizational approaches | \"What structural patterns appear in these 50 page titles?\" |\n| **Gap Identification** | Spot missing content areas | \"What topics are missing from this documentation set?\" |\n| **Redundancy Detection** | Find duplicate or overlapping content | \"Identify pages covering the same topics\" |\n\n**Example Workflow: Content Classification**\n\n```text Context\nYou have 300 documentation pages to classify using Di\u00e1taxis framework\n```\n\n```text Step 1 (Human): Prepare data and provide classification rules\nExport: Page titles + first 100 words of each page\nRules: Define each category clearly with examples\n```\n\n<CodeGroup>\n\n```text Step 2 (AI): Classify all pages\nPrompt: \"Classify each page as Tutorial (learning-oriented), \nHow-to Guide (task-oriented), Reference (information-oriented), \nor Explanation (understanding-oriented). \nProvide classification + brief reasoning.\"\n```\n\n```text Step 3 (Human): Spot-check results\nValidate ~20% randomly selected pages\nCheck edge cases manually\nReview AI's reasoning for uncertain classifications\n```\n\n```text Step 4 (Human + AI): Refine misclassifications\nAddress systematic errors in prompt\nReclassify problematic pages with more context\n```\n\n</CodeGroup>\n\n**Real Example Output:**\n\n```text AI Classifications\nPage: \"Getting Started with Authentication\"\nClassification: Tutorial\nReasoning: Step-by-step learning journey, assumes no prior knowledge, \nteaches by doing\n\nPage: \"Authentication Endpoint Reference\"  \nClassification: Reference\nReasoning: Technical specifications, lists all endpoints, \ndescribes what each does\n\nPage: \"How to Implement OAuth 2.0\"\nClassification: How-to Guide\nReasoning: Task-oriented, assumes some knowledge, \nfocuses on achieving specific goal\n\nPage: \"Understanding Token Expiration\"\nClassification: Explanation\nReasoning: Conceptual explanation, background knowledge, \nhelps understand why something works\n```\n\n<Tip>\n  **When to Use AI-First for Pattern Finding:**\n  - \u2705 Large content volumes (100+ items)\n  - \u2705 Repetitive classification criteria\n  - \u2705 Objective patterns (not subjective interpretation)\n  - \u2705 Speed is valuable\n</Tip>\n\n<Warning>\n  **When NOT to Use AI-First:**\n  - \u274c Nuanced interpretation required\n  - \u274c Small dataset (easier to do manually)\n  - \u274c Complex, multifaceted categorization\n  - \u274c Deep domain expertise needed per item\n</Warning>\n\n---",
            "hydration_source_header": "B. Pattern Finding Tasks",
            "hydration_method": "line_proximity"
          },
          {
            "id": "four-structure-variations",
            "title": "Four Navigation Structure Variations",
            "demonstrates": "variation-creation-tasks",
            "domain": "navigation",
            "lines": "230-255",
            "retrievalQuestions": [
              "Example of navigation structure variations"
            ],
            "content": "**What This Means:**\nGenerating multiple versions of the same concept for testing or exploration.\n\n**Why AI Excels:**\n- Creates variations without creativity fatigue\n- Produces systematically different approaches\n- Generates quickly in bulk\n- Offers perspectives you might not consider\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **A/B Testing Options** | Create variations for testing | \"Generate 5 different ways to structure this navigation\" |\n| **Perspective Shifting** | View problem from different angles | \"How would a novice vs. expert organize this content?\" |\n| **Label Testing** | Produce terminology variations | \"Create synonyms for each of these technical terms\" |\n| **Organizational Approaches** | Try different IA models | \"Organize this content by: task, role, product, and topic\" |\n\n**Example Workflow: Navigation Structure Variations**\n\n<CodeGroup>\n\n```text Step 1 (Human): Define the scope\nContent inventory: 75 documentation pages\nUser types: Developers, product managers, support staff\nBusiness goal: Reduce time-to-answer\n```\n\n```text Step 2 (AI): Generate 4 different structures\nPrompt: \"Create 4 different navigation structures for this documentation:\n1. Task-based (organized by what users want to do)\n2. Role-based (organized by user type)  \n3. Product-feature-based (organized by product components)\n4. Journey-based (organized by user maturity: beginner \u2192 advanced)\n\nFor each, provide the top 2 levels of hierarchy.\"\n```\n\n</CodeGroup>\n\n```text Step 3 (AI Output)\n1. TASK-BASED:\n   \u251c\u2500\u2500 Get Started\n   \u251c\u2500\u2500 Integrate\n   \u251c\u2500\u2500 Configure\n   \u251c\u2500\u2500 Monitor\n   \u2514\u2500\u2500 Troubleshoot\n\n2. ROLE-BASED:\n   \u251c\u2500\u2500 For Developers\n   \u251c\u2500\u2500 For Product Managers\n   \u251c\u2500\u2500 For Support Staff\n   \u2514\u2500\u2500 For Administrators\n\n3. PRODUCT-FEATURE-BASED:\n   \u251c\u2500\u2500 Authentication\n   \u251c\u2500\u2500 Data Management\n   \u251c\u2500\u2500 APIs\n   \u2514\u2500\u2500 Reporting\n\n4. JOURNEY-BASED:\n   \u251c\u2500\u2500 Beginner (First Steps)\n   \u251c\u2500\u2500 Intermediate (Common Tasks)\n   \u251c\u2500\u2500 Advanced (Optimization)\n   \u2514\u2500\u2500 Expert (Architecture)\n```\n\n```text Step 4 (Human): Evaluate and test\n- Which aligns with user research?\n- Which scales best with future features?\n- Test top 2 options with users\n- Select final approach\n```\n\n<Tip>\n  **Pro Tip:** When generating variations, ask AI to explain the trade-offs of each approach. This helps you understand implications before testing.\n</Tip>\n\n---",
            "hydration_source_header": "C. Variation Creation Tasks",
            "hydration_method": "line_proximity"
          },
          {
            "id": "api-documentation-strategic",
            "title": "API Documentation Strategic Decision",
            "demonstrates": "strategic-decisions",
            "domain": "api-docs",
            "lines": "290-328",
            "retrievalQuestions": [
              "Example of strategic IA decision"
            ],
            "content": "**What This Means:**\nHigh-level choices that shape the entire IA direction and align with business goals.\n\n**Why Humans Must Lead:**\n- Requires business context AI doesn't have\n- Involves trade-offs AI can't evaluate\n- Connects to broader organizational strategy\n- Has long-term implications beyond immediate task\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **IA Approach Selection** | Choose task-based vs. topic-based structure | Requires understanding user mental models from research |\n| **Scope Definition** | Decide what content to include/exclude | Requires business priorities and resource constraints |\n| **Stakeholder Alignment** | Get buy-in from product, engineering, marketing | Requires negotiation and relationship management |\n| **Governance Model** | Define who maintains what content | Requires org structure knowledge |\n| **Success Metrics** | Define what \"good IA\" means for your context | Requires business goal alignment |\n\n**Example: Strategic IA Decision**\n\n<Accordion title=\"Scenario: Organizing API Documentation\">\n\n**Question:** Should you organize by endpoint or by use case?\n\n**AI Can Help:**\n- Generate both structures for comparison\n- List pros/cons of each approach  \n- Show examples from similar products\n- Identify potential issues with each\n\n**Humans Must Decide Based On:**\n- \u2705 User research: How do YOUR users think about the product?\n- \u2705 Business goals: Are you selling solutions or technical features?\n- \u2705 Competitive positioning: How do competitors organize (and should you differ)?\n- \u2705 Product roadmap: Which structure scales better with planned features?\n- \u2705 Resource constraints: Which is more maintainable with your team?\n- \u2705 Technical constraints: What does your CMS support?\n\n**The Decision:** Humans synthesize these factors (which AI can't access or weigh)\n\n</Accordion>\n\n<Warning>\n  **Red Flags That This Is Human-First:**\n  - The phrase \"it depends\" applies heavily\n  - Multiple stakeholders have different preferences\n  - Trade-offs involve business strategy\n  - Decision has multi-year implications\n  - Requires knowledge of internal constraints\n</Warning>\n\n---",
            "hydration_source_header": "A. Strategic Decisions",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "card-sorting-interpretation",
            "title": "Card Sorting Interpretation Example",
            "demonstrates": "user-empathy-research",
            "domain": "user-research",
            "lines": "350-380",
            "retrievalQuestions": [
              "Example of card sorting interpretation"
            ],
            "content": "**What This Means:**\nUnderstanding user needs, behaviors, emotions, and mental models through research.\n\n**Why Humans Must Lead:**\n- Empathy requires human connection\n- Context and nuance matter enormously\n- Research uncovers unexpected insights\n- Follow-up questions are critical\n- Non-verbal cues inform understanding\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **User Interviews** | Conduct interviews, probe deeper | Requires empathy, reading between lines, following unexpected threads |\n| **Mental Model Mapping** | Understand how users conceptualize information | Requires synthesis of behavior + stated preferences + context |\n| **Usability Testing** | Observe users interacting with IA | Requires noting frustration, confusion, surprise |\n| **Card Sorting Interpretation** | Understand why users grouped content | Requires understanding reasoning, not just patterns |\n| **Research Synthesis** | Turn findings into IA principles | Requires weighing contradictions, identifying priorities |\n\n**Example: Card Sorting Analysis**\n\n**What AI Can Do:**\n\nAI Can Help:\n- Identify most common groupings\n- Calculate similarity matrices  \n- Cluster related cards\n- Generate initial category suggestions\n- Find outlier groupings\n\n**What Humans Must Do:**\n\nHumans Must Interpret:\n- \u2705 Why did 8 participants create an \"Advanced\" category but define it differently?\n- \u2705 What does it mean that 12 participants couldn't categorize \"Webhooks\"?\n- \u2705 When participants wrote notes like \"I'm not sure where this goes,\" what does that tell us?\n- \u2705 How do contradictions in sorting reflect different user roles or expertise?\n- \u2705 Which patterns reflect actual mental models vs. exposure to competitors?\n\n<Tip>\n**The Insight:** The confusion around \"Webhooks\" reveals a fundamental education gap, not just a categorization problem. (AI would miss this insight.)\n</Tip>\n\n**Example: Interview Analysis**\n\n<CodeGroup>\n\n```text Participant Quote\n\"I usually just search for what I need, but half the time \nI can't find it even though I know it exists.\"\n```\n\n```text AI Analysis (Surface Level)\nUser prefers search. Search functionality needs improvement.\n```\n\n```text Human Interpretation (Deep)\n\u2705 Why is search failing? (Labels don't match user language?)\n\u2705 What does \"even though I know it exists\" reveal? \n   (Findability problem, not availability)\n\u2705 What emotion is expressed? (Frustration\u2014indicates high-priority problem)\n\u2705 What's the underlying need? (Confidence in search results, not just better algorithm)\n\u2705 Follow-up questions needed: \"Tell me about the last time this happened...\"\n```\n\n</CodeGroup>\n\n<Tip>\n  **The Pattern:** AI can identify what users said; humans understand what users meant and felt.\n</Tip>\n\n---",
            "hydration_source_header": "B. User Empathy and Research Interpretation",
            "hydration_method": "line_proximity"
          },
          {
            "id": "interview-analysis-example",
            "title": "Interview Analysis Example",
            "demonstrates": "user-empathy-research",
            "domain": "user-research",
            "lines": "382-400",
            "retrievalQuestions": [
              "Example of interview analysis"
            ],
            "content": "**What This Means:**\nUnderstanding user needs, behaviors, emotions, and mental models through research.\n\n**Why Humans Must Lead:**\n- Empathy requires human connection\n- Context and nuance matter enormously\n- Research uncovers unexpected insights\n- Follow-up questions are critical\n- Non-verbal cues inform understanding\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **User Interviews** | Conduct interviews, probe deeper | Requires empathy, reading between lines, following unexpected threads |\n| **Mental Model Mapping** | Understand how users conceptualize information | Requires synthesis of behavior + stated preferences + context |\n| **Usability Testing** | Observe users interacting with IA | Requires noting frustration, confusion, surprise |\n| **Card Sorting Interpretation** | Understand why users grouped content | Requires understanding reasoning, not just patterns |\n| **Research Synthesis** | Turn findings into IA principles | Requires weighing contradictions, identifying priorities |\n\n**Example: Card Sorting Analysis**\n\n**What AI Can Do:**\n\nAI Can Help:\n- Identify most common groupings\n- Calculate similarity matrices  \n- Cluster related cards\n- Generate initial category suggestions\n- Find outlier groupings\n\n**What Humans Must Do:**\n\nHumans Must Interpret:\n- \u2705 Why did 8 participants create an \"Advanced\" category but define it differently?\n- \u2705 What does it mean that 12 participants couldn't categorize \"Webhooks\"?\n- \u2705 When participants wrote notes like \"I'm not sure where this goes,\" what does that tell us?\n- \u2705 How do contradictions in sorting reflect different user roles or expertise?\n- \u2705 Which patterns reflect actual mental models vs. exposure to competitors?\n\n<Tip>\n**The Insight:** The confusion around \"Webhooks\" reveals a fundamental education gap, not just a categorization problem. (AI would miss this insight.)\n</Tip>\n\n**Example: Interview Analysis**\n\n<CodeGroup>\n\n```text Participant Quote\n\"I usually just search for what I need, but half the time \nI can't find it even though I know it exists.\"\n```\n\n```text AI Analysis (Surface Level)\nUser prefers search. Search functionality needs improvement.\n```\n\n```text Human Interpretation (Deep)\n\u2705 Why is search failing? (Labels don't match user language?)\n\u2705 What does \"even though I know it exists\" reveal? \n   (Findability problem, not availability)\n\u2705 What emotion is expressed? (Frustration\u2014indicates high-priority problem)\n\u2705 What's the underlying need? (Confidence in search results, not just better algorithm)\n\u2705 Follow-up questions needed: \"Tell me about the last time this happened...\"\n```\n\n</CodeGroup>\n\n<Tip>\n  **The Pattern:** AI can identify what users said; humans understand what users meant and felt.\n</Tip>\n\n---",
            "hydration_source_header": "B. User Empathy and Research Interpretation",
            "hydration_method": "line_proximity"
          },
          {
            "id": "accessibility-labels-example",
            "title": "Accessibility Labels Example",
            "demonstrates": "ethical-judgment",
            "domain": "accessibility",
            "lines": "415-435",
            "retrievalQuestions": [
              "Example of accessible navigation labels"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "health-info-organization",
            "title": "Health Information Organization",
            "demonstrates": "ethical-judgment",
            "domain": "ethics",
            "lines": "437-448",
            "retrievalQuestions": [
              "Example of ethical IA decisions"
            ],
            "content": "**What This Means:**\nMaking decisions that affect user wellbeing, accessibility, inclusivity, and fairness.\n\n**Why Humans Must Lead:**\n- Requires values and moral reasoning\n- Involves considering harm and benefit\n- Needs understanding of social context\n- Must account for diverse user needs\n- Requires legal/compliance knowledge\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **Accessibility Design** | Ensure IA works for users with disabilities | Requires understanding WCAG, testing with assistive tech, empathy for diverse needs |\n| **Plain Language** | Make complex content understandable | Requires knowing your users' reading levels, cultural context, domain knowledge |\n| **Content Sensitivity** | Handle sensitive topics appropriately | Requires cultural awareness, understanding potential harm, legal knowledge |\n| **Inclusive Terminology** | Choose language that doesn't exclude | Requires awareness of marginalized groups, evolving language norms |\n| **Privacy Considerations** | Protect user data in IA decisions | Requires understanding privacy laws, data ethics, consent |\n\n**Example: Accessibility Decisions**\n\n<CodeGroup>\n\n```text AI Suggestion\nNavigation labels:\n- \"Authenticate Programmatically\"\n- \"Implement Authorization Logic\"\n- \"Configure OAuth Flows\"\n\nAI evaluation: \"Clear and descriptive\" (based on length and keywords)\n```\n\n```text Human Accessibility Analysis\nProblems:\n- Technical jargon assumes expert knowledge\n- Not clear to screen reader users\n- Cognitive load too high for beginners\n- Doesn't use plain language\n\nBetter:\n- \"Sign In to Your App\"\n- \"Control Access to Features\"  \n- \"Set Up Login with OAuth\"\n\nHuman ensures: Screen reader friendly, cognitively accessible, plain language\n```\n\n</CodeGroup>\n\n**Example: Ethical Content Organization**\n\n<Accordion title=\"Scenario: Organizing Health Information\">\n\n**Question:** How should you categorize content about medical conditions?\n\n**AI Suggestion:**\n- Organize alphabetically by condition name\n- Group by severity (minor, moderate, severe)\n- Sort by body system (cardiovascular, respiratory, etc.)\n\n**Ethical Considerations (Human):**\n- \u2705 Will organizing by \"severity\" cause anxiety for users seeking information?\n- \u2705 Does alphabetical grouping make emergency information hard to find?\n- \u2705 Are we using person-first language throughout?\n- \u2705 Do category names avoid stigmatizing conditions?\n- \u2705 Is mental health treated with equal prominence to physical health?\n- \u2705 Are we providing equal depth for conditions affecting marginalized groups?\n\n**The Decision:** Humans weigh these ethical implications, which require values and understanding of social impact.\n\n</Accordion>\n\n<Warning>\n  **Red Flags That This Is Human-First:**\n  - \"Should we\" questions (not just \"can we\")\n  - Impacts on vulnerable populations\n  - Legal or compliance requirements\n  - Potential for harm or discrimination\n  - Values-based trade-offs\n</Warning>\n\n---",
            "hydration_source_header": "C. Ethical Judgment and Responsibility",
            "hydration_method": "line_proximity"
          },
          {
            "id": "taxonomy-refinement-4-rounds",
            "title": "4-Round Taxonomy Refinement",
            "demonstrates": "iterative-refinement",
            "domain": "taxonomy",
            "lines": "475-530",
            "retrievalQuestions": [
              "Example of iterative taxonomy refinement"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "taxonomy-duplicate-error",
            "title": "Taxonomy Duplicate Error",
            "demonstrates": "level-1-quick-checks",
            "domain": "validation",
            "lines": "650-665",
            "retrievalQuestions": [
              "Example of duplicate taxonomy error"
            ],
            "content": "**What This Means:**\nAI generates, humans validate systematically, AI fixes identified issues.\n\n**Why Collaboration Works:**\n- AI produces volume quickly\n- Humans catch errors AI can't see\n- AI fixes errors quickly at scale\n- Humans verify fixes\n\n**IA Applications:**\n\n| Task | Collaboration Pattern | Example |\n|------|----------------------|---------|\n| **Consistency Checking** | AI identifies inconsistencies \u2192 Human confirms \u2192 AI standardizes | \"Fix all instances of 'log in' vs 'login'\" |\n| **Completeness Validation** | AI checks structure \u2192 Human adds missing elements \u2192 AI regenerates | \"Every category needs a landing page description\" |\n| **Link Relationship Mapping** | AI suggests relationships \u2192 Human validates relevance \u2192 AI builds map | \"Should 'OAuth Guide' link to 'Token Management'?\" |\n| **Metadata Validation** | AI checks schema adherence \u2192 Human fixes edge cases \u2192 AI revalidates | \"This page is missing required metadata\" |\n\n**Example Workflow: Metadata Validation**\n\n<Accordion title=\"Complete Workflow Example\">\n\n**Context:** You've defined a metadata schema for 200 documentation pages.\n\n**Required fields:** title, description, content_type, audience, last_updated  \n**Optional fields:** related_pages, prerequisites, estimated_time\n\n**Step 1 (AI): Validate all pages against schema**\n\n```text Prompt\n\"Check each page for required metadata. List any missing fields.\"\n```\n\n```text Output\nPages missing required metadata:\n- Page 47: Missing 'audience'\n- Page 89: Missing 'content_type' and 'description'  \n- Page 102: Missing 'last_updated'\n- Page 134: Missing 'content_type'\n[15 more pages with issues...]\n```\n\n**Step 2 (Human): Review and triage**\n- Most missing \"audience\" can be inferred from content\n- Missing \"content_type\" needs human judgment (Tutorial vs. Guide vs. Reference)\n- Missing \"last_updated\" can be pulled from CMS\n\n**Step 3 (AI): Fill in what it can**\n\n```text Prompt\n\"For pages missing 'audience', analyze content and suggest appropriate audience \n(developers, product managers, or support staff). For pages missing 'description', \ngenerate 150-character summaries.\"\n```\n\n**Step 4 (Human): Handle what AI can't**\nManually classify pages by content_type (requires understanding Di\u00e1taxis framework nuances)\n\n**Step 5 (AI): Final validation**\n\n```text Prompt\n\"Recheck all 200 pages. Confirm all required fields are now present.\"\n```\n\n</Accordion>\n\n<Tip>\n  **When to Use Collaborative Validation:**\n  - \u2705 Large datasets where manual checking is slow\n  - \u2705 Clear validation rules exist\n  - \u2705 Some cases need judgment, others don't\n  - \u2705 Iterative improvement is acceptable\n</Tip>\n\n---",
            "hydration_source_header": "B. Validation and Quality Assurance",
            "hydration_method": "line_proximity"
          },
          {
            "id": "label-redundancy-check",
            "title": "Label Redundancy Check",
            "demonstrates": "level-1-quick-checks",
            "domain": "validation",
            "lines": "667-680",
            "retrievalQuestions": [
              "Example of label redundancy"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "taxonomy-structure-check",
            "title": "Taxonomy Structure Check",
            "demonstrates": "level-2-structural",
            "domain": "validation",
            "lines": "700-740",
            "retrievalQuestions": [
              "Example of structural validation"
            ],
            "content": "**What This Means:**\nBreaking down complex IA problems into steps, using AI for some steps and human judgment for others.\n\n**Why Collaboration Works:**\n- Humans decompose the problem strategically\n- AI handles analytical/repetitive substeps\n- Humans synthesize findings\n- AI helps scale the solution\n\n**Example: Complete Documentation IA Audit**\n\n<Accordion title=\"Full Case Study: Software Documentation IA Audit\">\n\n**Context:** 250-page developer documentation site with known findability issues.\n\n**Goal:** Audit content, identify problems, recommend improvements.",
            "hydration_source_header": "C. Complex Problem Solving",
            "hydration_method": "line_proximity"
          },
          {
            "id": "auth-authz-semantic-issues",
            "title": "Auth vs Authz Semantic Issues",
            "demonstrates": "level-3-semantic",
            "domain": "terminology",
            "lines": "760-785",
            "retrievalQuestions": [
              "How do I check for semantic issues?",
              "Example of terminology problems"
            ],
            "content": "| Task | Owner | Why |\n|------|-------|-----|\n| Map current navigation structure | **AI** | Data extraction |\n| Identify navigation inconsistencies | **AI** | Pattern detection |\n| Calculate navigation depth metrics | **AI** | Quantitative analysis |\n| Analyze user search queries | **AI** | Pattern analysis at scale |\n| Compare navigation to user mental models | **Human** | Requires user research interpretation |\n| Identify navigation-search gaps | **Human** | Strategic insight |\n| Recommend navigation changes | **Human** | Strategic decision |\n\n**What AI Did Well:**\n```\n- Current structure: 7 top-level categories, max depth 5 levels\n- Found 23 pages buried 4+ levels deep (low discoverability)\n- Identified 45 search queries with 0 results despite relevant pages existing\n- Detected 8 pages accessible via multiple paths (ambiguous placement)\n```\n\n**What Human Decided:**\n- Reduce to 5 top-level categories (based on user research)\n- Flatten hierarchy to max 3 levels\n- Reorganize from feature-based to task-based structure\n- Create cross-links for genuinely multi-purpose content",
            "hydration_source_header": "Phase 2: Navigation Analysis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "audience-appropriateness-check",
            "title": "Audience Appropriateness Check",
            "demonstrates": "level-3-semantic",
            "domain": "audience",
            "lines": "790-810",
            "retrievalQuestions": [
              "Example of audience appropriateness check"
            ],
            "content": "Is the content appropriate for the stated purpose and audience?\n\n**Checklist:**\n- \u2610 Complexity matches audience level\n- \u2610 Scope aligns with user needs\n- \u2610 Tone is appropriate\n- \u2610 Examples are relevant\n- \u2610 No inappropriate content\n\n**Example: Audience Appropriateness Check**\n\n<CodeGroup>\n\n```text Context: Documentation for junior developers\n\nAI-Generated Navigation Labels:\n\u251c\u2500\u2500 Fundamentals\n\u2502   \u251c\u2500\u2500 RESTful Architecture Principles\n\u2502   \u251c\u2500\u2500 HTTP Methods & Status Codes\n\u2502   \u2514\u2500\u2500 JSON Schema Validation\n\u251c\u2500\u2500 Implementation\n\u2502   \u251c\u2500\u2500 Dependency Injection Patterns\n\u2502   \u251c\u2500\u2500 Async/Await Best Practices\n\u2502   \u2514\u2500\u2500 Error Handling Strategies\n```\n\n```text Appropriateness Issues\n\u2717 \"RESTful Architecture Principles\" - Too abstract for beginners\n\u2717 \"Dependency Injection Patterns\" - Advanced concept, assumes experience\n\u2717 Assumes knowledge of architectural patterns\n```\n\n```text Better for Junior Developers\n\u251c\u2500\u2500 Getting Started\n\u2502   \u251c\u2500\u2500 What is a REST API?\n\u2502   \u251c\u2500\u2500 Making Your First API Call\n\u2502   \u2514\u2500\u2500 Understanding API Responses\n\u251c\u2500\u2500 Common Tasks\n\u2502   \u251c\u2500\u2500 Authenticating Requests\n\u2502   \u251c\u2500\u2500 Handling Errors\n\u2502   \u2514\u2500\u2500 Working with Async Code\n```\n\n</CodeGroup>\n\n<Warning>\n  **Red Flags:**\n  - Labels use jargon audience won't know\n  - Assumes prerequisite knowledge not stated\n  - Complexity doesn't match stated user level\n  - Content too advanced or too basic\n</Warning>\n\n---",
            "hydration_source_header": "B. Content Appropriateness",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "tree-test-results",
            "title": "Tree Test Results Example",
            "demonstrates": "level-4-user-validation",
            "domain": "user-testing",
            "lines": "870-890",
            "retrievalQuestions": [
              "Example tree test results"
            ],
            "content": "**AI Generated Taxonomy:**\n```\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 API Reference\n\u251c\u2500\u2500 SDKs & Tools\n\u251c\u2500\u2500 Get Started\n\u2514\u2500\u2500 Troubleshooting\n```\n\n**Quick Check Findings:**\n- \u274c \"Get Started\" appears twice (obvious error)\n- \u2705 Format is correct (tree structure)\n- \u2705 All categories present\n- \u2705 No nonsensical content\n\n**Action:** Fix immediately, no deep analysis needed\n\n---",
            "hydration_source_header": "Example 1: Taxonomy Check",
            "hydration_method": "line_proximity"
          }
        ],
        "caseStudies": [
          {
            "id": "cloudstore-api-redesign",
            "title": "CloudStore API Documentation Redesign",
            "applies": [
              "ia-decision-framework",
              "validation-pyramid"
            ],
            "domain": "api-docs",
            "lines": "895-1100",
            "retrievalQuestions": [
              "Complete case study for IA redesign",
              "Example of AI-human collaboration on real project"
            ],
            "content": "**AI Generated Labels:**\n```\n- Authentication Guide\n- Authenticate Your Users\n- API Security\n- Secure Your API\n- OAuth Implementation\n```\n\n**Quick Check Findings:**\n- \u2705 All labels under 30 characters (format requirement met)\n- \u2705 No typos or obvious errors\n- \u26a0\ufe0f Possible redundancy (\"Authentication\" vs \"Authenticate\")\n\n**Action:** Passes Level 1, proceed to Level 2 for deeper check\n\n<Tip>\n  **Time Investment:** 2-5 minutes. Don't skip this\u2014it catches embarrassing errors before you invest more time.\n</Tip>\n\n---",
            "hydration_source_header": "Example 2: Label Check",
            "hydration_method": "line_proximity"
          }
        ],
        "decisionMatrices": [
          {
            "id": "generation-task-matrix",
            "title": "AI-First Generation Task Matrix",
            "helpsChoose": "5 task types",
            "lines": "65-80",
            "retrievalQuestions": [
              "What generation tasks can AI do?"
            ],
            "content": "**What This Means:**\nCreating initial drafts, variations, or options that you'll refine.\n\n**Why AI Excels:**\n- Generates quickly at scale\n- Pulls from vast pattern library\n- No fatigue or creative blocks\n- Produces multiple variations easily\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **Taxonomy Generation** | Create initial hierarchical structure | \"Generate a 3-level taxonomy for e-commerce documentation with these 50 page titles\" |\n| **Navigation Label Variations** | Produce 10+ alternatives for testing | \"Create 15 different labels for the 'Developer Resources' section\" |\n| **Metadata Attributes** | List potential attributes for content types | \"What metadata fields should a tutorial page include?\" |\n| **Content Descriptions** | Write summaries for sitemap pages | \"Create 50-character descriptions for each of these navigation items\" |\n| **Search Synonyms** | Generate keyword variations | \"List 20 terms users might search for instead of 'API Authentication'\" |\n\n**Example Workflow: Navigation Label Generation**\n\n```text Step 1 (Human): Define context and constraints\n\"I need navigation labels for a section about API security. \nTarget audience: Junior developers. \nConstraint: Labels must be under 20 characters.\"\n```\n\n```text Step 2 (AI): Generate variations\nOutput:\n- API Security\n- Secure Your API\n- Security Guide\n- Auth & Security\n- Keep APIs Safe\n- Security Basics\n- Protect Your API\n- Security Best Practices\n- API Protection\n- Safe Integration\n```\n\n```text Step 3 (Human): Select and refine\nChoose top 3, test with users, select winner.\n```\n\n**When to Use AI-First for Generation:**\n- \u2705 You need volume (multiple options)\n- \u2705 Speed matters more than perfection\n- \u2705 You have clear validation criteria\n- \u2705 The task is pattern-based, not deeply strategic\n\n**When NOT to Use AI-First:**\n- \u274c The first draft needs to be nearly perfect\n- \u274c Highly specialized domain knowledge required\n- \u274c Strategic positioning or brand voice is critical\n- \u274c Legal or compliance considerations\n\n---",
            "hydration_source_header": "A. Generation Tasks",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "pattern-finding-task-matrix",
            "title": "Pattern Finding Task Matrix",
            "helpsChoose": "5 task types",
            "lines": "125-135",
            "retrievalQuestions": [
              "What pattern finding tasks can AI do?"
            ],
            "content": "**What This Means:**\nIdentifying trends, inconsistencies, or structures in existing content.\n\n**Why AI Excels:**\n- Processes large volumes quickly\n- Doesn't miss patterns due to fatigue\n- No confirmation bias\n- Consistent classification criteria\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **Content Classification** | Categorize pages by type | \"Classify these 200 pages as Tutorial, Reference, Guide, or Concept\" |\n| **Inconsistency Detection** | Find naming variations | \"Identify inconsistent terminology across these documentation pages\" |\n| **Structure Pattern Analysis** | Recognize organizational approaches | \"What structural patterns appear in these 50 page titles?\" |\n| **Gap Identification** | Spot missing content areas | \"What topics are missing from this documentation set?\" |\n| **Redundancy Detection** | Find duplicate or overlapping content | \"Identify pages covering the same topics\" |\n\n**Example Workflow: Content Classification**\n\n```text Context\nYou have 300 documentation pages to classify using Di\u00e1taxis framework\n```\n\n```text Step 1 (Human): Prepare data and provide classification rules\nExport: Page titles + first 100 words of each page\nRules: Define each category clearly with examples\n```\n\n<CodeGroup>\n\n```text Step 2 (AI): Classify all pages\nPrompt: \"Classify each page as Tutorial (learning-oriented), \nHow-to Guide (task-oriented), Reference (information-oriented), \nor Explanation (understanding-oriented). \nProvide classification + brief reasoning.\"\n```\n\n```text Step 3 (Human): Spot-check results\nValidate ~20% randomly selected pages\nCheck edge cases manually\nReview AI's reasoning for uncertain classifications\n```\n\n```text Step 4 (Human + AI): Refine misclassifications\nAddress systematic errors in prompt\nReclassify problematic pages with more context\n```\n\n</CodeGroup>\n\n**Real Example Output:**\n\n```text AI Classifications\nPage: \"Getting Started with Authentication\"\nClassification: Tutorial\nReasoning: Step-by-step learning journey, assumes no prior knowledge, \nteaches by doing\n\nPage: \"Authentication Endpoint Reference\"  \nClassification: Reference\nReasoning: Technical specifications, lists all endpoints, \ndescribes what each does\n\nPage: \"How to Implement OAuth 2.0\"\nClassification: How-to Guide\nReasoning: Task-oriented, assumes some knowledge, \nfocuses on achieving specific goal\n\nPage: \"Understanding Token Expiration\"\nClassification: Explanation\nReasoning: Conceptual explanation, background knowledge, \nhelps understand why something works\n```\n\n<Tip>\n  **When to Use AI-First for Pattern Finding:**\n  - \u2705 Large content volumes (100+ items)\n  - \u2705 Repetitive classification criteria\n  - \u2705 Objective patterns (not subjective interpretation)\n  - \u2705 Speed is valuable\n</Tip>\n\n<Warning>\n  **When NOT to Use AI-First:**\n  - \u274c Nuanced interpretation required\n  - \u274c Small dataset (easier to do manually)\n  - \u274c Complex, multifaceted categorization\n  - \u274c Deep domain expertise needed per item\n</Warning>\n\n---",
            "hydration_source_header": "B. Pattern Finding Tasks",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "variation-task-matrix",
            "title": "Variation Creation Task Matrix",
            "helpsChoose": "4 task types",
            "lines": "200-210",
            "retrievalQuestions": [
              "What variation tasks can AI do?"
            ],
            "content": "**What This Means:**\nGenerating multiple versions of the same concept for testing or exploration.\n\n**Why AI Excels:**\n- Creates variations without creativity fatigue\n- Produces systematically different approaches\n- Generates quickly in bulk\n- Offers perspectives you might not consider\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **A/B Testing Options** | Create variations for testing | \"Generate 5 different ways to structure this navigation\" |\n| **Perspective Shifting** | View problem from different angles | \"How would a novice vs. expert organize this content?\" |\n| **Label Testing** | Produce terminology variations | \"Create synonyms for each of these technical terms\" |\n| **Organizational Approaches** | Try different IA models | \"Organize this content by: task, role, product, and topic\" |\n\n**Example Workflow: Navigation Structure Variations**\n\n<CodeGroup>\n\n```text Step 1 (Human): Define the scope\nContent inventory: 75 documentation pages\nUser types: Developers, product managers, support staff\nBusiness goal: Reduce time-to-answer\n```\n\n```text Step 2 (AI): Generate 4 different structures\nPrompt: \"Create 4 different navigation structures for this documentation:\n1. Task-based (organized by what users want to do)\n2. Role-based (organized by user type)  \n3. Product-feature-based (organized by product components)\n4. Journey-based (organized by user maturity: beginner \u2192 advanced)\n\nFor each, provide the top 2 levels of hierarchy.\"\n```\n\n</CodeGroup>\n\n```text Step 3 (AI Output)\n1. TASK-BASED:\n   \u251c\u2500\u2500 Get Started\n   \u251c\u2500\u2500 Integrate\n   \u251c\u2500\u2500 Configure\n   \u251c\u2500\u2500 Monitor\n   \u2514\u2500\u2500 Troubleshoot\n\n2. ROLE-BASED:\n   \u251c\u2500\u2500 For Developers\n   \u251c\u2500\u2500 For Product Managers\n   \u251c\u2500\u2500 For Support Staff\n   \u2514\u2500\u2500 For Administrators\n\n3. PRODUCT-FEATURE-BASED:\n   \u251c\u2500\u2500 Authentication\n   \u251c\u2500\u2500 Data Management\n   \u251c\u2500\u2500 APIs\n   \u2514\u2500\u2500 Reporting\n\n4. JOURNEY-BASED:\n   \u251c\u2500\u2500 Beginner (First Steps)\n   \u251c\u2500\u2500 Intermediate (Common Tasks)\n   \u251c\u2500\u2500 Advanced (Optimization)\n   \u2514\u2500\u2500 Expert (Architecture)\n```\n\n```text Step 4 (Human): Evaluate and test\n- Which aligns with user research?\n- Which scales best with future features?\n- Test top 2 options with users\n- Select final approach\n```\n\n<Tip>\n  **Pro Tip:** When generating variations, ask AI to explain the trade-offs of each approach. This helps you understand implications before testing.\n</Tip>\n\n---",
            "hydration_source_header": "C. Variation Creation Tasks",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "strategic-decision-matrix",
            "title": "Strategic Decision Matrix",
            "helpsChoose": "5 decision types",
            "lines": "275-285",
            "retrievalQuestions": [
              "What strategic decisions need humans?"
            ],
            "content": "**What This Means:**\nHigh-level choices that shape the entire IA direction and align with business goals.\n\n**Why Humans Must Lead:**\n- Requires business context AI doesn't have\n- Involves trade-offs AI can't evaluate\n- Connects to broader organizational strategy\n- Has long-term implications beyond immediate task\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **IA Approach Selection** | Choose task-based vs. topic-based structure | Requires understanding user mental models from research |\n| **Scope Definition** | Decide what content to include/exclude | Requires business priorities and resource constraints |\n| **Stakeholder Alignment** | Get buy-in from product, engineering, marketing | Requires negotiation and relationship management |\n| **Governance Model** | Define who maintains what content | Requires org structure knowledge |\n| **Success Metrics** | Define what \"good IA\" means for your context | Requires business goal alignment |\n\n**Example: Strategic IA Decision**\n\n<Accordion title=\"Scenario: Organizing API Documentation\">\n\n**Question:** Should you organize by endpoint or by use case?\n\n**AI Can Help:**\n- Generate both structures for comparison\n- List pros/cons of each approach  \n- Show examples from similar products\n- Identify potential issues with each\n\n**Humans Must Decide Based On:**\n- \u2705 User research: How do YOUR users think about the product?\n- \u2705 Business goals: Are you selling solutions or technical features?\n- \u2705 Competitive positioning: How do competitors organize (and should you differ)?\n- \u2705 Product roadmap: Which structure scales better with planned features?\n- \u2705 Resource constraints: Which is more maintainable with your team?\n- \u2705 Technical constraints: What does your CMS support?\n\n**The Decision:** Humans synthesize these factors (which AI can't access or weigh)\n\n</Accordion>\n\n<Warning>\n  **Red Flags That This Is Human-First:**\n  - The phrase \"it depends\" applies heavily\n  - Multiple stakeholders have different preferences\n  - Trade-offs involve business strategy\n  - Decision has multi-year implications\n  - Requires knowledge of internal constraints\n</Warning>\n\n---",
            "hydration_source_header": "A. Strategic Decisions",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "user-research-task-matrix",
            "title": "User Research Task Matrix",
            "helpsChoose": "5 task types",
            "lines": "340-350",
            "retrievalQuestions": [
              "What user research tasks need humans?"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "ethical-task-matrix",
            "title": "Ethical Judgment Task Matrix",
            "helpsChoose": "5 task types",
            "lines": "408-418",
            "retrievalQuestions": [
              "What ethical decisions need humans?"
            ],
            "content": "**What This Means:**\nMaking decisions that affect user wellbeing, accessibility, inclusivity, and fairness.\n\n**Why Humans Must Lead:**\n- Requires values and moral reasoning\n- Involves considering harm and benefit\n- Needs understanding of social context\n- Must account for diverse user needs\n- Requires legal/compliance knowledge\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **Accessibility Design** | Ensure IA works for users with disabilities | Requires understanding WCAG, testing with assistive tech, empathy for diverse needs |\n| **Plain Language** | Make complex content understandable | Requires knowing your users' reading levels, cultural context, domain knowledge |\n| **Content Sensitivity** | Handle sensitive topics appropriately | Requires cultural awareness, understanding potential harm, legal knowledge |\n| **Inclusive Terminology** | Choose language that doesn't exclude | Requires awareness of marginalized groups, evolving language norms |\n| **Privacy Considerations** | Protect user data in IA decisions | Requires understanding privacy laws, data ethics, consent |\n\n**Example: Accessibility Decisions**\n\n<CodeGroup>\n\n```text AI Suggestion\nNavigation labels:\n- \"Authenticate Programmatically\"\n- \"Implement Authorization Logic\"\n- \"Configure OAuth Flows\"\n\nAI evaluation: \"Clear and descriptive\" (based on length and keywords)\n```\n\n```text Human Accessibility Analysis\nProblems:\n- Technical jargon assumes expert knowledge\n- Not clear to screen reader users\n- Cognitive load too high for beginners\n- Doesn't use plain language\n\nBetter:\n- \"Sign In to Your App\"\n- \"Control Access to Features\"  \n- \"Set Up Login with OAuth\"\n\nHuman ensures: Screen reader friendly, cognitively accessible, plain language\n```\n\n</CodeGroup>\n\n**Example: Ethical Content Organization**\n\n<Accordion title=\"Scenario: Organizing Health Information\">\n\n**Question:** How should you categorize content about medical conditions?\n\n**AI Suggestion:**\n- Organize alphabetically by condition name\n- Group by severity (minor, moderate, severe)\n- Sort by body system (cardiovascular, respiratory, etc.)\n\n**Ethical Considerations (Human):**\n- \u2705 Will organizing by \"severity\" cause anxiety for users seeking information?\n- \u2705 Does alphabetical grouping make emergency information hard to find?\n- \u2705 Are we using person-first language throughout?\n- \u2705 Do category names avoid stigmatizing conditions?\n- \u2705 Is mental health treated with equal prominence to physical health?\n- \u2705 Are we providing equal depth for conditions affecting marginalized groups?\n\n**The Decision:** Humans weigh these ethical implications, which require values and understanding of social impact.\n\n</Accordion>\n\n<Warning>\n  **Red Flags That This Is Human-First:**\n  - \"Should we\" questions (not just \"can we\")\n  - Impacts on vulnerable populations\n  - Legal or compliance requirements\n  - Potential for harm or discrimination\n  - Values-based trade-offs\n</Warning>\n\n---",
            "hydration_source_header": "C. Ethical Judgment and Responsibility",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "iterative-refinement-matrix",
            "title": "Iterative Refinement Task Matrix",
            "helpsChoose": "4 task types",
            "lines": "465-475",
            "retrievalQuestions": [
              "What tasks need iterative refinement?"
            ],
            "content": "**What This Means:**\nStarting with AI generation, then refining through multiple rounds of human feedback and AI regeneration.\n\n**Why Collaboration Works:**\n- AI provides fast first drafts\n- Humans identify issues\n- AI incorporates feedback quickly\n- Humans validate improvements\n- Repeat until satisfactory\n\n**IA Applications:**\n\n| Task | Collaboration Pattern | Example |\n|------|----------------------|---------|\n| **Taxonomy Refinement** | AI generates \u2192 Human critiques \u2192 AI adjusts | \"Flatten this level, merge these categories, split that one\" |\n| **Label Optimization** | AI suggests \u2192 Human tests \u2192 AI revises | \"Too technical, make it plainer\" \u2192 AI rewrites \u2192 test again |\n| **Content Model Development** | AI proposes attributes \u2192 Human adds constraints \u2192 AI regenerates | \"Add required vs. optional flags, include character limits\" |\n| **Navigation Hierarchy** | AI builds structure \u2192 Human identifies gaps \u2192 AI fills | \"What about troubleshooting content?\" \u2192 AI adds category |\n\n**Example Workflow: Taxonomy Refinement**\n\n<CodeGroup>\n\n```text Round 1 (AI): Generate initial taxonomy\nPrompt: \"Create a 3-level taxonomy for 100 API documentation pages covering \nauthentication, payments, webhooks, and analytics.\"\n\nOutput:\n\u251c\u2500\u2500 Authentication (25 pages)\n\u2502   \u251c\u2500\u2500 Methods\n\u2502   \u251c\u2500\u2500 OAuth\n\u2502   \u2514\u2500\u2500 Security\n\u251c\u2500\u2500 Payments (35 pages)\n\u2502   \u251c\u2500\u2500 Processing\n\u2502   \u251c\u2500\u2500 Subscriptions\n\u2502   \u2514\u2500\u2500 Refunds\n\u251c\u2500\u2500 Webhooks (20 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u251c\u2500\u2500 Events\n\u2502   \u2514\u2500\u2500 Troubleshooting\n\u2514\u2500\u2500 Analytics (20 pages)\n    \u251c\u2500\u2500 Tracking\n    \u251c\u2500\u2500 Reports\n    \u2514\u2500\u2500 Dashboards\n```\n\n```text Round 2 (Human): Critique\nIssues identified:\n1. \"Payments\" at 35% is unbalanced\n2. \"Analytics\" feels like it should be under \"Webhooks\" \n   (webhook events generate analytics)\n3. Missing \"Getting Started\" section\n4. \"Security\" could be its own top-level (cross-cutting concern)\n```\n\n```text Round 3 (AI): Refine based on feedback\nPrompt: \"Adjust the taxonomy:\n1. Split 'Payments' into 'Payments' and 'Subscriptions' at top level\n2. Move 'Analytics' under 'Webhooks'\n3. Add 'Getting Started' as first top-level category\n4. Promote 'Security' to top level, covering auth security, payment security\"\n\nOutput:\n\u251c\u2500\u2500 Getting Started (8 pages)\n\u2502   \u251c\u2500\u2500 Quick Start\n\u2502   \u2514\u2500\u2500 Core Concepts\n\u251c\u2500\u2500 Authentication (18 pages)\n\u2502   \u251c\u2500\u2500 Methods\n\u2502   \u2514\u2500\u2500 OAuth\n\u251c\u2500\u2500 Payments (22 pages)\n\u2502   \u251c\u2500\u2500 Processing\n\u2502   \u2514\u2500\u2500 Refunds\n\u251c\u2500\u2500 Subscriptions (13 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u2514\u2500\u2500 Management\n\u251c\u2500\u2500 Webhooks (20 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u251c\u2500\u2500 Events\n\u2502   \u251c\u2500\u2500 Analytics\n\u2502   \u2514\u2500\u2500 Troubleshooting\n\u2514\u2500\u2500 Security (19 pages)\n    \u251c\u2500\u2500 Authentication Security\n    \u251c\u2500\u2500 Payment Security\n    \u2514\u2500\u2500 Best Practices\n```\n\n```text Round 4 (Human): Validate\nMuch better! Balanced (no category >25%), logical structure.\nFinal check: Test with 3 users navigating to common tasks.\n```\n\n</CodeGroup>\n\n<Tip>\n  **Iteration Best Practices:**\n  1. **Be specific in critiques:** Not \"this doesn't work\" but \"this is too vague for beginners\"\n  2. **Iterate in chunks:** Don't try to fix everything at once\n  3. **Set a stopping point:** Know when \"good enough\" is sufficient\n  4. **Document your prompts:** Save the winning prompt for future use\n</Tip>\n\n---",
            "hydration_source_header": "A. Iterative Refinement",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "validation-qa-matrix",
            "title": "Validation QA Task Matrix",
            "helpsChoose": "4 task types",
            "lines": "540-550",
            "retrievalQuestions": [
              "What validation tasks need collaboration?"
            ],
            "content": "**What This Means:**\nStarting with AI generation, then refining through multiple rounds of human feedback and AI regeneration.\n\n**Why Collaboration Works:**\n- AI provides fast first drafts\n- Humans identify issues\n- AI incorporates feedback quickly\n- Humans validate improvements\n- Repeat until satisfactory\n\n**IA Applications:**\n\n| Task | Collaboration Pattern | Example |\n|------|----------------------|---------|\n| **Taxonomy Refinement** | AI generates \u2192 Human critiques \u2192 AI adjusts | \"Flatten this level, merge these categories, split that one\" |\n| **Label Optimization** | AI suggests \u2192 Human tests \u2192 AI revises | \"Too technical, make it plainer\" \u2192 AI rewrites \u2192 test again |\n| **Content Model Development** | AI proposes attributes \u2192 Human adds constraints \u2192 AI regenerates | \"Add required vs. optional flags, include character limits\" |\n| **Navigation Hierarchy** | AI builds structure \u2192 Human identifies gaps \u2192 AI fills | \"What about troubleshooting content?\" \u2192 AI adds category |\n\n**Example Workflow: Taxonomy Refinement**\n\n<CodeGroup>\n\n```text Round 1 (AI): Generate initial taxonomy\nPrompt: \"Create a 3-level taxonomy for 100 API documentation pages covering \nauthentication, payments, webhooks, and analytics.\"\n\nOutput:\n\u251c\u2500\u2500 Authentication (25 pages)\n\u2502   \u251c\u2500\u2500 Methods\n\u2502   \u251c\u2500\u2500 OAuth\n\u2502   \u2514\u2500\u2500 Security\n\u251c\u2500\u2500 Payments (35 pages)\n\u2502   \u251c\u2500\u2500 Processing\n\u2502   \u251c\u2500\u2500 Subscriptions\n\u2502   \u2514\u2500\u2500 Refunds\n\u251c\u2500\u2500 Webhooks (20 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u251c\u2500\u2500 Events\n\u2502   \u2514\u2500\u2500 Troubleshooting\n\u2514\u2500\u2500 Analytics (20 pages)\n    \u251c\u2500\u2500 Tracking\n    \u251c\u2500\u2500 Reports\n    \u2514\u2500\u2500 Dashboards\n```\n\n```text Round 2 (Human): Critique\nIssues identified:\n1. \"Payments\" at 35% is unbalanced\n2. \"Analytics\" feels like it should be under \"Webhooks\" \n   (webhook events generate analytics)\n3. Missing \"Getting Started\" section\n4. \"Security\" could be its own top-level (cross-cutting concern)\n```\n\n```text Round 3 (AI): Refine based on feedback\nPrompt: \"Adjust the taxonomy:\n1. Split 'Payments' into 'Payments' and 'Subscriptions' at top level\n2. Move 'Analytics' under 'Webhooks'\n3. Add 'Getting Started' as first top-level category\n4. Promote 'Security' to top level, covering auth security, payment security\"\n\nOutput:\n\u251c\u2500\u2500 Getting Started (8 pages)\n\u2502   \u251c\u2500\u2500 Quick Start\n\u2502   \u2514\u2500\u2500 Core Concepts\n\u251c\u2500\u2500 Authentication (18 pages)\n\u2502   \u251c\u2500\u2500 Methods\n\u2502   \u2514\u2500\u2500 OAuth\n\u251c\u2500\u2500 Payments (22 pages)\n\u2502   \u251c\u2500\u2500 Processing\n\u2502   \u2514\u2500\u2500 Refunds\n\u251c\u2500\u2500 Subscriptions (13 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u2514\u2500\u2500 Management\n\u251c\u2500\u2500 Webhooks (20 pages)\n\u2502   \u251c\u2500\u2500 Setup\n\u2502   \u251c\u2500\u2500 Events\n\u2502   \u251c\u2500\u2500 Analytics\n\u2502   \u2514\u2500\u2500 Troubleshooting\n\u2514\u2500\u2500 Security (19 pages)\n    \u251c\u2500\u2500 Authentication Security\n    \u251c\u2500\u2500 Payment Security\n    \u2514\u2500\u2500 Best Practices\n```\n\n```text Round 4 (Human): Validate\nMuch better! Balanced (no category >25%), logical structure.\nFinal check: Test with 3 users navigating to common tasks.\n```\n\n</CodeGroup>\n\n<Tip>\n  **Iteration Best Practices:**\n  1. **Be specific in critiques:** Not \"this doesn't work\" but \"this is too vague for beginners\"\n  2. **Iterate in chunks:** Don't try to fix everything at once\n  3. **Set a stopping point:** Know when \"good enough\" is sufficient\n  4. **Document your prompts:** Save the winning prompt for future use\n</Tip>\n\n---",
            "hydration_source_header": "A. Iterative Refinement",
            "hydration_method": "line_proximity"
          },
          {
            "id": "user-validation-methods-matrix",
            "title": "User Validation Methods Matrix",
            "helpsChoose": "4 methods",
            "lines": "850-870",
            "retrievalQuestions": [
              "What validation methods should I use?"
            ],
            "content": "**Purpose:** Catch obvious errors fast\n\n**What to Check:**\n- \u2705 Format is correct (expected structure)\n- \u2705 Completeness (all requested parts present)\n- \u2705 Obvious factual errors\n- \u2705 Nonsensical outputs\n\n**Example Quick Checks:**",
            "hydration_source_header": "Level 1: Quick Checks (Minutes)",
            "hydration_method": "line_proximity"
          }
        ],
        "warnings": [
          {
            "id": "strategic-red-flags",
            "title": "Strategic Decision Red Flags",
            "prevents": "ai-overreach-strategy",
            "lines": "325-330",
            "retrievalQuestions": [
              "When should I NOT use AI for strategic decisions?"
            ],
            "content": "**What This Means:**\nHigh-level choices that shape the entire IA direction and align with business goals.\n\n**Why Humans Must Lead:**\n- Requires business context AI doesn't have\n- Involves trade-offs AI can't evaluate\n- Connects to broader organizational strategy\n- Has long-term implications beyond immediate task\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **IA Approach Selection** | Choose task-based vs. topic-based structure | Requires understanding user mental models from research |\n| **Scope Definition** | Decide what content to include/exclude | Requires business priorities and resource constraints |\n| **Stakeholder Alignment** | Get buy-in from product, engineering, marketing | Requires negotiation and relationship management |\n| **Governance Model** | Define who maintains what content | Requires org structure knowledge |\n| **Success Metrics** | Define what \"good IA\" means for your context | Requires business goal alignment |\n\n**Example: Strategic IA Decision**\n\n<Accordion title=\"Scenario: Organizing API Documentation\">\n\n**Question:** Should you organize by endpoint or by use case?\n\n**AI Can Help:**\n- Generate both structures for comparison\n- List pros/cons of each approach  \n- Show examples from similar products\n- Identify potential issues with each\n\n**Humans Must Decide Based On:**\n- \u2705 User research: How do YOUR users think about the product?\n- \u2705 Business goals: Are you selling solutions or technical features?\n- \u2705 Competitive positioning: How do competitors organize (and should you differ)?\n- \u2705 Product roadmap: Which structure scales better with planned features?\n- \u2705 Resource constraints: Which is more maintainable with your team?\n- \u2705 Technical constraints: What does your CMS support?\n\n**The Decision:** Humans synthesize these factors (which AI can't access or weigh)\n\n</Accordion>\n\n<Warning>\n  **Red Flags That This Is Human-First:**\n  - The phrase \"it depends\" applies heavily\n  - Multiple stakeholders have different preferences\n  - Trade-offs involve business strategy\n  - Decision has multi-year implications\n  - Requires knowledge of internal constraints\n</Warning>\n\n---",
            "hydration_source_header": "A. Strategic Decisions",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "ethical-red-flags",
            "title": "Ethical Decision Red Flags",
            "prevents": "ai-overreach-ethics",
            "lines": "445-450",
            "retrievalQuestions": [
              "When should I NOT use AI for ethical decisions?"
            ],
            "content": "**What This Means:**\nMaking decisions that affect user wellbeing, accessibility, inclusivity, and fairness.\n\n**Why Humans Must Lead:**\n- Requires values and moral reasoning\n- Involves considering harm and benefit\n- Needs understanding of social context\n- Must account for diverse user needs\n- Requires legal/compliance knowledge\n\n**IA Applications:**\n\n| Task | Human Role | Why AI Can't Lead |\n|------|------------|-------------------|\n| **Accessibility Design** | Ensure IA works for users with disabilities | Requires understanding WCAG, testing with assistive tech, empathy for diverse needs |\n| **Plain Language** | Make complex content understandable | Requires knowing your users' reading levels, cultural context, domain knowledge |\n| **Content Sensitivity** | Handle sensitive topics appropriately | Requires cultural awareness, understanding potential harm, legal knowledge |\n| **Inclusive Terminology** | Choose language that doesn't exclude | Requires awareness of marginalized groups, evolving language norms |\n| **Privacy Considerations** | Protect user data in IA decisions | Requires understanding privacy laws, data ethics, consent |\n\n**Example: Accessibility Decisions**\n\n<CodeGroup>\n\n```text AI Suggestion\nNavigation labels:\n- \"Authenticate Programmatically\"\n- \"Implement Authorization Logic\"\n- \"Configure OAuth Flows\"\n\nAI evaluation: \"Clear and descriptive\" (based on length and keywords)\n```\n\n```text Human Accessibility Analysis\nProblems:\n- Technical jargon assumes expert knowledge\n- Not clear to screen reader users\n- Cognitive load too high for beginners\n- Doesn't use plain language\n\nBetter:\n- \"Sign In to Your App\"\n- \"Control Access to Features\"  \n- \"Set Up Login with OAuth\"\n\nHuman ensures: Screen reader friendly, cognitively accessible, plain language\n```\n\n</CodeGroup>\n\n**Example: Ethical Content Organization**\n\n<Accordion title=\"Scenario: Organizing Health Information\">\n\n**Question:** How should you categorize content about medical conditions?\n\n**AI Suggestion:**\n- Organize alphabetically by condition name\n- Group by severity (minor, moderate, severe)\n- Sort by body system (cardiovascular, respiratory, etc.)\n\n**Ethical Considerations (Human):**\n- \u2705 Will organizing by \"severity\" cause anxiety for users seeking information?\n- \u2705 Does alphabetical grouping make emergency information hard to find?\n- \u2705 Are we using person-first language throughout?\n- \u2705 Do category names avoid stigmatizing conditions?\n- \u2705 Is mental health treated with equal prominence to physical health?\n- \u2705 Are we providing equal depth for conditions affecting marginalized groups?\n\n**The Decision:** Humans weigh these ethical implications, which require values and understanding of social impact.\n\n</Accordion>\n\n<Warning>\n  **Red Flags That This Is Human-First:**\n  - \"Should we\" questions (not just \"can we\")\n  - Impacts on vulnerable populations\n  - Legal or compliance requirements\n  - Potential for harm or discrimination\n  - Values-based trade-offs\n</Warning>\n\n---",
            "hydration_source_header": "C. Ethical Judgment and Responsibility",
            "hydration_method": "line_proximity"
          },
          {
            "id": "pattern-finding-red-flags",
            "title": "Pattern Finding Red Flags",
            "prevents": "misapplied-ai-classification",
            "lines": "185-190",
            "retrievalQuestions": [
              "Red flags for AI-first approach"
            ],
            "content": "**What This Means:**\nIdentifying trends, inconsistencies, or structures in existing content.\n\n**Why AI Excels:**\n- Processes large volumes quickly\n- Doesn't miss patterns due to fatigue\n- No confirmation bias\n- Consistent classification criteria\n\n**IA Applications:**\n\n| Task | AI Role | Example |\n|------|---------|---------|\n| **Content Classification** | Categorize pages by type | \"Classify these 200 pages as Tutorial, Reference, Guide, or Concept\" |\n| **Inconsistency Detection** | Find naming variations | \"Identify inconsistent terminology across these documentation pages\" |\n| **Structure Pattern Analysis** | Recognize organizational approaches | \"What structural patterns appear in these 50 page titles?\" |\n| **Gap Identification** | Spot missing content areas | \"What topics are missing from this documentation set?\" |\n| **Redundancy Detection** | Find duplicate or overlapping content | \"Identify pages covering the same topics\" |\n\n**Example Workflow: Content Classification**\n\n```text Context\nYou have 300 documentation pages to classify using Di\u00e1taxis framework\n```\n\n```text Step 1 (Human): Prepare data and provide classification rules\nExport: Page titles + first 100 words of each page\nRules: Define each category clearly with examples\n```\n\n<CodeGroup>\n\n```text Step 2 (AI): Classify all pages\nPrompt: \"Classify each page as Tutorial (learning-oriented), \nHow-to Guide (task-oriented), Reference (information-oriented), \nor Explanation (understanding-oriented). \nProvide classification + brief reasoning.\"\n```\n\n```text Step 3 (Human): Spot-check results\nValidate ~20% randomly selected pages\nCheck edge cases manually\nReview AI's reasoning for uncertain classifications\n```\n\n```text Step 4 (Human + AI): Refine misclassifications\nAddress systematic errors in prompt\nReclassify problematic pages with more context\n```\n\n</CodeGroup>\n\n**Real Example Output:**\n\n```text AI Classifications\nPage: \"Getting Started with Authentication\"\nClassification: Tutorial\nReasoning: Step-by-step learning journey, assumes no prior knowledge, \nteaches by doing\n\nPage: \"Authentication Endpoint Reference\"  \nClassification: Reference\nReasoning: Technical specifications, lists all endpoints, \ndescribes what each does\n\nPage: \"How to Implement OAuth 2.0\"\nClassification: How-to Guide\nReasoning: Task-oriented, assumes some knowledge, \nfocuses on achieving specific goal\n\nPage: \"Understanding Token Expiration\"\nClassification: Explanation\nReasoning: Conceptual explanation, background knowledge, \nhelps understand why something works\n```\n\n<Tip>\n  **When to Use AI-First for Pattern Finding:**\n  - \u2705 Large content volumes (100+ items)\n  - \u2705 Repetitive classification criteria\n  - \u2705 Objective patterns (not subjective interpretation)\n  - \u2705 Speed is valuable\n</Tip>\n\n<Warning>\n  **When NOT to Use AI-First:**\n  - \u274c Nuanced interpretation required\n  - \u274c Small dataset (easier to do manually)\n  - \u274c Complex, multifaceted categorization\n  - \u274c Deep domain expertise needed per item\n</Warning>\n\n---",
            "hydration_source_header": "B. Pattern Finding Tasks",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "skip-validation-warning",
            "title": "Don't Skip Earlier Validation Levels",
            "prevents": "wasted-user-testing",
            "lines": "888-892",
            "retrievalQuestions": [
              "What should I watch out for with validation?"
            ],
            "content": "**AI Generated Labels:**\n```\n- Authentication Guide\n- Authenticate Your Users\n- API Security\n- Secure Your API\n- OAuth Implementation\n```\n\n**Quick Check Findings:**\n- \u2705 All labels under 30 characters (format requirement met)\n- \u2705 No typos or obvious errors\n- \u26a0\ufe0f Possible redundancy (\"Authentication\" vs \"Authenticate\")\n\n**Action:** Passes Level 1, proceed to Level 2 for deeper check\n\n<Tip>\n  **Time Investment:** 2-5 minutes. Don't skip this\u2014it catches embarrassing errors before you invest more time.\n</Tip>\n\n---",
            "hydration_source_header": "Example 2: Label Check",
            "hydration_method": "line_proximity"
          }
        ],
        "userValidationMethods": [
          {
            "id": "tree-testing",
            "title": "Tree Testing",
            "time": "20-30 min/participant",
            "participants": "8-12",
            "lines": "855-860",
            "retrievalQuestions": [
              "What is tree testing?",
              "How many participants for tree testing?"
            ],
            "content": "**Purpose:** Catch obvious errors fast\n\n**What to Check:**\n- \u2705 Format is correct (expected structure)\n- \u2705 Completeness (all requested parts present)\n- \u2705 Obvious factual errors\n- \u2705 Nonsensical outputs\n\n**Example Quick Checks:**",
            "hydration_source_header": "Level 1: Quick Checks (Minutes)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "first-click-testing",
            "title": "First Click Testing",
            "time": "5-10 min/participant",
            "participants": "15-20",
            "lines": "860-865",
            "retrievalQuestions": [
              "What is first click testing?"
            ],
            "content": "**Purpose:** Catch obvious errors fast\n\n**What to Check:**\n- \u2705 Format is correct (expected structure)\n- \u2705 Completeness (all requested parts present)\n- \u2705 Obvious factual errors\n- \u2705 Nonsensical outputs\n\n**Example Quick Checks:**",
            "hydration_source_header": "Level 1: Quick Checks (Minutes)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "usability-testing",
            "title": "Usability Testing",
            "time": "60 min/participant",
            "participants": "5-8",
            "lines": "865-870",
            "retrievalQuestions": [
              "When should I do usability testing?"
            ],
            "content": "**Purpose:** Catch obvious errors fast\n\n**What to Check:**\n- \u2705 Format is correct (expected structure)\n- \u2705 Completeness (all requested parts present)\n- \u2705 Obvious factual errors\n- \u2705 Nonsensical outputs\n\n**Example Quick Checks:**",
            "hydration_source_header": "Level 1: Quick Checks (Minutes)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "ab-testing",
            "title": "A/B Testing",
            "time": "1-2 weeks",
            "participants": "Hundreds",
            "lines": "870-875",
            "retrievalQuestions": [
              "When to use A/B testing?"
            ],
            "content": "**AI Generated Taxonomy:**\n```\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 API Reference\n\u251c\u2500\u2500 SDKs & Tools\n\u251c\u2500\u2500 Get Started\n\u2514\u2500\u2500 Troubleshooting\n```\n\n**Quick Check Findings:**\n- \u274c \"Get Started\" appears twice (obvious error)\n- \u2705 Format is correct (tree structure)\n- \u2705 All categories present\n- \u2705 No nonsensical content\n\n**Action:** Fix immediately, no deep analysis needed\n\n---",
            "hydration_source_header": "Example 1: Taxonomy Check",
            "hydration_method": "line_proximity"
          }
        ]
      }
    },
    "1-3-prompt-engineering": {
      "file": "1-3-prompt-engineering.mdx",
      "focus": "Systematic prompt engineering techniques for IA tasks using the RICE framework and five-component model",
      "entityCount": 78,
      "entities": {
        "frameworks": [
          {
            "id": "prompt-anatomy",
            "title": "Anatomy of an Effective Prompt",
            "type": "framework",
            "definition": "Five-component model for structuring effective prompts: role, context, task, constraints, format",
            "contains": [
              "role-component",
              "context-component",
              "task-component",
              "constraints-component",
              "format-component"
            ],
            "lines": "50-300",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I write a good prompt?",
              "What are the components of an effective prompt?"
            ],
            "content": "Every effective prompt has five key components. Think of them as the building blocks that guide AI to produce what you need.\n\n### The Five Components\n\n**Five-step flow:** Every effective prompt includes five key components in sequence: (1) Role - who should the AI be, (2) Context - what's the situation, (3) Task - what should it do, (4) Constraints - what are the limits, and (5) Format - how should output look.\n\n**Text-based representation (for screen readers and text-only environments):**\n\n```\nPROMPT COMPONENT FLOW\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nStep 1: ROLE \u2192 Step 2: CONTEXT \u2192 Step 3: TASK \u2192 Step 4: CONSTRAINTS \u2192 Step 5: FORMAT\n\n1. ROLE: Who should the AI be?\n   \u2193\n2. CONTEXT: What's the situation?\n   \u2193\n3. TASK: What should it do?\n   \u2193\n4. CONSTRAINTS: What are the limits?\n   \u2193\n5. FORMAT: How should output look?\n\nThis sequential flow ensures prompts are complete and well-structured.\n```\n\n**Visual flowchart:**\n\n```mermaid\ngraph TD\n    A[1. ROLE<br/>Who should the AI be?]\n    B[2. CONTEXT<br/>What's the situation?]\n    C[3. TASK<br/>What should it do?]\n    D[4. CONSTRAINTS<br/>What are the limits?]\n    E[5. FORMAT<br/>How should output look?]\n\n    A --> B\n    B --> C\n    C --> D\n    D --> E\n\n    style A fill:#e3f2fd\n    style B fill:#e8f5e9\n    style C fill:#fff3e0\n    style D fill:#fce4ec\n    style E fill:#f3e5f5\n```\n\nLet's examine each component in detail.\n\n---\n\n### 1.1 Component 1: Role\n\n**What It Is:**\nDefine who the AI should act as. This sets the knowledge domain and perspective.\n\n**Why It Matters:**\n- Activates relevant knowledge patterns in the AI's training\n- Sets appropriate tone and depth\n- Helps AI understand context better\n\n**Examples:**\n\n<CardGroup cols={2}>\n  <Card title=\"Generic Role\" icon=\"user\">\n    \"You're an AI assistant.\"\n    \n    **Problem:** Too broad, doesn't activate specialized knowledge\n  </Card>\n  \n  <Card title=\"Specific Role\" icon=\"user-tie\">\n    \"You're an information architect with 10 years of experience designing taxonomies for developer documentation.\"\n    \n    **Better:** Activates relevant domain knowledge, sets expertise level\n  </Card>\n</CardGroup>\n\n**Role Formula for IA Work:**\n\n```text\n\"You are a/an [specific role] with expertise in [relevant specialization].\"\n\nExamples:\n- \"You are an information architect specializing in API documentation structure.\"\n- \"You are a UX researcher who analyzes card sorting results.\"\n- \"You are a content strategist who designs metadata schemas.\"\n- \"You are a navigation designer focused on developer experience.\"\n```\n\n<Tip>\n  **Pro Tip:** The more specific the role, the better the output. \"Information architect\" is good. \"Information architect specializing in software documentation using the Di\u00e1taxis framework\" is better.\n</Tip>\n\n---\n\n### 1.2 Component 2: Context\n\n**What It Is:**\nBackground information that helps AI understand the situation, constraints, and goals.\n\n**Three Types of Context for IA:**\n\n**1. User Context**\n- Who are your users?\n- What's their expertise level?\n- What are their goals and pain points?\n- What tasks do they need to accomplish?\n\n**2. Content Context**\n- How much content exists?\n- What types of content?\n- What's the current state/problem?\n- What content frameworks apply (e.g., Di\u00e1taxis)?\n\n**3. Business Context**\n- What are the goals?\n- What constraints exist (technical, resource, timeline)?\n- What organizational factors matter?\n- What success metrics?\n\n**Example Context Breakdown:**\n\n```text Bad Context (Vague)\n\"We have some documentation that needs organizing.\"\n\nGood Context (Specific)\n\"Background:\n- 120 pages of REST API documentation\n- Target users: Junior to mid-level developers (0-4 years experience)\n- Current problem: 65% of users resort to search, low task success rate\n- Content types: 30 tutorials, 45 reference pages, 30 how-to guides, 15 explanations\n- Business goal: Reduce time-to-first-API-call by 30%\n- Technical constraint: Must work with existing Markdown file structure\n- Timeline: Need to implement in 4 weeks\"\n```\n\n<Warning>\n  **Common Mistake:** Assuming AI knows your context. It doesn't! Always provide rich background, even if it feels obvious to you.\n</Warning>\n\n---\n\n### 1.3 Component 3: Task\n\n**What It Is:**\nThe specific action you want AI to perform, stated clearly and unambiguously.\n\n**From Vague to Specific:**\n\n| Vague | Specific | Why It's Better |\n|-------|----------|-----------------|\n| \"Create a taxonomy\" | \"Generate a 3-level hierarchical taxonomy\" | Defines structure depth |\n| \"Organize content\" | \"Classify these 50 pages using the Di\u00e1taxis framework (Tutorial, How-to, Reference, Explanation)\" | Specifies classification system |\n| \"Improve navigation\" | \"Generate 10 alternative navigation labels for the API Reference section, each under 25 characters\" | Quantified, constrained, measurable |\n| \"Analyze this data\" | \"Calculate similarity matrix from card sorting data showing co-occurrence percentages for all card pairs\" | Defines exact output needed |\n\n**Action Verb Formula:**\n\n```text Strong IA Task Verbs:\n- Generate [quantity] [what]\n- Classify [content] using [framework]\n- Analyze [data] to identify [patterns]\n- Create [structure] with [specifications]\n- Map [relationship type] between [entities]\n- Compare [option A] and [option B] based on [criteria]\n- Validate [artifact] against [principles/standards]\n```\n\n---\n\n### 1.4 Component 4: Constraints\n\n**What It Is:**\nLimits, requirements, and rules that the output must respect.\n\n**Three Types of Constraints:**\n\n**1. Technical Constraints**\n- Maximum depth/levels\n- Character limits\n- File format requirements\n- Platform limitations\n- Integration requirements\n\n**2. Business Constraints**\n- Budget/resource limits\n- Timeline restrictions\n- Stakeholder requirements\n- Existing standards to follow\n- Brand voice guidelines\n\n**3. IA Constraints**\n- Framework adherence (e.g., Di\u00e1taxis)\n- Accessibility requirements (WCAG)\n- Best practices (max 7\u00b12 items per level)\n- User research findings\n- Mental model alignment\n\n**Example Constraints Section:**\n\n```text\nConstraints:\n- Maximum 3 levels deep (avoid overwhelming users)\n- Top level: 5-7 categories (cognitive load limit)\n- Labels must be under 25 characters (UI limitation)\n- Must include clear location for troubleshooting content\n- Follow Di\u00e1taxis framework for content type classification\n- Navigation must work with keyboard-only navigation (accessibility)\n- Must be implementable in Docusaurus (technical constraint)\n- No reorganization of existing reference documentation (stakeholder requirement)\n```\n\n<Tip>\n  **The More Constraints, The Better:** Constraints don't limit AI\u2014they guide it toward outputs that actually work in your situation.\n</Tip>\n\n---\n\n### 1.5 Component 5: Format\n\n**What It Is:**\nSpecification of exactly how the output should be structured and presented.\n\n**Why It Matters:**\n- Ensures output is immediately usable\n- Reduces need for reformatting\n- Makes validation easier\n- Facilitates team sharing\n\n**Format Specification Examples:**\n\n### Example 1: Taxonomy Output Format\n\n```text Bad Format Spec\n\"Output as a list.\"\n\nGood Format Spec\n\"Output format:\n- Markdown indented list with three levels\n- Use em dashes (\u2014) for indentation\n- Include estimated page counts in (parentheses) after each category\n- Provide a 1-sentence description for each top-level category\n- Mark content types with [Tutorial], [How-to], [Reference], [Explanation] tags\"\n\nExample output:\n\u251c\u2500\u2500 Get Started (15 pages)\n\u2502   Purpose: Guide new users to first successful API call\n\u2502   \u251c\u2500\u2500 Installation [Tutorial]\n\u2502   \u251c\u2500\u2500 Quick Start [Tutorial]\n\u2502   \u2514\u2500\u2500 Core Concepts [Explanation]\n```\n\n### Example 2: Analysis Output Format\n\n```text\n\"Output format:\nStructured report with:\n1. Executive Summary (3-5 key findings)\n2. Detailed Analysis\n   - Data tables where appropriate\n   - Percentages and counts\n   - Confidence levels (high/medium/low)\n3. Specific Recommendations\n   - Actionable steps\n   - Rationale for each\n   - Expected impact\n4. Next Steps (prioritized list)\n\nUse markdown formatting with clear headers.\"\n```\n\n---\n\n### 1.6 Putting It All Together: Complete Prompt Anatomy\n\nHere's a complete prompt with all five components clearly labeled:\n\n```text\n[ROLE]\nYou're an information architect specializing in developer documentation \nand the Di\u00e1taxis framework.\n\n[CONTEXT]\nI'm redesigning the IA for a REST API documentation site with 120 pages. \nCurrent problems: developers can't find advanced features, troubleshooting \nis buried, and there's confusion between tutorials and reference docs. \nTarget audience: developers with 1-3 years experience. Content types: \n40 tutorials, 50 reference pages, 20 how-to guides, 10 conceptual explanations.\n\n[TASK]\nCreate a 3-level taxonomy that organizes all 120 pages by user task (top level), \nfeature area (second level), and content type (third level following Di\u00e1taxis).\n\n[CONSTRAINTS]\n- Maximum 3 levels deep\n- Top level: 5-7 categories\n- Must include clear homes for troubleshooting content\n- Keep related auth and security content together\n- Labels must be under 30 characters\n- Must work with existing Markdown file structure\n\n[FORMAT]\nOutput as an indented markdown list showing:\n- All three levels\n- Page count estimates for each category in (parentheses)\n- A brief 1-sentence description for each top-level category\n```\n\n**This prompt will produce far better results than:** \"Create a taxonomy for API docs\"\n\n---\n\n### Check Your Understanding: Section 1\n\n<Warning>\n**Quick Practice (3 minutes):** Test your grasp of the five components before continuing.\n</Warning>\n\n**Scenario:** You need a prompt to generate navigation labels for a mobile app's settings screen.\n\n**Question:** Which components are missing from this prompt?\n\n```text\n\"Generate navigation labels for app settings.\"\n```\n\n<details>\n<summary>Show Answer</summary>\n\n**Missing Components:**\n\n1. **\u274c Role:** No expertise defined (should be \"UX writer\" or \"Mobile app designer\")\n2. **\u274c Context:** No information about the app, users, or settings categories\n3. **\u274c Task:** Vague (\"generate labels\" - how many? for what specifically?)\n4. **\u274c Constraints:** No character limits, tone guidance, or accessibility requirements\n5. **\u274c Format:** No specification of output structure\n\n**Improved Prompt:**\n\n```text\n[Role] You're a UX writer specializing in mobile app navigation.\n\n[Context] Creating navigation labels for a fitness tracking app's settings screen.\nSettings categories: Account, Notifications, Privacy, Data & Storage, Appearance.\nUsers: Ages 25-45, mix of technical literacy levels.\n\n[Task] Generate 2-3 label variations for each of the 5 settings categories.\n\n[Constraints]\n- Maximum 20 characters per label\n- Plain language (avoid technical jargon)\n- Consistent voice across all labels\n- Mobile-friendly (clear on small screens)\n\n[Format] Present as a table with columns: Category | Option 1 | Option 2 | Option 3 | Recommendation\n```\n\n**Key Takeaway:** A complete prompt includes ALL five components. Missing even one reduces output quality significantly.\n\n</details>\n\n---",
            "hydration_source_header": "1. Anatomy of an Effective Prompt",
            "hydration_method": "title_match"
          },
          {
            "id": "rice-framework",
            "title": "RICE Framework",
            "type": "framework",
            "definition": "Role, Instructions, Context, Examples - structured framework for IA prompts",
            "contains": [
              "role",
              "instructions",
              "context",
              "examples"
            ],
            "lines": "380-700",
            "crossModule": true,
            "retrievalQuestions": [
              "What is the RICE framework?",
              "How do I structure prompts for IA work?"
            ],
            "content": "Now that you understand the five components, let's look at a systematic framework for organizing them: **RICE**.\n\n**RICE stands for:**\n- **R**ole\n- **I**nstructions (Task + Constraints + Format)\n- **C**ontext\n- **E**xamples\n\n<Info>\n  **Note:** Format and Constraints are embedded within Instructions in the RICE framework.\n</Info>\n\n---\n\n### 2.1 Why Use RICE?\n\n**Benefits:**\n- \u2705 Systematic approach (don't forget components)\n- \u2705 Clear structure (easy to review and refine)\n- \u2705 Reproducible (save and reuse successful prompts)\n- \u2705 Teachable (share with team)\n- \u2705 Scalable (works for simple and complex prompts)\n\n**When to Use RICE:**\n- Complex IA tasks requiring specificity\n- Prompts you'll reuse multiple times\n- When initial outputs aren't meeting expectations\n- Team collaboration (standardized approach)\n\n---\n\n### 2.2 RICE Template for IA Work\n\n```text\n[R - ROLE]\nYou are a/an [specific role] with expertise in [relevant specialization].\n\n[I - INSTRUCTIONS]\nYour task is to [specific action verb] [what] [for what purpose].\n\nRequirements:\n- [Requirement 1]\n- [Requirement 2]\n- [Constraint 1]\n- [Constraint 2]\n\nOutput format:\n- [Format specification]\n\n[C - CONTEXT]\nBackground:\n- [Audience information]\n- [Current state/problems]\n- [Business goals]\n- [Content inventory details]\n\nPrinciples to follow:\n- [IA principle 1]\n- [IA principle 2]\n\n[E - EXAMPLES]\n[If applicable, provide examples of:]\n- Good outputs you're looking for\n- Bad outputs to avoid\n- Sample input data\n- Reference structures\n```\n\n---\n\n### 2.3 RICE Example 1: Taxonomy Generation\n\n```text\n[R - ROLE]\nYou are an information architect with 10 years of experience designing \ntaxonomies for software documentation, specializing in developer-focused \ncontent and API documentation.\n\n[I - INSTRUCTIONS]\nYour task is to generate a 3-level taxonomy that organizes 85 API \ndocumentation pages covering authentication, payments, webhooks, and analytics.\n\nRequirements:\n- Use task-based organization at the top level\n- Group by feature area at the second level\n- Organize by content type (following Di\u00e1taxis) at the third level\n- Each top-level category should have 3-6 subcategories\n- Labels must be clear, action-oriented, and under 25 characters\n- Must include a clear location for troubleshooting content\n\nOutput format:\n- Markdown indented list with three levels\n- Include estimated page counts in (parentheses)\n- Provide a 1-sentence description for each top-level category\n\n[C - CONTEXT]\nBackground:\n- Target audience: Junior to mid-level developers (0-4 years experience)\n- Current problem: Poor findability, 52% of users resort to search\n- Business goal: Reduce time-to-first-successful-API-call by 30%\n- Content types: 20 tutorials, 45 reference pages, 15 how-to guides, 5 explanations\n\nPrinciples to follow:\n- Di\u00e1taxis framework (Tutorial/How-to/Reference/Explanation)\n- Progressive disclosure (beginner content first)\n- Task-oriented (organize by what users want to accomplish)\n- Maximum 3 levels deep (avoid overwhelming users)\n\n[E - EXAMPLES]\nExample of good top-level category:\n\"Get Started\" (15 pages)\n- Covers installation, first API call, basic concepts\n- Task-oriented label\n- Clear entry point for new users\n\nExample of poor category to avoid:\n\"Advanced Stuff\" \n- Vague label\n- \"Advanced\" is subjective\n- Doesn't indicate what tasks it supports\n\nSample content that needs categorizing:\n- \"OAuth 2.0 Implementation Tutorial\"\n- \"Payment API Endpoint Reference\"\n- \"Understanding Webhook Events\"\n- \"How to Handle API Errors\"\n```\n\n---\n\n### 2.4 RICE Example 2: Content Classification\n\n```text\n[R - ROLE]\nYou are a content strategist and information architect who specializes in \nclassifying documentation using the Di\u00e1taxis framework. You understand the \nsubtle differences between tutorials, how-to guides, reference docs, and \nconceptual explanations.\n\n[I - INSTRUCTIONS]\nYour task is to classify 50 documentation pages using the Di\u00e1taxis framework.\n\nFor each page, provide:\n1. Page title\n2. Classification (Tutorial, How-to Guide, Reference, or Explanation)\n3. Brief reasoning (one sentence explaining why)\n4. Confidence level (high/medium/low)\n\nRequirements:\n- Use ONLY the four Di\u00e1taxis categories\n- Base classification on content purpose, not just format\n- Flag any pages that don't fit cleanly (hybrid content)\n- Note pages that might need splitting or reconceptualization\n\nOutput format:\nStructured table with columns:\n| Page Title | Type | Reasoning | Confidence | Notes |\n\n[C - CONTEXT]\nBackground:\n- Payment API documentation with mixed content types\n- Current organization is feature-based, not content-type-based\n- Users struggle to find \"how to do X\" vs \"what is X\"\n- Goal: Reorganize to support different user intents\n\nDi\u00e1taxis definitions for reference:\n- Tutorial: Learning-oriented, step-by-step lesson, teaches by doing\n- How-to Guide: Task-oriented, solves specific problem, assumes some knowledge\n- Reference: Information-oriented, describes the machinery, technical specs\n- Explanation: Understanding-oriented, clarifies concepts, discusses why\n\nContent characteristics:\n- 50 pages total\n- Mix of API endpoints, conceptual topics, and practical guides\n- Some pages cover multiple intents (these are problem cases)\n\n[E - EXAMPLES]\nGood classification:\n\"Building Your First Payment Flow\" \u2192 Tutorial\nReasoning: Step-by-step walkthrough for beginners, teaches fundamentals\nConfidence: High\n\n\"Payment Endpoint Reference\" \u2192 Reference\nReasoning: Technical specifications, describes parameters and responses\nConfidence: High\n\n\"How to Handle Failed Payments\" \u2192 How-to Guide\nReasoning: Task-oriented, solves specific problem, assumes basic knowledge\nConfidence: High\n\nProblematic case:\n\"Understanding Webhook Signatures\" \u2192 Explanation + How-to (hybrid)\nReasoning: First half explains what signatures are (Explanation), \nsecond half shows how to validate them (How-to)\nConfidence: Medium\nNotes: Consider splitting into two pages\n```\n\n---\n\n### 2.5 RICE Example 3: Navigation Label Generation\n\n```text\n[R - ROLE]\nYou are a UX writer and information architect specializing in creating \nclear, accessible navigation labels for developer documentation. You \nunderstand information scent and how to write labels that work without \nvisual context.\n\n[I - INSTRUCTIONS]\nYour task is to generate 10 different navigation label options for the \nsection covering API security, authentication, and authorization content.\n\nRequirements:\n- Labels must be under 25 characters\n- Must be meaningful to screen reader users (no \"Learn More\" type labels)\n- Should indicate content scope clearly\n- Use plain language where possible (avoid unnecessary jargon)\n- Consider both novice and experienced developers\n- Labels should work in a horizontal navigation bar\n\nOutput format:\nNumbered list with:\n1. Label text\n2. Character count\n3. Brief rationale (why this label works)\n4. Potential concerns (if any)\n\n[C - CONTEXT]\nBackground:\n- Developer documentation for a REST API\n- This section contains 30 pages covering API keys, OAuth, security best practices, and common auth errors\n- Users come from various backgrounds: some understand auth deeply, others are learning\n- Current label \"Security\" is too vague and causes low click-through\n- Analytics show users searching for \"authentication\", \"oauth\", \"api key\"\n\nContent this label covers:\n- API authentication methods (API keys, OAuth 2.0, JWT)\n- Authorization and permissions\n- Security best practices\n- Common security errors and troubleshooting\n\nConstraints:\n- Must work in 25 characters max (UI limitation)\n- Needs to be accessible (clear to screen readers)\n- Should match common search terms when possible\n\n[E - EXAMPLES]\nExample of GOOD label:\n\"Authentication & Security\" (25 chars)\nRationale: Specific scope, includes top search term, indicates dual coverage\nConcerns: Slightly long but within limit\n\nExample of BAD label:\n\"Auth Stuff\" (10 chars)\nIssues: Too casual, \"stuff\" is vague, unclear scope\n\nAnother BAD label:\n\"Learn About Security\" (20 chars)\nIssues: Unclear destination, \"learn about\" adds no info, not screen-reader friendly\n```\n\n---\n\n### 2.6 When to Include Examples (The \"E\" in RICE)\n\n**Examples are optional\u2014but powerful.** Use this decision tree to determine when they're worth the effort.\n\n#### Decision Flowchart: Should You Include Examples?\n\n**Text-based decision tree (for screen readers):**\n\n```\nSHOULD YOU INCLUDE EXAMPLES IN YOUR PROMPT?\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nStart \u2192 Is the task ambiguous or subjective? (e.g., \"write clearly\", \"good labels\")\n        \u251c\u2500 YES \u2192 INCLUDE EXAMPLES (90% of the time)\n        \u2514\u2500 NO  \u2192 Continue to next question\n                 \u2193\n        Has the AI missed the mark on previous attempts?\n        \u251c\u2500 YES \u2192 INCLUDE EXAMPLES (fixes misalignment)\n        \u2514\u2500 NO  \u2192 Continue to next question\n                 \u2193\n        Do you have specific style, tone, or quality requirements?\n        \u251c\u2500 YES \u2192 INCLUDE EXAMPLES (shows desired quality bar)\n        \u2514\u2500 NO  \u2192 Continue to next question\n                 \u2193\n        Are you distinguishing between good vs. bad approaches?\n        \u251c\u2500 YES \u2192 INCLUDE EXAMPLES (use contrast pairs)\n        \u2514\u2500 NO  \u2192 Continue to next question\n                 \u2193\n        Is the task straightforward with objective criteria?\n        \u251c\u2500 YES \u2192 SKIP EXAMPLES (clear instructions suffice)\n        \u2514\u2500 NO  \u2192 INCLUDE EXAMPLES (when in doubt, include)\n\nKEY INSIGHT: Examples are especially critical for subjective tasks.\nIf you're using words like \"clear\", \"good\", \"effective\", \"professional\"\n\u2192 You need examples to define what these mean.\n```\n\n**Visual decision flowchart:**\n\n```mermaid\ngraph TD\n    Start([Start: Writing a prompt])\n    Q1{Is task ambiguous<br/>or subjective?}\n    Q2{Has AI missed the<br/>mark before?}\n    Q3{Specific style/quality<br/>requirements?}\n    Q4{Showing good vs.<br/>bad approaches?}\n    Q5{Task straightforward<br/>with objective criteria?}\n\n    Include1[\u2705 INCLUDE EXAMPLES<br/>Ambiguity = High value]\n    Include2[\u2705 INCLUDE EXAMPLES<br/>Fix misalignment]\n    Include3[\u2705 INCLUDE EXAMPLES<br/>Show quality bar]\n    Include4[\u2705 INCLUDE EXAMPLES<br/>Use contrast pairs]\n    Skip[\u274c SKIP EXAMPLES<br/>Instructions suffice]\n    Include5[\u2705 INCLUDE EXAMPLES<br/>When in doubt, include]\n\n    Start --> Q1\n    Q1 -->|Yes| Include1\n    Q1 -->|No| Q2\n    Q2 -->|Yes| Include2\n    Q2 -->|No| Q3\n    Q3 -->|Yes| Include3\n    Q3 -->|No| Q4\n    Q4 -->|Yes| Include4\n    Q4 -->|No| Q5\n    Q5 -->|Yes| Skip\n    Q5 -->|No| Include5\n\n    style Include1 fill:#d4edda\n    style Include2 fill:#d4edda\n    style Include3 fill:#d4edda\n    style Include4 fill:#d4edda\n    style Include5 fill:#d4edda\n    style Skip fill:#f8d7da\n```\n\n---\n\n#### When Examples Made the Difference: Real Scenarios\n\n**Scenario 1: Navigation Label Clarity**\n\n\u274c **Without Examples:**\n```text\n[R] You're an information architect.\n[I] Generate clear, concise navigation labels for these sections.\n[C] Documentation site with API reference, tutorials, guides, SDK docs.\n```\n\n**Result:** Generic labels like \"Documentation\", \"Resources\", \"Learn More\" (unhelpful, vague)\n\n\u2705 **With Examples:**\n```text\n[E] Example of GOOD label:\n- \"API Reference\" (specific, clear purpose)\n- \"Quick Start Guide\" (action-oriented, clear outcome)\n\nExample of BAD label to avoid:\n- \"Resources\" (too vague, no clear destination)\n- \"Documentation\" (redundant - entire site is docs)\n```\n\n**Result:** Specific, scannable labels like \"API Reference\", \"Tutorials\", \"SDK Setup\", \"Integration Guides\"\n\n**Why Examples Mattered:** \"Clear\" and \"concise\" are subjective without concrete demonstrations.\n\n---\n\n**Scenario 2: Taxonomy Quality Standards**\n\n\u274c **Without Examples:**\n```text\n[R] You're an information architect.\n[I] Create a taxonomy for software documentation.\n[C] 80 pages covering authentication, payments, webhooks, analytics.\n```\n\n**Result:** Generic categories like \"Getting Started\", \"Features\", \"Advanced Topics\" (shallow, predictable)\n\n\u2705 **With Examples:**\n```text\n[E] Example of GOOD top-level category:\n- \"Authentication & Security\" (precise scope, clear user need)\n  - Subcategories: OAuth Setup, API Keys, Session Management\n  - Why good: Groups related security tasks together\n\nExample of BAD category to avoid:\n- \"Advanced Topics\" (vague, unclear what qualifies as \"advanced\")\n  - Why bad: Doesn't help users navigate, subjective classification\n```\n\n**Result:** Specific, user-focused categories like \"Authentication & Security\", \"Payment Processing\", \"Event & Webhook Setup\", \"Analytics Integration\"\n\n**Why Examples Mattered:** Showed quality bar and prevented generic placeholder categories.\n\n---\n\n**Scenario 3: Content Audit Severity Ratings**\n\n\u274c **Without Examples:**\n```text\n[R] You're a content strategist.\n[I] Audit help articles. Rate issues as High/Medium/Low severity.\n[C] 50 articles, users report confusion about SSO and billing.\n```\n\n**Result:** Inconsistent severity ratings (e.g., outdated screenshots rated \"High\", missing critical SSO docs rated \"Medium\")\n\n\u2705 **With Examples:**\n```text\n[E] Severity Examples:\n\nHIGH: Missing critical information users need to complete core tasks\n- Example: No SSO setup documentation (users blocked from enterprise setup)\n\nMEDIUM: Outdated information that may cause confusion\n- Example: Screenshots show old UI (users can still complete task with effort)\n\nLOW: Minor improvements to clarity or polish\n- Example: Typo in help article (doesn't block understanding)\n```\n\n**Result:** Consistent, useful severity ratings aligned with user impact\n\n**Why Examples Mattered:** \"High/Medium/Low\" means different things to different people without calibration examples.\n\n---\n\n**Scenario 4: Writing Tone Consistency**\n\n\u274c **Without Examples:**\n```text\n[R] You're a UX writer.\n[I] Write error messages in a friendly, helpful tone.\n[C] E-commerce checkout flow, various error scenarios.\n```\n\n**Result:** Inconsistent tone ranging from overly casual (\"Oops! Something broke!\") to robotic (\"Error code 4521: Invalid payment method\")\n\n\u2705 **With Examples:**\n```text\n[E] Example of GOOD error message (friendly + helpful):\n\"We couldn't process your payment. Please check your card number and try again,\nor use a different payment method.\"\n- Why good: Explains problem, suggests solution, stays professional\n\nExample of BAD error message:\n\"Payment failed.\" (unhelpful, no guidance)\n\"Oops! The payment gremlins are at it again! \ud83e\udd2a\" (too casual, unprofessional)\n```\n\n**Result:** Consistent, professional-friendly error messages across all scenarios\n\n**Why Examples Mattered:** \"Friendly tone\" is highly subjective without concrete demonstrations.\n\n---\n\n#### Quick Reference: Include vs. Skip Examples\n\n| **Include Examples When:** | **Skip Examples When:** |\n|---|---|\n| \u2705 Task uses subjective words (\"clear\", \"good\", \"professional\") | \u274c Task is purely objective (\"count words\", \"extract dates\") |\n| \u2705 AI previously produced wrong style/quality | \u274c You want maximum creativity/exploration |\n| \u2705 Showing good vs. bad approaches helps | \u274c Prompt is already very long (>300 words) |\n| \u2705 Output quality varies without examples | \u274c Instructions are unambiguous (e.g., \"convert JSON to CSV\") |\n| \u2705 First time attempting this type of task | \u274c You're brainstorming (want diverse ideas) |\n\n**When in Doubt:** Include 1-2 examples. They take 30 seconds to write but often save 10+ minutes of iteration.\n\n**Cost-Benefit Rule:** If adding examples takes less than 1 minute but saves one re-prompt cycle (5+ minutes), include them.\n\n---\n\n### Check Your Understanding: Section 2\n\n<Warning>\n**Quick Practice (4 minutes):** Apply the RICE framework to a real scenario.\n</Warning>\n\n**Scenario:** You need to audit 50 help articles to identify content gaps.\n\n**Task:** Organize these prompt elements into RICE structure:\n\n**Given elements:**\n- \"You're a content strategist specializing in help documentation\"\n- \"Identify: Missing topics, outdated information, unclear explanations\"\n- \"Output as markdown table with columns: Article Title, Issues Found, Severity (High/Medium/Low), Recommended Action\"\n- \"The help center has 50 articles covering account setup, billing, integrations, and troubleshooting\"\n- \"Users report: Can't find SSO setup info, billing FAQ is confusing, integration guides are outdated\"\n\n<details>\n<summary>Show Answer</summary>\n\n**Correct RICE Structure:**\n\n```text\n[R - ROLE]\nYou're a content strategist specializing in help documentation\n\n[I - INSTRUCTIONS]\nIdentify: Missing topics, outdated information, unclear explanations\n\nOutput as markdown table with columns: Article Title, Issues Found,\nSeverity (High/Medium/Low), Recommended Action\n\n[C - CONTEXT]\nThe help center has 50 articles covering account setup, billing,\nintegrations, and troubleshooting\n\nUsers report: Can't find SSO setup info, billing FAQ is confusing,\nintegration guides are outdated\n\n[E - EXAMPLES]\n(None provided - could add sample table row for clarity)\n```\n\n**Why This Organization:**\n- **R** = Expertise definition (content strategist)\n- **I** = What to do + how to present it (identify issues + table format)\n- **C** = Background information (existing content + user feedback)\n- **E** = Optional here (task is clear enough without examples)\n\n**Common Mistake:** Putting user feedback in Instructions instead of Context. User feedback is background information, not a task directive.\n\n</details>\n\n**Self-Check:** Can you identify R, I, C, E in every prompt you write? Practice this skill\u2014it's the foundation of effective prompting.\n\n---",
            "hydration_source_header": "2. The RICE Framework",
            "hydration_method": "title_match"
          }
        ],
        "promptComponents": [
          {
            "id": "role-component",
            "title": "Component 1: Role",
            "partOf": "prompt-anatomy",
            "lines": "70-115",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I define a role in a prompt?"
            ],
            "content": "**What It Is:**\nDefine who the AI should act as. This sets the knowledge domain and perspective.\n\n**Why It Matters:**\n- Activates relevant knowledge patterns in the AI's training\n- Sets appropriate tone and depth\n- Helps AI understand context better\n\n**Examples:**\n\n<CardGroup cols={2}>\n  <Card title=\"Generic Role\" icon=\"user\">\n    \"You're an AI assistant.\"\n    \n    **Problem:** Too broad, doesn't activate specialized knowledge\n  </Card>\n  \n  <Card title=\"Specific Role\" icon=\"user-tie\">\n    \"You're an information architect with 10 years of experience designing taxonomies for developer documentation.\"\n    \n    **Better:** Activates relevant domain knowledge, sets expertise level\n  </Card>\n</CardGroup>\n\n**Role Formula for IA Work:**\n\n```text\n\"You are a/an [specific role] with expertise in [relevant specialization].\"\n\nExamples:\n- \"You are an information architect specializing in API documentation structure.\"\n- \"You are a UX researcher who analyzes card sorting results.\"\n- \"You are a content strategist who designs metadata schemas.\"\n- \"You are a navigation designer focused on developer experience.\"\n```\n\n<Tip>\n  **Pro Tip:** The more specific the role, the better the output. \"Information architect\" is good. \"Information architect specializing in software documentation using the Di\u00e1taxis framework\" is better.\n</Tip>\n\n---",
            "hydration_source_header": "1.1 Component 1: Role",
            "hydration_method": "title_match"
          },
          {
            "id": "context-component",
            "title": "Component 2: Context",
            "partOf": "prompt-anatomy",
            "lines": "117-175",
            "crossModule": true,
            "retrievalQuestions": [
              "What context should I provide?"
            ],
            "content": "**What It Is:**\nBackground information that helps AI understand the situation, constraints, and goals.\n\n**Three Types of Context for IA:**\n\n**1. User Context**\n- Who are your users?\n- What's their expertise level?\n- What are their goals and pain points?\n- What tasks do they need to accomplish?\n\n**2. Content Context**\n- How much content exists?\n- What types of content?\n- What's the current state/problem?\n- What content frameworks apply (e.g., Di\u00e1taxis)?\n\n**3. Business Context**\n- What are the goals?\n- What constraints exist (technical, resource, timeline)?\n- What organizational factors matter?\n- What success metrics?\n\n**Example Context Breakdown:**\n\n```text Bad Context (Vague)\n\"We have some documentation that needs organizing.\"\n\nGood Context (Specific)\n\"Background:\n- 120 pages of REST API documentation\n- Target users: Junior to mid-level developers (0-4 years experience)\n- Current problem: 65% of users resort to search, low task success rate\n- Content types: 30 tutorials, 45 reference pages, 30 how-to guides, 15 explanations\n- Business goal: Reduce time-to-first-API-call by 30%\n- Technical constraint: Must work with existing Markdown file structure\n- Timeline: Need to implement in 4 weeks\"\n```\n\n<Warning>\n  **Common Mistake:** Assuming AI knows your context. It doesn't! Always provide rich background, even if it feels obvious to you.\n</Warning>\n\n---",
            "hydration_source_header": "1.2 Component 2: Context",
            "hydration_method": "title_match"
          },
          {
            "id": "task-component",
            "title": "Component 3: Task",
            "partOf": "prompt-anatomy",
            "lines": "177-215",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I write a clear task?"
            ],
            "content": "**What It Is:**\nThe specific action you want AI to perform, stated clearly and unambiguously.\n\n**From Vague to Specific:**\n\n| Vague | Specific | Why It's Better |\n|-------|----------|-----------------|\n| \"Create a taxonomy\" | \"Generate a 3-level hierarchical taxonomy\" | Defines structure depth |\n| \"Organize content\" | \"Classify these 50 pages using the Di\u00e1taxis framework (Tutorial, How-to, Reference, Explanation)\" | Specifies classification system |\n| \"Improve navigation\" | \"Generate 10 alternative navigation labels for the API Reference section, each under 25 characters\" | Quantified, constrained, measurable |\n| \"Analyze this data\" | \"Calculate similarity matrix from card sorting data showing co-occurrence percentages for all card pairs\" | Defines exact output needed |\n\n**Action Verb Formula:**\n\n```text Strong IA Task Verbs:\n- Generate [quantity] [what]\n- Classify [content] using [framework]\n- Analyze [data] to identify [patterns]\n- Create [structure] with [specifications]\n- Map [relationship type] between [entities]\n- Compare [option A] and [option B] based on [criteria]\n- Validate [artifact] against [principles/standards]\n```\n\n---",
            "hydration_source_header": "1.3 Component 3: Task",
            "hydration_method": "title_match"
          },
          {
            "id": "constraints-component",
            "title": "Component 4: Constraints",
            "partOf": "prompt-anatomy",
            "lines": "217-270",
            "crossModule": true,
            "retrievalQuestions": [
              "What constraints should I include?"
            ],
            "content": "**What It Is:**\nLimits, requirements, and rules that the output must respect.\n\n**Three Types of Constraints:**\n\n**1. Technical Constraints**\n- Maximum depth/levels\n- Character limits\n- File format requirements\n- Platform limitations\n- Integration requirements\n\n**2. Business Constraints**\n- Budget/resource limits\n- Timeline restrictions\n- Stakeholder requirements\n- Existing standards to follow\n- Brand voice guidelines\n\n**3. IA Constraints**\n- Framework adherence (e.g., Di\u00e1taxis)\n- Accessibility requirements (WCAG)\n- Best practices (max 7\u00b12 items per level)\n- User research findings\n- Mental model alignment\n\n**Example Constraints Section:**\n\n```text\nConstraints:\n- Maximum 3 levels deep (avoid overwhelming users)\n- Top level: 5-7 categories (cognitive load limit)\n- Labels must be under 25 characters (UI limitation)\n- Must include clear location for troubleshooting content\n- Follow Di\u00e1taxis framework for content type classification\n- Navigation must work with keyboard-only navigation (accessibility)\n- Must be implementable in Docusaurus (technical constraint)\n- No reorganization of existing reference documentation (stakeholder requirement)\n```\n\n<Tip>\n  **The More Constraints, The Better:** Constraints don't limit AI\u2014they guide it toward outputs that actually work in your situation.\n</Tip>\n\n---",
            "hydration_source_header": "1.4 Component 4: Constraints",
            "hydration_method": "title_match"
          },
          {
            "id": "format-component",
            "title": "Component 5: Format",
            "partOf": "prompt-anatomy",
            "lines": "272-330",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I specify output format?"
            ],
            "content": "**What It Is:**\nSpecification of exactly how the output should be structured and presented.\n\n**Why It Matters:**\n- Ensures output is immediately usable\n- Reduces need for reformatting\n- Makes validation easier\n- Facilitates team sharing\n\n**Format Specification Examples:**",
            "hydration_source_header": "1.5 Component 5: Format",
            "hydration_method": "title_match"
          }
        ],
        "principles": [
          {
            "id": "specificity-over-vagueness",
            "title": "Specificity, Context, and Structure",
            "partOf": "introduction",
            "lines": "30-48",
            "crossModule": true,
            "retrievalQuestions": [
              "Why is specificity important in prompts?"
            ],
            "content": "You've learned when to use AI (Module 1.2) and how AI works (Module 1.1). Now comes the practical skill that determines success: **writing prompts that get good results**.\n\n**The Reality:**\n- A vague prompt \u2192 generic, often useless output\n- A well-crafted prompt \u2192 specific, actionable output that saves time\n\n**The Difference:**\n\n<CodeGroup>\n\n```text Vague Prompt\n\"Create a taxonomy for documentation\"\n\nResult: Generic structure that doesn't fit your needs\n```\n\n```text Well-Crafted Prompt\n\"You're an information architect. Create a 3-level taxonomy for software \nAPI documentation with 80 pages covering authentication, payments, webhooks, \nand analytics. Target audience: junior developers. Use task-based organization \nfollowing the Di\u00e1taxis framework. Output as an indented list.\"\n\nResult: Specific, usable structure tailored to your context\n```\n\n</CodeGroup>\n\nThe difference? **Specificity, context, and structure.**\n\nLet's learn how to write prompts that work.\n\n---",
            "hydration_source_header": "Introduction: Why Prompt Engineering Matters",
            "hydration_method": "line_proximity"
          },
          {
            "id": "more-constraints-better",
            "title": "More Constraints Guide AI Better",
            "partOf": "constraints-component",
            "lines": "265-270",
            "crossModule": true,
            "retrievalQuestions": [
              "Should I add more constraints?"
            ],
            "content": "**What It Is:**\nSpecification of exactly how the output should be structured and presented.\n\n**Why It Matters:**\n- Ensures output is immediately usable\n- Reduces need for reformatting\n- Makes validation easier\n- Facilitates team sharing\n\n**Format Specification Examples:**",
            "hydration_source_header": "1.5 Component 5: Format",
            "hydration_method": "line_proximity"
          },
          {
            "id": "iteration-is-normal",
            "title": "Iteration is Normal",
            "partOf": "iteration-strategies",
            "lines": "1215-1220",
            "crossModule": true,
            "retrievalQuestions": [
              "Is it normal to iterate on prompts?"
            ],
            "content": "**What to Include:**\n- Timeline and resource constraints\n- Technical limitations (platform, CMS, tools)\n- Stakeholder requirements\n- Budget constraints\n- Existing standards to maintain\n- Organizational politics (if relevant)\n\n**Example Business Constraints Context:**\n\n```text\nBusiness Constraints:\n\nTimeline:\n- Must complete IA design in 2 weeks\n- Implementation in 4 weeks\n- Go-live deadline: End of Q2\n\nTechnical Constraints:\n- Using Docusaurus static site generator\n- Markdown source files\n- Cannot change URL structure (SEO preservation)\n- Must work with existing CI/CD pipeline\n\nResource Constraints:\n- Solo IA (you)\n- 2 technical writers (30% time available)\n- Engineering support: 1 day/week\n- No budget for user testing tools\n\nStakeholder Requirements:\n- Engineering VP wants prominent API reference\n- Product wants prominent getting started\n- Support wants troubleshooting easy to find\n- Legal requires security docs accessible\n\nOrganizational Standards:\n- Follow company style guide for terminology\n- Maintain brand voice (friendly but professional)\n- Must include accessibility statement\n```\n\n---",
            "hydration_source_header": "4.3 Business Constraints Context",
            "hydration_method": "line_proximity"
          },
          {
            "id": "progressive-refinement",
            "title": "Progressive Refinement Beats Perfection",
            "partOf": "iteration-strategies",
            "lines": "1220-1225",
            "crossModule": true,
            "retrievalQuestions": [
              "Should I try for a perfect first prompt?"
            ],
            "content": "**Round 1: Exploration**\n- Goal: Generate options, explore possibilities\n- Approach: Broad prompt, fewer constraints\n- Expected: Multiple directions, some won't work\n- Your Job: Identify promising directions\n\n**Round 2: Direction + Constraints**\n- Goal: Apply constraints to best direction\n- Approach: Add specific requirements from Round 1 learnings\n- Expected: More targeted output, closer to needs\n- Your Job: Identify specific issues\n\n**Round 3: Fix Specific Issues**\n- Goal: Address problems identified in Round 2\n- Approach: Very specific refinements\n- Expected: Nearly usable output\n- Your Job: Final quality checks\n\n**Round 4: Final Polish**\n- Goal: Perfect the details\n- Approach: Micro-adjustments\n- Expected: Production-ready output\n- Your Job: Validate against all requirements\n\n**Example: Taxonomy Refinement Across 4 Rounds**",
            "hydration_source_header": "5.1 Progressive Refinement Process",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "contextTypes": [
          {
            "id": "user-context",
            "title": "User Context",
            "domain": "context-component",
            "lines": "1085-1130",
            "crossModule": true,
            "retrievalQuestions": [
              "What user context should I provide?"
            ],
            "content": "**What to Include:**\n- Demographics (developer, PM, support staff, etc.)\n- Experience level (junior, mid, senior)\n- Goals and motivations\n- Pain points and frustrations\n- Common tasks\n- Mental models (how they think about the domain)\n\n**Example User Context:**\n\n```text\nUser Context:\n- Primary users: Backend developers (70%), frontend developers (30%)\n- Experience: 0-4 years (60% junior, 40% mid-level)\n- Top tasks:\n  1. Implement authentication (65% of users)\n  2. Process payments (55% of users)\n  3. Set up webhooks (40% of users)\n- Pain points:\n  - Can't distinguish tutorials from reference docs\n  - OAuth concepts unclear\n  - Don't know where to start\n- Mental model: Think in terms of \"I want to accomplish X\" not \"Show me feature Y\"\n- Search behavior: Use specific terms like \"oauth token\" not generic \"security\"\n```\n\n<Tip>\n  **Pro Tip:** If you have user research data (interviews, surveys, analytics), reference it directly in your prompts. Real data beats assumptions.\n</Tip>\n\n---",
            "hydration_source_header": "4.1 User Context",
            "hydration_method": "title_match"
          },
          {
            "id": "ia-principles-context",
            "title": "IA Principles Context",
            "domain": "context-component",
            "lines": "1132-1175",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I include IA principles in prompts?"
            ],
            "content": "**What to Include:**\n- Frameworks you're using (Di\u00e1taxis, Jobs-to-be-Done)\n- Best practices you want followed\n- Accessibility requirements\n- Standards or guidelines\n- Organizational patterns\n\n**Example IA Principles Context:**\n\n```text\nIA Principles to Follow:\n\n1. Di\u00e1taxis Framework\n   - Tutorials: Learning-oriented, step-by-step for beginners\n   - How-to Guides: Task-oriented, problem-solving\n   - Reference: Information-oriented, technical specs\n   - Explanation: Understanding-oriented, concepts and context\n\n2. Hierarchy Best Practices\n   - Maximum 3 levels deep\n   - 5-7 categories at top level (Miller's Law)\n   - Balanced distribution (no category >40% of content)\n   - Clear, non-overlapping boundaries\n\n3. Accessibility Requirements (WCAG 2.1 AA)\n   - Labels meaningful without visual context\n   - Keyboard navigable\n   - Screen reader friendly\n   - No reliance on color alone\n\n4. Progressive Disclosure\n   - Beginner content prominently placed\n   - Advanced content accessible but not overwhelming\n   - Clear learning paths\n\n5. Information Scent\n   - Labels clearly indicate destination content\n   - No \"Learn More\" or ambiguous labels\n   - Match user language (from search analytics)\n```\n\n---",
            "hydration_source_header": "4.2 IA Principles Context",
            "hydration_method": "title_match"
          },
          {
            "id": "business-constraints-context",
            "title": "Business Constraints Context",
            "domain": "context-component",
            "lines": "1177-1215",
            "crossModule": true,
            "retrievalQuestions": [
              "What business constraints matter for prompts?"
            ],
            "content": "**What to Include:**\n- Timeline and resource constraints\n- Technical limitations (platform, CMS, tools)\n- Stakeholder requirements\n- Budget constraints\n- Existing standards to maintain\n- Organizational politics (if relevant)\n\n**Example Business Constraints Context:**\n\n```text\nBusiness Constraints:\n\nTimeline:\n- Must complete IA design in 2 weeks\n- Implementation in 4 weeks\n- Go-live deadline: End of Q2\n\nTechnical Constraints:\n- Using Docusaurus static site generator\n- Markdown source files\n- Cannot change URL structure (SEO preservation)\n- Must work with existing CI/CD pipeline\n\nResource Constraints:\n- Solo IA (you)\n- 2 technical writers (30% time available)\n- Engineering support: 1 day/week\n- No budget for user testing tools\n\nStakeholder Requirements:\n- Engineering VP wants prominent API reference\n- Product wants prominent getting started\n- Support wants troubleshooting easy to find\n- Legal requires security docs accessible\n\nOrganizational Standards:\n- Follow company style guide for terminology\n- Maintain brand voice (friendly but professional)\n- Must include accessibility statement\n```\n\n---",
            "hydration_source_header": "4.3 Business Constraints Context",
            "hydration_method": "title_match"
          }
        ],
        "constraintTypes": [
          {
            "id": "technical-constraints",
            "title": "Technical Constraints",
            "partOf": "constraints-component",
            "lines": "230-245",
            "crossModule": true,
            "content": "**What It Is:**\nLimits, requirements, and rules that the output must respect.\n\n**Three Types of Constraints:**\n\n**1. Technical Constraints**\n- Maximum depth/levels\n- Character limits\n- File format requirements\n- Platform limitations\n- Integration requirements\n\n**2. Business Constraints**\n- Budget/resource limits\n- Timeline restrictions\n- Stakeholder requirements\n- Existing standards to follow\n- Brand voice guidelines\n\n**3. IA Constraints**\n- Framework adherence (e.g., Di\u00e1taxis)\n- Accessibility requirements (WCAG)\n- Best practices (max 7\u00b12 items per level)\n- User research findings\n- Mental model alignment\n\n**Example Constraints Section:**\n\n```text\nConstraints:\n- Maximum 3 levels deep (avoid overwhelming users)\n- Top level: 5-7 categories (cognitive load limit)\n- Labels must be under 25 characters (UI limitation)\n- Must include clear location for troubleshooting content\n- Follow Di\u00e1taxis framework for content type classification\n- Navigation must work with keyboard-only navigation (accessibility)\n- Must be implementable in Docusaurus (technical constraint)\n- No reorganization of existing reference documentation (stakeholder requirement)\n```\n\n<Tip>\n  **The More Constraints, The Better:** Constraints don't limit AI\u2014they guide it toward outputs that actually work in your situation.\n</Tip>\n\n---",
            "hydration_source_header": "1.4 Component 4: Constraints",
            "hydration_method": "line_proximity"
          },
          {
            "id": "business-constraints",
            "title": "Business Constraints",
            "partOf": "constraints-component",
            "lines": "247-255",
            "crossModule": true,
            "content": "**What to Include:**\n- Timeline and resource constraints\n- Technical limitations (platform, CMS, tools)\n- Stakeholder requirements\n- Budget constraints\n- Existing standards to maintain\n- Organizational politics (if relevant)\n\n**Example Business Constraints Context:**\n\n```text\nBusiness Constraints:\n\nTimeline:\n- Must complete IA design in 2 weeks\n- Implementation in 4 weeks\n- Go-live deadline: End of Q2\n\nTechnical Constraints:\n- Using Docusaurus static site generator\n- Markdown source files\n- Cannot change URL structure (SEO preservation)\n- Must work with existing CI/CD pipeline\n\nResource Constraints:\n- Solo IA (you)\n- 2 technical writers (30% time available)\n- Engineering support: 1 day/week\n- No budget for user testing tools\n\nStakeholder Requirements:\n- Engineering VP wants prominent API reference\n- Product wants prominent getting started\n- Support wants troubleshooting easy to find\n- Legal requires security docs accessible\n\nOrganizational Standards:\n- Follow company style guide for terminology\n- Maintain brand voice (friendly but professional)\n- Must include accessibility statement\n```\n\n---",
            "hydration_source_header": "4.3 Business Constraints Context",
            "hydration_method": "title_match"
          },
          {
            "id": "ia-constraints",
            "title": "IA Constraints",
            "partOf": "constraints-component",
            "lines": "257-270",
            "crossModule": true,
            "content": "```text\n\"You're an information architect specializing in developer documentation \nand API reference design.\n\nContext:\n- Documentation for a REST API with 120 pages\n- Target users: Mid-level developers (2-5 years experience)\n- Current problem: Users can't find what they need, 65% resort to search\n- Content covers: authentication, data operations, webhooks, error handling\n- Content types: 30 tutorials, 50 how-to guides, 30 reference pages, 10 explanations\n\nTask:\nCreate a 3-level hierarchical taxonomy that organizes all 120 pages.\n- Level 1: Organize by user task (what they want to accomplish)\n- Level 2: Group by feature area  \n- Level 3: Organize by content type (following Di\u00e1taxis framework)\n\nConstraints:\n- Maximum 3 levels deep (no deeper)\n- Top level: 5-7 categories only\n- Labels must be under 30 characters\n- Must include clear home for troubleshooting content\n- Follow Di\u00e1taxis: Tutorial, How-to, Reference, Explanation\n- Progressive disclosure (beginner content first)\n- Balanced distribution (no category >30% of content)\"\n```\n\n**Improvement:** Clear boundaries and requirements  \n**Quality Prediction:** 8/10 (almost there, needs format)\n\n---",
            "hydration_source_header": "Step 4: Add Constraints",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "promptPatterns": [
          {
            "id": "rice-template-ia",
            "title": "RICE Template for IA Work",
            "taskType": "general",
            "lines": "435-470",
            "crossModule": true,
            "retrievalQuestions": [
              "Give me a template for IA prompts"
            ],
            "content": "```text\n[R - ROLE]\nYou are a/an [specific role] with expertise in [relevant specialization].\n\n[I - INSTRUCTIONS]\nYour task is to [specific action verb] [what] [for what purpose].\n\nRequirements:\n- [Requirement 1]\n- [Requirement 2]\n- [Constraint 1]\n- [Constraint 2]\n\nOutput format:\n- [Format specification]\n\n[C - CONTEXT]\nBackground:\n- [Audience information]\n- [Current state/problems]\n- [Business goals]\n- [Content inventory details]\n\nPrinciples to follow:\n- [IA principle 1]\n- [IA principle 2]\n\n[E - EXAMPLES]\n[If applicable, provide examples of:]\n- Good outputs you're looking for\n- Bad outputs to avoid\n- Sample input data\n- Reference structures\n```\n\n---",
            "hydration_source_header": "2.2 RICE Template for IA Work",
            "hydration_method": "title_match"
          },
          {
            "id": "rice-taxonomy-generation",
            "title": "RICE Example: Taxonomy Generation",
            "taskType": "taxonomy",
            "lines": "475-560",
            "crossModule": true,
            "retrievalQuestions": [
              "Give me a template for taxonomy prompts"
            ],
            "content": "```text\n[R - ROLE]\nYou are an information architect with 10 years of experience designing \ntaxonomies for software documentation, specializing in developer-focused \ncontent and API documentation.\n\n[I - INSTRUCTIONS]\nYour task is to generate a 3-level taxonomy that organizes 85 API \ndocumentation pages covering authentication, payments, webhooks, and analytics.\n\nRequirements:\n- Use task-based organization at the top level\n- Group by feature area at the second level\n- Organize by content type (following Di\u00e1taxis) at the third level\n- Each top-level category should have 3-6 subcategories\n- Labels must be clear, action-oriented, and under 25 characters\n- Must include a clear location for troubleshooting content\n\nOutput format:\n- Markdown indented list with three levels\n- Include estimated page counts in (parentheses)\n- Provide a 1-sentence description for each top-level category\n\n[C - CONTEXT]\nBackground:\n- Target audience: Junior to mid-level developers (0-4 years experience)\n- Current problem: Poor findability, 52% of users resort to search\n- Business goal: Reduce time-to-first-successful-API-call by 30%\n- Content types: 20 tutorials, 45 reference pages, 15 how-to guides, 5 explanations\n\nPrinciples to follow:\n- Di\u00e1taxis framework (Tutorial/How-to/Reference/Explanation)\n- Progressive disclosure (beginner content first)\n- Task-oriented (organize by what users want to accomplish)\n- Maximum 3 levels deep (avoid overwhelming users)\n\n[E - EXAMPLES]\nExample of good top-level category:\n\"Get Started\" (15 pages)\n- Covers installation, first API call, basic concepts\n- Task-oriented label\n- Clear entry point for new users\n\nExample of poor category to avoid:\n\"Advanced Stuff\" \n- Vague label\n- \"Advanced\" is subjective\n- Doesn't indicate what tasks it supports\n\nSample content that needs categorizing:\n- \"OAuth 2.0 Implementation Tutorial\"\n- \"Payment API Endpoint Reference\"\n- \"Understanding Webhook Events\"\n- \"How to Handle API Errors\"\n```\n\n---",
            "hydration_source_header": "2.3 RICE Example 1: Taxonomy Generation",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "rice-content-classification",
            "title": "RICE Example: Content Classification",
            "taskType": "classification",
            "lines": "562-640",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I write a content classification prompt?"
            ],
            "content": "```text\n[R - ROLE]\nYou are a content strategist and information architect who specializes in \nclassifying documentation using the Di\u00e1taxis framework. You understand the \nsubtle differences between tutorials, how-to guides, reference docs, and \nconceptual explanations.\n\n[I - INSTRUCTIONS]\nYour task is to classify 50 documentation pages using the Di\u00e1taxis framework.\n\nFor each page, provide:\n1. Page title\n2. Classification (Tutorial, How-to Guide, Reference, or Explanation)\n3. Brief reasoning (one sentence explaining why)\n4. Confidence level (high/medium/low)\n\nRequirements:\n- Use ONLY the four Di\u00e1taxis categories\n- Base classification on content purpose, not just format\n- Flag any pages that don't fit cleanly (hybrid content)\n- Note pages that might need splitting or reconceptualization\n\nOutput format:\nStructured table with columns:\n| Page Title | Type | Reasoning | Confidence | Notes |\n\n[C - CONTEXT]\nBackground:\n- Payment API documentation with mixed content types\n- Current organization is feature-based, not content-type-based\n- Users struggle to find \"how to do X\" vs \"what is X\"\n- Goal: Reorganize to support different user intents\n\nDi\u00e1taxis definitions for reference:\n- Tutorial: Learning-oriented, step-by-step lesson, teaches by doing\n- How-to Guide: Task-oriented, solves specific problem, assumes some knowledge\n- Reference: Information-oriented, describes the machinery, technical specs\n- Explanation: Understanding-oriented, clarifies concepts, discusses why\n\nContent characteristics:\n- 50 pages total\n- Mix of API endpoints, conceptual topics, and practical guides\n- Some pages cover multiple intents (these are problem cases)\n\n[E - EXAMPLES]\nGood classification:\n\"Building Your First Payment Flow\" \u2192 Tutorial\nReasoning: Step-by-step walkthrough for beginners, teaches fundamentals\nConfidence: High\n\n\"Payment Endpoint Reference\" \u2192 Reference\nReasoning: Technical specifications, describes parameters and responses\nConfidence: High\n\n\"How to Handle Failed Payments\" \u2192 How-to Guide\nReasoning: Task-oriented, solves specific problem, assumes basic knowledge\nConfidence: High\n\nProblematic case:\n\"Understanding Webhook Signatures\" \u2192 Explanation + How-to (hybrid)\nReasoning: First half explains what signatures are (Explanation), \nsecond half shows how to validate them (How-to)\nConfidence: Medium\nNotes: Consider splitting into two pages\n```\n\n---",
            "hydration_source_header": "2.4 RICE Example 2: Content Classification",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "rice-navigation-labels",
            "title": "RICE Example: Navigation Label Generation",
            "taskType": "labeling",
            "lines": "642-700",
            "crossModule": true,
            "retrievalQuestions": [
              "Template for navigation label generation"
            ],
            "content": "```text\n[R - ROLE]\nYou are a UX writer and information architect specializing in creating \nclear, accessible navigation labels for developer documentation. You \nunderstand information scent and how to write labels that work without \nvisual context.\n\n[I - INSTRUCTIONS]\nYour task is to generate 10 different navigation label options for the \nsection covering API security, authentication, and authorization content.\n\nRequirements:\n- Labels must be under 25 characters\n- Must be meaningful to screen reader users (no \"Learn More\" type labels)\n- Should indicate content scope clearly\n- Use plain language where possible (avoid unnecessary jargon)\n- Consider both novice and experienced developers\n- Labels should work in a horizontal navigation bar\n\nOutput format:\nNumbered list with:\n1. Label text\n2. Character count\n3. Brief rationale (why this label works)\n4. Potential concerns (if any)\n\n[C - CONTEXT]\nBackground:\n- Developer documentation for a REST API\n- This section contains 30 pages covering API keys, OAuth, security best practices, and common auth errors\n- Users come from various backgrounds: some understand auth deeply, others are learning\n- Current label \"Security\" is too vague and causes low click-through\n- Analytics show users searching for \"authentication\", \"oauth\", \"api key\"\n\nContent this label covers:\n- API authentication methods (API keys, OAuth 2.0, JWT)\n- Authorization and permissions\n- Security best practices\n- Common security errors and troubleshooting\n\nConstraints:\n- Must work in 25 characters max (UI limitation)\n- Needs to be accessible (clear to screen readers)\n- Should match common search terms when possible\n\n[E - EXAMPLES]\nExample of GOOD label:\n\"Authentication & Security\" (25 chars)\nRationale: Specific scope, includes top search term, indicates dual coverage\nConcerns: Slightly long but within limit\n\nExample of BAD label:\n\"Auth Stuff\" (10 chars)\nIssues: Too casual, \"stuff\" is vague, unclear scope\n\nAnother BAD label:\n\"Learn About Security\" (20 chars)\nIssues: Unclear destination, \"learn about\" adds no info, not screen-reader friendly\n```\n\n---",
            "hydration_source_header": "2.5 RICE Example 3: Navigation Label Generation",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "complete-prompt-anatomy",
            "title": "Complete Prompt with All 5 Components",
            "taskType": "general",
            "lines": "332-375",
            "crossModule": true,
            "retrievalQuestions": [
              "Complete prompt example for IA"
            ],
            "content": "Here's a complete prompt with all five components clearly labeled:\n\n```text\n[ROLE]\nYou're an information architect specializing in developer documentation \nand the Di\u00e1taxis framework.\n\n[CONTEXT]\nI'm redesigning the IA for a REST API documentation site with 120 pages. \nCurrent problems: developers can't find advanced features, troubleshooting \nis buried, and there's confusion between tutorials and reference docs. \nTarget audience: developers with 1-3 years experience. Content types: \n40 tutorials, 50 reference pages, 20 how-to guides, 10 conceptual explanations.\n\n[TASK]\nCreate a 3-level taxonomy that organizes all 120 pages by user task (top level), \nfeature area (second level), and content type (third level following Di\u00e1taxis).\n\n[CONSTRAINTS]\n- Maximum 3 levels deep\n- Top level: 5-7 categories\n- Must include clear homes for troubleshooting content\n- Keep related auth and security content together\n- Labels must be under 30 characters\n- Must work with existing Markdown file structure\n\n[FORMAT]\nOutput as an indented markdown list showing:\n- All three levels\n- Page count estimates for each category in (parentheses)\n- A brief 1-sentence description for each top-level category\n```\n\n**This prompt will produce far better results than:** \"Create a taxonomy for API docs\"\n\n---",
            "hydration_source_header": "1.6 Putting It All Together: Complete Prompt Anatomy",
            "hydration_method": "line_proximity"
          }
        ],
        "decisionTrees": [
          {
            "id": "examples-decision-tree",
            "title": "When to Include Examples",
            "helpsDecide": "example-inclusion",
            "lines": "705-780",
            "crossModule": true,
            "retrievalQuestions": [
              "Should I include examples in my prompt?",
              "When are examples necessary?"
            ],
            "content": "**Examples are optional\u2014but powerful.** Use this decision tree to determine when they're worth the effort.\n\n#### Decision Flowchart: Should You Include Examples?\n\n**Text-based decision tree (for screen readers):**\n\n```\nSHOULD YOU INCLUDE EXAMPLES IN YOUR PROMPT?\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nStart \u2192 Is the task ambiguous or subjective? (e.g., \"write clearly\", \"good labels\")\n        \u251c\u2500 YES \u2192 INCLUDE EXAMPLES (90% of the time)\n        \u2514\u2500 NO  \u2192 Continue to next question\n                 \u2193\n        Has the AI missed the mark on previous attempts?\n        \u251c\u2500 YES \u2192 INCLUDE EXAMPLES (fixes misalignment)\n        \u2514\u2500 NO  \u2192 Continue to next question\n                 \u2193\n        Do you have specific style, tone, or quality requirements?\n        \u251c\u2500 YES \u2192 INCLUDE EXAMPLES (shows desired quality bar)\n        \u2514\u2500 NO  \u2192 Continue to next question\n                 \u2193\n        Are you distinguishing between good vs. bad approaches?\n        \u251c\u2500 YES \u2192 INCLUDE EXAMPLES (use contrast pairs)\n        \u2514\u2500 NO  \u2192 Continue to next question\n                 \u2193\n        Is the task straightforward with objective criteria?\n        \u251c\u2500 YES \u2192 SKIP EXAMPLES (clear instructions suffice)\n        \u2514\u2500 NO  \u2192 INCLUDE EXAMPLES (when in doubt, include)\n\nKEY INSIGHT: Examples are especially critical for subjective tasks.\nIf you're using words like \"clear\", \"good\", \"effective\", \"professional\"\n\u2192 You need examples to define what these mean.\n```\n\n**Visual decision flowchart:**\n\n```mermaid\ngraph TD\n    Start([Start: Writing a prompt])\n    Q1{Is task ambiguous<br/>or subjective?}\n    Q2{Has AI missed the<br/>mark before?}\n    Q3{Specific style/quality<br/>requirements?}\n    Q4{Showing good vs.<br/>bad approaches?}\n    Q5{Task straightforward<br/>with objective criteria?}\n\n    Include1[\u2705 INCLUDE EXAMPLES<br/>Ambiguity = High value]\n    Include2[\u2705 INCLUDE EXAMPLES<br/>Fix misalignment]\n    Include3[\u2705 INCLUDE EXAMPLES<br/>Show quality bar]\n    Include4[\u2705 INCLUDE EXAMPLES<br/>Use contrast pairs]\n    Skip[\u274c SKIP EXAMPLES<br/>Instructions suffice]\n    Include5[\u2705 INCLUDE EXAMPLES<br/>When in doubt, include]\n\n    Start --> Q1\n    Q1 -->|Yes| Include1\n    Q1 -->|No| Q2\n    Q2 -->|Yes| Include2\n    Q2 -->|No| Q3\n    Q3 -->|Yes| Include3\n    Q3 -->|No| Q4\n    Q4 -->|Yes| Include4\n    Q4 -->|No| Q5\n    Q5 -->|Yes| Skip\n    Q5 -->|No| Include5\n\n    style Include1 fill:#d4edda\n    style Include2 fill:#d4edda\n    style Include3 fill:#d4edda\n    style Include4 fill:#d4edda\n    style Include5 fill:#d4edda\n    style Skip fill:#f8d7da\n```\n\n---\n\n#### When Examples Made the Difference: Real Scenarios\n\n**Scenario 1: Navigation Label Clarity**\n\n\u274c **Without Examples:**\n```text\n[R] You're an information architect.\n[I] Generate clear, concise navigation labels for these sections.\n[C] Documentation site with API reference, tutorials, guides, SDK docs.\n```\n\n**Result:** Generic labels like \"Documentation\", \"Resources\", \"Learn More\" (unhelpful, vague)\n\n\u2705 **With Examples:**\n```text\n[E] Example of GOOD label:\n- \"API Reference\" (specific, clear purpose)\n- \"Quick Start Guide\" (action-oriented, clear outcome)\n\nExample of BAD label to avoid:\n- \"Resources\" (too vague, no clear destination)\n- \"Documentation\" (redundant - entire site is docs)\n```\n\n**Result:** Specific, scannable labels like \"API Reference\", \"Tutorials\", \"SDK Setup\", \"Integration Guides\"\n\n**Why Examples Mattered:** \"Clear\" and \"concise\" are subjective without concrete demonstrations.\n\n---\n\n**Scenario 2: Taxonomy Quality Standards**\n\n\u274c **Without Examples:**\n```text\n[R] You're an information architect.\n[I] Create a taxonomy for software documentation.\n[C] 80 pages covering authentication, payments, webhooks, analytics.\n```\n\n**Result:** Generic categories like \"Getting Started\", \"Features\", \"Advanced Topics\" (shallow, predictable)\n\n\u2705 **With Examples:**\n```text\n[E] Example of GOOD top-level category:\n- \"Authentication & Security\" (precise scope, clear user need)\n  - Subcategories: OAuth Setup, API Keys, Session Management\n  - Why good: Groups related security tasks together\n\nExample of BAD category to avoid:\n- \"Advanced Topics\" (vague, unclear what qualifies as \"advanced\")\n  - Why bad: Doesn't help users navigate, subjective classification\n```\n\n**Result:** Specific, user-focused categories like \"Authentication & Security\", \"Payment Processing\", \"Event & Webhook Setup\", \"Analytics Integration\"\n\n**Why Examples Mattered:** Showed quality bar and prevented generic placeholder categories.\n\n---\n\n**Scenario 3: Content Audit Severity Ratings**\n\n\u274c **Without Examples:**\n```text\n[R] You're a content strategist.\n[I] Audit help articles. Rate issues as High/Medium/Low severity.\n[C] 50 articles, users report confusion about SSO and billing.\n```\n\n**Result:** Inconsistent severity ratings (e.g., outdated screenshots rated \"High\", missing critical SSO docs rated \"Medium\")\n\n\u2705 **With Examples:**\n```text\n[E] Severity Examples:\n\nHIGH: Missing critical information users need to complete core tasks\n- Example: No SSO setup documentation (users blocked from enterprise setup)\n\nMEDIUM: Outdated information that may cause confusion\n- Example: Screenshots show old UI (users can still complete task with effort)\n\nLOW: Minor improvements to clarity or polish\n- Example: Typo in help article (doesn't block understanding)\n```\n\n**Result:** Consistent, useful severity ratings aligned with user impact\n\n**Why Examples Mattered:** \"High/Medium/Low\" means different things to different people without calibration examples.\n\n---\n\n**Scenario 4: Writing Tone Consistency**\n\n\u274c **Without Examples:**\n```text\n[R] You're a UX writer.\n[I] Write error messages in a friendly, helpful tone.\n[C] E-commerce checkout flow, various error scenarios.\n```\n\n**Result:** Inconsistent tone ranging from overly casual (\"Oops! Something broke!\") to robotic (\"Error code 4521: Invalid payment method\")\n\n\u2705 **With Examples:**\n```text\n[E] Example of GOOD error message (friendly + helpful):\n\"We couldn't process your payment. Please check your card number and try again,\nor use a different payment method.\"\n- Why good: Explains problem, suggests solution, stays professional\n\nExample of BAD error message:\n\"Payment failed.\" (unhelpful, no guidance)\n\"Oops! The payment gremlins are at it again! \ud83e\udd2a\" (too casual, unprofessional)\n```\n\n**Result:** Consistent, professional-friendly error messages across all scenarios\n\n**Why Examples Mattered:** \"Friendly tone\" is highly subjective without concrete demonstrations.\n\n---\n\n#### Quick Reference: Include vs. Skip Examples\n\n| **Include Examples When:** | **Skip Examples When:** |\n|---|---|\n| \u2705 Task uses subjective words (\"clear\", \"good\", \"professional\") | \u274c Task is purely objective (\"count words\", \"extract dates\") |\n| \u2705 AI previously produced wrong style/quality | \u274c You want maximum creativity/exploration |\n| \u2705 Showing good vs. bad approaches helps | \u274c Prompt is already very long (>300 words) |\n| \u2705 Output quality varies without examples | \u274c Instructions are unambiguous (e.g., \"convert JSON to CSV\") |\n| \u2705 First time attempting this type of task | \u274c You're brainstorming (want diverse ideas) |\n\n**When in Doubt:** Include 1-2 examples. They take 30 seconds to write but often save 10+ minutes of iteration.\n\n**Cost-Benefit Rule:** If adding examples takes less than 1 minute but saves one re-prompt cycle (5+ minutes), include them.\n\n---",
            "hydration_source_header": "2.6 When to Include Examples (The \"E\" in RICE)",
            "hydration_method": "title_match"
          }
        ],
        "transformationExamples": [
          {
            "id": "vague-vs-clear-intro",
            "title": "Vague vs Well-Crafted Prompt",
            "taskType": "general",
            "lines": "30-48",
            "content": "You've learned when to use AI (Module 1.2) and how AI works (Module 1.1). Now comes the practical skill that determines success: **writing prompts that get good results**.\n\n**The Reality:**\n- A vague prompt \u2192 generic, often useless output\n- A well-crafted prompt \u2192 specific, actionable output that saves time\n\n**The Difference:**\n\n<CodeGroup>\n\n```text Vague Prompt\n\"Create a taxonomy for documentation\"\n\nResult: Generic structure that doesn't fit your needs\n```\n\n```text Well-Crafted Prompt\n\"You're an information architect. Create a 3-level taxonomy for software \nAPI documentation with 80 pages covering authentication, payments, webhooks, \nand analytics. Target audience: junior developers. Use task-based organization \nfollowing the Di\u00e1taxis framework. Output as an indented list.\"\n\nResult: Specific, usable structure tailored to your context\n```\n\n</CodeGroup>\n\nThe difference? **Specificity, context, and structure.**\n\nLet's learn how to write prompts that work.\n\n---",
            "hydration_source_header": "Introduction: Why Prompt Engineering Matters",
            "hydration_method": "line_proximity"
          },
          {
            "id": "taxonomy-vague-to-clear",
            "title": "Taxonomy: Vague to Clear",
            "taskType": "taxonomy",
            "lines": "865-905",
            "retrievalQuestions": [
              "Example of bad vs. good taxonomy prompt"
            ],
            "content": "| **Include Examples When:** | **Skip Examples When:** |\n|---|---|\n| \u2705 Task uses subjective words (\"clear\", \"good\", \"professional\") | \u274c Task is purely objective (\"count words\", \"extract dates\") |\n| \u2705 AI previously produced wrong style/quality | \u274c You want maximum creativity/exploration |\n| \u2705 Showing good vs. bad approaches helps | \u274c Prompt is already very long (>300 words) |\n| \u2705 Output quality varies without examples | \u274c Instructions are unambiguous (e.g., \"convert JSON to CSV\") |\n| \u2705 First time attempting this type of task | \u274c You're brainstorming (want diverse ideas) |\n\n**When in Doubt:** Include 1-2 examples. They take 30 seconds to write but often save 10+ minutes of iteration.\n\n**Cost-Benefit Rule:** If adding examples takes less than 1 minute but saves one re-prompt cycle (5+ minutes), include them.\n\n---",
            "hydration_source_header": "Quick Reference: Include vs. Skip Examples",
            "hydration_method": "line_proximity"
          },
          {
            "id": "content-audit-vague-to-clear",
            "title": "Content Audit: Vague to Clear",
            "taskType": "audit",
            "lines": "907-945",
            "content": "<Warning>\n**Quick Practice (4 minutes):** Apply the RICE framework to a real scenario.\n</Warning>\n\n**Scenario:** You need to audit 50 help articles to identify content gaps.\n\n**Task:** Organize these prompt elements into RICE structure:\n\n**Given elements:**\n- \"You're a content strategist specializing in help documentation\"\n- \"Identify: Missing topics, outdated information, unclear explanations\"\n- \"Output as markdown table with columns: Article Title, Issues Found, Severity (High/Medium/Low), Recommended Action\"\n- \"The help center has 50 articles covering account setup, billing, integrations, and troubleshooting\"\n- \"Users report: Can't find SSO setup info, billing FAQ is confusing, integration guides are outdated\"\n\n<details>\n<summary>Show Answer</summary>\n\n**Correct RICE Structure:**\n\n```text\n[R - ROLE]\nYou're a content strategist specializing in help documentation\n\n[I - INSTRUCTIONS]\nIdentify: Missing topics, outdated information, unclear explanations\n\nOutput as markdown table with columns: Article Title, Issues Found,\nSeverity (High/Medium/Low), Recommended Action\n\n[C - CONTEXT]\nThe help center has 50 articles covering account setup, billing,\nintegrations, and troubleshooting\n\nUsers report: Can't find SSO setup info, billing FAQ is confusing,\nintegration guides are outdated\n\n[E - EXAMPLES]\n(None provided - could add sample table row for clarity)\n```\n\n**Why This Organization:**\n- **R** = Expertise definition (content strategist)\n- **I** = What to do + how to present it (identify issues + table format)\n- **C** = Background information (existing content + user feedback)\n- **E** = Optional here (task is clear enough without examples)\n\n**Common Mistake:** Putting user feedback in Instructions instead of Context. User feedback is background information, not a task directive.\n\n</details>\n\n**Self-Check:** Can you identify R, I, C, E in every prompt you write? Practice this skill\u2014it's the foundation of effective prompting.\n\n---",
            "hydration_source_header": "Check Your Understanding: Section 2",
            "hydration_method": "line_proximity"
          },
          {
            "id": "navigation-vague-to-clear",
            "title": "Navigation Design: Vague to Clear",
            "taskType": "navigation",
            "lines": "947-990",
            "content": "**Vague Request:**\n```text\n\"Make the navigation better.\"\n```\n\n**Problems:**\n- Better how?\n- What metrics define \"better\"?\n- What constraints exist?\n- Generate or evaluate?\n\n**Clear Instructions:**\n```text\n\"Generate 3 alternative navigation structures for API documentation.\n\nCurrent problem: 42% task success rate, high search reliance\nGoal: Support both learning paths and quick reference lookup\nContent: 85 pages across 4 feature areas\n\nFor each alternative:\n1. Show top 2 levels of hierarchy\n2. Indicate page distribution percentages\n3. List 3 pros and 3 cons\n4. Explain which user types it serves best\n\nAlternatives to explore:\n- Option 1: Task-based organization\n- Option 2: Feature-based organization\n- Option 3: Hybrid (task + feature)\n\nOutput: Comparison table with structured analysis\"\n```\n\n---",
            "hydration_source_header": "3.3 Navigation Design",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "iterationWorkflows": [
          {
            "id": "progressive-refinement-process",
            "title": "Progressive Refinement Process",
            "rounds": 4,
            "lines": "1230-1270",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I iterate on prompts?"
            ],
            "content": "**Round 1: Exploration**\n- Goal: Generate options, explore possibilities\n- Approach: Broad prompt, fewer constraints\n- Expected: Multiple directions, some won't work\n- Your Job: Identify promising directions\n\n**Round 2: Direction + Constraints**\n- Goal: Apply constraints to best direction\n- Approach: Add specific requirements from Round 1 learnings\n- Expected: More targeted output, closer to needs\n- Your Job: Identify specific issues\n\n**Round 3: Fix Specific Issues**\n- Goal: Address problems identified in Round 2\n- Approach: Very specific refinements\n- Expected: Nearly usable output\n- Your Job: Final quality checks\n\n**Round 4: Final Polish**\n- Goal: Perfect the details\n- Approach: Micro-adjustments\n- Expected: Production-ready output\n- Your Job: Validate against all requirements\n\n**Example: Taxonomy Refinement Across 4 Rounds**",
            "hydration_source_header": "5.1 Progressive Refinement Process",
            "hydration_method": "title_match"
          },
          {
            "id": "taxonomy-refinement-4-rounds",
            "title": "Taxonomy Refinement 4-Round Example",
            "rounds": 4,
            "lines": "1275-1500",
            "crossModule": true,
            "retrievalQuestions": [
              "What's the refinement process?"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "refinement-checklist",
            "title": "The Refinement Checklist",
            "rounds": 4,
            "lines": "1505-1540",
            "crossModule": true,
            "content": "Use this to guide your iteration process:\n\n```text\nRound 1: Exploration\n\u2610 Generate multiple approaches\n\u2610 Identify promising direction\n\u2610 Note what's working and what's not\n\nRound 2: Direction + Constraints\n\u2610 Apply specific constraints\n\u2610 Expand to full detail level\n\u2610 Check for major structural issues\n\nRound 3: Fix Specific Issues\n\u2610 Address balance problems\n\u2610 Improve clarity\n\u2610 Resolve ambiguities\n\u2610 Check edge cases\n\nRound 4: Final Polish\n\u2610 Verify completeness\n\u2610 Check all constraints met\n\u2610 Validate accessibility\n\u2610 Confirm readiness for user testing\n```\n\n---",
            "hydration_source_header": "5.2 The Refinement Checklist",
            "hydration_method": "title_match"
          },
          {
            "id": "ab-testing-prompts",
            "title": "A/B Testing Prompts Strategy",
            "rounds": "variable",
            "lines": "1545-1610",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I A/B test prompts?"
            ],
            "content": "**The Concept:**\nGenerate variations by systematically changing ONE element of your prompt to see what produces better results.\n\n**What to Test:**\n\n**1. Role Variations:**\n- Generic role vs. specific role\n- Senior expert vs. beginner-friendly expert\n- Single specialty vs. multiple specialties\n\n**2. Organizational Principle:**\n- Task-based vs. feature-based\n- Audience-based vs. content-type-based\n- Alphabetical vs. priority-based\n\n**3. Constraint Levels:**\n- Strict constraints vs. flexible guidelines\n- Many constraints vs. few constraints\n- Technical constraints only vs. technical + business\n\n**4. Output Format:**\n- Detailed vs. summary level\n- Structured table vs. prose\n- Visual diagram vs. text list\n\n**Example A/B Test:**\n\n<CodeGroup>\n\n```text Version A: Generic Role\n\"You're an information architect. Create a taxonomy for API documentation \nwith 100 pages.\"\n\nResult: Generic structure, lacks domain specificity\n```\n\n```text Version B: Specific Role\n\"You're an information architect with 10 years of experience designing \ntaxonomies specifically for developer API documentation, with expertise \nin the Di\u00e1taxis framework. Create a taxonomy for API documentation with \n100 pages.\"\n\nResult: More sophisticated structure, better use of IA principles\n```\n\n</CodeGroup>\n\n**Conclusion:** Version B produces better results. Use specific roles going forward.\n\n---",
            "hydration_source_header": "5.3 A/B Testing Prompts Strategy",
            "hydration_method": "title_match"
          }
        ],
        "iterationRounds": [
          {
            "id": "round-1-exploration",
            "title": "Round 1: Exploration",
            "goal": "Generate options",
            "lines": "1235-1280",
            "content": "**Prompt:**\n```text\n\"You're an information architect. Create 2 different taxonomy approaches \nfor API documentation with 150 pages covering payments, authentication, \nwebhooks, and analytics. Target audience: developers. One should be \ntask-based, one feature-based. Show top 2 levels only.\"\n```\n\n**Output:**\n```text\nAPPROACH 1: TASK-BASED\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Integrate\n\u251c\u2500\u2500 Secure\n\u251c\u2500\u2500 Monitor\n\u2514\u2500\u2500 Troubleshoot\n\nAPPROACH 2: FEATURE-BASED\n\u251c\u2500\u2500 Authentication\n\u251c\u2500\u2500 Payments\n\u251c\u2500\u2500 Webhooks\n\u2514\u2500\u2500 Analytics\n```\n\n**Your Analysis:**\n\"Task-based looks more user-friendly. Let's refine that direction.\"\n\n---",
            "hydration_source_header": "Round 1: Exploration",
            "hydration_method": "title_match"
          },
          {
            "id": "round-2-direction",
            "title": "Round 2: Direction + Constraints",
            "goal": "Apply constraints",
            "lines": "1282-1340",
            "content": "**Prompt:**\n```text\n\"Expand the task-based taxonomy to 3 levels. Requirements:\n- 150 pages total distributed across categories\n- Use Di\u00e1taxis at level 3 (Tutorial/How-to/Reference/Explanation)\n- Include specific page count estimates\n- Keep top level to 5-7 categories\n- Include troubleshooting and security as first-class concerns\"\n```\n\n**Output:**\n```text\nTask-Based Taxonomy (150 pages):\n\n\u251c\u2500\u2500 Get Started (20 pages)\n\u2502   \u251c\u2500\u2500 Installation & Setup\n\u2502   \u2502   \u2514\u2500\u2500 [Tutorials, How-tos]\n\u2502   \u251c\u2500\u2500 First API Call\n\u2502   \u2502   \u2514\u2500\u2500 [Tutorials]\n\u2502   \u2514\u2500\u2500 Core Concepts\n\u2502       \u2514\u2500\u2500 [Explanations]\n\n\u251c\u2500\u2500 Authenticate & Secure (30 pages)\n\u2502   \u251c\u2500\u2500 Authentication Methods\n\u2502   \u2502   \u2514\u2500\u2500 [How-tos, Reference]\n\u2502   \u251c\u2500\u2500 OAuth Implementation\n\u2502   \u2502   \u2514\u2500\u2500 [Tutorials, How-tos]\n\u2502   \u2514\u2500\u2500 Security Best Practices\n\u2502       \u2514\u2500\u2500 [Explanations, Reference]\n\n\u251c\u2500\u2500 Process Payments (40 pages)\n\u2502   \u251c\u2500\u2500 Core Features\n\u2502   \u2502   \u2514\u2500\u2500 [How-tos, Reference]\n\u2502   \u251c\u2500\u2500 Advanced Features\n\u2502   \u2502   \u2514\u2500\u2500 [How-tos, Reference]\n\u2502   \u2514\u2500\u2500 Payment Workflows\n\u2502       \u2514\u2500\u2500 [Tutorials, Explanations]\n\n\u251c\u2500\u2500 Integrate Webhooks (25 pages)\n\u2502   \u251c\u2500\u2500 Setup & Configuration\n\u2502   \u2502   \u2514\u2500\u2500 [Tutorials, How-tos]\n\u2502   \u251c\u2500\u2500 Event Reference\n\u2502   \u2502   \u2514\u2500\u2500 [Reference]\n\u2502   \u2514\u2500\u2500 Testing & Debugging\n\u2502       \u2514\u2500\u2500 [How-tos]\n\n\u251c\u2500\u2500 Monitor & Analyze (20 pages)\n\u2502   \u251c\u2500\u2500 Dashboards & Reports\n\u2502   \u2502   \u2514\u2500\u2500 [How-tos, Reference]\n\u2502   \u2514\u2500\u2500 Analytics API\n\u2502       \u2514\u2500\u2500 [Reference, Explanations]\n\n\u2514\u2500\u2500 Troubleshoot (15 pages)\n    \u251c\u2500\u2500 Common Errors\n    \u2502   \u2514\u2500\u2500 [Reference, How-tos]\n    \u2514\u2500\u2500 Debug Tools\n        \u2514\u2500\u2500 [How-tos]\n```\n\n**Your Analysis:**\n\"Good structure! Issues: 'Core Features' vs 'Advanced Features' is subjective. \n'Process Payments' is 40 pages (27%) - too heavy. Need better balance.\"\n\n---",
            "hydration_source_header": "Round 2: Direction + Constraints",
            "hydration_method": "title_match"
          },
          {
            "id": "round-3-fix-issues",
            "title": "Round 3: Fix Specific Issues",
            "goal": "Address problems",
            "lines": "1342-1420",
            "content": "**Prompt:**\n```text\n\"Refine the taxonomy. Changes needed:\n\n1. Split 'Process Payments' (currently 40 pages) into more specific \n   categories that don't use 'Core' vs 'Advanced'\n   \n2. Redistribute content for better balance (aim for 15-25 pages per \n   top-level category)\n   \n3. Make level 2 labels more specific and task-oriented\n\nKeep the overall structure, just adjust as specified.\"\n```\n\n**Output:**\n```text\nRefined Task-Based Taxonomy (150 pages):\n\n\u251c\u2500\u2500 Get Started (20 pages, 13%)\n\u2502   \u251c\u2500\u2500 Install & Configure\n\u2502   \u251c\u2500\u2500 Your First API Call  \n\u2502   \u2514\u2500\u2500 Essential Concepts\n\n\u251c\u2500\u2500 Authenticate Users (25 pages, 17%)\n\u2502   \u251c\u2500\u2500 Choose Auth Method\n\u2502   \u251c\u2500\u2500 Implement OAuth\n\u2502   \u2514\u2500\u2500 Manage API Keys\n\n\u251c\u2500\u2500 Accept Payments (25 pages, 17%)\n\u2502   \u251c\u2500\u2500 One-Time Payments\n\u2502   \u251c\u2500\u2500 Subscriptions\n\u2502   \u2514\u2500\u2500 Payment Methods\n\n\u251c\u2500\u2500 Handle Webhooks (20 pages, 13%)\n\u2502   \u251c\u2500\u2500 Configure Webhooks\n\u2502   \u251c\u2500\u2500 Process Events\n\u2502   \u2514\u2500\u2500 Test & Debug\n\n\u251c\u2500\u2500 Track Analytics (15 pages, 10%)\n\u2502   \u251c\u2500\u2500 View Dashboards\n\u2502   \u2514\u2500\u2500 Query Analytics API\n\n\u2514\u2500\u2500 Troubleshoot Issues (15 pages, 10%)\n    \u251c\u2500\u2500 Common Problems\n    \u2514\u2500\u2500 Debugging Tools\n\n[Better balance: 13-17% per category, more specific labels]\n```\n\n**Your Analysis:**\n\"Much better! But realized we're missing 'Refunds & Disputes' (30 pages). \nAlso 'Authenticate Users' vs 'Manage API Keys' might be confusing - \nAPI keys are also authentication. Final refinement needed.\"\n\n---",
            "hydration_source_header": "Round 3: Fix Specific Issues",
            "hydration_method": "title_match"
          },
          {
            "id": "round-4-final-polish",
            "title": "Round 4: Final Polish",
            "goal": "Perfect details",
            "lines": "1422-1500",
            "content": "**Prompt:**\n```text\n\"Final refinements:\n\n1. Add 'Refunds & Disputes' content (30 pages) - should this be under \n   payments or separate?\n   \n2. Clarify 'Authenticate Users' vs API key management - these overlap\n   \n3. Ensure all 180 pages (updated count) are accounted for\n\n4. Add one-sentence purpose statement for each top-level category\"\n```\n\n**Output:**\n```text\nFinal Task-Based Taxonomy (180 pages):\n\n\u251c\u2500\u2500 Get Started (20 pages, 11%)\n\u2502   Purpose: Guide new users from setup to first successful API integration\n\u2502   \u251c\u2500\u2500 Install & Configure\n\u2502   \u251c\u2500\u2500 Your First API Call\n\u2502   \u2514\u2500\u2500 Essential Concepts\n\n\u251c\u2500\u2500 Authenticate Requests (25 pages, 14%)\n\u2502   Purpose: Secure your API integration with authentication\n\u2502   \u251c\u2500\u2500 API Keys Quick Start\n\u2502   \u251c\u2500\u2500 OAuth 2.0 Implementation\n\u2502   \u2514\u2500\u2500 Token Management\n\n\u251c\u2500\u2500 Accept Payments (25 pages, 14%)\n\u2502   Purpose: Process one-time and recurring payments\n\u2502   \u251c\u2500\u2500 One-Time Payments\n\u2502   \u251c\u2500\u2500 Subscriptions & Billing\n\u2502   \u2514\u2500\u2500 Payment Methods\n\n\u251c\u2500\u2500 Manage Transactions (30 pages, 17%)\n\u2502   Purpose: Handle post-payment operations\n\u2502   \u251c\u2500\u2500 Issue Refunds\n\u2502   \u251c\u2500\u2500 Handle Disputes\n\u2502   \u2514\u2500\u2500 View Transaction History\n\n\u251c\u2500\u2500 Integrate Webhooks (20 pages, 11%)\n\u2502   Purpose: Receive real-time event notifications\n\u2502   \u251c\u2500\u2500 Configure Webhooks\n\u2502   \u251c\u2500\u2500 Process Events\n\u2502   \u2514\u2500\u2500 Test & Debug\n\n\u251c\u2500\u2500 Track Performance (15 pages, 8%)\n\u2502   Purpose: Monitor and analyze your integration\n\u2502   \u251c\u2500\u2500 Dashboards\n\u2502   \u2514\u2500\u2500 Analytics API\n\n\u2514\u2500\u2500 Troubleshoot (25 pages, 14%)\n    Purpose: Diagnose and fix integration issues\n    \u251c\u2500\u2500 Common Errors\n    \u251c\u2500\u2500 Debugging Guide\n    \u2514\u2500\u2500 Get Help\n\nTotal: 180 pages, well-balanced distribution (8-17% per category)\n```\n\n**Your Analysis:**\n\"Perfect! Ready for user validation.\"\n\n---",
            "hydration_source_header": "Round 4: Final Polish",
            "hydration_method": "title_match"
          }
        ],
        "tutorials": [
          {
            "id": "bad-to-good-transformation",
            "title": "Transform Bad Prompt to Good Prompt",
            "teaches": "5-component application",
            "steps": 6,
            "lines": "1700-1900",
            "retrievalQuestions": [
              "Walk me through improving a prompt"
            ],
            "content": "Let's practice everything you've learned by transforming a terrible prompt into an excellent one.\n\n### 6.1 The Scenario\n\n**Context:**\nYou're redesigning the IA for \"DevDocs API\" documentation. Current navigation is confusing. You want AI to help generate a new taxonomy.\n\n---\n\n### 6.2 The Bad Prompt\n\n```text\n\"Create a taxonomy for our API documentation.\"\n```\n\n**Problems:**\n- No role definition\n- No context about content, users, or goals\n- No constraints\n- No format specification\n- Vague task (\"create a taxonomy\" - how many levels? What structure?)\n\n**Predicted Output Quality:** 2/10\n\nAI will produce generic structure that doesn't fit your needs.\n\n---\n\n### 6.3 Step-by-Step Transformation\n\nLet's improve this prompt using the RICE framework and the five components.\n\n### Step 1: Add Role\n\n```text\n\"You're an information architect specializing in developer documentation \nand API reference design.\n\nCreate a taxonomy for our API documentation.\"\n```\n\n**Improvement:** AI now knows relevant domain  \n**Quality Prediction:** 3/10 (still too vague)\n\n---\n\n### Step 2: Add Context\n\n```text\n\"You're an information architect specializing in developer documentation \nand API reference design.\n\nContext:\n- Documentation for a REST API with 120 pages\n- Target users: Mid-level developers (2-5 years experience)\n- Current problem: Users can't find what they need, 65% resort to search\n- Content covers: authentication, data operations, webhooks, error handling\n- Content types: 30 tutorials, 50 how-to guides, 30 reference pages, 10 explanations\n\nCreate a taxonomy for our API documentation.\"\n```\n\n**Improvement:** AI understands situation  \n**Quality Prediction:** 5/10 (better, but task still unclear)\n\n---\n\n### Step 3: Make Task Specific\n\n```text\n\"You're an information architect specializing in developer documentation \nand API reference design.\n\nContext:\n- Documentation for a REST API with 120 pages\n- Target users: Mid-level developers (2-5 years experience)\n- Current problem: Users can't find what they need, 65% resort to search\n- Content covers: authentication, data operations, webhooks, error handling\n- Content types: 30 tutorials, 50 how-to guides, 30 reference pages, 10 explanations\n\nTask:\nCreate a 3-level hierarchical taxonomy that organizes all 120 pages.\n- Level 1: Organize by user task (what they want to accomplish)\n- Level 2: Group by feature area  \n- Level 3: Organize by content type (following Di\u00e1taxis framework)\"\n```\n\n**Improvement:** Clear structure and logic  \n**Quality Prediction:** 7/10 (much better, needs constraints)\n\n---\n\n### Step 4: Add Constraints\n\n```text\n\"You're an information architect specializing in developer documentation \nand API reference design.\n\nContext:\n- Documentation for a REST API with 120 pages\n- Target users: Mid-level developers (2-5 years experience)\n- Current problem: Users can't find what they need, 65% resort to search\n- Content covers: authentication, data operations, webhooks, error handling\n- Content types: 30 tutorials, 50 how-to guides, 30 reference pages, 10 explanations\n\nTask:\nCreate a 3-level hierarchical taxonomy that organizes all 120 pages.\n- Level 1: Organize by user task (what they want to accomplish)\n- Level 2: Group by feature area  \n- Level 3: Organize by content type (following Di\u00e1taxis framework)\n\nConstraints:\n- Maximum 3 levels deep (no deeper)\n- Top level: 5-7 categories only\n- Labels must be under 30 characters\n- Must include clear home for troubleshooting content\n- Follow Di\u00e1taxis: Tutorial, How-to, Reference, Explanation\n- Progressive disclosure (beginner content first)\n- Balanced distribution (no category >30% of content)\"\n```\n\n**Improvement:** Clear boundaries and requirements  \n**Quality Prediction:** 8/10 (almost there, needs format)\n\n---\n\n### Step 5: Add Format Specification\n\n```text\n\"You're an information architect specializing in developer documentation \nand API reference design.\n\nContext:\n- Documentation for a REST API with 120 pages\n- Target users: Mid-level developers (2-5 years experience)\n- Current problem: Users can't find what they need, 65% resort to search\n- Content covers: authentication, data operations, webhooks, error handling\n- Content types: 30 tutorials, 50 how-to guides, 30 reference pages, 10 explanations\n\nTask:\nCreate a 3-level hierarchical taxonomy that organizes all 120 pages.\n- Level 1: Organize by user task (what they want to accomplish)\n- Level 2: Group by feature area  \n- Level 3: Organize by content type (following Di\u00e1taxis framework)\n\nConstraints:\n- Maximum 3 levels deep (no deeper)\n- Top level: 5-7 categories only\n- Labels must be under 30 characters\n- Must include clear home for troubleshooting content\n- Follow Di\u00e1taxis: Tutorial, How-to, Reference, Explanation\n- Progressive disclosure (beginner content first)\n- Balanced distribution (no category >30% of content)\n\nOutput Format:\n- Markdown indented list showing all three levels\n- Include estimated page counts in (parentheses) after each category\n- Show percentage distribution for top-level categories\n- Provide a 1-sentence purpose statement for each top-level category\n- Mark content types at level 3 with [Tutorial], [How-to], [Reference], [Explanation]\"\n```\n\n**Improvement:** Complete specification  \n**Quality Prediction:** 9/10 (excellent prompt!)\n\n---\n\n### Step 6: Add Examples (Optional but Recommended)\n\n```text\n[All of the above, PLUS:]\n\nExamples:\n\nGood top-level category example:\n\"Get Started\" (18 pages, 15%)\nPurpose: Guide new users from installation to first successful API call\n\u251c\u2500\u2500 Installation [Tutorial]\n\u251c\u2500\u2500 Quick Start [Tutorial]\n\u2514\u2500\u2500 Core Concepts [Explanation]\n\nBad category example to avoid:\n\"Advanced Topics\" \nProblems: Vague, subjective definition of \"advanced\", doesn't indicate tasks\n\nSample pages to categorize:\n- \"OAuth 2.0 Complete Tutorial\"\n- \"Webhook Event Reference\"  \n- \"How to Handle Rate Limiting\"\n- \"Understanding API Versioning\"\n```\n\n**Improvement:** Clear quality expectations  \n**Quality Prediction:** 10/10 (production-ready prompt!)\n\n---",
            "hydration_source_header": "6. Hands-On Tutorial: Transform Bad Prompt into Good Prompt",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "tutorialSteps": [
          {
            "id": "step-1-add-role",
            "title": "Step 1: Add Role",
            "adds": "role-component",
            "qualityPrediction": "3/10",
            "lines": "1720-1735",
            "content": "```text\n\"You're an information architect specializing in developer documentation \nand API reference design.\n\nCreate a taxonomy for our API documentation.\"\n```\n\n**Improvement:** AI now knows relevant domain  \n**Quality Prediction:** 3/10 (still too vague)\n\n---",
            "hydration_source_header": "Step 1: Add Role",
            "hydration_method": "title_match"
          },
          {
            "id": "step-2-add-context",
            "title": "Step 2: Add Context",
            "adds": "context-component",
            "qualityPrediction": "5/10",
            "lines": "1737-1760",
            "content": "```text\n\"You're an information architect specializing in developer documentation \nand API reference design.\n\nContext:\n- Documentation for a REST API with 120 pages\n- Target users: Mid-level developers (2-5 years experience)\n- Current problem: Users can't find what they need, 65% resort to search\n- Content covers: authentication, data operations, webhooks, error handling\n- Content types: 30 tutorials, 50 how-to guides, 30 reference pages, 10 explanations\n\nCreate a taxonomy for our API documentation.\"\n```\n\n**Improvement:** AI understands situation  \n**Quality Prediction:** 5/10 (better, but task still unclear)\n\n---",
            "hydration_source_header": "Step 2: Add Context",
            "hydration_method": "title_match"
          },
          {
            "id": "step-3-make-task-specific",
            "title": "Step 3: Make Task Specific",
            "adds": "task-component",
            "qualityPrediction": "7/10",
            "lines": "1762-1790",
            "content": "```text\n\"You're an information architect specializing in developer documentation \nand API reference design.\n\nContext:\n- Documentation for a REST API with 120 pages\n- Target users: Mid-level developers (2-5 years experience)\n- Current problem: Users can't find what they need, 65% resort to search\n- Content covers: authentication, data operations, webhooks, error handling\n- Content types: 30 tutorials, 50 how-to guides, 30 reference pages, 10 explanations\n\nTask:\nCreate a 3-level hierarchical taxonomy that organizes all 120 pages.\n- Level 1: Organize by user task (what they want to accomplish)\n- Level 2: Group by feature area  \n- Level 3: Organize by content type (following Di\u00e1taxis framework)\"\n```\n\n**Improvement:** Clear structure and logic  \n**Quality Prediction:** 7/10 (much better, needs constraints)\n\n---",
            "hydration_source_header": "Step 3: Make Task Specific",
            "hydration_method": "title_match"
          },
          {
            "id": "step-4-add-constraints",
            "title": "Step 4: Add Constraints",
            "adds": "constraints-component",
            "qualityPrediction": "8/10",
            "lines": "1792-1830",
            "content": "```text\n\"You're an information architect specializing in developer documentation \nand API reference design.\n\nContext:\n- Documentation for a REST API with 120 pages\n- Target users: Mid-level developers (2-5 years experience)\n- Current problem: Users can't find what they need, 65% resort to search\n- Content covers: authentication, data operations, webhooks, error handling\n- Content types: 30 tutorials, 50 how-to guides, 30 reference pages, 10 explanations\n\nTask:\nCreate a 3-level hierarchical taxonomy that organizes all 120 pages.\n- Level 1: Organize by user task (what they want to accomplish)\n- Level 2: Group by feature area  \n- Level 3: Organize by content type (following Di\u00e1taxis framework)\n\nConstraints:\n- Maximum 3 levels deep (no deeper)\n- Top level: 5-7 categories only\n- Labels must be under 30 characters\n- Must include clear home for troubleshooting content\n- Follow Di\u00e1taxis: Tutorial, How-to, Reference, Explanation\n- Progressive disclosure (beginner content first)\n- Balanced distribution (no category >30% of content)\"\n```\n\n**Improvement:** Clear boundaries and requirements  \n**Quality Prediction:** 8/10 (almost there, needs format)\n\n---",
            "hydration_source_header": "Step 4: Add Constraints",
            "hydration_method": "title_match"
          },
          {
            "id": "step-5-add-format",
            "title": "Step 5: Add Format Specification",
            "adds": "format-component",
            "qualityPrediction": "9/10",
            "lines": "1832-1870",
            "content": "```text\n\"You're an information architect specializing in developer documentation \nand API reference design.\n\nContext:\n- Documentation for a REST API with 120 pages\n- Target users: Mid-level developers (2-5 years experience)\n- Current problem: Users can't find what they need, 65% resort to search\n- Content covers: authentication, data operations, webhooks, error handling\n- Content types: 30 tutorials, 50 how-to guides, 30 reference pages, 10 explanations\n\nTask:\nCreate a 3-level hierarchical taxonomy that organizes all 120 pages.\n- Level 1: Organize by user task (what they want to accomplish)\n- Level 2: Group by feature area  \n- Level 3: Organize by content type (following Di\u00e1taxis framework)\n\nConstraints:\n- Maximum 3 levels deep (no deeper)\n- Top level: 5-7 categories only\n- Labels must be under 30 characters\n- Must include clear home for troubleshooting content\n- Follow Di\u00e1taxis: Tutorial, How-to, Reference, Explanation\n- Progressive disclosure (beginner content first)\n- Balanced distribution (no category >30% of content)\n\nOutput Format:\n- Markdown indented list showing all three levels\n- Include estimated page counts in (parentheses) after each category\n- Show percentage distribution for top-level categories\n- Provide a 1-sentence purpose statement for each top-level category\n- Mark content types at level 3 with [Tutorial], [How-to], [Reference], [Explanation]\"\n```\n\n**Improvement:** Complete specification  \n**Quality Prediction:** 9/10 (excellent prompt!)\n\n---",
            "hydration_source_header": "Step 5: Add Format Specification",
            "hydration_method": "title_match"
          },
          {
            "id": "step-6-add-examples",
            "title": "Step 6: Add Examples (Optional)",
            "adds": "examples",
            "qualityPrediction": "10/10",
            "lines": "1872-1900",
            "content": "```text\n[All of the above, PLUS:]\n\nExamples:\n\nGood top-level category example:\n\"Get Started\" (18 pages, 15%)\nPurpose: Guide new users from installation to first successful API call\n\u251c\u2500\u2500 Installation [Tutorial]\n\u251c\u2500\u2500 Quick Start [Tutorial]\n\u2514\u2500\u2500 Core Concepts [Explanation]\n\nBad category example to avoid:\n\"Advanced Topics\" \nProblems: Vague, subjective definition of \"advanced\", doesn't indicate tasks\n\nSample pages to categorize:\n- \"OAuth 2.0 Complete Tutorial\"\n- \"Webhook Event Reference\"  \n- \"How to Handle Rate Limiting\"\n- \"Understanding API Versioning\"\n```\n\n**Improvement:** Clear quality expectations  \n**Quality Prediction:** 10/10 (production-ready prompt!)\n\n---",
            "hydration_source_header": "Step 6: Add Examples (Optional but Recommended)",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "practiceExercises": [
          {
            "id": "exercise-content-classification",
            "title": "Fix Broken Prompt: Content Classification",
            "practices": [
              "rice-framework",
              "diataxis"
            ],
            "difficulty": "intermediate",
            "lines": "1920-1990",
            "content": "**Bad Prompt:**\n```text\n\"Classify this content.\"\n```\n\n**Your Task:**  \nRewrite this as a complete, excellent prompt for classifying 50 API documentation pages using the Di\u00e1taxis framework.\n\n**Include:**\n- \u2610 Appropriate role\n- \u2610 Rich context (users, content, problems)\n- \u2610 Specific task with clear deliverable\n- \u2610 Constraints (what framework, how to handle edge cases)\n- \u2610 Output format (table? list? with what columns?)\n- \u2610 Examples of good/bad classifications\n\n<details>\n<summary>View Solution Key</summary>\n\n```text\n[R - ROLE]\nYou are an information architect and technical documentation specialist with expertise\nin the Di\u00e1taxis framework (Tutorial, How-To Guide, Reference, Explanation). You understand\nhow to identify content types based on learning goals, user intent, and documentation purpose.\n\n[I - INSTRUCTIONS]\nYour task is to classify 50 API documentation pages using the Di\u00e1taxis framework.\n\nFor each page:\n1. Determine its primary Di\u00e1taxis type (Tutorial, How-To, Reference, or Explanation)\n2. Provide a confidence score (High/Medium/Low)\n3. Note any secondary types if the page is hybrid\n4. Flag pages that don't fit cleanly and explain why\n\nOutput as a markdown table with these columns:\n| Page Title | Primary Type | Confidence | Secondary Type | Notes | Recommendation |\n\nIf a page is poorly structured or tries to do too much:\n- Mark confidence as \"Low\"\n- Explain the confusion in Notes\n- Suggest splitting or restructuring in Recommendation\n\n[C - CONTEXT]\nThis API documentation serves developers with varying experience levels (junior to senior)\nwho are integrating our payment processing API. Current feedback shows users struggle to\nfind what they need\u2014task completion rate is only 58%. We suspect the documentation mixes\nlearning-oriented content with task-oriented content, making navigation unclear.\n\nThe classification will inform a restructure where:\n- Tutorials help new users get started\n- How-To guides solve specific integration tasks\n- Reference docs provide technical specifications\n- Explanations clarify concepts and design decisions\n\n[E - EXAMPLES]\n\n**Good Classification:**\n| Getting Started with Payments API | Tutorial | High | - | Walks through first integration step-by-step with working code | Keep as-is |\n\n**Hybrid Page:**\n| Authentication Methods | Reference | Medium | Explanation | Lists all auth methods (reference) but also explains security trade-offs (explanation) | Consider splitting into \"Auth Reference\" + \"Choosing Auth Methods\" |\n\n**Problematic Page:**\n| Working with Webhooks | Mixed | Low | All types | Combines setup tutorial, troubleshooting how-tos, webhook reference, and architecture explanation | Split into 4 pages: \"Webhook Setup Tutorial\", \"Webhook Troubleshooting\", \"Webhook Reference\", \"Understanding Webhook Architecture\" |\n```\n\n**Why This Works:**\n- **Role** establishes Di\u00e1taxis expertise\n- **Instructions** break down the classification task with clear deliverables\n- **Context** explains the business problem (58% task completion) and how classification will be used\n- **Examples** show edge cases: clean pages, hybrid pages, and problematic pages\n- **Constraints** specify handling of ambiguous content\n- **Format** provides exact table structure with all needed columns\n\n</details>\n\n---",
            "hydration_source_header": "Exercise 1: Content Classification",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "exercise-navigation-labels",
            "title": "Fix Broken Prompt: Navigation Labels",
            "practices": [
              "rice-framework",
              "accessibility"
            ],
            "difficulty": "intermediate",
            "lines": "1992-2085",
            "content": "**Bad Prompt:**\n```text\n\"Give me some labels for navigation.\"\n```\n\n**Your Task:**  \nRewrite this as a complete, excellent prompt for generating navigation label options for an API security section.\n\n**Include:**\n- \u2610 Role (UX writer? IA? Both?)\n- \u2610 Context (what content, what users, what problem)\n- \u2610 Task (how many options, for what section)\n- \u2610 Constraints (character limits, accessibility, etc.)\n- \u2610 Format (how should options be presented)\n- \u2610 Examples of good/bad labels\n\n<details>\n<summary>View Solution Key</summary>\n\n```text\n[R - ROLE]\nYou are a UX writer and information architect specializing in navigation design\nfor technical documentation. You understand plain language principles, accessibility\nrequirements, and how to write labels that match user mental models while staying concise.\n\n[I - INSTRUCTIONS]\nGenerate 5-7 navigation label options for our API security documentation section.\n\nFor each option, provide:\n1. The label text (2-4 words max)\n2. Rationale: Why this label works\n3. Accessibility note: How it works with screen readers\n4. SEO consideration: Search terms it aligns with\n5. Potential drawback: Where it might fall short\n\nConstraints:\n- Maximum 25 characters including spaces\n- Must be noun-based or action-based (avoid ambiguous adjectives)\n- Must pass plain language test (understandable to junior developers)\n- Must differentiate from \"Authentication\" section (related but different)\n- Should avoid jargon unless it's universal (e.g., \"OAuth\" acceptable, \"HMAC-SHA256\" not)\n\nOutput format:\n**Option [#]: [Label]**\n- Rationale: [why it works]\n- Accessibility: [screen reader experience]\n- SEO: [search alignment]\n- Drawback: [potential weakness]\n\n[C - CONTEXT]\nThis section covers API security topics including:\n- API key management and rotation\n- Rate limiting and abuse prevention\n- HTTPS/TLS requirements\n- Input validation and sanitization\n- Common vulnerabilities (injection, XSS, CSRF)\n\nOur users are:\n- 60% junior-to-mid level developers (new to API security)\n- 30% senior developers (refreshing knowledge)\n- 10% security engineers (auditing implementations)\n\nCurrent label \"API Protection\" tested poorly (only 42% of users correctly predicted content).\nUsers searched for terms like \"API security\", \"secure API\", \"API safety\", and \"protecting APIs.\"\n\nThis navigation appears in:\n- Top-level nav bar\n- Left sidebar (expanded section)\n- Sitemap and search results\n\n[E - EXAMPLES]\n\n**Good Label:**\n**Option 1: API Security**\n- Rationale: Direct match to user search terms, universally understood\n- Accessibility: Clear, no ambiguity for screen readers\n- SEO: Exact match for \"API security\" searches\n- Drawback: Very generic, might be expected for authentication too\n\n**Problematic Label:**\n**Option X: Hardening** \u274c\n- Rationale: Security industry term\n- Accessibility: Vague without context, screen reader users may not understand scope\n- SEO: Weak - users don't search \"API hardening\"\n- Drawback: Jargon that excludes junior developers\n\n**Context-Dependent Label:**\n**Option 2: Securing Your API**\n- Rationale: Action-oriented, task-focused, matches user goal\n- Accessibility: Clear action, works well with screen readers\n- SEO: Matches \"secure API\" and \"securing API\" searches\n- Drawback: Longer (18 chars), implies tutorial vs. reference content\n```\n\n**Why This Works:**\n- **Role** combines UX writing and IA expertise\n- **Instructions** request multiple options with structured analysis for each\n- **Context** provides:\n  - Section content scope\n  - User demographics (60% junior devs)\n  - Current performance data (42% prediction accuracy)\n  - Real search terms from users\n  - Where labels appear (multiple contexts)\n- **Constraints** address:\n  - Character limits (25 max)\n  - Plain language requirement\n  - Differentiation from related sections\n  - Jargon avoidance\n- **Examples** show what good vs. problematic labels look like with reasoning\n\n</details>\n\n---",
            "hydration_source_header": "Exercise 2: Navigation Labels",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "exercise-card-sort-analysis",
            "title": "Fix Broken Prompt: Card Sort Analysis",
            "practices": [
              "rice-framework",
              "research-analysis"
            ],
            "difficulty": "advanced",
            "lines": "2087-2180",
            "content": "**Bad Prompt:**\n```text\n\"Analyze this card sort data.\"\n```\n\n**Your Task:**  \nRewrite this as a complete, excellent prompt for analyzing card sorting results from 30 participants who sorted 48 cards.\n\n**Include:**\n- \u2610 Role (UX researcher, IA, both?)\n- \u2610 Context (what project, what goal, what will inform)\n- \u2610 Task (what specific analysis to perform)\n- \u2610 Constraints (confidence thresholds, how to handle conflicts)\n- \u2610 Format (report structure, what sections)\n- \u2610 Examples or data structure explanation\n\n<Warning>\n  **Hint for Exercise 3:** This is a complex analysis task. Your prompt should specify:\n  - How to calculate similarity/agreement\n  - What percentage constitutes \"high agreement\"\n  - How to handle cards that were difficult to categorize\n  - How to synthesize category naming from participant labels\n</Warning>\n\n---",
            "hydration_source_header": "Exercise 3: Card Sort Analysis",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "scoringRubrics": [
          {
            "id": "prompt-scoring-rubric",
            "title": "Self-Assessment Scoring Rubric",
            "scores": "basic + advanced",
            "maxPoints": 15,
            "lines": "2182-2280",
            "retrievalQuestions": [
              "How do I score my prompt?"
            ],
            "content": "For each exercise, score your rewritten prompt using these detailed criteria. **Aim for 13-15 points.**\n\n#### Basic Elements (1 point each - Total: 5 points)\n\n| Criteria | 0 Points (Missing) | 1 Point (Present) |\n|---|---|---|\n| **Role defined** | No role specified, or generic \"you are an AI\" | Specific role with relevant expertise (e.g., \"information architect\", \"content strategist\") |\n| **Context provided** | No background about project, users, or constraints | Clear context: users, content scope, business goals, or technical environment |\n| **Specific task stated** | Vague task (e.g., \"help me\") | Concrete action verb + deliverable (e.g., \"Generate a 3-level taxonomy\") |\n| **Constraints included** | No limits specified | At least one constraint: technical (levels, count) or business (time, audience) |\n| **Output format specified** | Format unclear or missing | Explicit format (e.g., \"indented list\", \"markdown table\", \"Mermaid diagram\") |\n\n**How to Score Basic Elements:**\n- Count each element present in your prompt\n- Each earns exactly 1 point (no partial credit)\n- Maximum: 5 points\n\n---\n\n#### Advanced Elements (2 points each - Total: 10 points)\n\n| Criteria | 0 Points (Missing) | 1 Point (Basic Attempt) | 2 Points (Well-Integrated) |\n|---|---|---|---|\n| **IA principles referenced** | No mention of IA concepts | Generic mention (\"organize logically\") | Specific principle with application (e.g., \"Use task-based organization following Di\u00e1taxis: Tutorials, How-To, Reference, Explanation\") |\n| **User needs addressed** | Users not mentioned | Users mentioned generically (\"for users\") | Specific user context: mental models, pain points, or tasks (e.g., \"Junior developers learning authentication for first time, unfamiliar with OAuth terminology\") |\n| **Success criteria defined** | No quality bar stated | Vague criteria (\"make it good\") | Measurable success criteria (e.g., \"User finds correct article in less than 30 seconds\", \"No category exceeds 30% of total content\") |\n| **Edge cases handled** | No consideration of problems | Mentions edge cases without guidance | Explicit handling (e.g., \"For hybrid pages covering multiple topics, prioritize primary user task\") |\n| **Examples provided** | No examples included | Generic example without reasoning | Contrast pair (good vs. bad) with explanation of why each works/fails |\n\n**How to Score Advanced Elements:**\n- Score each element: 0 (absent), 1 (basic attempt), or 2 (well-integrated)\n- Look for depth and specificity\n- Maximum: 10 points\n\n---\n\n#### Scoring Guide\n\n**Total Score: /15 points**\n\n- **13-15 points:** Excellent prompt engineering (Portfolio-ready work)\n- **10-12 points:** Good, minor improvements possible (Professional standard)\n- **7-9 points:** Adequate, needs more specificity (Functional but not polished)\n- **Below 7 points:** Review module content and rewrite (Insufficient quality)\n\n---",
            "hydration_source_header": "Self-Assessment: Scoring Your Fixes",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "basic-elements-rubric",
            "title": "Basic Elements Rubric",
            "criteria": 5,
            "maxPoints": 5,
            "lines": "2190-2210",
            "content": "For each exercise, score your rewritten prompt using these detailed criteria. **Aim for 13-15 points.**\n\n#### Basic Elements (1 point each - Total: 5 points)\n\n| Criteria | 0 Points (Missing) | 1 Point (Present) |\n|---|---|---|\n| **Role defined** | No role specified, or generic \"you are an AI\" | Specific role with relevant expertise (e.g., \"information architect\", \"content strategist\") |\n| **Context provided** | No background about project, users, or constraints | Clear context: users, content scope, business goals, or technical environment |\n| **Specific task stated** | Vague task (e.g., \"help me\") | Concrete action verb + deliverable (e.g., \"Generate a 3-level taxonomy\") |\n| **Constraints included** | No limits specified | At least one constraint: technical (levels, count) or business (time, audience) |\n| **Output format specified** | Format unclear or missing | Explicit format (e.g., \"indented list\", \"markdown table\", \"Mermaid diagram\") |\n\n**How to Score Basic Elements:**\n- Count each element present in your prompt\n- Each earns exactly 1 point (no partial credit)\n- Maximum: 5 points\n\n---\n\n#### Advanced Elements (2 points each - Total: 10 points)\n\n| Criteria | 0 Points (Missing) | 1 Point (Basic Attempt) | 2 Points (Well-Integrated) |\n|---|---|---|---|\n| **IA principles referenced** | No mention of IA concepts | Generic mention (\"organize logically\") | Specific principle with application (e.g., \"Use task-based organization following Di\u00e1taxis: Tutorials, How-To, Reference, Explanation\") |\n| **User needs addressed** | Users not mentioned | Users mentioned generically (\"for users\") | Specific user context: mental models, pain points, or tasks (e.g., \"Junior developers learning authentication for first time, unfamiliar with OAuth terminology\") |\n| **Success criteria defined** | No quality bar stated | Vague criteria (\"make it good\") | Measurable success criteria (e.g., \"User finds correct article in less than 30 seconds\", \"No category exceeds 30% of total content\") |\n| **Edge cases handled** | No consideration of problems | Mentions edge cases without guidance | Explicit handling (e.g., \"For hybrid pages covering multiple topics, prioritize primary user task\") |\n| **Examples provided** | No examples included | Generic example without reasoning | Contrast pair (good vs. bad) with explanation of why each works/fails |\n\n**How to Score Advanced Elements:**\n- Score each element: 0 (absent), 1 (basic attempt), or 2 (well-integrated)\n- Look for depth and specificity\n- Maximum: 10 points\n\n---\n\n#### Scoring Guide\n\n**Total Score: /15 points**\n\n- **13-15 points:** Excellent prompt engineering (Portfolio-ready work)\n- **10-12 points:** Good, minor improvements possible (Professional standard)\n- **7-9 points:** Adequate, needs more specificity (Functional but not polished)\n- **Below 7 points:** Review module content and rewrite (Insufficient quality)\n\n---",
            "hydration_source_header": "Self-Assessment: Scoring Your Fixes",
            "hydration_method": "line_proximity"
          },
          {
            "id": "advanced-elements-rubric",
            "title": "Advanced Elements Rubric",
            "criteria": 5,
            "maxPoints": 10,
            "lines": "2212-2240",
            "content": "| Criteria | 0 Points (Missing) | 1 Point (Present) |\n|---|---|---|\n| **Role defined** | No role specified, or generic \"you are an AI\" | Specific role with relevant expertise (e.g., \"information architect\", \"content strategist\") |\n| **Context provided** | No background about project, users, or constraints | Clear context: users, content scope, business goals, or technical environment |\n| **Specific task stated** | Vague task (e.g., \"help me\") | Concrete action verb + deliverable (e.g., \"Generate a 3-level taxonomy\") |\n| **Constraints included** | No limits specified | At least one constraint: technical (levels, count) or business (time, audience) |\n| **Output format specified** | Format unclear or missing | Explicit format (e.g., \"indented list\", \"markdown table\", \"Mermaid diagram\") |\n\n**How to Score Basic Elements:**\n- Count each element present in your prompt\n- Each earns exactly 1 point (no partial credit)\n- Maximum: 5 points\n\n---",
            "hydration_source_header": "Basic Elements (1 point each - Total: 5 points)",
            "hydration_method": "line_proximity"
          }
        ],
        "scoredExamples": [
          {
            "id": "example-prompt-basic",
            "title": "Example Prompt A: Basic Quality",
            "score": "8/15",
            "qualityLevel": "Adequate",
            "lines": "2285-2340",
            "content": "```text\n[R] You are an information architect.\n\n[I] Create a taxonomy for the DevHub documentation.\n\n[C] We have 80+ pages about APIs, authentication, webhooks, and analytics.\nUsers are developers.\n\n[E] None provided\n```\n\n**Score Breakdown:**\n\n**Basic Elements: 4/5**\n- \u2705 Role defined (1 pt) - \"information architect\" is specific\n- \u2705 Context provided (1 pt) - Mentions content scope and user type\n- \u2705 Specific task stated (1 pt) - \"Create a taxonomy\" is clear\n- \u274c Constraints included (0 pts) - No depth limits, balance requirements, or organizational principle specified\n- \u2705 Output format specified (1 pt) - Implied from context (taxonomy), though not explicitly stated\n\n**Advanced Elements: 4/10**\n- \u274c IA principles referenced (0 pts) - No organizational principle mentioned\n- \u26a0\ufe0f User needs addressed (1 pt) - Mentions \"developers\" but no mental models, pain points, or specific tasks\n- \u274c Success criteria defined (0 pts) - No quality bar or validation criteria\n- \u274c Edge cases handled (0 pts) - No guidance for hybrid content\n- \u26a0\ufe0f Examples provided (1 pt) - Explicitly states \"None provided\" (acknowledging but not including)\n\n**Total: 8/15 (Adequate, needs specificity)**\n\n**What's Missing:**\n- No organizational principle (task-based? topic-based?)\n- No depth or breadth constraints\n- No user pain points or mental models\n- No success criteria or validation approach\n- No examples of good vs. bad categories\n\n---",
            "hydration_source_header": "Example Prompt A: Basic Quality (8/15 points)",
            "hydration_method": "title_match"
          },
          {
            "id": "example-prompt-advanced",
            "title": "Example Prompt B: Advanced Quality",
            "score": "14/15",
            "qualityLevel": "Excellent",
            "lines": "2342-2420",
            "content": "```text\n[R] You are an information architect specializing in developer documentation.\n\n[I] Create a 3-level taxonomy for DevHub documentation covering 80+ pages.\n\nStructure requirements:\n- Maximum 3 levels deep\n- 5-7 top-level categories\n- No category should exceed 30% of total content (balanced distribution)\n- Use task-based organization following Di\u00e1taxis framework (Tutorial, How-To, Reference, Explanation)\n\nOutput as indented markdown list with category names and brief descriptions.\n\n[C] Content covers: Authentication (OAuth, API keys), Payments (processing, refunds),\nWebhooks (setup, events), Analytics (tracking, reports)\n\nTarget users: Junior to mid-level developers learning API integration for first time\n- Mental model: Thinking in terms of \"What do I need to do?\" not \"What features exist?\"\n- Pain points: Overwhelmed by too many options, unfamiliar with OAuth terminology\n- Primary task: Get first API call working in <30 minutes\n\n[E] Example of GOOD top-level category:\n\"Authentication & Security\" (task-focused, clear scope)\n  - OAuth 2.0 Setup\n  - API Key Management\n  - Session Handling\n\nExample of BAD category to avoid:\n\"Advanced Topics\" (vague, subjective definition of \"advanced\")\n\nEdge case handling:\nFor pages covering multiple topics (e.g., \"Secure Payment Processing\"),\nprioritize primary user task (Payments > Security)\n```\n\n**Score Breakdown:**\n\n**Basic Elements: 5/5**\n- \u2705 Role defined (1 pt) - \"information architect specializing in developer documentation\" (highly specific)\n- \u2705 Context provided (1 pt) - Detailed user mental models, pain points, primary task\n- \u2705 Specific task stated (1 pt) - \"Create a 3-level taxonomy for 80+ pages\"\n- \u2705 Constraints included (1 pt) - Multiple constraints: depth, breadth, balance, organizational principle\n- \u2705 Output format specified (1 pt) - \"indented markdown list with category names and brief descriptions\"\n\n**Advanced Elements: 9/10**\n- \u2705 IA principles referenced (2 pts) - \"Task-based organization following Di\u00e1taxis framework\" with explicit categories\n- \u2705 User needs addressed (2 pts) - Detailed mental models, pain points, specific primary task with timing\n- \u26a0\ufe0f Success criteria defined (1 pt) - Has measurable constraint (30% balance, less than 30 min task completion) but could specify how to validate\n- \u2705 Edge cases handled (2 pts) - Explicit guidance for hybrid pages with prioritization rule\n- \u2705 Examples provided (2 pts) - Contrast pair (good vs. bad) with reasoning for each\n\n**Total: 14/15 (Excellent, portfolio-ready)**\n\n**Why This Scores High:**\n- Every RICE component fully developed\n- Multiple specific constraints (depth, breadth, balance, principle)\n- Rich user context (mental models + pain points + tasks)\n- Contrast examples with clear reasoning\n- Edge case handling with decision rule\n- Measurable success criteria (30% limit, 30-minute goal)\n\n**Minor Improvement for 15/15:**\nAdd explicit validation criteria (e.g., \"Success = user can navigate to correct article in less than 3 clicks AND no confusion about which category applies\")\n\n---",
            "hydration_source_header": "Example Prompt B: Advanced Quality (14/15 points)",
            "hydration_method": "title_match"
          }
        ],
        "checklists": [
          {
            "id": "before-writing-checklist",
            "title": "Before Writing Prompt",
            "validates": "preparation",
            "time": "2 min",
            "lines": "2430-2440",
            "content": "```text\n\u2610 What specific output do I need?\n\u2610 What context does AI need to know?\n\u2610 What constraints must be respected?\n\u2610 What format will be most useful?\n\u2610 Do I have examples to guide AI?\n```",
            "hydration_source_header": "Before Writing",
            "hydration_method": "title_match"
          },
          {
            "id": "while-writing-checklist",
            "title": "While Writing Prompt",
            "validates": "completeness",
            "time": "5 min",
            "lines": "2442-2455",
            "content": "```text\n\u2610 Did I define a relevant role?\n\u2610 Did I provide rich context (users, content, problems, goals)?\n\u2610 Did I use a specific action verb?\n\u2610 Did I include technical constraints?\n\u2610 Did I include business constraints?\n\u2610 Did I specify output format?\n\u2610 Did I reference IA principles?\n\u2610 Did I define success criteria?\n\u2610 Is my prompt clear enough that a human could execute it?\n```",
            "hydration_source_header": "While Writing",
            "hydration_method": "title_match"
          },
          {
            "id": "after-first-output-checklist",
            "title": "After First Output",
            "validates": "iteration-needs",
            "time": "3 min",
            "lines": "2457-2465",
            "content": "```text\n\u2610 Does output match what I asked for?\n\u2610 What's working well?\n\u2610 What's missing or wrong?\n\u2610 What constraints weren't respected?\n\u2610 What should I change in next iteration?\n```",
            "hydration_source_header": "After First Output",
            "hydration_method": "title_match"
          },
          {
            "id": "before-final-use-checklist",
            "title": "Before Final Use",
            "validates": "production-readiness",
            "time": "5 min",
            "lines": "2467-2480",
            "content": "```text\n\u2610 Have I validated output quality?\n\u2610 Does it respect all constraints?\n\u2610 Have I tested with multiple inputs?\n\u2610 Is it ready for human review?\n\u2610 Should I save this prompt for reuse?\n```\n\n---",
            "hydration_source_header": "Before Final Use",
            "hydration_method": "title_match"
          },
          {
            "id": "prompt-engineering-master-checklist",
            "title": "Prompt Engineering Best Practices",
            "validates": "all-phases",
            "time": "15 min",
            "lines": "2428-2480",
            "content": "Use this checklist every time you write a prompt for IA work:\n\n### Before Writing\n\n```text\n\u2610 What specific output do I need?\n\u2610 What context does AI need to know?\n\u2610 What constraints must be respected?\n\u2610 What format will be most useful?\n\u2610 Do I have examples to guide AI?\n```\n\n### While Writing\n\n```text\n\u2610 Did I define a relevant role?\n\u2610 Did I provide rich context (users, content, problems, goals)?\n\u2610 Did I use a specific action verb?\n\u2610 Did I include technical constraints?\n\u2610 Did I include business constraints?\n\u2610 Did I specify output format?\n\u2610 Did I reference IA principles?\n\u2610 Did I define success criteria?\n\u2610 Is my prompt clear enough that a human could execute it?\n```\n\n### After First Output\n\n```text\n\u2610 Does output match what I asked for?\n\u2610 What's working well?\n\u2610 What's missing or wrong?\n\u2610 What constraints weren't respected?\n\u2610 What should I change in next iteration?\n```\n\n### Before Final Use\n\n```text\n\u2610 Have I validated output quality?\n\u2610 Does it respect all constraints?\n\u2610 Have I tested with multiple inputs?\n\u2610 Is it ready for human review?\n\u2610 Should I save this prompt for reuse?\n```\n\n---",
            "hydration_source_header": "8. Prompt Engineering Best Practices Checklist",
            "hydration_method": "title_match"
          }
        ],
        "warnings": [
          {
            "id": "context-assumption-warning",
            "title": "Don't Assume AI Knows Context",
            "prevents": "context-gaps",
            "lines": "170-175",
            "content": "**What It Is:**\nBackground information that helps AI understand the situation, constraints, and goals.\n\n**Three Types of Context for IA:**\n\n**1. User Context**\n- Who are your users?\n- What's their expertise level?\n- What are their goals and pain points?\n- What tasks do they need to accomplish?\n\n**2. Content Context**\n- How much content exists?\n- What types of content?\n- What's the current state/problem?\n- What content frameworks apply (e.g., Di\u00e1taxis)?\n\n**3. Business Context**\n- What are the goals?\n- What constraints exist (technical, resource, timeline)?\n- What organizational factors matter?\n- What success metrics?\n\n**Example Context Breakdown:**\n\n```text Bad Context (Vague)\n\"We have some documentation that needs organizing.\"\n\nGood Context (Specific)\n\"Background:\n- 120 pages of REST API documentation\n- Target users: Junior to mid-level developers (0-4 years experience)\n- Current problem: 65% of users resort to search, low task success rate\n- Content types: 30 tutorials, 45 reference pages, 30 how-to guides, 15 explanations\n- Business goal: Reduce time-to-first-API-call by 30%\n- Technical constraint: Must work with existing Markdown file structure\n- Timeline: Need to implement in 4 weeks\"\n```\n\n<Warning>\n  **Common Mistake:** Assuming AI knows your context. It doesn't! Always provide rich background, even if it feels obvious to you.\n</Warning>\n\n---",
            "hydration_source_header": "1.2 Component 2: Context",
            "hydration_method": "line_proximity"
          },
          {
            "id": "role-too-broad-warning",
            "title": "Avoid Generic Roles",
            "prevents": "weak-prompts",
            "lines": "90-95",
            "content": "**What It Is:**\nDefine who the AI should act as. This sets the knowledge domain and perspective.\n\n**Why It Matters:**\n- Activates relevant knowledge patterns in the AI's training\n- Sets appropriate tone and depth\n- Helps AI understand context better\n\n**Examples:**\n\n<CardGroup cols={2}>\n  <Card title=\"Generic Role\" icon=\"user\">\n    \"You're an AI assistant.\"\n    \n    **Problem:** Too broad, doesn't activate specialized knowledge\n  </Card>\n  \n  <Card title=\"Specific Role\" icon=\"user-tie\">\n    \"You're an information architect with 10 years of experience designing taxonomies for developer documentation.\"\n    \n    **Better:** Activates relevant domain knowledge, sets expertise level\n  </Card>\n</CardGroup>\n\n**Role Formula for IA Work:**\n\n```text\n\"You are a/an [specific role] with expertise in [relevant specialization].\"\n\nExamples:\n- \"You are an information architect specializing in API documentation structure.\"\n- \"You are a UX researcher who analyzes card sorting results.\"\n- \"You are a content strategist who designs metadata schemas.\"\n- \"You are a navigation designer focused on developer experience.\"\n```\n\n<Tip>\n  **Pro Tip:** The more specific the role, the better the output. \"Information architect\" is good. \"Information architect specializing in software documentation using the Di\u00e1taxis framework\" is better.\n</Tip>\n\n---",
            "hydration_source_header": "1.1 Component 1: Role",
            "hydration_method": "line_proximity"
          }
        ],
        "tips": [
          {
            "id": "specific-role-tip",
            "title": "More Specific Role = Better Output",
            "improves": "role-quality",
            "lines": "110-115",
            "content": "**What It Is:**\nDefine who the AI should act as. This sets the knowledge domain and perspective.\n\n**Why It Matters:**\n- Activates relevant knowledge patterns in the AI's training\n- Sets appropriate tone and depth\n- Helps AI understand context better\n\n**Examples:**\n\n<CardGroup cols={2}>\n  <Card title=\"Generic Role\" icon=\"user\">\n    \"You're an AI assistant.\"\n    \n    **Problem:** Too broad, doesn't activate specialized knowledge\n  </Card>\n  \n  <Card title=\"Specific Role\" icon=\"user-tie\">\n    \"You're an information architect with 10 years of experience designing taxonomies for developer documentation.\"\n    \n    **Better:** Activates relevant domain knowledge, sets expertise level\n  </Card>\n</CardGroup>\n\n**Role Formula for IA Work:**\n\n```text\n\"You are a/an [specific role] with expertise in [relevant specialization].\"\n\nExamples:\n- \"You are an information architect specializing in API documentation structure.\"\n- \"You are a UX researcher who analyzes card sorting results.\"\n- \"You are a content strategist who designs metadata schemas.\"\n- \"You are a navigation designer focused on developer experience.\"\n```\n\n<Tip>\n  **Pro Tip:** The more specific the role, the better the output. \"Information architect\" is good. \"Information architect specializing in software documentation using the Di\u00e1taxis framework\" is better.\n</Tip>\n\n---",
            "hydration_source_header": "1.1 Component 1: Role",
            "hydration_method": "line_proximity"
          },
          {
            "id": "constraints-guide-tip",
            "title": "Constraints Guide, Not Limit",
            "improves": "constraint-understanding",
            "lines": "265-270",
            "content": "**What It Is:**\nSpecification of exactly how the output should be structured and presented.\n\n**Why It Matters:**\n- Ensures output is immediately usable\n- Reduces need for reformatting\n- Makes validation easier\n- Facilitates team sharing\n\n**Format Specification Examples:**",
            "hydration_source_header": "1.5 Component 5: Format",
            "hydration_method": "line_proximity"
          },
          {
            "id": "examples-cost-benefit",
            "title": "Examples: 30 Seconds Saves 10 Minutes",
            "improves": "example-efficiency",
            "lines": "888-892",
            "content": "| **Include Examples When:** | **Skip Examples When:** |\n|---|---|\n| \u2705 Task uses subjective words (\"clear\", \"good\", \"professional\") | \u274c Task is purely objective (\"count words\", \"extract dates\") |\n| \u2705 AI previously produced wrong style/quality | \u274c You want maximum creativity/exploration |\n| \u2705 Showing good vs. bad approaches helps | \u274c Prompt is already very long (>300 words) |\n| \u2705 Output quality varies without examples | \u274c Instructions are unambiguous (e.g., \"convert JSON to CSV\") |\n| \u2705 First time attempting this type of task | \u274c You're brainstorming (want diverse ideas) |\n\n**When in Doubt:** Include 1-2 examples. They take 30 seconds to write but often save 10+ minutes of iteration.\n\n**Cost-Benefit Rule:** If adding examples takes less than 1 minute but saves one re-prompt cycle (5+ minutes), include them.\n\n---",
            "hydration_source_header": "Quick Reference: Include vs. Skip Examples",
            "hydration_method": "line_proximity"
          },
          {
            "id": "iteration-surgical-tip",
            "title": "Iteration Should Be Surgical",
            "improves": "refinement-efficiency",
            "lines": "1675-1680",
            "content": "<Warning>\n**Quick Practice (3 minutes):** Identify the iteration strategy.\n</Warning>\n\n**Scenario:** You asked AI to generate a sitemap, but the output has 12 top-level categories (way too many).\n\n**Question:** Which iteration strategy should you use?\n\n**A.** Start over with a completely different prompt\n**B.** Add a constraint: \"Limit to 5-7 top-level categories\"\n**C.** Ask \"Why did you choose 12 categories?\"\n**D.** Generate 3 alternative versions with different constraints\n\n<details>\n<summary>Show Answer</summary>\n\n**Best Answer: B** - Add a constraint\n\n**Why:**\n- The AI did its job (generated a sitemap)\n- The problem is specific and fixable (too many categories)\n- Adding a constraint is the fastest path to improvement\n- You keep the good parts and fix one issue\n\n**When to use other strategies:**\n\n**A - Start over:** Use when output is fundamentally wrong (wrong format, wrong domain, misunderstood task)\n\n**C - Ask why:** Use when you don't understand the AI's reasoning or want to learn its thought process\n\n**D - Generate alternatives:** Use when exploring options, not sure which approach is best, or early in Round 1\n\n**The Refinement Prompt:**\n```text\nRefine this sitemap to have 5-7 top-level categories instead of 12.\n\nCurrent structure:\n[paste the 12-category sitemap]\n\nConsolidate related categories logically. For each consolidation, explain your rationale.\n```\n\n**Key Insight:** Don't restart from scratch when targeted refinement can fix specific issues. Iteration should be surgical, not a full reset.\n\n</details>\n\n**Remember:** Iteration is about progressive improvement. Each round should solve 1-2 specific problems, not rebuild everything.\n\n---",
            "hydration_source_header": "Check Your Understanding: Section 5",
            "hydration_method": "line_proximity"
          }
        ]
      }
    },
    "2-1-taxonomy": {
      "file": "2-1-taxonomy.mdx",
      "focus": "AI-assisted taxonomy generation, validation systems, advanced classification patterns, and real-world case studies",
      "entityCount": 89,
      "entities": {
        "frameworks": [
          {
            "id": "5-check-validation-system",
            "title": "5-Check Validation System",
            "type": "framework",
            "definition": "Five-check system for validating taxonomies: depth, balance, granularity, exclusivity, label clarity",
            "contains": [
              "depth-check",
              "balance-check",
              "granularity-check",
              "exclusivity-check",
              "label-clarity-check"
            ],
            "lines": "302-780",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I validate a taxonomy?",
              "What are the 5 checks for taxonomy validation?"
            ],
            "content": "1. Depth Check\n 2. Balance Check\n 3. Granularity Check\n 4. Mutual Exclusivity Check\n 5. Label Clarity Check\n\nLet's examine each in detail.\n\n---\n\n#### Check 1: Depth Check\n\n**What to Evaluate:**\n- Is the hierarchy too deep or too shallow?\n- Does depth match content volume?\n- Could it be flattened without losing clarity?\n\n**Rules of Thumb:**\n- **Small sites (20-50 pages):** 2 levels usually sufficient\n- **Medium sites (50-200 pages):** 2-3 levels optimal\n- **Large sites (200+ pages):** 3 levels max, 4 only if absolutely necessary\n\n**Depth Problems:**\n\n<!-- START EXAMPLE-EX-93: \"Depth Problems Examples\" -->\n<CardGroup cols={2}>\n  <Card title=\"Too Shallow\" icon=\"compress\">\n    **Problem:** All 150 pages in a flat list\n    \n    **Impact:** Overwhelming, poor scannability\n    \n    **Fix:** Add 1-2 levels of categorization\n  </Card>\n  \n  <Card title=\"Too Deep\" icon=\"expand\">\n    **Problem:** 5-6 levels of nesting\n    \n    **Impact:** Users get lost, excessive clicking\n    \n    **Fix:** Flatten by combining levels\n  </Card>\n</CardGroup>\n<!-- END EXAMPLE-EX-93 -->\n\n**Example Depth Analysis:**\n\n<!-- START EXAMPLE-EX-94: \"Depth Analysis Examples\" -->\n```text\n\u2713 GOOD (80 pages, 3 levels):\n\u251c\u2500\u2500 Get Started (12 pages)\n\u2502   \u251c\u2500\u2500 Installation (3 pages)\n\u2502   \u2514\u2500\u2500 Quick Start (9 pages)\n\u251c\u2500\u2500 Features (50 pages)\n\u2502   \u251c\u2500\u2500 Authentication (15 pages)\n\u2502   \u2514\u2500\u2500 Payments (35 pages)\n\u2514\u2500\u2500 Reference (18 pages)\n\n\u2717 TOO DEEP (80 pages, 5 levels):\n\u251c\u2500\u2500 Documentation\n\u2502   \u251c\u2500\u2500 Getting Started\n\u2502   \u2502   \u251c\u2500\u2500 Prerequisites\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 System Requirements\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 Operating Systems\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 Windows (1 page) \u2190 Way too deep!\n\n\u2717 TOO SHALLOW (80 pages, 1 level):\n- 80 flat pages (no hierarchy at all)\n```\n<!-- END EXAMPLE-EX-94 -->\n\n---\n\n<!-- START CHECKLIST-CL-2: \"Balance Check\" -->\n#### Check 2: Balance Check\n\n**What to Evaluate:**\n- Is content distributed reasonably across categories?\n- Does any single category dominate (>35%)?\n- Are there tiny categories that don't warrant top-level status?\n\n**Balance Thresholds (Apply these specific criteria):**\n\n| Threshold | Percentage | Status | Action Required |\n|---|---|---|---|\n| **Balanced** | No category exceeds 35% | \u2705 PASS | No action needed |\n| **Slightly Unbalanced** | 1 category at 36-40% | \u26a0\ufe0f REVIEW | Consider splitting if it will grow |\n| **Unbalanced** | 1+ categories >40% | \u274c FAIL | Must split large categories |\n| **Too Granular** | 2+ categories less than 8% | \u274c FAIL | Combine or demote tiny categories |\n| **Micro-Category** | Any category less than 5% | \ud83d\udeab RED FLAG | Not viable at top level |\n\n**Ideal Range:** 12-35% per top-level category with 5-7 categories total\n\n---\n\n#### Balance Validation Examples with Scores\n\n<!-- START EXAMPLE-EX-95: \"Well-Balanced Taxonomy Example\" -->\n**Example 1: Well-Balanced Taxonomy (Score: 90/100)**\n\n```text\nSITE: 100 pages total\n\n\u251c\u2500\u2500 Get Started (15 pages, 15%) \u2705\n\u251c\u2500\u2500 Authentication (20 pages, 20%) \u2705\n\u251c\u2500\u2500 Core Features (28 pages, 28%) \u2705\n\u251c\u2500\u2500 Advanced Topics (18 pages, 18%) \u2705\n\u2514\u2500\u2500 API Reference (19 pages, 19%) \u2705\n\n**Score Breakdown:**\n\u2705 Balance (30/30): All categories 15-35% range, well-distributed\n\u2705 Range (25/25): Good variety (smallest=15%, largest=28%, spread=13%)\n\u2705 Total Categories (20/20): 5 categories (ideal range)\n\u2705 Naming (15/15): Clear, distinct, appropriate granularity\nMinor: Could combine \"Advanced Topics\" + \"API Reference\" for 4 categories\n\n**Total: 90/100 - Excellent balance**\n```\n\n---\n\n**Example 2: Unbalanced Taxonomy (Score: 45/100)**\n\n```text\nSITE: 100 pages total\n\n\u251c\u2500\u2500 Get Started (8 pages, 8%) \u26a0\ufe0f BORDERLINE LOW\n\u251c\u2500\u2500 Everything Else (68 pages, 68%) \ud83d\udeab RED FLAG - Dominates!\n\u251c\u2500\u2500 Troubleshooting (12 pages, 12%) \u2705\n\u251c\u2500\u2500 FAQ (7 pages, 7%) \u26a0\ufe0f BORDERLINE LOW\n\u2514\u2500\u2500 Changelog (5 pages, 5%) \ud83d\udeab RED FLAG - Too small\n\n**Score Breakdown:**\n\u274c Balance (5/30): One category dominates at 68% (FAIL >40% threshold)\n\u274c Range (0/25): Massive spread (5% to 68%) indicates poor distribution\n\u26a0\ufe0f Total Categories (10/20): 5 categories but 2 are micro-categories\n\u26a0\ufe0f Naming (10/15): \"Everything Else\" is vague catch-all (red flag)\n\u274c Viability (0/10): 2 categories below 8% threshold\n\n**Total: 45/100 - Needs major restructuring**\n\n**Critical Issues:**\n1. \ud83d\udeab \"Everything Else\" at 68% \u2192 Split into 3-4 specific feature categories\n2. \ud83d\udeab \"Changelog\" at 5% \u2192 Move to utility navigation, not top-level\n3. \u26a0\ufe0f \"FAQ\" at 7% \u2192 Combine with Troubleshooting OR demote to footer\n\n**Recommended Fix:**\nSplit \"Everything Else\" (68 pages) into:\n- Authentication & Security (22 pages, 22%)\n- Payment Processing (25 pages, 25%)\n- Data & Analytics (21 pages, 21%)\n\nNew structure:\n- Get Started (8%) + FAQ (7%) \u2192 \"Get Started & Support\" (15%)\n- Authentication (22%)\n- Payment Processing (25%)\n- Data & Analytics (21%)\n- Troubleshooting (12%)\n- Changelog \u2192 Move to footer (not top-level)\n\nResult: 5 categories, range 12-25%, all within thresholds \u2705\n```\n<!-- END EXAMPLE-EX-95 -->\n\n---\n\n<!-- START EXAMPLE-EX-96: \"Too Granular Taxonomy Example\" -->\n**Example 3: Too Granular Taxonomy (Score: 55/100)**\n\n```text\nSITE: 100 pages total\n\n\u251c\u2500\u2500 Authentication (35 pages, 35%) \u26a0\ufe0f AT THRESHOLD\n\u251c\u2500\u2500 Payments (32 pages, 32%) \u2705\n\u251c\u2500\u2500 Webhooks (28 pages, 28%) \u2705\n\u251c\u2500\u2500 Troubleshooting (3 pages, 3%) \ud83d\udeab RED FLAG - Too small\n\u2514\u2500\u2500 Changelog (2 pages, 2%) \ud83d\udeab RED FLAG - Too small\n\n**Score Breakdown:**\n\u26a0\ufe0f Balance (15/30): Authentication at 35% (exactly at threshold, borderline)\n\u2705 Range (20/25): Main categories well-distributed (28-35%)\n\u274c Total Categories (5/20): 5 categories but 2 are non-viable micro-categories\n\u2705 Naming (15/15): Clear, specific, appropriate labels\n\u274c Viability (0/10): 2 categories well below 8% threshold (3% and 2%)\n\n**Total: 55/100 - Needs consolidation**\n\n**Critical Issues:**\n1. \ud83d\udeab \"Troubleshooting\" at 3% \u2192 Too small for top-level category\n2. \ud83d\udeab \"Changelog\" at 2% \u2192 Utility content, not primary navigation\n3. \u26a0\ufe0f \"Authentication\" at 35% \u2192 Right at threshold, monitor growth\n\n**Recommended Fix:**\n- Merge \"Troubleshooting\" (3 pages) into relevant feature sections\n- Move \"Changelog\" to footer or utility navigation\n- Result: 3 strong top-level categories (Authentication 35%, Payments 32%, Webhooks 28%)\n- Add \"Get Started\" section if you have onboarding content\n\n**Alternative:** If you have 15+ more pages of content:\n- Keep Authentication, Payments, Webhooks as-is\n- Add \"Get Started & Tutorials\" (10-15 pages)\n- Distribute Troubleshooting across feature sections\n- Move Changelog to footer\n```\n<!-- END EXAMPLE-EX-96 -->\n\n---\n\n<!-- START EXAMPLE-EX-97: \"Red Flags Checklist\" -->\n##### Red Flags Checklist\n\nWhen validating taxonomy balance, watch for these **automatic red flags**:\n\n```\n\ud83d\udeab RED FLAG #1: Mega-Category (>40%)\n\u251c\u2500\u2500 Indicates: Category is too broad, mixing multiple concepts\n\u2514\u2500\u2500 Fix: Split into 2-3 specific subcategories\n\n\ud83d\udeab RED FLAG #2: Micro-Category (<5%)\n\u251c\u2500\u2500 Indicates: Not enough content to warrant top-level status\n\u2514\u2500\u2500 Fix: Combine with related category OR demote to subcategory\n\n\ud83d\udeab RED FLAG #3: Catch-All Label (\"Other\", \"Miscellaneous\", \"Everything Else\")\n\u251c\u2500\u2500 Indicates: Lack of clear organizational principle\n\u2514\u2500\u2500 Fix: Identify patterns in \"other\" content, create specific categories\n\n\ud83d\udeab RED FLAG #4: Massive Spread (70+ percentage point gap)\n\u251c\u2500\u2500 Example: Smallest=5%, Largest=75% (70-point spread)\n\u2514\u2500\u2500 Fix: Split large categories, combine/demote small ones\n\n\ud83d\udeab RED FLAG #5: Ratio Imbalance (>10:1 ratio between largest and smallest)\n\u251c\u2500\u2500 Example: Largest=60 pages, Smallest=5 pages (12:1 ratio)\n\u2514\u2500\u2500 Fix: Indicates granularity mismatch, restructure levels\n\n\u26a0\ufe0f WARNING: Future Growth Pattern\n\u251c\u2500\u2500 Indicates: Category at 33-35% but expected to grow significantly\n\u2514\u2500\u2500 Fix: Proactively split before hitting 40% threshold\n```\n<!-- END EXAMPLE-EX-97 -->\n<!-- END CHECKLIST-CL-2 -->\n\n---\n\n<!-- START FIGURE-DG-12: \"Balance Validation Prompt\" -->\n**Validation Prompt (Enhanced):**\n\n```text\n[R] You are an information architect validating taxonomy balance.\n\n[I] Analyze this taxonomy for balance using these specific thresholds:\n\nBALANCE THRESHOLDS:\n- \u2705 Balanced: No category exceeds 35%\n- \u26a0\ufe0f Review: Any category 36-40%\n- \u274c Fail: Any category >40% OR <5%\n- \ud83d\udeab Red Flag: Catch-all labels, >10:1 size ratio\n\nCalculate:\n1. Percentage distribution for each top-level category\n2. Smallest vs. largest category spread\n3. Number of micro-categories (<8%)\n4. Ratio between largest and smallest categories\n\nFlag red flags and provide scored assessment (0-100).\n\n[C] Taxonomy to validate:\n[Paste taxonomy with page counts]\n\n[E] Output format:\nCategory | Pages | % | Status\nGet Started | 15 | 15% | \u2705 Balanced\n\n**Score:** /100\n**Red Flags:** [List any found]\n**Recommendation:** [Specific fixes if score <70]\n```\n<!-- END FIGURE-DG-12 -->\n\n---\n\n<!-- START CHECKLIST-CL-3: \"Granularity Check\" -->\n#### Check 3: Granularity Check\n\n**What to Evaluate:**\n- Are items at the same level at similar levels of abstraction?\n- Are you mixing broad topics with narrow topics?\n\n**Granularity Problems:**\n\n<!-- START EXAMPLE-EX-98: \"Granularity Problem Examples\" -->\n```text\n\u2717 INCONSISTENT GRANULARITY:\n\u251c\u2500\u2500 Authentication \u2190 Broad\n\u251c\u2500\u2500 OAuth 2.0 \u2190 Specific (subset of authentication!)\n\u251c\u2500\u2500 Payments \u2190 Broad\n\u251c\u2500\u2500 Visa Card Processing \u2190 Too specific (subset of payments!)\n\u2514\u2500\u2500 API Reference \u2190 Broad\n\nProblem: Mixing different levels of specificity at same level\n\n\u2713 CONSISTENT GRANULARITY:\n\u251c\u2500\u2500 Authentication \u2190 Broad feature\n\u251c\u2500\u2500 Payments \u2190 Broad feature\n\u251c\u2500\u2500 Webhooks \u2190 Broad feature\n\u2514\u2500\u2500 API Reference \u2190 Broad reference section\n\nAll items are at similar level of abstraction\n```\n\n**Example from real taxonomy:**\n\n```text\n\u2717 BAD:\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Core Concepts \u2190 Broad\n\u251c\u2500\u2500 Understanding OAuth \u2190 Specific concept (should be under \"Core Concepts\")\n\u251c\u2500\u2500 Implementation Guides \u2190 Broad\n\u2514\u2500\u2500 How to Validate Tokens \u2190 Specific guide (should be under \"Implementation\")\n\n\u2713 GOOD:\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Core Concepts\n\u2502   \u251c\u2500\u2500 Understanding OAuth\n\u2502   \u251c\u2500\u2500 Token Types\n\u2502   \u2514\u2500\u2500 Security Model\n\u251c\u2500\u2500 Implementation Guides\n\u2502   \u251c\u2500\u2500 Validate Tokens\n\u2502   \u2514\u2500\u2500 Handle Errors\n\u2514\u2500\u2500 API Reference\n```\n<!-- END EXAMPLE-EX-98 -->\n<!-- END CHECKLIST-CL-3 -->\n\n---\n\n<!-- START CHECKLIST-CL-4: \"Mutual Exclusivity Check\" -->\n#### Check 4: Mutual Exclusivity Check\n\n**What to Evaluate:**\n- Does content have one clear, obvious home?\n- Is there significant overlap between categories?\n- Can users easily decide where to look?\n\n**Exclusivity Problems:**\n\n<!-- START EXAMPLE-EX-99: \"Exclusivity Problem Examples\" -->\n```text\n\u2717 OVERLAPPING CATEGORIES:\n\u251c\u2500\u2500 Security\n\u2502   \u251c\u2500\u2500 Authentication\n\u2502   \u251c\u2500\u2500 Encryption\n\u2502   \u2514\u2500\u2500 API Keys\n\u251c\u2500\u2500 Authentication \u2190 Wait, this is also a top-level category?\n\u2502   \u251c\u2500\u2500 OAuth\n\u2502   \u2514\u2500\u2500 API Keys \u2190 Duplicate! Also in \"Security\"\n\u2514\u2500\u2500 Getting Started\n    \u2514\u2500\u2500 Set Up Authentication \u2190 Third place for auth content!\n\nProblem: Authentication content scattered across 3 locations\n\n\u2713 CLEAR BOUNDARIES:\n\u251c\u2500\u2500 Get Started\n\u2502   \u2514\u2500\u2500 Authentication Quickstart (links to main auth docs)\n\u251c\u2500\u2500 Authentication \u2190 Primary home for ALL auth content\n\u2502   \u251c\u2500\u2500 OAuth\n\u2502   \u251c\u2500\u2500 API Keys\n\u2502   \u2514\u2500\u2500 Security Best Practices\n\u2514\u2500\u2500 Reference\n    \u2514\u2500\u2500 Auth Endpoints (references primary auth docs)\n\nSolution: One primary home, cross-links from elsewhere\n```\n<!-- END EXAMPLE-EX-99 -->\n\n**When Overlap Is Intentional:**\n\nSometimes content legitimately belongs in multiple places. This is called **polyhierarchy**.\n\n<!-- START EXAMPLE-EX-100: \"Intentional Polyhierarchy Example\" -->\n```text\n\u2713 INTENTIONAL POLYHIERARCHY:\n\u251c\u2500\u2500 Security\n\u2502   \u251c\u2500\u2500 Encryption at Rest\n\u2502   \u251c\u2500\u2500 Encryption in Transit\n\u2502   \u2514\u2500\u2500 API Security Best Practices \u2190 Lives here AND...\n\u251c\u2500\u2500 API Reference\n\u2502   \u2514\u2500\u2500 Security Best Practices \u2190 ...also here\n\u2514\u2500\u2500 Getting Started\n    \u2514\u2500\u2500 Security Checklist \u2190 References both of the above\n\nNote: \"API Security Best Practices\" appears in two places intentionally\nbecause users approach from different angles (learning vs. reference lookup).\nImplementation: Single source of truth, duplicate navigation pointers.\n```\n<!-- END EXAMPLE-EX-100 -->\n<!-- END CHECKLIST-CL-4 -->\n\n---\n\n<!-- START FIGURE-DG-28: \"Label Clarity Check\" -->\n#### Check 5: Label Clarity Check\n\n**What to Evaluate:**\n- Do labels clearly describe what's inside?\n- Can users predict content from the label alone?\n- Are labels consistent in style and specificity?\n\n**Label Problems:**\n\n<!-- START EXAMPLE-EX-101: \"Label Problems and Solutions\" -->\n<CardGroup cols={2}>\n  <Card title=\"Vague Labels\" icon=\"question\">\n    **Bad Examples:**\n    - \"Resources\"\n    - \"Other\"\n    - \"Miscellaneous\"\n    - \"Advanced Topics\"\n    - \"More\"\n    \n    **Why:** Doesn't indicate what's actually inside\n  </Card>\n  \n  <Card title=\"Good Labels\" icon=\"check\">\n    **Good Examples:**\n    - \"API Reference\"\n    - \"Getting Started Tutorials\"\n    - \"Troubleshooting Guides\"\n    - \"Security Best Practices\"\n    \n    **Why:** Clear, specific, predictive\n  </Card>\n</CardGroup>\n<!-- END EXAMPLE-EX-101 -->\n\n**Label Consistency:**\n\n```text\n\u2717 INCONSISTENT STYLE:\n\u251c\u2500\u2500 Getting Started \u2190 Gerund (progressive verb)\n\u251c\u2500\u2500 Implement Features \u2190 Imperative verb\n\u251c\u2500\u2500 Reference \u2190 Noun\n\u2514\u2500\u2500 How to Troubleshoot \u2190 Question format\n\nProblem: Mixed grammatical structures\n\n\u2713 CONSISTENT STYLE (Gerunds):\n\u251c\u2500\u2500 Getting Started\n\u251c\u2500\u2500 Implementing Features\n\u251c\u2500\u2500 Referencing APIs\n\u2514\u2500\u2500 Troubleshooting Issues\n\n\u2713 CONSISTENT STYLE (Nouns):\n\u251c\u2500\u2500 Getting Started Guide\n\u251c\u2500\u2500 Implementation Guide\n\u251c\u2500\u2500 API Reference\n\u2514\u2500\u2500 Troubleshooting Guide\n\n\u2713 CONSISTENT STYLE (Imperatives):\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Implement Features\n\u251c\u2500\u2500 Reference APIs\n\u2514\u2500\u2500 Troubleshoot Issues\n```\n\n**Accessibility Check:**\n\nLabels must work for screen reader users:\n\n```text\n\u2717 NOT SCREEN-READER FRIENDLY:\n\u251c\u2500\u2500 Click Here\n\u251c\u2500\u2500 Learn More\n\u251c\u2500\u2500 Resources\n\u2514\u2500\u2500 This Section\n\n\u2713 SCREEN-READER FRIENDLY:\n\u251c\u2500\u2500 API Authentication Guide\n\u251c\u2500\u2500 Payment Integration Tutorials\n\u251c\u2500\u2500 SDK Documentation\n\u2514\u2500\u2500 Troubleshooting Reference\n\nWhy: Specific labels work without visual context\n```\n<!-- END FIGURE-DG-28 -->\n<!-- END CHECKLIST-CL-1 -->\n\n---\n\n<!-- START EXAMPLE-EX-102: \"Complete Validation Walkthrough\" -->",
            "hydration_source_header": "2.1 The 5-Check Validation system",
            "hydration_method": "title_match"
          },
          {
            "id": "diataxis-framework",
            "title": "Di\u00e1taxis Framework",
            "type": "framework",
            "definition": "Four-quadrant content type framework: tutorials, how-to guides, reference, explanations",
            "contains": [
              "tutorials",
              "how-to-guides",
              "reference",
              "explanations"
            ],
            "lines": "1779-1900",
            "crossModule": true,
            "retrievalQuestions": [
              "What is the Di\u00e1taxis framework?",
              "What content types are in Di\u00e1taxis?"
            ],
            "content": "The Di\u00e1taxis framework provides a powerful lens for organizing documentation. Let's learn how to integrate it with AI assistance.\n\n### 5.1 Understanding Di\u00e1taxis\n\n**The Four Content Types:**\n\n<CardGroup cols={2}>\n  <Card title=\"Tutorials\" icon=\"graduation-cap\">\n    **Learning-oriented**\n    \n    Teaches through hands-on practice\n    \n    **Examples:** \"Build Your First API Integration\", \"Getting Started Tutorial\"\n  </Card>\n  \n  <Card title=\"How-to Guides\" icon=\"screwdriver-wrench\">\n    **Task-oriented**\n    \n    Solves specific problems\n    \n    **Examples:** \"How to Handle Failed Payments\", \"Set Up Webhooks\"\n  </Card>\n  \n  <Card title=\"Reference\" icon=\"book\">\n    **Information-oriented**\n    \n    Technical descriptions\n    \n    **Examples:** \"API Endpoint Reference\", \"Error Codes\", \"Configuration Options\"\n  </Card>\n  \n  <Card title=\"Explanations\" icon=\"lightbulb\">\n    **Understanding-oriented**\n    \n    Clarifies and discusses\n    \n    **Examples:** \"Understanding OAuth 2.0\", \"How Webhooks Work\", \"Why Use Versioning\"\n  </Card>\n</CardGroup>\n\n---\n\n### 5.2 Two Approaches to Di\u00e1taxis Integration\n\n<!-- START EXAMPLE-EX-110: \"Di\u00e1taxis-First Approach\" -->\n**Approach 1: Di\u00e1taxis-First (Content Type at Top Level)**\n\n```text\n\u251c\u2500\u2500 Tutorials (Learning Path)\n\u2502   \u251c\u2500\u2500 Getting Started with API\n\u2502   \u251c\u2500\u2500 Build a Payment Integration\n\u2502   \u2514\u2500\u2500 Implement Webhooks\n\u251c\u2500\u2500 How-to Guides (Task Solutions)\n\u2502   \u251c\u2500\u2500 Handle Failed Payments\n\u2502   \u251c\u2500\u2500 Set Up Authentication\n\u2502   \u2514\u2500\u2500 Configure Retry Logic\n\u251c\u2500\u2500 Reference (Technical Specs)\n\u2502   \u251c\u2500\u2500 API Endpoints\n\u2502   \u251c\u2500\u2500 Error Codes\n\u2502   \u2514\u2500\u2500 SDKs\n\u2514\u2500\u2500 Explanations (Understanding)\n    \u251c\u2500\u2500 OAuth 2.0 Explained\n    \u251c\u2500\u2500 Understanding Rate Limits\n    \u2514\u2500\u2500 Payment Flow Architecture\n```\n\n**Pros:**\n- Very clear content type separation\n- Users know exactly what format to expect\n- Easy to maintain consistency\n\n**Cons:**\n- Users must know content type they need\n- Harder for mixed-need scenarios (learning + reference)\n- Less aligned with feature-based mental models\n\n**Best For:** Education-focused documentation, learning platforms\n<!-- END EXAMPLE-EX-110 -->\n\n---\n\n<!-- START EXAMPLE-EX-111: \"Feature-First with Di\u00e1taxis Approach\" -->\n**Approach 2: Feature-First with Di\u00e1taxis at Lower Levels (Recommended for APIs)**\n\n```text\n\u251c\u2500\u2500 Get Started\n\u2502   \u251c\u2500\u2500 Installation [Tutorial]\n\u2502   \u251c\u2500\u2500 First API Call [Tutorial]\n\u2502   \u2514\u2500\u2500 Core Concepts [Explanation]\n\u251c\u2500\u2500 Authentication\n\u2502   \u251c\u2500\u2500 OAuth Tutorial [Tutorial]\n\u2502   \u251c\u2500\u2500 How to Validate Tokens [How-to]\n\u2502   \u251c\u2500\u2500 Auth Endpoints [Reference]\n\u2502   \u2514\u2500\u2500 Understanding OAuth [Explanation]\n\u251c\u2500\u2500 Payments\n\u2502   \u251c\u2500\u2500 Payment Integration Tutorial [Tutorial]\n\u2502   \u251c\u2500\u2500 How to Handle Refunds [How-to]\n\u2502   \u251c\u2500\u2500 Payment API Reference [Reference]\n\u2502   \u2514\u2500\u2500 Payment Flows Explained [Explanation]\n\u2514\u2500\u2500 API Reference [Reference]\n    \u2514\u2500\u2500 Complete endpoint docs\n```\n\n**Pros:**\n- Aligned with user mental models (feature-based)\n- All content for a feature in one place\n- Supports mixed workflows (learn + implement + reference)\n\n**Cons:**\n- Requires disciplined labeling of content types\n- Risk of mixing types if not careful\n\n**Best For:** API documentation, feature-rich products\n<!-- END EXAMPLE-EX-111 -->\n<!-- END FIGURE-DG-14 -->\n\n---\n\n<!-- START REFERENCE-PP-7: \"Di\u00e1taxis Integration Prompt Pattern\" -->\n### 5.3 Di\u00e1taxis Integration Prompt\n\n```text\nYou're an information architect who specializes in the Di\u00e1taxis framework.\n\nCreate a 3-level taxonomy that integrates all four Di\u00e1taxis content types.\n\nContext:\n- Documentation for: [YOUR PRODUCT]\n- Content: [PAGE COUNT]\n  - X tutorials (learning-oriented)\n  - Y how-to guides (task-oriented)\n  - Z reference pages (information-oriented)\n  - W explanations (understanding-oriented)\n  \nFeatures/Topics:\n- [List main features or topics]\n\nApproach: Feature-first with Di\u00e1taxis at level 3\n- Level 1: Product features or user tasks\n- Level 2: Sub-features or aspects\n- Level 3: Content items tagged with [Tutorial], [How-to], [Reference], [Explanation]\n\nRequirements:\n- Each major feature should have multiple content types\n- Balance content types within each feature (not just reference)\n- Clear labels indicating both feature and content type\n- Support both learning paths and quick reference lookup\n\nOutput:\n1. Complete 3-level taxonomy with content type tags\n2. Content type distribution analysis per feature\n3. Sample user journeys through the structure\n4. Notes on maintaining balance as content grows\n```\n<!-- END REFERENCE-PP-7 -->\n\n---\n\n<!-- START EXAMPLE-EX-112: \"CloudStore API Tutorial Walkthrough\" -->",
            "hydration_source_header": "5. Di\u00e1taxis Framework Integration",
            "hydration_method": "title_match"
          },
          {
            "id": "organizational-approach-matrix",
            "title": "Organizational Approach Decision Matrix",
            "type": "framework",
            "definition": "Matrix for choosing organizational approach: content-type, feature, hybrid, role-based, framework, task",
            "contains": [
              "content-type-first",
              "feature-product-first",
              "hybrid-product-usecase",
              "role-based-approach",
              "framework-techstack-first",
              "task-goal-based"
            ],
            "lines": "1730-1780",
            "crossModule": true,
            "retrievalQuestions": [
              "Which organizational approach should I use?",
              "How do I choose taxonomy structure?"
            ],
            "content": "**From Kubernetes:**\n- \u2705 Separate content types clearly (Concepts, Tasks, Tutorials, Reference)\n- \u2705 Task-based organization for procedural content\n- \u2705 Progressive difficulty levels\n\n**From Stripe:**\n- \u2705 Feature/product-based top level (if API is feature-rich)\n- \u2705 Keep API reference comprehensive and separate\n- \u2705 Prominent getting started section\n\n**From Twilio:**\n- \u2705 Hybrid organization (Products + Use Cases) serves dual mental models\n- \u2705 Real-world use case language matches user intent\n- \u2705 Immediate \"Try It Out\" reduces onboarding friction\n\n**From GitHub:**\n- \u2705 Role-based segmentation (general users vs. developers vs. admins)\n- \u2705 Group features by usage patterns, not technical architecture\n- \u2705 Keep enterprise/admin docs separate to reduce clutter\n\n**From Netlify:**\n- \u2705 Framework-first for opinionated developers\n- \u2705 Flat structure (2-3 levels) for scannability\n- \u2705 Feature-complete categories (don't split related content)\n\n**Universal Principles:**\n- \u2705 Clear information scent (labels indicate contents)\n- \u2705 Multiple access paths for different user needs\n- \u2705 Balanced distribution of content\n- \u2705 Separation of learning vs. reference content\n- \u2705 Scalable structure (room to grow)\n<!-- END FIGURE-DG-39 -->\n\n---\n\n<!-- START FIGURE-DG-14: \"Di\u00e1taxis Framework Overview\" -->",
            "hydration_source_header": "4.7 Lessons for Your Taxonomy",
            "hydration_method": "line_proximity"
          }
        ],
        "validationChecks": [
          {
            "id": "depth-check",
            "title": "Check 1: Depth Check",
            "validates": "hierarchy-depth",
            "lines": "310-360",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I check if taxonomy is too deep?"
            ],
            "content": "**What to Evaluate:**\n- Is the hierarchy too deep or too shallow?\n- Does depth match content volume?\n- Could it be flattened without losing clarity?\n\n**Rules of Thumb:**\n- **Small sites (20-50 pages):** 2 levels usually sufficient\n- **Medium sites (50-200 pages):** 2-3 levels optimal\n- **Large sites (200+ pages):** 3 levels max, 4 only if absolutely necessary\n\n**Depth Problems:**\n\n<!-- START EXAMPLE-EX-93: \"Depth Problems Examples\" -->\n<CardGroup cols={2}>\n  <Card title=\"Too Shallow\" icon=\"compress\">\n    **Problem:** All 150 pages in a flat list\n    \n    **Impact:** Overwhelming, poor scannability\n    \n    **Fix:** Add 1-2 levels of categorization\n  </Card>\n  \n  <Card title=\"Too Deep\" icon=\"expand\">\n    **Problem:** 5-6 levels of nesting\n    \n    **Impact:** Users get lost, excessive clicking\n    \n    **Fix:** Flatten by combining levels\n  </Card>\n</CardGroup>\n<!-- END EXAMPLE-EX-93 -->\n\n**Example Depth Analysis:**\n\n<!-- START EXAMPLE-EX-94: \"Depth Analysis Examples\" -->\n```text\n\u2713 GOOD (80 pages, 3 levels):\n\u251c\u2500\u2500 Get Started (12 pages)\n\u2502   \u251c\u2500\u2500 Installation (3 pages)\n\u2502   \u2514\u2500\u2500 Quick Start (9 pages)\n\u251c\u2500\u2500 Features (50 pages)\n\u2502   \u251c\u2500\u2500 Authentication (15 pages)\n\u2502   \u2514\u2500\u2500 Payments (35 pages)\n\u2514\u2500\u2500 Reference (18 pages)\n\n\u2717 TOO DEEP (80 pages, 5 levels):\n\u251c\u2500\u2500 Documentation\n\u2502   \u251c\u2500\u2500 Getting Started\n\u2502   \u2502   \u251c\u2500\u2500 Prerequisites\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 System Requirements\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 Operating Systems\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 Windows (1 page) \u2190 Way too deep!\n\n\u2717 TOO SHALLOW (80 pages, 1 level):\n- 80 flat pages (no hierarchy at all)\n```\n<!-- END EXAMPLE-EX-94 -->\n\n---\n\n<!-- START CHECKLIST-CL-2: \"Balance Check\" -->",
            "hydration_source_header": "Check 1: Depth Check",
            "hydration_method": "title_match"
          },
          {
            "id": "balance-check",
            "title": "Check 2: Balance Check",
            "validates": "content-distribution",
            "lines": "365-500",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I validate taxonomy balance?"
            ],
            "content": "**What to Evaluate:**\n- Is content distributed reasonably across categories?\n- Does any single category dominate (>35%)?\n- Are there tiny categories that don't warrant top-level status?\n\n**Balance Thresholds (Apply these specific criteria):**\n\n| Threshold | Percentage | Status | Action Required |\n|---|---|---|---|\n| **Balanced** | No category exceeds 35% | \u2705 PASS | No action needed |\n| **Slightly Unbalanced** | 1 category at 36-40% | \u26a0\ufe0f REVIEW | Consider splitting if it will grow |\n| **Unbalanced** | 1+ categories >40% | \u274c FAIL | Must split large categories |\n| **Too Granular** | 2+ categories less than 8% | \u274c FAIL | Combine or demote tiny categories |\n| **Micro-Category** | Any category less than 5% | \ud83d\udeab RED FLAG | Not viable at top level |\n\n**Ideal Range:** 12-35% per top-level category with 5-7 categories total\n\n---",
            "hydration_source_header": "Check 2: Balance Check",
            "hydration_method": "title_match"
          },
          {
            "id": "granularity-check",
            "title": "Check 3: Granularity Check",
            "validates": "abstraction-levels",
            "lines": "505-560",
            "crossModule": true,
            "retrievalQuestions": [
              "What is granularity in taxonomy?"
            ],
            "content": "**What to Evaluate:**\n- Are items at the same level at similar levels of abstraction?\n- Are you mixing broad topics with narrow topics?\n\n**Granularity Problems:**\n\n<!-- START EXAMPLE-EX-98: \"Granularity Problem Examples\" -->\n```text\n\u2717 INCONSISTENT GRANULARITY:\n\u251c\u2500\u2500 Authentication \u2190 Broad\n\u251c\u2500\u2500 OAuth 2.0 \u2190 Specific (subset of authentication!)\n\u251c\u2500\u2500 Payments \u2190 Broad\n\u251c\u2500\u2500 Visa Card Processing \u2190 Too specific (subset of payments!)\n\u2514\u2500\u2500 API Reference \u2190 Broad\n\nProblem: Mixing different levels of specificity at same level\n\n\u2713 CONSISTENT GRANULARITY:\n\u251c\u2500\u2500 Authentication \u2190 Broad feature\n\u251c\u2500\u2500 Payments \u2190 Broad feature\n\u251c\u2500\u2500 Webhooks \u2190 Broad feature\n\u2514\u2500\u2500 API Reference \u2190 Broad reference section\n\nAll items are at similar level of abstraction\n```\n\n**Example from real taxonomy:**\n\n```text\n\u2717 BAD:\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Core Concepts \u2190 Broad\n\u251c\u2500\u2500 Understanding OAuth \u2190 Specific concept (should be under \"Core Concepts\")\n\u251c\u2500\u2500 Implementation Guides \u2190 Broad\n\u2514\u2500\u2500 How to Validate Tokens \u2190 Specific guide (should be under \"Implementation\")\n\n\u2713 GOOD:\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Core Concepts\n\u2502   \u251c\u2500\u2500 Understanding OAuth\n\u2502   \u251c\u2500\u2500 Token Types\n\u2502   \u2514\u2500\u2500 Security Model\n\u251c\u2500\u2500 Implementation Guides\n\u2502   \u251c\u2500\u2500 Validate Tokens\n\u2502   \u2514\u2500\u2500 Handle Errors\n\u2514\u2500\u2500 API Reference\n```\n<!-- END EXAMPLE-EX-98 -->\n<!-- END CHECKLIST-CL-3 -->\n\n---\n\n<!-- START CHECKLIST-CL-4: \"Mutual Exclusivity Check\" -->",
            "hydration_source_header": "Check 3: Granularity Check",
            "hydration_method": "title_match"
          },
          {
            "id": "exclusivity-check",
            "title": "Check 4: Mutual Exclusivity Check",
            "validates": "content-boundaries",
            "lines": "565-695",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I check for overlapping categories?"
            ],
            "content": "**What to Evaluate:**\n- Does content have one clear, obvious home?\n- Is there significant overlap between categories?\n- Can users easily decide where to look?\n\n**Exclusivity Problems:**\n\n<!-- START EXAMPLE-EX-99: \"Exclusivity Problem Examples\" -->\n```text\n\u2717 OVERLAPPING CATEGORIES:\n\u251c\u2500\u2500 Security\n\u2502   \u251c\u2500\u2500 Authentication\n\u2502   \u251c\u2500\u2500 Encryption\n\u2502   \u2514\u2500\u2500 API Keys\n\u251c\u2500\u2500 Authentication \u2190 Wait, this is also a top-level category?\n\u2502   \u251c\u2500\u2500 OAuth\n\u2502   \u2514\u2500\u2500 API Keys \u2190 Duplicate! Also in \"Security\"\n\u2514\u2500\u2500 Getting Started\n    \u2514\u2500\u2500 Set Up Authentication \u2190 Third place for auth content!\n\nProblem: Authentication content scattered across 3 locations\n\n\u2713 CLEAR BOUNDARIES:\n\u251c\u2500\u2500 Get Started\n\u2502   \u2514\u2500\u2500 Authentication Quickstart (links to main auth docs)\n\u251c\u2500\u2500 Authentication \u2190 Primary home for ALL auth content\n\u2502   \u251c\u2500\u2500 OAuth\n\u2502   \u251c\u2500\u2500 API Keys\n\u2502   \u2514\u2500\u2500 Security Best Practices\n\u2514\u2500\u2500 Reference\n    \u2514\u2500\u2500 Auth Endpoints (references primary auth docs)\n\nSolution: One primary home, cross-links from elsewhere\n```\n<!-- END EXAMPLE-EX-99 -->\n\n**When Overlap Is Intentional:**\n\nSometimes content legitimately belongs in multiple places. This is called **polyhierarchy**.\n\n<!-- START EXAMPLE-EX-100: \"Intentional Polyhierarchy Example\" -->\n```text\n\u2713 INTENTIONAL POLYHIERARCHY:\n\u251c\u2500\u2500 Security\n\u2502   \u251c\u2500\u2500 Encryption at Rest\n\u2502   \u251c\u2500\u2500 Encryption in Transit\n\u2502   \u2514\u2500\u2500 API Security Best Practices \u2190 Lives here AND...\n\u251c\u2500\u2500 API Reference\n\u2502   \u2514\u2500\u2500 Security Best Practices \u2190 ...also here\n\u2514\u2500\u2500 Getting Started\n    \u2514\u2500\u2500 Security Checklist \u2190 References both of the above\n\nNote: \"API Security Best Practices\" appears in two places intentionally\nbecause users approach from different angles (learning vs. reference lookup).\nImplementation: Single source of truth, duplicate navigation pointers.\n```\n<!-- END EXAMPLE-EX-100 -->\n<!-- END CHECKLIST-CL-4 -->\n\n---\n\n<!-- START FIGURE-DG-28: \"Label Clarity Check\" -->",
            "hydration_source_header": "Check 4: Mutual Exclusivity Check",
            "hydration_method": "title_match"
          },
          {
            "id": "label-clarity-check",
            "title": "Check 5: Label Clarity Check",
            "validates": "navigation-labels",
            "lines": "700-780",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I validate taxonomy labels?"
            ],
            "content": "**What to Evaluate:**\n- Do labels clearly describe what's inside?\n- Can users predict content from the label alone?\n- Are labels consistent in style and specificity?\n\n**Label Problems:**\n\n<!-- START EXAMPLE-EX-101: \"Label Problems and Solutions\" -->\n<CardGroup cols={2}>\n  <Card title=\"Vague Labels\" icon=\"question\">\n    **Bad Examples:**\n    - \"Resources\"\n    - \"Other\"\n    - \"Miscellaneous\"\n    - \"Advanced Topics\"\n    - \"More\"\n    \n    **Why:** Doesn't indicate what's actually inside\n  </Card>\n  \n  <Card title=\"Good Labels\" icon=\"check\">\n    **Good Examples:**\n    - \"API Reference\"\n    - \"Getting Started Tutorials\"\n    - \"Troubleshooting Guides\"\n    - \"Security Best Practices\"\n    \n    **Why:** Clear, specific, predictive\n  </Card>\n</CardGroup>\n<!-- END EXAMPLE-EX-101 -->\n\n**Label Consistency:**\n\n```text\n\u2717 INCONSISTENT STYLE:\n\u251c\u2500\u2500 Getting Started \u2190 Gerund (progressive verb)\n\u251c\u2500\u2500 Implement Features \u2190 Imperative verb\n\u251c\u2500\u2500 Reference \u2190 Noun\n\u2514\u2500\u2500 How to Troubleshoot \u2190 Question format\n\nProblem: Mixed grammatical structures\n\n\u2713 CONSISTENT STYLE (Gerunds):\n\u251c\u2500\u2500 Getting Started\n\u251c\u2500\u2500 Implementing Features\n\u251c\u2500\u2500 Referencing APIs\n\u2514\u2500\u2500 Troubleshooting Issues\n\n\u2713 CONSISTENT STYLE (Nouns):\n\u251c\u2500\u2500 Getting Started Guide\n\u251c\u2500\u2500 Implementation Guide\n\u251c\u2500\u2500 API Reference\n\u2514\u2500\u2500 Troubleshooting Guide\n\n\u2713 CONSISTENT STYLE (Imperatives):\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Implement Features\n\u251c\u2500\u2500 Reference APIs\n\u2514\u2500\u2500 Troubleshoot Issues\n```\n\n**Accessibility Check:**\n\nLabels must work for screen reader users:\n\n```text\n\u2717 NOT SCREEN-READER FRIENDLY:\n\u251c\u2500\u2500 Click Here\n\u251c\u2500\u2500 Learn More\n\u251c\u2500\u2500 Resources\n\u2514\u2500\u2500 This Section\n\n\u2713 SCREEN-READER FRIENDLY:\n\u251c\u2500\u2500 API Authentication Guide\n\u251c\u2500\u2500 Payment Integration Tutorials\n\u251c\u2500\u2500 SDK Documentation\n\u2514\u2500\u2500 Troubleshooting Reference\n\nWhy: Specific labels work without visual context\n```\n<!-- END FIGURE-DG-28 -->\n<!-- END CHECKLIST-CL-1 -->\n\n---\n\n<!-- START EXAMPLE-EX-102: \"Complete Validation Walkthrough\" -->",
            "hydration_source_header": "Check 5: Label Clarity Check",
            "hydration_method": "title_match"
          }
        ],
        "promptPatterns": [
          {
            "id": "basic-taxonomy-generation",
            "title": "Basic Taxonomy Generation Pattern",
            "taskType": "generation",
            "lines": "115-175",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I prompt for taxonomy generation?"
            ],
            "content": "**Structure:**\n```text\n[R - Role] + [C - Content Context] + [I - Organizational Principle] +\n[I - Structural Requirements] + [C - Constraints] + [I - Output Format]\n```\n\n**Example:**\n\n```text\nYou're an information architect specializing in software documentation taxonomies.\n\nI have 80 pages of API documentation covering:\n- Authentication (15 pages)\n- Data operations (30 pages)\n- Webhooks (20 pages)\n- Error handling (15 pages)\n\nCreate a 3-level taxonomy organized by:\n- Level 1: User task (what they want to accomplish)\n- Level 2: Feature area\n- Level 3: Content type (Tutorial/How-to/Reference/Explanation)\n\nConstraints:\n- Top level: 5-7 categories\n- Balanced distribution (no single category dominates)\n- Labels under 30 characters\n- Must include clear homes for troubleshooting content\n\nOutput as markdown indented list with estimated page counts.\n```\n\n**Why This Pattern Works:**\n- \u2713 Clear role sets domain expertise\n- \u2713 Content context grounds output in reality\n- \u2713 Organizational principle provides logic\n- \u2713 Structural requirements define shape\n- \u2713 Constraints ensure practicality\n- \u2713 Format makes output immediately usable\n<!-- END REFERENCE-PP-3 -->\n\n---\n\n<!-- START REFERENCE-PP-4: \"Exploratory Pattern (Multiple Options)\" -->",
            "hydration_source_header": "1.1 The Basic Taxonomy Generation Pattern",
            "hydration_method": "title_match"
          },
          {
            "id": "exploratory-pattern",
            "title": "Exploratory Pattern (Multiple Options)",
            "taskType": "exploration",
            "lines": "180-230",
            "crossModule": true,
            "retrievalQuestions": [
              "Prompt to generate multiple taxonomy options"
            ],
            "content": "**Use When:** You're unsure which organizational approach is best\n\n**Structure:**\n```text\nGenerate [NUMBER] different taxonomies using different organizing principles:\n1. [Principle 1]\n2. [Principle 2]\n3. [Principle 3]\n\nFor each, show [DETAIL LEVEL] and provide [COMPARISON CRITERIA]\n```\n\n**Example:**\n\n```text\nYou're an information architect exploring organizational approaches.\n\nGenerate 3 different taxonomies for API documentation with 100 pages:\n\n1. **Task-based:** Organize by what users want to accomplish\n2. **Feature-based:** Organize by product capabilities  \n3. **Audience-based:** Organize by user role (backend dev, frontend dev, DevOps)\n\nFor each approach:\n- Show top 2 levels\n- Estimate page distribution\n- List 3 pros and 3 cons\n- Indicate which user type it serves best\n\nContext:\n- Audience: Developers with varied experience (junior to senior)\n- Content: Authentication, payments, webhooks, analytics\n- Goals: Reduce time-to-first-API-call, improve findability\n\nHelp me decide which approach to pursue.\n```\n\n<!-- START TIP-TC-18: \"Why Exploratory Works\" -->\n<Tip>\n  **Why This Works:** You get multiple perspectives quickly, with built-in comparison criteria to guide your decision.\n</Tip>\n<!-- END TIP-TC-18 -->\n<!-- END REFERENCE-PP-4 -->\n\n---\n\n<!-- START REFERENCE-PP-5: \"Refinement Pattern\" -->",
            "hydration_source_header": "1.2 The Exploratory Pattern (Multiple Options)",
            "hydration_method": "title_match"
          },
          {
            "id": "refinement-pattern",
            "title": "Refinement Pattern",
            "taskType": "iteration",
            "lines": "235-285",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I refine a taxonomy with AI?"
            ],
            "content": "**Use When:** You have a taxonomy that needs improvement\n\n**Structure:**\n```text\nRefine this existing taxonomy based on [SPECIFIC ISSUES].\nCurrent structure: [PASTE TAXONOMY]\nProblems identified: [LIST ISSUES]\nRequirements for refinement: [CONSTRAINTS]\n```\n\n**Example:**\n\n```text\nRefine this taxonomy based on validation feedback.\n\nCurrent structure:\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Build Features (85 pages) \u2190 Too large\n\u251c\u2500\u2500 Deploy\n\u2514\u2500\u2500 Reference\n\nProblems:\n1. \"Build Features\" contains 85% of content (unbalanced)\n2. Mixing high-level and low-level categories\n3. \"Build Features\" is vague\n\nRefinement requirements:\n- Split \"Build Features\" into 3-4 specific categories\n- Balance top level (no category >40% of content)\n- Use action-oriented labels\n- Maintain all existing page assignments\n\nOutput: Refined taxonomy with explanation of changes.\n```\n<!-- END REFERENCE-PP-5 -->\n\n---\n\n<!-- START REFERENCE-PP-6: \"Di\u00e1taxis Integration Pattern\" -->",
            "hydration_source_header": "1.3 The Refinement Pattern",
            "hydration_method": "title_match"
          },
          {
            "id": "diataxis-integration-pattern",
            "title": "Di\u00e1taxis Integration Pattern",
            "taskType": "classification",
            "lines": "290-350",
            "crossModule": true,
            "retrievalQuestions": [
              "Prompt for Di\u00e1taxis-based taxonomy"
            ],
            "content": "**Use When:** You want to organize documentation using the Di\u00e1taxis framework\n\n**Structure:**\n```text\nCreate taxonomy integrating Di\u00e1taxis content types.\nApproach: [Di\u00e1taxis-first OR Feature-first with Di\u00e1taxis at lower levels]\nContent types: Tutorial, How-to Guide, Reference, Explanation\n[REST OF REQUIREMENTS]\n```\n\n**Example:**\n\n```text\nYou're an information architect who specializes in the Di\u00e1taxis framework.\n\nCreate a 3-level taxonomy for API documentation that integrates all four \nDi\u00e1taxis content types.\n\nApproach: Feature-based at top level, Di\u00e1taxis at level 3\n- Level 1: Product features (Authentication, Payments, Webhooks, etc.)\n- Level 2: Sub-features or aspects\n- Level 3: Content types (Tutorial, How-to, Reference, Explanation)\n\nContent: 80 pages\n- 20 Tutorials (learning-oriented)\n- 30 How-to Guides (task-oriented)\n- 20 Reference (information-oriented)\n- 10 Explanations (understanding-oriented)\n\nFeatures:\n- Authentication (15 pages)\n- Payments (30 pages)\n- Webhooks (20 pages)\n- Analytics (15 pages)\n\nRequirements:\n- Each feature area must have multiple content types\n- Balance distribution across features\n- Labels indicate both feature and content type\n\nOutput as indented list with [Content Type] tags.\n```\n<!-- END REFERENCE-PP-6 -->\n\n---\n\n<!-- START CHECKLIST-CL-1: \"5-Check Validation System\" -->",
            "hydration_source_header": "1.4 The Di\u00e1taxis Integration Pattern",
            "hydration_method": "title_match"
          },
          {
            "id": "polyhierarchy-prompt-pattern",
            "title": "Polyhierarchy Prompt Pattern",
            "taskType": "advanced-structure",
            "lines": "960-1020",
            "crossModule": true,
            "content": "```text\nYou're an information architect analyzing content for polyhierarchy.\n\nReview this taxonomy and identify content that users might approach from \nmultiple angles.\n\nTaxonomy:\n[Paste taxonomy]\n\nFor each piece of polyhierarchy content, specify:\n1. Title and current location\n2. Why it has multiple access paths (user scenarios)\n3. Recommended locations (primary + secondary)\n4. Implementation approach (duplicate nav, cross-link, contextual reference)\n\nExample format:\n**Content:** \"OAuth 2.0 Implementation\"\n**Primary home:** Authentication > OAuth\n**Secondary homes:** \n- Get Started > Security Setup (contextual reference)\n- Troubleshooting > Auth Issues (cross-link)\n**Reason:** Users approach from learning path, implementation, or debugging\n**Implementation:** Single source in Authentication, cross-links elsewhere\n\nFocus on content where secondary access significantly improves findability.\n```\n\n**Real Example:**\n\n```text\nContent for polyhierarchy analysis:\n\nSecurity-related content in CloudStore API:\n1. OAuth 2.0 Implementation\n2. API Key Security\n3. Encryption in Transit (TLS)\n4. Encryption at Rest\n5. PCI Compliance for Payments\n6. Securing Webhook Endpoints\n7. Rate Limiting for Security\n8. Security Monitoring & Logging\n9. Incident Response\n10. Security Checklist for Production\n\nCreate:\n1. Primary hierarchical taxonomy\n2. Secondary access paths (how else users might look for content)\n3. Polyhierarchy recommendations (what should appear in multiple places)\n4. Implementation notes (duplicate page, cross-link, or contextual reference)\n\nEnsure each piece of content has one clear primary home.\n```\n<!-- END REFERENCE-PP-38 -->\n\n---\n\n<!-- START REFERENCE-PP-39: \"Faceted Classification Pattern\" -->",
            "hydration_source_header": "3.2 Polyhierarchy Prompt Pattern",
            "hydration_method": "title_match"
          },
          {
            "id": "faceted-classification-pattern",
            "title": "Faceted Classification Pattern",
            "taskType": "advanced-structure",
            "lines": "1025-1130",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I prompt for faceted classification?"
            ],
            "content": "**Definition:** Multiple independent classification schemes applied to the same content, allowing filtering by different facets.\n\n**Common Facets for Documentation:**\n- Content type (Tutorial, How-to, Reference, Explanation)\n- Difficulty (Beginner, Intermediate, Advanced)\n- Product feature (Payments, Auth, Webhooks)\n- User role (Developer, Admin, Business User)\n- API version (v1, v2, v3)\n- Programming language (Python, JavaScript, Ruby)\n\n---\n\n**Prompt Pattern for Faceted Taxonomy:**\n\n```text\nYou're an information architect who designs faceted classification systems.\n\nCreate a faceted taxonomy for [CONTENT] that allows users to filter by:\n- Facet 1: [TYPE] (values: [LIST])\n- Facet 2: [TYPE] (values: [LIST])\n- Facet 3: [TYPE] (values: [LIST])\n\nFor each piece of content, assign values for all facets.\n\nProvide:\n1. Complete facet definition (facet names and allowed values)\n2. Sample content classified with all facets\n3. Common filter combinations users might want\n4. Implementation notes for documentation platform\n```\n\n**Example:**\n\n```text\nYou're an information architect designing a faceted classification system \nfor API documentation.\n\nCreate faceted taxonomy for 100 pages of payment API documentation allowing \nfiltering by:\n- Content Type: Tutorial | How-to Guide | Reference | Explanation\n- Difficulty: Beginner | Intermediate | Advanced\n- Topic: Authentication | Payments | Refunds | Subscriptions | Webhooks | Testing\n- Language: Python | JavaScript | Ruby | Java | PHP | cURL\n\nContent sample:\n1. \"Building Your First Payment Integration\"\n2. \"Charge API Endpoint Reference\"\n3. \"How to Handle Failed Payments\"\n4. \"Understanding PCI Compliance\"\n5. \"Python SDK: Creating Charges\"\n6. \"JavaScript: Implementing Webhooks\"\n7. \"Testing Payment Flows in Sandbox\"\n8. \"Subscription Lifecycle Explained\"\n9. \"Refund API Reference\"\n10. \"How to Retry Failed Charges\"\n\nProvide:\n1. Faceted classification for all sample content (table format)\n2. Most common filter combinations (based on user needs)\n3. Recommended default view (what users see first)\n4. Implementation guidance for Docusaurus or similar platform\n\nEnsure facet values are:\n- Mutually exclusive within each facet\n- Comprehensive (cover all content)\n- User-friendly (match user language)\n```\n\n**Expected Output Format:**\n\n| Page Title | Content Type | Difficulty | Topic | Language |\n|------------|--------------|------------|-------|----------|\n| Building Your First Payment Integration | Tutorial | Beginner | Payments | Multiple |\n| Charge API Endpoint Reference | Reference | All | Payments | cURL |\n| How to Handle Failed Payments | How-to | Intermediate | Payments | Multiple |\n| Understanding PCI Compliance | Explanation | Intermediate | Payments | N/A |\n| Python SDK: Creating Charges | Tutorial | Beginner | Payments | Python |\n| JavaScript: Implementing Webhooks | Tutorial | Intermediate | Webhooks | JavaScript |\n\n---",
            "hydration_source_header": "3.3 Faceted Classification with AI",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "comparative-analysis-prompt",
            "title": "Comparative Analysis Prompt",
            "taskType": "analysis",
            "lines": "1340-1380",
            "content": "**Use This to Compare Taxonomies:**\n\n```text\nYou're an information architect analyzing successful documentation structures.\n\nCompare these two documentation taxonomies:\n\nKUBERNETES:\n[paste structure]\n\nSTRIPE:\n[paste structure]\n\nAnalyze:\n1. What organizational principles does each use?\n2. How do these serve their respective audiences?\n   - Kubernetes: DevOps engineers, infrastructure teams\n   - Stripe: Developers building payment features\n3. What are the strengths of each approach?\n4. When would you use each organizational model?\n\nThen recommend:\nFor documentation about [YOUR DOMAIN], which approach is more appropriate and why?\nWhat elements from each should be adapted?\nWhat unique considerations exist for [YOUR DOMAIN]?\n```\n\n---",
            "hydration_source_header": "4.3 Comparative Analysis Prompt",
            "hydration_method": "title_match"
          },
          {
            "id": "diataxis-integration-prompt",
            "title": "Di\u00e1taxis Integration Prompt",
            "taskType": "integration",
            "lines": "1895-1940",
            "crossModule": true,
            "content": "```text\nYou're an information architect who specializes in the Di\u00e1taxis framework.\n\nCreate a 3-level taxonomy that integrates all four Di\u00e1taxis content types.\n\nContext:\n- Documentation for: [YOUR PRODUCT]\n- Content: [PAGE COUNT]\n  - X tutorials (learning-oriented)\n  - Y how-to guides (task-oriented)\n  - Z reference pages (information-oriented)\n  - W explanations (understanding-oriented)\n  \nFeatures/Topics:\n- [List main features or topics]\n\nApproach: Feature-first with Di\u00e1taxis at level 3\n- Level 1: Product features or user tasks\n- Level 2: Sub-features or aspects\n- Level 3: Content items tagged with [Tutorial], [How-to], [Reference], [Explanation]\n\nRequirements:\n- Each major feature should have multiple content types\n- Balance content types within each feature (not just reference)\n- Clear labels indicating both feature and content type\n- Support both learning paths and quick reference lookup\n\nOutput:\n1. Complete 3-level taxonomy with content type tags\n2. Content type distribution analysis per feature\n3. Sample user journeys through the structure\n4. Notes on maintaining balance as content grows\n```\n<!-- END REFERENCE-PP-7 -->\n\n---\n\n<!-- START EXAMPLE-EX-112: \"CloudStore API Tutorial Walkthrough\" -->",
            "hydration_source_header": "5.3 Di\u00e1taxis Integration Prompt",
            "hydration_method": "title_match"
          }
        ],
        "balanceThresholds": [
          {
            "id": "balanced-threshold",
            "title": "Balanced",
            "threshold": "No category >35%",
            "status": "PASS",
            "lines": "380-385",
            "content": "**The Problem:**\n```text\nSITE: 100 pages total\n\n\u251c\u2500\u2500 Getting Started (5 pages, 5%) \u2190 Too small\n\u251c\u2500\u2500 Everything You Need to Know (78 pages, 78%) \ud83d\udeab MEGA-CATEGORY\n\u251c\u2500\u2500 FAQ (12 pages, 12%)\n\u2514\u2500\u2500 Contact (5 pages, 5%) \u2190 Too small\n```\n\n**Why It's Bad:**\n- One category dominates (78% is excessive)\n- Users overwhelmed by too many options in main category\n- Small categories may not warrant top-level status\n- Poor scannability and navigation\n- Indicates lack of thoughtful organization\n\n**The Fix:**\n```text\nPrompt: \"This taxonomy has severe balance issues with one category containing\n78% of all content. Analyze the 'Everything You Need to Know' category and:\n\n1. Break it into 3-5 specific, meaningful categories based on:\n   - Content topics/themes\n   - User tasks\n   - Feature areas\n2. Ensure no single category exceeds 35% of total content\n3. Combine or demote categories under 8% unless essential\n4. Provide page distribution for each new category\n\nTarget: 5-7 top-level categories, each 12-35% of total pages.\"\n```\n\n**Better Result:**\n```text\nSITE: 100 pages total\n\n\u251c\u2500\u2500 Get Started (10 pages, 10%) \u2190 Combined with Getting Started\n\u2502   \u2514\u2500\u2500 [Onboarding content]\n\u251c\u2500\u2500 Core Features (28 pages, 28%) \u2190 Extracted from mega-category\n\u2502   \u2514\u2500\u2500 [Primary product features]\n\u251c\u2500\u2500 Advanced Configuration (22 pages, 22%) \u2190 Extracted from mega-category\n\u2502   \u2514\u2500\u2500 [Power user features]\n\u251c\u2500\u2500 Integrations & Extensions (20 pages, 20%) \u2190 Extracted from mega-category\n\u2502   \u2514\u2500\u2500 [Third-party integrations]\n\u251c\u2500\u2500 Troubleshooting & Support (15 pages, 15%) \u2190 Combined FAQ + extracted\n\u2502   \u2514\u2500\u2500 [Common issues, FAQ, contact]\n\u2514\u2500\u2500 API & Developer Tools (13 pages, 13%) \u2190 Extracted from mega-category\n    \u2514\u2500\u2500 [Technical reference]\n\nResult: Balanced distribution, 10-28% range, all categories viable\n```\n\n**Validation Check:**\n```text\n\u2705 No category exceeds 35% threshold\n\u2705 No category below 8% threshold\n\u2705 Range: 10-28% (18-point spread - GOOD)\n\u2705 6 categories (within 5-7 ideal range)\n\u2705 Each category has clear, specific purpose\n```\n<!-- END EXAMPLE-EX-130 -->\n<!-- END EXAMPLE-EX-123 -->\n\n---\n\n<!-- START FIGURE-DG-32: \"Error Recovery Troubleshooting Guide\" -->",
            "hydration_source_header": "Mistake 7: Unbalanced Content Distribution (The Mega-Category Problem)",
            "hydration_method": "title_match"
          },
          {
            "id": "slightly-unbalanced",
            "title": "Slightly Unbalanced",
            "threshold": "1 category 36-40%",
            "status": "REVIEW",
            "lines": "386-388",
            "content": "**What to Evaluate:**\n- Is content distributed reasonably across categories?\n- Does any single category dominate (>35%)?\n- Are there tiny categories that don't warrant top-level status?\n\n**Balance Thresholds (Apply these specific criteria):**\n\n| Threshold | Percentage | Status | Action Required |\n|---|---|---|---|\n| **Balanced** | No category exceeds 35% | \u2705 PASS | No action needed |\n| **Slightly Unbalanced** | 1 category at 36-40% | \u26a0\ufe0f REVIEW | Consider splitting if it will grow |\n| **Unbalanced** | 1+ categories >40% | \u274c FAIL | Must split large categories |\n| **Too Granular** | 2+ categories less than 8% | \u274c FAIL | Combine or demote tiny categories |\n| **Micro-Category** | Any category less than 5% | \ud83d\udeab RED FLAG | Not viable at top level |\n\n**Ideal Range:** 12-35% per top-level category with 5-7 categories total\n\n---",
            "hydration_source_header": "Check 2: Balance Check",
            "hydration_method": "line_proximity"
          },
          {
            "id": "unbalanced-threshold",
            "title": "Unbalanced",
            "threshold": "1+ categories >40%",
            "status": "FAIL",
            "lines": "389-391",
            "content": "**The Problem:**\n```text\nSITE: 100 pages total\n\n\u251c\u2500\u2500 Getting Started (5 pages, 5%) \u2190 Too small\n\u251c\u2500\u2500 Everything You Need to Know (78 pages, 78%) \ud83d\udeab MEGA-CATEGORY\n\u251c\u2500\u2500 FAQ (12 pages, 12%)\n\u2514\u2500\u2500 Contact (5 pages, 5%) \u2190 Too small\n```\n\n**Why It's Bad:**\n- One category dominates (78% is excessive)\n- Users overwhelmed by too many options in main category\n- Small categories may not warrant top-level status\n- Poor scannability and navigation\n- Indicates lack of thoughtful organization\n\n**The Fix:**\n```text\nPrompt: \"This taxonomy has severe balance issues with one category containing\n78% of all content. Analyze the 'Everything You Need to Know' category and:\n\n1. Break it into 3-5 specific, meaningful categories based on:\n   - Content topics/themes\n   - User tasks\n   - Feature areas\n2. Ensure no single category exceeds 35% of total content\n3. Combine or demote categories under 8% unless essential\n4. Provide page distribution for each new category\n\nTarget: 5-7 top-level categories, each 12-35% of total pages.\"\n```\n\n**Better Result:**\n```text\nSITE: 100 pages total\n\n\u251c\u2500\u2500 Get Started (10 pages, 10%) \u2190 Combined with Getting Started\n\u2502   \u2514\u2500\u2500 [Onboarding content]\n\u251c\u2500\u2500 Core Features (28 pages, 28%) \u2190 Extracted from mega-category\n\u2502   \u2514\u2500\u2500 [Primary product features]\n\u251c\u2500\u2500 Advanced Configuration (22 pages, 22%) \u2190 Extracted from mega-category\n\u2502   \u2514\u2500\u2500 [Power user features]\n\u251c\u2500\u2500 Integrations & Extensions (20 pages, 20%) \u2190 Extracted from mega-category\n\u2502   \u2514\u2500\u2500 [Third-party integrations]\n\u251c\u2500\u2500 Troubleshooting & Support (15 pages, 15%) \u2190 Combined FAQ + extracted\n\u2502   \u2514\u2500\u2500 [Common issues, FAQ, contact]\n\u2514\u2500\u2500 API & Developer Tools (13 pages, 13%) \u2190 Extracted from mega-category\n    \u2514\u2500\u2500 [Technical reference]\n\nResult: Balanced distribution, 10-28% range, all categories viable\n```\n\n**Validation Check:**\n```text\n\u2705 No category exceeds 35% threshold\n\u2705 No category below 8% threshold\n\u2705 Range: 10-28% (18-point spread - GOOD)\n\u2705 6 categories (within 5-7 ideal range)\n\u2705 Each category has clear, specific purpose\n```\n<!-- END EXAMPLE-EX-130 -->\n<!-- END EXAMPLE-EX-123 -->\n\n---\n\n<!-- START FIGURE-DG-32: \"Error Recovery Troubleshooting Guide\" -->",
            "hydration_source_header": "Mistake 7: Unbalanced Content Distribution (The Mega-Category Problem)",
            "hydration_method": "title_match"
          },
          {
            "id": "too-granular-threshold",
            "title": "Too Granular",
            "threshold": "2+ categories <8%",
            "status": "FAIL",
            "lines": "392-394",
            "content": "<!-- START EXAMPLE-EX-95: \"Well-Balanced Taxonomy Example\" -->\n**Example 1: Well-Balanced Taxonomy (Score: 90/100)**\n\n```text\nSITE: 100 pages total\n\n\u251c\u2500\u2500 Get Started (15 pages, 15%) \u2705\n\u251c\u2500\u2500 Authentication (20 pages, 20%) \u2705\n\u251c\u2500\u2500 Core Features (28 pages, 28%) \u2705\n\u251c\u2500\u2500 Advanced Topics (18 pages, 18%) \u2705\n\u2514\u2500\u2500 API Reference (19 pages, 19%) \u2705\n\n**Score Breakdown:**\n\u2705 Balance (30/30): All categories 15-35% range, well-distributed\n\u2705 Range (25/25): Good variety (smallest=15%, largest=28%, spread=13%)\n\u2705 Total Categories (20/20): 5 categories (ideal range)\n\u2705 Naming (15/15): Clear, distinct, appropriate granularity\nMinor: Could combine \"Advanced Topics\" + \"API Reference\" for 4 categories\n\n**Total: 90/100 - Excellent balance**\n```\n\n---\n\n**Example 2: Unbalanced Taxonomy (Score: 45/100)**\n\n```text\nSITE: 100 pages total\n\n\u251c\u2500\u2500 Get Started (8 pages, 8%) \u26a0\ufe0f BORDERLINE LOW\n\u251c\u2500\u2500 Everything Else (68 pages, 68%) \ud83d\udeab RED FLAG - Dominates!\n\u251c\u2500\u2500 Troubleshooting (12 pages, 12%) \u2705\n\u251c\u2500\u2500 FAQ (7 pages, 7%) \u26a0\ufe0f BORDERLINE LOW\n\u2514\u2500\u2500 Changelog (5 pages, 5%) \ud83d\udeab RED FLAG - Too small\n\n**Score Breakdown:**\n\u274c Balance (5/30): One category dominates at 68% (FAIL >40% threshold)\n\u274c Range (0/25): Massive spread (5% to 68%) indicates poor distribution\n\u26a0\ufe0f Total Categories (10/20): 5 categories but 2 are micro-categories\n\u26a0\ufe0f Naming (10/15): \"Everything Else\" is vague catch-all (red flag)\n\u274c Viability (0/10): 2 categories below 8% threshold\n\n**Total: 45/100 - Needs major restructuring**\n\n**Critical Issues:**\n1. \ud83d\udeab \"Everything Else\" at 68% \u2192 Split into 3-4 specific feature categories\n2. \ud83d\udeab \"Changelog\" at 5% \u2192 Move to utility navigation, not top-level\n3. \u26a0\ufe0f \"FAQ\" at 7% \u2192 Combine with Troubleshooting OR demote to footer\n\n**Recommended Fix:**\nSplit \"Everything Else\" (68 pages) into:\n- Authentication & Security (22 pages, 22%)\n- Payment Processing (25 pages, 25%)\n- Data & Analytics (21 pages, 21%)\n\nNew structure:\n- Get Started (8%) + FAQ (7%) \u2192 \"Get Started & Support\" (15%)\n- Authentication (22%)\n- Payment Processing (25%)\n- Data & Analytics (21%)\n- Troubleshooting (12%)\n- Changelog \u2192 Move to footer (not top-level)\n\nResult: 5 categories, range 12-25%, all within thresholds \u2705\n```\n<!-- END EXAMPLE-EX-95 -->\n\n---\n\n<!-- START EXAMPLE-EX-96: \"Too Granular Taxonomy Example\" -->\n**Example 3: Too Granular Taxonomy (Score: 55/100)**\n\n```text\nSITE: 100 pages total\n\n\u251c\u2500\u2500 Authentication (35 pages, 35%) \u26a0\ufe0f AT THRESHOLD\n\u251c\u2500\u2500 Payments (32 pages, 32%) \u2705\n\u251c\u2500\u2500 Webhooks (28 pages, 28%) \u2705\n\u251c\u2500\u2500 Troubleshooting (3 pages, 3%) \ud83d\udeab RED FLAG - Too small\n\u2514\u2500\u2500 Changelog (2 pages, 2%) \ud83d\udeab RED FLAG - Too small\n\n**Score Breakdown:**\n\u26a0\ufe0f Balance (15/30): Authentication at 35% (exactly at threshold, borderline)\n\u2705 Range (20/25): Main categories well-distributed (28-35%)\n\u274c Total Categories (5/20): 5 categories but 2 are non-viable micro-categories\n\u2705 Naming (15/15): Clear, specific, appropriate labels\n\u274c Viability (0/10): 2 categories well below 8% threshold (3% and 2%)\n\n**Total: 55/100 - Needs consolidation**\n\n**Critical Issues:**\n1. \ud83d\udeab \"Troubleshooting\" at 3% \u2192 Too small for top-level category\n2. \ud83d\udeab \"Changelog\" at 2% \u2192 Utility content, not primary navigation\n3. \u26a0\ufe0f \"Authentication\" at 35% \u2192 Right at threshold, monitor growth\n\n**Recommended Fix:**\n- Merge \"Troubleshooting\" (3 pages) into relevant feature sections\n- Move \"Changelog\" to footer or utility navigation\n- Result: 3 strong top-level categories (Authentication 35%, Payments 32%, Webhooks 28%)\n- Add \"Get Started\" section if you have onboarding content\n\n**Alternative:** If you have 15+ more pages of content:\n- Keep Authentication, Payments, Webhooks as-is\n- Add \"Get Started & Tutorials\" (10-15 pages)\n- Distribute Troubleshooting across feature sections\n- Move Changelog to footer\n```\n<!-- END EXAMPLE-EX-96 -->\n\n---\n\n<!-- START EXAMPLE-EX-97: \"Red Flags Checklist\" -->\n##### Red Flags Checklist\n\nWhen validating taxonomy balance, watch for these **automatic red flags**:\n\n```\n\ud83d\udeab RED FLAG #1: Mega-Category (>40%)\n\u251c\u2500\u2500 Indicates: Category is too broad, mixing multiple concepts\n\u2514\u2500\u2500 Fix: Split into 2-3 specific subcategories\n\n\ud83d\udeab RED FLAG #2: Micro-Category (<5%)\n\u251c\u2500\u2500 Indicates: Not enough content to warrant top-level status\n\u2514\u2500\u2500 Fix: Combine with related category OR demote to subcategory\n\n\ud83d\udeab RED FLAG #3: Catch-All Label (\"Other\", \"Miscellaneous\", \"Everything Else\")\n\u251c\u2500\u2500 Indicates: Lack of clear organizational principle\n\u2514\u2500\u2500 Fix: Identify patterns in \"other\" content, create specific categories\n\n\ud83d\udeab RED FLAG #4: Massive Spread (70+ percentage point gap)\n\u251c\u2500\u2500 Example: Smallest=5%, Largest=75% (70-point spread)\n\u2514\u2500\u2500 Fix: Split large categories, combine/demote small ones\n\n\ud83d\udeab RED FLAG #5: Ratio Imbalance (>10:1 ratio between largest and smallest)\n\u251c\u2500\u2500 Example: Largest=60 pages, Smallest=5 pages (12:1 ratio)\n\u2514\u2500\u2500 Fix: Indicates granularity mismatch, restructure levels\n\n\u26a0\ufe0f WARNING: Future Growth Pattern\n\u251c\u2500\u2500 Indicates: Category at 33-35% but expected to grow significantly\n\u2514\u2500\u2500 Fix: Proactively split before hitting 40% threshold\n```\n<!-- END EXAMPLE-EX-97 -->\n<!-- END CHECKLIST-CL-2 -->\n\n---\n\n<!-- START FIGURE-DG-12: \"Balance Validation Prompt\" -->\n**Validation Prompt (Enhanced):**\n\n```text\n[R] You are an information architect validating taxonomy balance.\n\n[I] Analyze this taxonomy for balance using these specific thresholds:\n\nBALANCE THRESHOLDS:\n- \u2705 Balanced: No category exceeds 35%\n- \u26a0\ufe0f Review: Any category 36-40%\n- \u274c Fail: Any category >40% OR <5%\n- \ud83d\udeab Red Flag: Catch-all labels, >10:1 size ratio\n\nCalculate:\n1. Percentage distribution for each top-level category\n2. Smallest vs. largest category spread\n3. Number of micro-categories (<8%)\n4. Ratio between largest and smallest categories\n\nFlag red flags and provide scored assessment (0-100).\n\n[C] Taxonomy to validate:\n[Paste taxonomy with page counts]\n\n[E] Output format:\nCategory | Pages | % | Status\nGet Started | 15 | 15% | \u2705 Balanced\n\n**Score:** /100\n**Red Flags:** [List any found]\n**Recommendation:** [Specific fixes if score <70]\n```\n<!-- END FIGURE-DG-12 -->\n\n---\n\n<!-- START CHECKLIST-CL-3: \"Granularity Check\" -->",
            "hydration_source_header": "Balance Validation Examples with Scores",
            "hydration_method": "line_proximity"
          },
          {
            "id": "micro-category-threshold",
            "title": "Micro-Category",
            "threshold": "Any category <5%",
            "status": "RED FLAG",
            "lines": "395-397",
            "content": "<!-- START EXAMPLE-EX-95: \"Well-Balanced Taxonomy Example\" -->\n**Example 1: Well-Balanced Taxonomy (Score: 90/100)**\n\n```text\nSITE: 100 pages total\n\n\u251c\u2500\u2500 Get Started (15 pages, 15%) \u2705\n\u251c\u2500\u2500 Authentication (20 pages, 20%) \u2705\n\u251c\u2500\u2500 Core Features (28 pages, 28%) \u2705\n\u251c\u2500\u2500 Advanced Topics (18 pages, 18%) \u2705\n\u2514\u2500\u2500 API Reference (19 pages, 19%) \u2705\n\n**Score Breakdown:**\n\u2705 Balance (30/30): All categories 15-35% range, well-distributed\n\u2705 Range (25/25): Good variety (smallest=15%, largest=28%, spread=13%)\n\u2705 Total Categories (20/20): 5 categories (ideal range)\n\u2705 Naming (15/15): Clear, distinct, appropriate granularity\nMinor: Could combine \"Advanced Topics\" + \"API Reference\" for 4 categories\n\n**Total: 90/100 - Excellent balance**\n```\n\n---\n\n**Example 2: Unbalanced Taxonomy (Score: 45/100)**\n\n```text\nSITE: 100 pages total\n\n\u251c\u2500\u2500 Get Started (8 pages, 8%) \u26a0\ufe0f BORDERLINE LOW\n\u251c\u2500\u2500 Everything Else (68 pages, 68%) \ud83d\udeab RED FLAG - Dominates!\n\u251c\u2500\u2500 Troubleshooting (12 pages, 12%) \u2705\n\u251c\u2500\u2500 FAQ (7 pages, 7%) \u26a0\ufe0f BORDERLINE LOW\n\u2514\u2500\u2500 Changelog (5 pages, 5%) \ud83d\udeab RED FLAG - Too small\n\n**Score Breakdown:**\n\u274c Balance (5/30): One category dominates at 68% (FAIL >40% threshold)\n\u274c Range (0/25): Massive spread (5% to 68%) indicates poor distribution\n\u26a0\ufe0f Total Categories (10/20): 5 categories but 2 are micro-categories\n\u26a0\ufe0f Naming (10/15): \"Everything Else\" is vague catch-all (red flag)\n\u274c Viability (0/10): 2 categories below 8% threshold\n\n**Total: 45/100 - Needs major restructuring**\n\n**Critical Issues:**\n1. \ud83d\udeab \"Everything Else\" at 68% \u2192 Split into 3-4 specific feature categories\n2. \ud83d\udeab \"Changelog\" at 5% \u2192 Move to utility navigation, not top-level\n3. \u26a0\ufe0f \"FAQ\" at 7% \u2192 Combine with Troubleshooting OR demote to footer\n\n**Recommended Fix:**\nSplit \"Everything Else\" (68 pages) into:\n- Authentication & Security (22 pages, 22%)\n- Payment Processing (25 pages, 25%)\n- Data & Analytics (21 pages, 21%)\n\nNew structure:\n- Get Started (8%) + FAQ (7%) \u2192 \"Get Started & Support\" (15%)\n- Authentication (22%)\n- Payment Processing (25%)\n- Data & Analytics (21%)\n- Troubleshooting (12%)\n- Changelog \u2192 Move to footer (not top-level)\n\nResult: 5 categories, range 12-25%, all within thresholds \u2705\n```\n<!-- END EXAMPLE-EX-95 -->\n\n---\n\n<!-- START EXAMPLE-EX-96: \"Too Granular Taxonomy Example\" -->\n**Example 3: Too Granular Taxonomy (Score: 55/100)**\n\n```text\nSITE: 100 pages total\n\n\u251c\u2500\u2500 Authentication (35 pages, 35%) \u26a0\ufe0f AT THRESHOLD\n\u251c\u2500\u2500 Payments (32 pages, 32%) \u2705\n\u251c\u2500\u2500 Webhooks (28 pages, 28%) \u2705\n\u251c\u2500\u2500 Troubleshooting (3 pages, 3%) \ud83d\udeab RED FLAG - Too small\n\u2514\u2500\u2500 Changelog (2 pages, 2%) \ud83d\udeab RED FLAG - Too small\n\n**Score Breakdown:**\n\u26a0\ufe0f Balance (15/30): Authentication at 35% (exactly at threshold, borderline)\n\u2705 Range (20/25): Main categories well-distributed (28-35%)\n\u274c Total Categories (5/20): 5 categories but 2 are non-viable micro-categories\n\u2705 Naming (15/15): Clear, specific, appropriate labels\n\u274c Viability (0/10): 2 categories well below 8% threshold (3% and 2%)\n\n**Total: 55/100 - Needs consolidation**\n\n**Critical Issues:**\n1. \ud83d\udeab \"Troubleshooting\" at 3% \u2192 Too small for top-level category\n2. \ud83d\udeab \"Changelog\" at 2% \u2192 Utility content, not primary navigation\n3. \u26a0\ufe0f \"Authentication\" at 35% \u2192 Right at threshold, monitor growth\n\n**Recommended Fix:**\n- Merge \"Troubleshooting\" (3 pages) into relevant feature sections\n- Move \"Changelog\" to footer or utility navigation\n- Result: 3 strong top-level categories (Authentication 35%, Payments 32%, Webhooks 28%)\n- Add \"Get Started\" section if you have onboarding content\n\n**Alternative:** If you have 15+ more pages of content:\n- Keep Authentication, Payments, Webhooks as-is\n- Add \"Get Started & Tutorials\" (10-15 pages)\n- Distribute Troubleshooting across feature sections\n- Move Changelog to footer\n```\n<!-- END EXAMPLE-EX-96 -->\n\n---\n\n<!-- START EXAMPLE-EX-97: \"Red Flags Checklist\" -->\n##### Red Flags Checklist\n\nWhen validating taxonomy balance, watch for these **automatic red flags**:\n\n```\n\ud83d\udeab RED FLAG #1: Mega-Category (>40%)\n\u251c\u2500\u2500 Indicates: Category is too broad, mixing multiple concepts\n\u2514\u2500\u2500 Fix: Split into 2-3 specific subcategories\n\n\ud83d\udeab RED FLAG #2: Micro-Category (<5%)\n\u251c\u2500\u2500 Indicates: Not enough content to warrant top-level status\n\u2514\u2500\u2500 Fix: Combine with related category OR demote to subcategory\n\n\ud83d\udeab RED FLAG #3: Catch-All Label (\"Other\", \"Miscellaneous\", \"Everything Else\")\n\u251c\u2500\u2500 Indicates: Lack of clear organizational principle\n\u2514\u2500\u2500 Fix: Identify patterns in \"other\" content, create specific categories\n\n\ud83d\udeab RED FLAG #4: Massive Spread (70+ percentage point gap)\n\u251c\u2500\u2500 Example: Smallest=5%, Largest=75% (70-point spread)\n\u2514\u2500\u2500 Fix: Split large categories, combine/demote small ones\n\n\ud83d\udeab RED FLAG #5: Ratio Imbalance (>10:1 ratio between largest and smallest)\n\u251c\u2500\u2500 Example: Largest=60 pages, Smallest=5 pages (12:1 ratio)\n\u2514\u2500\u2500 Fix: Indicates granularity mismatch, restructure levels\n\n\u26a0\ufe0f WARNING: Future Growth Pattern\n\u251c\u2500\u2500 Indicates: Category at 33-35% but expected to grow significantly\n\u2514\u2500\u2500 Fix: Proactively split before hitting 40% threshold\n```\n<!-- END EXAMPLE-EX-97 -->\n<!-- END CHECKLIST-CL-2 -->\n\n---\n\n<!-- START FIGURE-DG-12: \"Balance Validation Prompt\" -->\n**Validation Prompt (Enhanced):**\n\n```text\n[R] You are an information architect validating taxonomy balance.\n\n[I] Analyze this taxonomy for balance using these specific thresholds:\n\nBALANCE THRESHOLDS:\n- \u2705 Balanced: No category exceeds 35%\n- \u26a0\ufe0f Review: Any category 36-40%\n- \u274c Fail: Any category >40% OR <5%\n- \ud83d\udeab Red Flag: Catch-all labels, >10:1 size ratio\n\nCalculate:\n1. Percentage distribution for each top-level category\n2. Smallest vs. largest category spread\n3. Number of micro-categories (<8%)\n4. Ratio between largest and smallest categories\n\nFlag red flags and provide scored assessment (0-100).\n\n[C] Taxonomy to validate:\n[Paste taxonomy with page counts]\n\n[E] Output format:\nCategory | Pages | % | Status\nGet Started | 15 | 15% | \u2705 Balanced\n\n**Score:** /100\n**Red Flags:** [List any found]\n**Recommendation:** [Specific fixes if score <70]\n```\n<!-- END FIGURE-DG-12 -->\n\n---\n\n<!-- START CHECKLIST-CL-3: \"Granularity Check\" -->",
            "hydration_source_header": "Balance Validation Examples with Scores",
            "hydration_method": "line_proximity"
          }
        ],
        "redFlags": [
          {
            "id": "mega-category-flag",
            "title": "Mega-Category (>40%)",
            "indicates": "Category too broad",
            "lines": "555-560",
            "hydration_status": "failed"
          },
          {
            "id": "micro-category-flag",
            "title": "Micro-Category (<5%)",
            "indicates": "Not enough content for top-level",
            "lines": "561-565",
            "content": "**What to Evaluate:**\n- Are items at the same level at similar levels of abstraction?\n- Are you mixing broad topics with narrow topics?\n\n**Granularity Problems:**\n\n<!-- START EXAMPLE-EX-98: \"Granularity Problem Examples\" -->\n```text\n\u2717 INCONSISTENT GRANULARITY:\n\u251c\u2500\u2500 Authentication \u2190 Broad\n\u251c\u2500\u2500 OAuth 2.0 \u2190 Specific (subset of authentication!)\n\u251c\u2500\u2500 Payments \u2190 Broad\n\u251c\u2500\u2500 Visa Card Processing \u2190 Too specific (subset of payments!)\n\u2514\u2500\u2500 API Reference \u2190 Broad\n\nProblem: Mixing different levels of specificity at same level\n\n\u2713 CONSISTENT GRANULARITY:\n\u251c\u2500\u2500 Authentication \u2190 Broad feature\n\u251c\u2500\u2500 Payments \u2190 Broad feature\n\u251c\u2500\u2500 Webhooks \u2190 Broad feature\n\u2514\u2500\u2500 API Reference \u2190 Broad reference section\n\nAll items are at similar level of abstraction\n```\n\n**Example from real taxonomy:**\n\n```text\n\u2717 BAD:\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Core Concepts \u2190 Broad\n\u251c\u2500\u2500 Understanding OAuth \u2190 Specific concept (should be under \"Core Concepts\")\n\u251c\u2500\u2500 Implementation Guides \u2190 Broad\n\u2514\u2500\u2500 How to Validate Tokens \u2190 Specific guide (should be under \"Implementation\")\n\n\u2713 GOOD:\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Core Concepts\n\u2502   \u251c\u2500\u2500 Understanding OAuth\n\u2502   \u251c\u2500\u2500 Token Types\n\u2502   \u2514\u2500\u2500 Security Model\n\u251c\u2500\u2500 Implementation Guides\n\u2502   \u251c\u2500\u2500 Validate Tokens\n\u2502   \u2514\u2500\u2500 Handle Errors\n\u2514\u2500\u2500 API Reference\n```\n<!-- END EXAMPLE-EX-98 -->\n<!-- END CHECKLIST-CL-3 -->\n\n---\n\n<!-- START CHECKLIST-CL-4: \"Mutual Exclusivity Check\" -->",
            "hydration_source_header": "Check 3: Granularity Check",
            "hydration_method": "line_proximity"
          },
          {
            "id": "catch-all-label-flag",
            "title": "Catch-All Label",
            "indicates": "Lack of clear organizational principle",
            "lines": "566-570",
            "content": "**What to Evaluate:**\n- Are items at the same level at similar levels of abstraction?\n- Are you mixing broad topics with narrow topics?\n\n**Granularity Problems:**\n\n<!-- START EXAMPLE-EX-98: \"Granularity Problem Examples\" -->\n```text\n\u2717 INCONSISTENT GRANULARITY:\n\u251c\u2500\u2500 Authentication \u2190 Broad\n\u251c\u2500\u2500 OAuth 2.0 \u2190 Specific (subset of authentication!)\n\u251c\u2500\u2500 Payments \u2190 Broad\n\u251c\u2500\u2500 Visa Card Processing \u2190 Too specific (subset of payments!)\n\u2514\u2500\u2500 API Reference \u2190 Broad\n\nProblem: Mixing different levels of specificity at same level\n\n\u2713 CONSISTENT GRANULARITY:\n\u251c\u2500\u2500 Authentication \u2190 Broad feature\n\u251c\u2500\u2500 Payments \u2190 Broad feature\n\u251c\u2500\u2500 Webhooks \u2190 Broad feature\n\u2514\u2500\u2500 API Reference \u2190 Broad reference section\n\nAll items are at similar level of abstraction\n```\n\n**Example from real taxonomy:**\n\n```text\n\u2717 BAD:\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Core Concepts \u2190 Broad\n\u251c\u2500\u2500 Understanding OAuth \u2190 Specific concept (should be under \"Core Concepts\")\n\u251c\u2500\u2500 Implementation Guides \u2190 Broad\n\u2514\u2500\u2500 How to Validate Tokens \u2190 Specific guide (should be under \"Implementation\")\n\n\u2713 GOOD:\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Core Concepts\n\u2502   \u251c\u2500\u2500 Understanding OAuth\n\u2502   \u251c\u2500\u2500 Token Types\n\u2502   \u2514\u2500\u2500 Security Model\n\u251c\u2500\u2500 Implementation Guides\n\u2502   \u251c\u2500\u2500 Validate Tokens\n\u2502   \u2514\u2500\u2500 Handle Errors\n\u2514\u2500\u2500 API Reference\n```\n<!-- END EXAMPLE-EX-98 -->\n<!-- END CHECKLIST-CL-3 -->\n\n---\n\n<!-- START CHECKLIST-CL-4: \"Mutual Exclusivity Check\" -->",
            "hydration_source_header": "Check 3: Granularity Check",
            "hydration_method": "line_proximity"
          },
          {
            "id": "massive-spread-flag",
            "title": "Massive Spread (70+ points)",
            "indicates": "Poor distribution",
            "lines": "571-575",
            "content": "**What to Evaluate:**\n- Are items at the same level at similar levels of abstraction?\n- Are you mixing broad topics with narrow topics?\n\n**Granularity Problems:**\n\n<!-- START EXAMPLE-EX-98: \"Granularity Problem Examples\" -->\n```text\n\u2717 INCONSISTENT GRANULARITY:\n\u251c\u2500\u2500 Authentication \u2190 Broad\n\u251c\u2500\u2500 OAuth 2.0 \u2190 Specific (subset of authentication!)\n\u251c\u2500\u2500 Payments \u2190 Broad\n\u251c\u2500\u2500 Visa Card Processing \u2190 Too specific (subset of payments!)\n\u2514\u2500\u2500 API Reference \u2190 Broad\n\nProblem: Mixing different levels of specificity at same level\n\n\u2713 CONSISTENT GRANULARITY:\n\u251c\u2500\u2500 Authentication \u2190 Broad feature\n\u251c\u2500\u2500 Payments \u2190 Broad feature\n\u251c\u2500\u2500 Webhooks \u2190 Broad feature\n\u2514\u2500\u2500 API Reference \u2190 Broad reference section\n\nAll items are at similar level of abstraction\n```\n\n**Example from real taxonomy:**\n\n```text\n\u2717 BAD:\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Core Concepts \u2190 Broad\n\u251c\u2500\u2500 Understanding OAuth \u2190 Specific concept (should be under \"Core Concepts\")\n\u251c\u2500\u2500 Implementation Guides \u2190 Broad\n\u2514\u2500\u2500 How to Validate Tokens \u2190 Specific guide (should be under \"Implementation\")\n\n\u2713 GOOD:\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Core Concepts\n\u2502   \u251c\u2500\u2500 Understanding OAuth\n\u2502   \u251c\u2500\u2500 Token Types\n\u2502   \u2514\u2500\u2500 Security Model\n\u251c\u2500\u2500 Implementation Guides\n\u2502   \u251c\u2500\u2500 Validate Tokens\n\u2502   \u2514\u2500\u2500 Handle Errors\n\u2514\u2500\u2500 API Reference\n```\n<!-- END EXAMPLE-EX-98 -->\n<!-- END CHECKLIST-CL-3 -->\n\n---\n\n<!-- START CHECKLIST-CL-4: \"Mutual Exclusivity Check\" -->",
            "hydration_source_header": "Check 3: Granularity Check",
            "hydration_method": "line_proximity"
          },
          {
            "id": "ratio-imbalance-flag",
            "title": "Ratio Imbalance (>10:1)",
            "indicates": "Granularity mismatch",
            "lines": "576-580",
            "content": "**What to Evaluate:**\n- Are items at the same level at similar levels of abstraction?\n- Are you mixing broad topics with narrow topics?\n\n**Granularity Problems:**\n\n<!-- START EXAMPLE-EX-98: \"Granularity Problem Examples\" -->\n```text\n\u2717 INCONSISTENT GRANULARITY:\n\u251c\u2500\u2500 Authentication \u2190 Broad\n\u251c\u2500\u2500 OAuth 2.0 \u2190 Specific (subset of authentication!)\n\u251c\u2500\u2500 Payments \u2190 Broad\n\u251c\u2500\u2500 Visa Card Processing \u2190 Too specific (subset of payments!)\n\u2514\u2500\u2500 API Reference \u2190 Broad\n\nProblem: Mixing different levels of specificity at same level\n\n\u2713 CONSISTENT GRANULARITY:\n\u251c\u2500\u2500 Authentication \u2190 Broad feature\n\u251c\u2500\u2500 Payments \u2190 Broad feature\n\u251c\u2500\u2500 Webhooks \u2190 Broad feature\n\u2514\u2500\u2500 API Reference \u2190 Broad reference section\n\nAll items are at similar level of abstraction\n```\n\n**Example from real taxonomy:**\n\n```text\n\u2717 BAD:\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Core Concepts \u2190 Broad\n\u251c\u2500\u2500 Understanding OAuth \u2190 Specific concept (should be under \"Core Concepts\")\n\u251c\u2500\u2500 Implementation Guides \u2190 Broad\n\u2514\u2500\u2500 How to Validate Tokens \u2190 Specific guide (should be under \"Implementation\")\n\n\u2713 GOOD:\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Core Concepts\n\u2502   \u251c\u2500\u2500 Understanding OAuth\n\u2502   \u251c\u2500\u2500 Token Types\n\u2502   \u2514\u2500\u2500 Security Model\n\u251c\u2500\u2500 Implementation Guides\n\u2502   \u251c\u2500\u2500 Validate Tokens\n\u2502   \u2514\u2500\u2500 Handle Errors\n\u2514\u2500\u2500 API Reference\n```\n<!-- END EXAMPLE-EX-98 -->\n<!-- END CHECKLIST-CL-3 -->\n\n---\n\n<!-- START CHECKLIST-CL-4: \"Mutual Exclusivity Check\" -->",
            "hydration_source_header": "Check 3: Granularity Check",
            "hydration_method": "line_proximity"
          },
          {
            "id": "future-growth-warning",
            "title": "Future Growth Pattern",
            "indicates": "Proactive split needed",
            "lines": "581-585",
            "content": "**What to Evaluate:**\n- Are items at the same level at similar levels of abstraction?\n- Are you mixing broad topics with narrow topics?\n\n**Granularity Problems:**\n\n<!-- START EXAMPLE-EX-98: \"Granularity Problem Examples\" -->\n```text\n\u2717 INCONSISTENT GRANULARITY:\n\u251c\u2500\u2500 Authentication \u2190 Broad\n\u251c\u2500\u2500 OAuth 2.0 \u2190 Specific (subset of authentication!)\n\u251c\u2500\u2500 Payments \u2190 Broad\n\u251c\u2500\u2500 Visa Card Processing \u2190 Too specific (subset of payments!)\n\u2514\u2500\u2500 API Reference \u2190 Broad\n\nProblem: Mixing different levels of specificity at same level\n\n\u2713 CONSISTENT GRANULARITY:\n\u251c\u2500\u2500 Authentication \u2190 Broad feature\n\u251c\u2500\u2500 Payments \u2190 Broad feature\n\u251c\u2500\u2500 Webhooks \u2190 Broad feature\n\u2514\u2500\u2500 API Reference \u2190 Broad reference section\n\nAll items are at similar level of abstraction\n```\n\n**Example from real taxonomy:**\n\n```text\n\u2717 BAD:\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Core Concepts \u2190 Broad\n\u251c\u2500\u2500 Understanding OAuth \u2190 Specific concept (should be under \"Core Concepts\")\n\u251c\u2500\u2500 Implementation Guides \u2190 Broad\n\u2514\u2500\u2500 How to Validate Tokens \u2190 Specific guide (should be under \"Implementation\")\n\n\u2713 GOOD:\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Core Concepts\n\u2502   \u251c\u2500\u2500 Understanding OAuth\n\u2502   \u251c\u2500\u2500 Token Types\n\u2502   \u2514\u2500\u2500 Security Model\n\u251c\u2500\u2500 Implementation Guides\n\u2502   \u251c\u2500\u2500 Validate Tokens\n\u2502   \u2514\u2500\u2500 Handle Errors\n\u2514\u2500\u2500 API Reference\n```\n<!-- END EXAMPLE-EX-98 -->\n<!-- END CHECKLIST-CL-3 -->\n\n---\n\n<!-- START CHECKLIST-CL-4: \"Mutual Exclusivity Check\" -->",
            "hydration_source_header": "Check 3: Granularity Check",
            "hydration_method": "line_proximity"
          }
        ],
        "depthRules": [
          {
            "id": "small-site-depth",
            "title": "Small Site Depth",
            "pages": "20-50",
            "recommendedLevels": "2 levels",
            "lines": "320-322",
            "content": "**What to Evaluate:**\n- Is the hierarchy too deep or too shallow?\n- Does depth match content volume?\n- Could it be flattened without losing clarity?\n\n**Rules of Thumb:**\n- **Small sites (20-50 pages):** 2 levels usually sufficient\n- **Medium sites (50-200 pages):** 2-3 levels optimal\n- **Large sites (200+ pages):** 3 levels max, 4 only if absolutely necessary\n\n**Depth Problems:**\n\n<!-- START EXAMPLE-EX-93: \"Depth Problems Examples\" -->\n<CardGroup cols={2}>\n  <Card title=\"Too Shallow\" icon=\"compress\">\n    **Problem:** All 150 pages in a flat list\n    \n    **Impact:** Overwhelming, poor scannability\n    \n    **Fix:** Add 1-2 levels of categorization\n  </Card>\n  \n  <Card title=\"Too Deep\" icon=\"expand\">\n    **Problem:** 5-6 levels of nesting\n    \n    **Impact:** Users get lost, excessive clicking\n    \n    **Fix:** Flatten by combining levels\n  </Card>\n</CardGroup>\n<!-- END EXAMPLE-EX-93 -->\n\n**Example Depth Analysis:**\n\n<!-- START EXAMPLE-EX-94: \"Depth Analysis Examples\" -->\n```text\n\u2713 GOOD (80 pages, 3 levels):\n\u251c\u2500\u2500 Get Started (12 pages)\n\u2502   \u251c\u2500\u2500 Installation (3 pages)\n\u2502   \u2514\u2500\u2500 Quick Start (9 pages)\n\u251c\u2500\u2500 Features (50 pages)\n\u2502   \u251c\u2500\u2500 Authentication (15 pages)\n\u2502   \u2514\u2500\u2500 Payments (35 pages)\n\u2514\u2500\u2500 Reference (18 pages)\n\n\u2717 TOO DEEP (80 pages, 5 levels):\n\u251c\u2500\u2500 Documentation\n\u2502   \u251c\u2500\u2500 Getting Started\n\u2502   \u2502   \u251c\u2500\u2500 Prerequisites\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 System Requirements\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 Operating Systems\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 Windows (1 page) \u2190 Way too deep!\n\n\u2717 TOO SHALLOW (80 pages, 1 level):\n- 80 flat pages (no hierarchy at all)\n```\n<!-- END EXAMPLE-EX-94 -->\n\n---\n\n<!-- START CHECKLIST-CL-2: \"Balance Check\" -->",
            "hydration_source_header": "Check 1: Depth Check",
            "hydration_method": "line_proximity"
          },
          {
            "id": "medium-site-depth",
            "title": "Medium Site Depth",
            "pages": "50-200",
            "recommendedLevels": "2-3 levels",
            "lines": "323-325",
            "content": "**What to Evaluate:**\n- Is the hierarchy too deep or too shallow?\n- Does depth match content volume?\n- Could it be flattened without losing clarity?\n\n**Rules of Thumb:**\n- **Small sites (20-50 pages):** 2 levels usually sufficient\n- **Medium sites (50-200 pages):** 2-3 levels optimal\n- **Large sites (200+ pages):** 3 levels max, 4 only if absolutely necessary\n\n**Depth Problems:**\n\n<!-- START EXAMPLE-EX-93: \"Depth Problems Examples\" -->\n<CardGroup cols={2}>\n  <Card title=\"Too Shallow\" icon=\"compress\">\n    **Problem:** All 150 pages in a flat list\n    \n    **Impact:** Overwhelming, poor scannability\n    \n    **Fix:** Add 1-2 levels of categorization\n  </Card>\n  \n  <Card title=\"Too Deep\" icon=\"expand\">\n    **Problem:** 5-6 levels of nesting\n    \n    **Impact:** Users get lost, excessive clicking\n    \n    **Fix:** Flatten by combining levels\n  </Card>\n</CardGroup>\n<!-- END EXAMPLE-EX-93 -->\n\n**Example Depth Analysis:**\n\n<!-- START EXAMPLE-EX-94: \"Depth Analysis Examples\" -->\n```text\n\u2713 GOOD (80 pages, 3 levels):\n\u251c\u2500\u2500 Get Started (12 pages)\n\u2502   \u251c\u2500\u2500 Installation (3 pages)\n\u2502   \u2514\u2500\u2500 Quick Start (9 pages)\n\u251c\u2500\u2500 Features (50 pages)\n\u2502   \u251c\u2500\u2500 Authentication (15 pages)\n\u2502   \u2514\u2500\u2500 Payments (35 pages)\n\u2514\u2500\u2500 Reference (18 pages)\n\n\u2717 TOO DEEP (80 pages, 5 levels):\n\u251c\u2500\u2500 Documentation\n\u2502   \u251c\u2500\u2500 Getting Started\n\u2502   \u2502   \u251c\u2500\u2500 Prerequisites\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 System Requirements\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 Operating Systems\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 Windows (1 page) \u2190 Way too deep!\n\n\u2717 TOO SHALLOW (80 pages, 1 level):\n- 80 flat pages (no hierarchy at all)\n```\n<!-- END EXAMPLE-EX-94 -->\n\n---\n\n<!-- START CHECKLIST-CL-2: \"Balance Check\" -->",
            "hydration_source_header": "Check 1: Depth Check",
            "hydration_method": "line_proximity"
          },
          {
            "id": "large-site-depth",
            "title": "Large Site Depth",
            "pages": "200+",
            "recommendedLevels": "3 levels max, 4 only if necessary",
            "lines": "326-328",
            "content": "**What to Evaluate:**\n- Is the hierarchy too deep or too shallow?\n- Does depth match content volume?\n- Could it be flattened without losing clarity?\n\n**Rules of Thumb:**\n- **Small sites (20-50 pages):** 2 levels usually sufficient\n- **Medium sites (50-200 pages):** 2-3 levels optimal\n- **Large sites (200+ pages):** 3 levels max, 4 only if absolutely necessary\n\n**Depth Problems:**\n\n<!-- START EXAMPLE-EX-93: \"Depth Problems Examples\" -->\n<CardGroup cols={2}>\n  <Card title=\"Too Shallow\" icon=\"compress\">\n    **Problem:** All 150 pages in a flat list\n    \n    **Impact:** Overwhelming, poor scannability\n    \n    **Fix:** Add 1-2 levels of categorization\n  </Card>\n  \n  <Card title=\"Too Deep\" icon=\"expand\">\n    **Problem:** 5-6 levels of nesting\n    \n    **Impact:** Users get lost, excessive clicking\n    \n    **Fix:** Flatten by combining levels\n  </Card>\n</CardGroup>\n<!-- END EXAMPLE-EX-93 -->\n\n**Example Depth Analysis:**\n\n<!-- START EXAMPLE-EX-94: \"Depth Analysis Examples\" -->\n```text\n\u2713 GOOD (80 pages, 3 levels):\n\u251c\u2500\u2500 Get Started (12 pages)\n\u2502   \u251c\u2500\u2500 Installation (3 pages)\n\u2502   \u2514\u2500\u2500 Quick Start (9 pages)\n\u251c\u2500\u2500 Features (50 pages)\n\u2502   \u251c\u2500\u2500 Authentication (15 pages)\n\u2502   \u2514\u2500\u2500 Payments (35 pages)\n\u2514\u2500\u2500 Reference (18 pages)\n\n\u2717 TOO DEEP (80 pages, 5 levels):\n\u251c\u2500\u2500 Documentation\n\u2502   \u251c\u2500\u2500 Getting Started\n\u2502   \u2502   \u251c\u2500\u2500 Prerequisites\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 System Requirements\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 Operating Systems\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 Windows (1 page) \u2190 Way too deep!\n\n\u2717 TOO SHALLOW (80 pages, 1 level):\n- 80 flat pages (no hierarchy at all)\n```\n<!-- END EXAMPLE-EX-94 -->\n\n---\n\n<!-- START CHECKLIST-CL-2: \"Balance Check\" -->",
            "hydration_source_header": "Check 1: Depth Check",
            "hydration_method": "line_proximity"
          }
        ],
        "advancedPatterns": [
          {
            "id": "polyhierarchy",
            "title": "Polyhierarchy",
            "definition": "Content appearing in multiple places for multiple access paths",
            "useCase": "Multiple access paths",
            "lines": "920-1020",
            "retrievalQuestions": [
              "What is polyhierarchy?",
              "When should content appear in multiple places?"
            ],
            "content": "Beyond simple hierarchies, there are two advanced approaches: **polyhierarchy** (content appearing in multiple places) and **faceted classification** (multiple independent classification systems).\n\n### Decision Framework: Which Approach to Use\n\n| Use Polyhierarchy When | Use Faceted Classification When |\n|------------------------|----------------------------------|\n| Few cross-cutting pieces of content | Many items needing multiple views |\n| Primarily hierarchical with some overlap | Primarily filtering-based access |\n| Small to medium content sets | Large content sets |\n| Simple navigation systems | Advanced filtering capabilities |\n| Cross-links suffice for most needs | Users need to combine multiple criteria |\n\n### 3.1 Polyhierarchy: Content in Multiple Places\n\n**Definition:** Polyhierarchy is when content appears in more than one place in the hierarchy.\n\n**When to Use:**\n- Users approach content from different angles\n- Content serves multiple purposes\n- Clear primary home exists, but secondary access paths help\n\n**Example:**\n\n```text\n\"API Security Best Practices\" appears in multiple locations:\n\n\u251c\u2500\u2500 Get Started\n\u2502   \u2514\u2500\u2500 Security Checklist \u2190 Beginner-focused version\n\u251c\u2500\u2500 Authentication\n\u2502   \u2514\u2500\u2500 Security Best Practices \u2190 Primary, comprehensive version\n\u2514\u2500\u2500 Reference\n    \u2514\u2500\u2500 Security Best Practices \u2190 Technical specs version\n\nWhy this works:\n- Beginners: Start in \"Get Started\", find security checklist\n- Implementers: Start in \"Authentication\", find comprehensive guide\n- Quick lookup: Start in \"Reference\", find technical specs\n```\n\n**Implementation Strategies:**\n\n1. **Duplicate navigation pointers** (single source content)\n2. **Cross-links** (content in one place, linked from others)\n3. **Contextual references** (tailored intro paragraph that links to primary)\n\n---\n\n### 3.2 Polyhierarchy Prompt Pattern\n\n```text\nYou're an information architect analyzing content for polyhierarchy.\n\nReview this taxonomy and identify content that users might approach from \nmultiple angles.\n\nTaxonomy:\n[Paste taxonomy]\n\nFor each piece of polyhierarchy content, specify:\n1. Title and current location\n2. Why it has multiple access paths (user scenarios)\n3. Recommended locations (primary + secondary)\n4. Implementation approach (duplicate nav, cross-link, contextual reference)\n\nExample format:\n**Content:** \"OAuth 2.0 Implementation\"\n**Primary home:** Authentication > OAuth\n**Secondary homes:** \n- Get Started > Security Setup (contextual reference)\n- Troubleshooting > Auth Issues (cross-link)\n**Reason:** Users approach from learning path, implementation, or debugging\n**Implementation:** Single source in Authentication, cross-links elsewhere\n\nFocus on content where secondary access significantly improves findability.\n```\n\n**Real Example:**\n\n```text\nContent for polyhierarchy analysis:\n\nSecurity-related content in CloudStore API:\n1. OAuth 2.0 Implementation\n2. API Key Security\n3. Encryption in Transit (TLS)\n4. Encryption at Rest\n5. PCI Compliance for Payments\n6. Securing Webhook Endpoints\n7. Rate Limiting for Security\n8. Security Monitoring & Logging\n9. Incident Response\n10. Security Checklist for Production\n\nCreate:\n1. Primary hierarchical taxonomy\n2. Secondary access paths (how else users might look for content)\n3. Polyhierarchy recommendations (what should appear in multiple places)\n4. Implementation notes (duplicate page, cross-link, or contextual reference)\n\nEnsure each piece of content has one clear primary home.\n```\n<!-- END REFERENCE-PP-38 -->\n\n---\n\n<!-- START REFERENCE-PP-39: \"Faceted Classification Pattern\" -->\n### 3.3 Faceted Classification with AI\n\n**Definition:** Multiple independent classification schemes applied to the same content, allowing filtering by different facets.\n\n**Common Facets for Documentation:**\n- Content type (Tutorial, How-to, Reference, Explanation)\n- Difficulty (Beginner, Intermediate, Advanced)\n- Product feature (Payments, Auth, Webhooks)\n- User role (Developer, Admin, Business User)\n- API version (v1, v2, v3)\n- Programming language (Python, JavaScript, Ruby)\n\n---\n\n**Prompt Pattern for Faceted Taxonomy:**\n\n```text\nYou're an information architect who designs faceted classification systems.\n\nCreate a faceted taxonomy for [CONTENT] that allows users to filter by:\n- Facet 1: [TYPE] (values: [LIST])\n- Facet 2: [TYPE] (values: [LIST])\n- Facet 3: [TYPE] (values: [LIST])\n\nFor each piece of content, assign values for all facets.\n\nProvide:\n1. Complete facet definition (facet names and allowed values)\n2. Sample content classified with all facets\n3. Common filter combinations users might want\n4. Implementation notes for documentation platform\n```\n\n**Example:**\n\n```text\nYou're an information architect designing a faceted classification system \nfor API documentation.\n\nCreate faceted taxonomy for 100 pages of payment API documentation allowing \nfiltering by:\n- Content Type: Tutorial | How-to Guide | Reference | Explanation\n- Difficulty: Beginner | Intermediate | Advanced\n- Topic: Authentication | Payments | Refunds | Subscriptions | Webhooks | Testing\n- Language: Python | JavaScript | Ruby | Java | PHP | cURL\n\nContent sample:\n1. \"Building Your First Payment Integration\"\n2. \"Charge API Endpoint Reference\"\n3. \"How to Handle Failed Payments\"\n4. \"Understanding PCI Compliance\"\n5. \"Python SDK: Creating Charges\"\n6. \"JavaScript: Implementing Webhooks\"\n7. \"Testing Payment Flows in Sandbox\"\n8. \"Subscription Lifecycle Explained\"\n9. \"Refund API Reference\"\n10. \"How to Retry Failed Charges\"\n\nProvide:\n1. Faceted classification for all sample content (table format)\n2. Most common filter combinations (based on user needs)\n3. Recommended default view (what users see first)\n4. Implementation guidance for Docusaurus or similar platform\n\nEnsure facet values are:\n- Mutually exclusive within each facet\n- Comprehensive (cover all content)\n- User-friendly (match user language)\n```\n\n**Expected Output Format:**\n\n| Page Title | Content Type | Difficulty | Topic | Language |\n|------------|--------------|------------|-------|----------|\n| Building Your First Payment Integration | Tutorial | Beginner | Payments | Multiple |\n| Charge API Endpoint Reference | Reference | All | Payments | cURL |\n| How to Handle Failed Payments | How-to | Intermediate | Payments | Multiple |\n| Understanding PCI Compliance | Explanation | Intermediate | Payments | N/A |\n| Python SDK: Creating Charges | Tutorial | Beginner | Payments | Python |\n| JavaScript: Implementing Webhooks | Tutorial | Intermediate | Webhooks | JavaScript |\n\n---\n\n### 3.4 Comparing Approaches in Practice\n\n**Example:**\n\n**Polyhierarchy Approach:**\n```text\n\u251c\u2500\u2500 Authentication\n\u2502   \u251c\u2500\u2500 OAuth 2.0\n\u2502   \u251c\u2500\u2500 API Keys\n\u2502   \u2514\u2500\u2500 Security Best Practices \u2190 Also in Security section\n\u251c\u2500\u2500 Security\n\u2502   \u251c\u2500\u2500 Encryption\n\u2502   \u251c\u2500\u2500 Security Best Practices \u2190 Primary home\n\u2502   \u2514\u2500\u2500 Compliance\n```\n\n**Faceted Approach:**\n```text\nSame content, but users filter by:\n- Topic: [Authentication] + [Security]\n- Content Type: [Best Practices]\n- Difficulty: [Intermediate]\n\nResult: \"Security Best Practices\" appears in filtered results for \nAuthentication OR Security topics\n```\n<!-- END REFERENCE-PP-39 -->\n\n---\n\n<!-- START EXAMPLE-EX-105: \"Kubernetes Documentation Case Study\" -->",
            "hydration_source_header": "3. Advanced Taxonomy Patterns: Polyhierarchy and Faceted Classification",
            "hydration_method": "title_match"
          },
          {
            "id": "faceted-classification",
            "title": "Faceted Classification",
            "definition": "Multiple independent classification schemes for filtering-based access",
            "useCase": "Filtering-based access",
            "lines": "1025-1170",
            "retrievalQuestions": [
              "What is faceted classification?",
              "How do I create a faceted taxonomy?"
            ],
            "content": "Beyond simple hierarchies, there are two advanced approaches: **polyhierarchy** (content appearing in multiple places) and **faceted classification** (multiple independent classification systems).\n\n### Decision Framework: Which Approach to Use\n\n| Use Polyhierarchy When | Use Faceted Classification When |\n|------------------------|----------------------------------|\n| Few cross-cutting pieces of content | Many items needing multiple views |\n| Primarily hierarchical with some overlap | Primarily filtering-based access |\n| Small to medium content sets | Large content sets |\n| Simple navigation systems | Advanced filtering capabilities |\n| Cross-links suffice for most needs | Users need to combine multiple criteria |\n\n### 3.1 Polyhierarchy: Content in Multiple Places\n\n**Definition:** Polyhierarchy is when content appears in more than one place in the hierarchy.\n\n**When to Use:**\n- Users approach content from different angles\n- Content serves multiple purposes\n- Clear primary home exists, but secondary access paths help\n\n**Example:**\n\n```text\n\"API Security Best Practices\" appears in multiple locations:\n\n\u251c\u2500\u2500 Get Started\n\u2502   \u2514\u2500\u2500 Security Checklist \u2190 Beginner-focused version\n\u251c\u2500\u2500 Authentication\n\u2502   \u2514\u2500\u2500 Security Best Practices \u2190 Primary, comprehensive version\n\u2514\u2500\u2500 Reference\n    \u2514\u2500\u2500 Security Best Practices \u2190 Technical specs version\n\nWhy this works:\n- Beginners: Start in \"Get Started\", find security checklist\n- Implementers: Start in \"Authentication\", find comprehensive guide\n- Quick lookup: Start in \"Reference\", find technical specs\n```\n\n**Implementation Strategies:**\n\n1. **Duplicate navigation pointers** (single source content)\n2. **Cross-links** (content in one place, linked from others)\n3. **Contextual references** (tailored intro paragraph that links to primary)\n\n---\n\n### 3.2 Polyhierarchy Prompt Pattern\n\n```text\nYou're an information architect analyzing content for polyhierarchy.\n\nReview this taxonomy and identify content that users might approach from \nmultiple angles.\n\nTaxonomy:\n[Paste taxonomy]\n\nFor each piece of polyhierarchy content, specify:\n1. Title and current location\n2. Why it has multiple access paths (user scenarios)\n3. Recommended locations (primary + secondary)\n4. Implementation approach (duplicate nav, cross-link, contextual reference)\n\nExample format:\n**Content:** \"OAuth 2.0 Implementation\"\n**Primary home:** Authentication > OAuth\n**Secondary homes:** \n- Get Started > Security Setup (contextual reference)\n- Troubleshooting > Auth Issues (cross-link)\n**Reason:** Users approach from learning path, implementation, or debugging\n**Implementation:** Single source in Authentication, cross-links elsewhere\n\nFocus on content where secondary access significantly improves findability.\n```\n\n**Real Example:**\n\n```text\nContent for polyhierarchy analysis:\n\nSecurity-related content in CloudStore API:\n1. OAuth 2.0 Implementation\n2. API Key Security\n3. Encryption in Transit (TLS)\n4. Encryption at Rest\n5. PCI Compliance for Payments\n6. Securing Webhook Endpoints\n7. Rate Limiting for Security\n8. Security Monitoring & Logging\n9. Incident Response\n10. Security Checklist for Production\n\nCreate:\n1. Primary hierarchical taxonomy\n2. Secondary access paths (how else users might look for content)\n3. Polyhierarchy recommendations (what should appear in multiple places)\n4. Implementation notes (duplicate page, cross-link, or contextual reference)\n\nEnsure each piece of content has one clear primary home.\n```\n<!-- END REFERENCE-PP-38 -->\n\n---\n\n<!-- START REFERENCE-PP-39: \"Faceted Classification Pattern\" -->\n### 3.3 Faceted Classification with AI\n\n**Definition:** Multiple independent classification schemes applied to the same content, allowing filtering by different facets.\n\n**Common Facets for Documentation:**\n- Content type (Tutorial, How-to, Reference, Explanation)\n- Difficulty (Beginner, Intermediate, Advanced)\n- Product feature (Payments, Auth, Webhooks)\n- User role (Developer, Admin, Business User)\n- API version (v1, v2, v3)\n- Programming language (Python, JavaScript, Ruby)\n\n---\n\n**Prompt Pattern for Faceted Taxonomy:**\n\n```text\nYou're an information architect who designs faceted classification systems.\n\nCreate a faceted taxonomy for [CONTENT] that allows users to filter by:\n- Facet 1: [TYPE] (values: [LIST])\n- Facet 2: [TYPE] (values: [LIST])\n- Facet 3: [TYPE] (values: [LIST])\n\nFor each piece of content, assign values for all facets.\n\nProvide:\n1. Complete facet definition (facet names and allowed values)\n2. Sample content classified with all facets\n3. Common filter combinations users might want\n4. Implementation notes for documentation platform\n```\n\n**Example:**\n\n```text\nYou're an information architect designing a faceted classification system \nfor API documentation.\n\nCreate faceted taxonomy for 100 pages of payment API documentation allowing \nfiltering by:\n- Content Type: Tutorial | How-to Guide | Reference | Explanation\n- Difficulty: Beginner | Intermediate | Advanced\n- Topic: Authentication | Payments | Refunds | Subscriptions | Webhooks | Testing\n- Language: Python | JavaScript | Ruby | Java | PHP | cURL\n\nContent sample:\n1. \"Building Your First Payment Integration\"\n2. \"Charge API Endpoint Reference\"\n3. \"How to Handle Failed Payments\"\n4. \"Understanding PCI Compliance\"\n5. \"Python SDK: Creating Charges\"\n6. \"JavaScript: Implementing Webhooks\"\n7. \"Testing Payment Flows in Sandbox\"\n8. \"Subscription Lifecycle Explained\"\n9. \"Refund API Reference\"\n10. \"How to Retry Failed Charges\"\n\nProvide:\n1. Faceted classification for all sample content (table format)\n2. Most common filter combinations (based on user needs)\n3. Recommended default view (what users see first)\n4. Implementation guidance for Docusaurus or similar platform\n\nEnsure facet values are:\n- Mutually exclusive within each facet\n- Comprehensive (cover all content)\n- User-friendly (match user language)\n```\n\n**Expected Output Format:**\n\n| Page Title | Content Type | Difficulty | Topic | Language |\n|------------|--------------|------------|-------|----------|\n| Building Your First Payment Integration | Tutorial | Beginner | Payments | Multiple |\n| Charge API Endpoint Reference | Reference | All | Payments | cURL |\n| How to Handle Failed Payments | How-to | Intermediate | Payments | Multiple |\n| Understanding PCI Compliance | Explanation | Intermediate | Payments | N/A |\n| Python SDK: Creating Charges | Tutorial | Beginner | Payments | Python |\n| JavaScript: Implementing Webhooks | Tutorial | Intermediate | Webhooks | JavaScript |\n\n---\n\n### 3.4 Comparing Approaches in Practice\n\n**Example:**\n\n**Polyhierarchy Approach:**\n```text\n\u251c\u2500\u2500 Authentication\n\u2502   \u251c\u2500\u2500 OAuth 2.0\n\u2502   \u251c\u2500\u2500 API Keys\n\u2502   \u2514\u2500\u2500 Security Best Practices \u2190 Also in Security section\n\u251c\u2500\u2500 Security\n\u2502   \u251c\u2500\u2500 Encryption\n\u2502   \u251c\u2500\u2500 Security Best Practices \u2190 Primary home\n\u2502   \u2514\u2500\u2500 Compliance\n```\n\n**Faceted Approach:**\n```text\nSame content, but users filter by:\n- Topic: [Authentication] + [Security]\n- Content Type: [Best Practices]\n- Difficulty: [Intermediate]\n\nResult: \"Security Best Practices\" appears in filtered results for \nAuthentication OR Security topics\n```\n<!-- END REFERENCE-PP-39 -->\n\n---\n\n<!-- START EXAMPLE-EX-105: \"Kubernetes Documentation Case Study\" -->",
            "hydration_source_header": "3. Advanced Taxonomy Patterns: Polyhierarchy and Faceted Classification",
            "hydration_method": "title_match"
          }
        ],
        "commonFacets": [
          {
            "id": "content-type-facet",
            "title": "Content Type Facet",
            "values": "Tutorial, How-to, Reference, Explanation",
            "lines": "1040-1042",
            "content": "**Definition:** Multiple independent classification schemes applied to the same content, allowing filtering by different facets.\n\n**Common Facets for Documentation:**\n- Content type (Tutorial, How-to, Reference, Explanation)\n- Difficulty (Beginner, Intermediate, Advanced)\n- Product feature (Payments, Auth, Webhooks)\n- User role (Developer, Admin, Business User)\n- API version (v1, v2, v3)\n- Programming language (Python, JavaScript, Ruby)\n\n---\n\n**Prompt Pattern for Faceted Taxonomy:**\n\n```text\nYou're an information architect who designs faceted classification systems.\n\nCreate a faceted taxonomy for [CONTENT] that allows users to filter by:\n- Facet 1: [TYPE] (values: [LIST])\n- Facet 2: [TYPE] (values: [LIST])\n- Facet 3: [TYPE] (values: [LIST])\n\nFor each piece of content, assign values for all facets.\n\nProvide:\n1. Complete facet definition (facet names and allowed values)\n2. Sample content classified with all facets\n3. Common filter combinations users might want\n4. Implementation notes for documentation platform\n```\n\n**Example:**\n\n```text\nYou're an information architect designing a faceted classification system \nfor API documentation.\n\nCreate faceted taxonomy for 100 pages of payment API documentation allowing \nfiltering by:\n- Content Type: Tutorial | How-to Guide | Reference | Explanation\n- Difficulty: Beginner | Intermediate | Advanced\n- Topic: Authentication | Payments | Refunds | Subscriptions | Webhooks | Testing\n- Language: Python | JavaScript | Ruby | Java | PHP | cURL\n\nContent sample:\n1. \"Building Your First Payment Integration\"\n2. \"Charge API Endpoint Reference\"\n3. \"How to Handle Failed Payments\"\n4. \"Understanding PCI Compliance\"\n5. \"Python SDK: Creating Charges\"\n6. \"JavaScript: Implementing Webhooks\"\n7. \"Testing Payment Flows in Sandbox\"\n8. \"Subscription Lifecycle Explained\"\n9. \"Refund API Reference\"\n10. \"How to Retry Failed Charges\"\n\nProvide:\n1. Faceted classification for all sample content (table format)\n2. Most common filter combinations (based on user needs)\n3. Recommended default view (what users see first)\n4. Implementation guidance for Docusaurus or similar platform\n\nEnsure facet values are:\n- Mutually exclusive within each facet\n- Comprehensive (cover all content)\n- User-friendly (match user language)\n```\n\n**Expected Output Format:**\n\n| Page Title | Content Type | Difficulty | Topic | Language |\n|------------|--------------|------------|-------|----------|\n| Building Your First Payment Integration | Tutorial | Beginner | Payments | Multiple |\n| Charge API Endpoint Reference | Reference | All | Payments | cURL |\n| How to Handle Failed Payments | How-to | Intermediate | Payments | Multiple |\n| Understanding PCI Compliance | Explanation | Intermediate | Payments | N/A |\n| Python SDK: Creating Charges | Tutorial | Beginner | Payments | Python |\n| JavaScript: Implementing Webhooks | Tutorial | Intermediate | Webhooks | JavaScript |\n\n---",
            "hydration_source_header": "3.3 Faceted Classification with AI",
            "hydration_method": "line_proximity"
          },
          {
            "id": "difficulty-facet",
            "title": "Difficulty Facet",
            "values": "Beginner, Intermediate, Advanced",
            "lines": "1043-1044",
            "content": "**Definition:** Multiple independent classification schemes applied to the same content, allowing filtering by different facets.\n\n**Common Facets for Documentation:**\n- Content type (Tutorial, How-to, Reference, Explanation)\n- Difficulty (Beginner, Intermediate, Advanced)\n- Product feature (Payments, Auth, Webhooks)\n- User role (Developer, Admin, Business User)\n- API version (v1, v2, v3)\n- Programming language (Python, JavaScript, Ruby)\n\n---\n\n**Prompt Pattern for Faceted Taxonomy:**\n\n```text\nYou're an information architect who designs faceted classification systems.\n\nCreate a faceted taxonomy for [CONTENT] that allows users to filter by:\n- Facet 1: [TYPE] (values: [LIST])\n- Facet 2: [TYPE] (values: [LIST])\n- Facet 3: [TYPE] (values: [LIST])\n\nFor each piece of content, assign values for all facets.\n\nProvide:\n1. Complete facet definition (facet names and allowed values)\n2. Sample content classified with all facets\n3. Common filter combinations users might want\n4. Implementation notes for documentation platform\n```\n\n**Example:**\n\n```text\nYou're an information architect designing a faceted classification system \nfor API documentation.\n\nCreate faceted taxonomy for 100 pages of payment API documentation allowing \nfiltering by:\n- Content Type: Tutorial | How-to Guide | Reference | Explanation\n- Difficulty: Beginner | Intermediate | Advanced\n- Topic: Authentication | Payments | Refunds | Subscriptions | Webhooks | Testing\n- Language: Python | JavaScript | Ruby | Java | PHP | cURL\n\nContent sample:\n1. \"Building Your First Payment Integration\"\n2. \"Charge API Endpoint Reference\"\n3. \"How to Handle Failed Payments\"\n4. \"Understanding PCI Compliance\"\n5. \"Python SDK: Creating Charges\"\n6. \"JavaScript: Implementing Webhooks\"\n7. \"Testing Payment Flows in Sandbox\"\n8. \"Subscription Lifecycle Explained\"\n9. \"Refund API Reference\"\n10. \"How to Retry Failed Charges\"\n\nProvide:\n1. Faceted classification for all sample content (table format)\n2. Most common filter combinations (based on user needs)\n3. Recommended default view (what users see first)\n4. Implementation guidance for Docusaurus or similar platform\n\nEnsure facet values are:\n- Mutually exclusive within each facet\n- Comprehensive (cover all content)\n- User-friendly (match user language)\n```\n\n**Expected Output Format:**\n\n| Page Title | Content Type | Difficulty | Topic | Language |\n|------------|--------------|------------|-------|----------|\n| Building Your First Payment Integration | Tutorial | Beginner | Payments | Multiple |\n| Charge API Endpoint Reference | Reference | All | Payments | cURL |\n| How to Handle Failed Payments | How-to | Intermediate | Payments | Multiple |\n| Understanding PCI Compliance | Explanation | Intermediate | Payments | N/A |\n| Python SDK: Creating Charges | Tutorial | Beginner | Payments | Python |\n| JavaScript: Implementing Webhooks | Tutorial | Intermediate | Webhooks | JavaScript |\n\n---",
            "hydration_source_header": "3.3 Faceted Classification with AI",
            "hydration_method": "line_proximity"
          },
          {
            "id": "product-feature-facet",
            "title": "Product Feature Facet",
            "values": "Variable by product",
            "lines": "1045-1046",
            "content": "**Definition:** Multiple independent classification schemes applied to the same content, allowing filtering by different facets.\n\n**Common Facets for Documentation:**\n- Content type (Tutorial, How-to, Reference, Explanation)\n- Difficulty (Beginner, Intermediate, Advanced)\n- Product feature (Payments, Auth, Webhooks)\n- User role (Developer, Admin, Business User)\n- API version (v1, v2, v3)\n- Programming language (Python, JavaScript, Ruby)\n\n---\n\n**Prompt Pattern for Faceted Taxonomy:**\n\n```text\nYou're an information architect who designs faceted classification systems.\n\nCreate a faceted taxonomy for [CONTENT] that allows users to filter by:\n- Facet 1: [TYPE] (values: [LIST])\n- Facet 2: [TYPE] (values: [LIST])\n- Facet 3: [TYPE] (values: [LIST])\n\nFor each piece of content, assign values for all facets.\n\nProvide:\n1. Complete facet definition (facet names and allowed values)\n2. Sample content classified with all facets\n3. Common filter combinations users might want\n4. Implementation notes for documentation platform\n```\n\n**Example:**\n\n```text\nYou're an information architect designing a faceted classification system \nfor API documentation.\n\nCreate faceted taxonomy for 100 pages of payment API documentation allowing \nfiltering by:\n- Content Type: Tutorial | How-to Guide | Reference | Explanation\n- Difficulty: Beginner | Intermediate | Advanced\n- Topic: Authentication | Payments | Refunds | Subscriptions | Webhooks | Testing\n- Language: Python | JavaScript | Ruby | Java | PHP | cURL\n\nContent sample:\n1. \"Building Your First Payment Integration\"\n2. \"Charge API Endpoint Reference\"\n3. \"How to Handle Failed Payments\"\n4. \"Understanding PCI Compliance\"\n5. \"Python SDK: Creating Charges\"\n6. \"JavaScript: Implementing Webhooks\"\n7. \"Testing Payment Flows in Sandbox\"\n8. \"Subscription Lifecycle Explained\"\n9. \"Refund API Reference\"\n10. \"How to Retry Failed Charges\"\n\nProvide:\n1. Faceted classification for all sample content (table format)\n2. Most common filter combinations (based on user needs)\n3. Recommended default view (what users see first)\n4. Implementation guidance for Docusaurus or similar platform\n\nEnsure facet values are:\n- Mutually exclusive within each facet\n- Comprehensive (cover all content)\n- User-friendly (match user language)\n```\n\n**Expected Output Format:**\n\n| Page Title | Content Type | Difficulty | Topic | Language |\n|------------|--------------|------------|-------|----------|\n| Building Your First Payment Integration | Tutorial | Beginner | Payments | Multiple |\n| Charge API Endpoint Reference | Reference | All | Payments | cURL |\n| How to Handle Failed Payments | How-to | Intermediate | Payments | Multiple |\n| Understanding PCI Compliance | Explanation | Intermediate | Payments | N/A |\n| Python SDK: Creating Charges | Tutorial | Beginner | Payments | Python |\n| JavaScript: Implementing Webhooks | Tutorial | Intermediate | Webhooks | JavaScript |\n\n---",
            "hydration_source_header": "3.3 Faceted Classification with AI",
            "hydration_method": "line_proximity"
          },
          {
            "id": "user-role-facet",
            "title": "User Role Facet",
            "values": "Developer, Admin, Business User",
            "lines": "1047-1048",
            "hydration_status": "failed"
          },
          {
            "id": "api-version-facet",
            "title": "API Version Facet",
            "values": "v1, v2, v3",
            "lines": "1049-1050",
            "hydration_status": "failed"
          },
          {
            "id": "language-facet",
            "title": "Programming Language Facet",
            "values": "Python, JavaScript, Ruby, etc.",
            "lines": "1051-1052",
            "hydration_status": "failed"
          }
        ],
        "di\u00e1taxisContentTypes": [
          {
            "id": "tutorials",
            "title": "Tutorials",
            "orientation": "Learning-oriented",
            "userNeed": "Learn by doing",
            "lines": "1785-1790",
            "content": "**Context:**\nYou're creating documentation for \"CloudStore API\" - a cloud storage API with features for:\n- File upload/download\n- Sharing and permissions\n- Versioning\n- Search and metadata\n- Webhooks for events\n\n**Content Inventory:** 60 pages\n- 12 tutorials\n- 20 how-to guides\n- 20 reference pages\n- 8 explanations\n\n**Target Users:** \n- Backend developers (70%)\n- Frontend developers (30%)\n- Mix of junior (40%) and senior (60%)\n\n**Business Goals:**\n- Reduce time-to-first-upload to under 10 minutes\n- Improve documentation satisfaction from 6.8 to 8.5\n- Reduce support tickets about \"how to\" questions by 40%\n\n---",
            "hydration_source_header": "Tutorial Scenario",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "how-to-guides",
            "title": "How-to Guides",
            "orientation": "Task-oriented",
            "userNeed": "Solve a problem",
            "lines": "1791-1796",
            "content": "**The Four Content Types:**\n\n<CardGroup cols={2}>\n  <Card title=\"Tutorials\" icon=\"graduation-cap\">\n    **Learning-oriented**\n    \n    Teaches through hands-on practice\n    \n    **Examples:** \"Build Your First API Integration\", \"Getting Started Tutorial\"\n  </Card>\n  \n  <Card title=\"How-to Guides\" icon=\"screwdriver-wrench\">\n    **Task-oriented**\n    \n    Solves specific problems\n    \n    **Examples:** \"How to Handle Failed Payments\", \"Set Up Webhooks\"\n  </Card>\n  \n  <Card title=\"Reference\" icon=\"book\">\n    **Information-oriented**\n    \n    Technical descriptions\n    \n    **Examples:** \"API Endpoint Reference\", \"Error Codes\", \"Configuration Options\"\n  </Card>\n  \n  <Card title=\"Explanations\" icon=\"lightbulb\">\n    **Understanding-oriented**\n    \n    Clarifies and discusses\n    \n    **Examples:** \"Understanding OAuth 2.0\", \"How Webhooks Work\", \"Why Use Versioning\"\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "5.1 Understanding Di\u00e1taxis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "reference",
            "title": "Reference",
            "orientation": "Information-oriented",
            "userNeed": "Look up details",
            "lines": "1797-1802",
            "content": "<!-- START EXAMPLE-EX-110: \"Di\u00e1taxis-First Approach\" -->\n**Approach 1: Di\u00e1taxis-First (Content Type at Top Level)**\n\n```text\n\u251c\u2500\u2500 Tutorials (Learning Path)\n\u2502   \u251c\u2500\u2500 Getting Started with API\n\u2502   \u251c\u2500\u2500 Build a Payment Integration\n\u2502   \u2514\u2500\u2500 Implement Webhooks\n\u251c\u2500\u2500 How-to Guides (Task Solutions)\n\u2502   \u251c\u2500\u2500 Handle Failed Payments\n\u2502   \u251c\u2500\u2500 Set Up Authentication\n\u2502   \u2514\u2500\u2500 Configure Retry Logic\n\u251c\u2500\u2500 Reference (Technical Specs)\n\u2502   \u251c\u2500\u2500 API Endpoints\n\u2502   \u251c\u2500\u2500 Error Codes\n\u2502   \u2514\u2500\u2500 SDKs\n\u2514\u2500\u2500 Explanations (Understanding)\n    \u251c\u2500\u2500 OAuth 2.0 Explained\n    \u251c\u2500\u2500 Understanding Rate Limits\n    \u2514\u2500\u2500 Payment Flow Architecture\n```\n\n**Pros:**\n- Very clear content type separation\n- Users know exactly what format to expect\n- Easy to maintain consistency\n\n**Cons:**\n- Users must know content type they need\n- Harder for mixed-need scenarios (learning + reference)\n- Less aligned with feature-based mental models\n\n**Best For:** Education-focused documentation, learning platforms\n<!-- END EXAMPLE-EX-110 -->\n\n---\n\n<!-- START EXAMPLE-EX-111: \"Feature-First with Di\u00e1taxis Approach\" -->\n**Approach 2: Feature-First with Di\u00e1taxis at Lower Levels (Recommended for APIs)**\n\n```text\n\u251c\u2500\u2500 Get Started\n\u2502   \u251c\u2500\u2500 Installation [Tutorial]\n\u2502   \u251c\u2500\u2500 First API Call [Tutorial]\n\u2502   \u2514\u2500\u2500 Core Concepts [Explanation]\n\u251c\u2500\u2500 Authentication\n\u2502   \u251c\u2500\u2500 OAuth Tutorial [Tutorial]\n\u2502   \u251c\u2500\u2500 How to Validate Tokens [How-to]\n\u2502   \u251c\u2500\u2500 Auth Endpoints [Reference]\n\u2502   \u2514\u2500\u2500 Understanding OAuth [Explanation]\n\u251c\u2500\u2500 Payments\n\u2502   \u251c\u2500\u2500 Payment Integration Tutorial [Tutorial]\n\u2502   \u251c\u2500\u2500 How to Handle Refunds [How-to]\n\u2502   \u251c\u2500\u2500 Payment API Reference [Reference]\n\u2502   \u2514\u2500\u2500 Payment Flows Explained [Explanation]\n\u2514\u2500\u2500 API Reference [Reference]\n    \u2514\u2500\u2500 Complete endpoint docs\n```\n\n**Pros:**\n- Aligned with user mental models (feature-based)\n- All content for a feature in one place\n- Supports mixed workflows (learn + implement + reference)\n\n**Cons:**\n- Requires disciplined labeling of content types\n- Risk of mixing types if not careful\n\n**Best For:** API documentation, feature-rich products\n<!-- END EXAMPLE-EX-111 -->\n<!-- END FIGURE-DG-14 -->\n\n---\n\n<!-- START REFERENCE-PP-7: \"Di\u00e1taxis Integration Prompt Pattern\" -->",
            "hydration_source_header": "5.2 Two Approaches to Di\u00e1taxis Integration",
            "hydration_method": "line_proximity"
          },
          {
            "id": "explanations",
            "title": "Explanations",
            "orientation": "Understanding-oriented",
            "userNeed": "Understand concepts",
            "lines": "1803-1810",
            "content": "<!-- START EXAMPLE-EX-110: \"Di\u00e1taxis-First Approach\" -->\n**Approach 1: Di\u00e1taxis-First (Content Type at Top Level)**\n\n```text\n\u251c\u2500\u2500 Tutorials (Learning Path)\n\u2502   \u251c\u2500\u2500 Getting Started with API\n\u2502   \u251c\u2500\u2500 Build a Payment Integration\n\u2502   \u2514\u2500\u2500 Implement Webhooks\n\u251c\u2500\u2500 How-to Guides (Task Solutions)\n\u2502   \u251c\u2500\u2500 Handle Failed Payments\n\u2502   \u251c\u2500\u2500 Set Up Authentication\n\u2502   \u2514\u2500\u2500 Configure Retry Logic\n\u251c\u2500\u2500 Reference (Technical Specs)\n\u2502   \u251c\u2500\u2500 API Endpoints\n\u2502   \u251c\u2500\u2500 Error Codes\n\u2502   \u2514\u2500\u2500 SDKs\n\u2514\u2500\u2500 Explanations (Understanding)\n    \u251c\u2500\u2500 OAuth 2.0 Explained\n    \u251c\u2500\u2500 Understanding Rate Limits\n    \u2514\u2500\u2500 Payment Flow Architecture\n```\n\n**Pros:**\n- Very clear content type separation\n- Users know exactly what format to expect\n- Easy to maintain consistency\n\n**Cons:**\n- Users must know content type they need\n- Harder for mixed-need scenarios (learning + reference)\n- Less aligned with feature-based mental models\n\n**Best For:** Education-focused documentation, learning platforms\n<!-- END EXAMPLE-EX-110 -->\n\n---\n\n<!-- START EXAMPLE-EX-111: \"Feature-First with Di\u00e1taxis Approach\" -->\n**Approach 2: Feature-First with Di\u00e1taxis at Lower Levels (Recommended for APIs)**\n\n```text\n\u251c\u2500\u2500 Get Started\n\u2502   \u251c\u2500\u2500 Installation [Tutorial]\n\u2502   \u251c\u2500\u2500 First API Call [Tutorial]\n\u2502   \u2514\u2500\u2500 Core Concepts [Explanation]\n\u251c\u2500\u2500 Authentication\n\u2502   \u251c\u2500\u2500 OAuth Tutorial [Tutorial]\n\u2502   \u251c\u2500\u2500 How to Validate Tokens [How-to]\n\u2502   \u251c\u2500\u2500 Auth Endpoints [Reference]\n\u2502   \u2514\u2500\u2500 Understanding OAuth [Explanation]\n\u251c\u2500\u2500 Payments\n\u2502   \u251c\u2500\u2500 Payment Integration Tutorial [Tutorial]\n\u2502   \u251c\u2500\u2500 How to Handle Refunds [How-to]\n\u2502   \u251c\u2500\u2500 Payment API Reference [Reference]\n\u2502   \u2514\u2500\u2500 Payment Flows Explained [Explanation]\n\u2514\u2500\u2500 API Reference [Reference]\n    \u2514\u2500\u2500 Complete endpoint docs\n```\n\n**Pros:**\n- Aligned with user mental models (feature-based)\n- All content for a feature in one place\n- Supports mixed workflows (learn + implement + reference)\n\n**Cons:**\n- Requires disciplined labeling of content types\n- Risk of mixing types if not careful\n\n**Best For:** API documentation, feature-rich products\n<!-- END EXAMPLE-EX-111 -->\n<!-- END FIGURE-DG-14 -->\n\n---\n\n<!-- START REFERENCE-PP-7: \"Di\u00e1taxis Integration Prompt Pattern\" -->",
            "hydration_source_header": "5.2 Two Approaches to Di\u00e1taxis Integration",
            "hydration_method": "line_proximity"
          }
        ],
        "di\u00e1taxisApproaches": [
          {
            "id": "diataxis-first-approach",
            "title": "Di\u00e1taxis-First (Content Type at Top Level)",
            "structure": "Content types as L1",
            "bestFor": "Education-focused docs",
            "lines": "1820-1850",
            "content": "<!-- START EXAMPLE-EX-110: \"Di\u00e1taxis-First Approach\" -->\n**Approach 1: Di\u00e1taxis-First (Content Type at Top Level)**\n\n```text\n\u251c\u2500\u2500 Tutorials (Learning Path)\n\u2502   \u251c\u2500\u2500 Getting Started with API\n\u2502   \u251c\u2500\u2500 Build a Payment Integration\n\u2502   \u2514\u2500\u2500 Implement Webhooks\n\u251c\u2500\u2500 How-to Guides (Task Solutions)\n\u2502   \u251c\u2500\u2500 Handle Failed Payments\n\u2502   \u251c\u2500\u2500 Set Up Authentication\n\u2502   \u2514\u2500\u2500 Configure Retry Logic\n\u251c\u2500\u2500 Reference (Technical Specs)\n\u2502   \u251c\u2500\u2500 API Endpoints\n\u2502   \u251c\u2500\u2500 Error Codes\n\u2502   \u2514\u2500\u2500 SDKs\n\u2514\u2500\u2500 Explanations (Understanding)\n    \u251c\u2500\u2500 OAuth 2.0 Explained\n    \u251c\u2500\u2500 Understanding Rate Limits\n    \u2514\u2500\u2500 Payment Flow Architecture\n```\n\n**Pros:**\n- Very clear content type separation\n- Users know exactly what format to expect\n- Easy to maintain consistency\n\n**Cons:**\n- Users must know content type they need\n- Harder for mixed-need scenarios (learning + reference)\n- Less aligned with feature-based mental models\n\n**Best For:** Education-focused documentation, learning platforms\n<!-- END EXAMPLE-EX-110 -->\n\n---\n\n<!-- START EXAMPLE-EX-111: \"Feature-First with Di\u00e1taxis Approach\" -->\n**Approach 2: Feature-First with Di\u00e1taxis at Lower Levels (Recommended for APIs)**\n\n```text\n\u251c\u2500\u2500 Get Started\n\u2502   \u251c\u2500\u2500 Installation [Tutorial]\n\u2502   \u251c\u2500\u2500 First API Call [Tutorial]\n\u2502   \u2514\u2500\u2500 Core Concepts [Explanation]\n\u251c\u2500\u2500 Authentication\n\u2502   \u251c\u2500\u2500 OAuth Tutorial [Tutorial]\n\u2502   \u251c\u2500\u2500 How to Validate Tokens [How-to]\n\u2502   \u251c\u2500\u2500 Auth Endpoints [Reference]\n\u2502   \u2514\u2500\u2500 Understanding OAuth [Explanation]\n\u251c\u2500\u2500 Payments\n\u2502   \u251c\u2500\u2500 Payment Integration Tutorial [Tutorial]\n\u2502   \u251c\u2500\u2500 How to Handle Refunds [How-to]\n\u2502   \u251c\u2500\u2500 Payment API Reference [Reference]\n\u2502   \u2514\u2500\u2500 Payment Flows Explained [Explanation]\n\u2514\u2500\u2500 API Reference [Reference]\n    \u2514\u2500\u2500 Complete endpoint docs\n```\n\n**Pros:**\n- Aligned with user mental models (feature-based)\n- All content for a feature in one place\n- Supports mixed workflows (learn + implement + reference)\n\n**Cons:**\n- Requires disciplined labeling of content types\n- Risk of mixing types if not careful\n\n**Best For:** API documentation, feature-rich products\n<!-- END EXAMPLE-EX-111 -->\n<!-- END FIGURE-DG-14 -->\n\n---\n\n<!-- START REFERENCE-PP-7: \"Di\u00e1taxis Integration Prompt Pattern\" -->",
            "hydration_source_header": "5.2 Two Approaches to Di\u00e1taxis Integration",
            "hydration_method": "line_proximity"
          },
          {
            "id": "feature-first-diataxis",
            "title": "Feature-First with Di\u00e1taxis at Lower Levels",
            "structure": "Features L1, Di\u00e1taxis L3",
            "bestFor": "API documentation",
            "lines": "1855-1900",
            "hydration_status": "failed"
          }
        ],
        "caseStudies": [
          {
            "id": "kubernetes-docs-case",
            "title": "Kubernetes Documentation",
            "url": "kubernetes.io/docs",
            "approach": "Content-Type First (Di\u00e1taxis)",
            "lines": "1175-1230",
            "retrievalQuestions": [
              "How does Kubernetes organize docs?"
            ],
            "content": "**URL:** kubernetes.io/docs\n\n**Taxonomy Structure:**\n\n```text\n\u251c\u2500\u2500 Getting Started\n\u2502   \u251c\u2500\u2500 Learning Environment\n\u2502   \u251c\u2500\u2500 Production Environment\n\u2502   \u2514\u2500\u2500 Best Practices\n\u251c\u2500\u2500 Concepts\n\u2502   \u251c\u2500\u2500 Overview\n\u2502   \u251c\u2500\u2500 Cluster Architecture\n\u2502   \u251c\u2500\u2500 Containers\n\u2502   \u251c\u2500\u2500 Workloads\n\u2502   \u251c\u2500\u2500 Services, Load Balancing, Networking\n\u2502   \u251c\u2500\u2500 Storage\n\u2502   \u251c\u2500\u2500 Configuration\n\u2502   \u251c\u2500\u2500 Security\n\u2502   \u251c\u2500\u2500 Policies\n\u2502   \u251c\u2500\u2500 Scheduling & Eviction\n\u2502   \u2514\u2500\u2500 Cluster Administration\n\u251c\u2500\u2500 Tasks\n\u2502   \u251c\u2500\u2500 Install Tools\n\u2502   \u251c\u2500\u2500 Configure Pods and Containers\n\u2502   \u251c\u2500\u2500 Manage Cluster Resources\n\u2502   \u251c\u2500\u2500 Manage Kubernetes Objects\n\u2502   \u251c\u2500\u2500 Inject Data Into Applications\n\u2502   \u251c\u2500\u2500 Run Applications\n\u2502   \u251c\u2500\u2500 Run Jobs\n\u2502   \u251c\u2500\u2500 Access Applications\n\u2502   \u251c\u2500\u2500 Monitoring, Logging, Debugging\n\u2502   \u251c\u2500\u2500 Extend Kubernetes\n\u2502   \u2514\u2500\u2500 TLS\n\u251c\u2500\u2500 Tutorials\n\u2502   \u251c\u2500\u2500 Hello Minikube\n\u2502   \u251c\u2500\u2500 Learn Kubernetes Basics\n\u2502   \u251c\u2500\u2500 Stateless Applications\n\u2502   \u251c\u2500\u2500 Stateful Applications\n\u2502   \u2514\u2500\u2500 Services\n\u2514\u2500\u2500 Reference\n    \u251c\u2500\u2500 API Reference\n    \u251c\u2500\u2500 API Overview\n    \u251c\u2500\u2500 CLI Reference (kubectl)\n    \u251c\u2500\u2500 Component Reference\n    \u2514\u2500\u2500 Glossary\n```\n\n**What Works Well:**\n\n1. **Clear Content Type Separation**\n   - Concepts, Tasks, Tutorials, Reference are distinct\n   - Similar to Di\u00e1taxis framework\n   - Users know what to expect in each section\n\n2. **Task-Based Organization**\n   - \"Tasks\" section organized by what users want to do\n   - Matches user mental models\n   - Makes findability easier\n\n3. **Progressive Disclosure**\n   - Getting Started \u2192 Concepts \u2192 Tasks \u2192 Tutorials \u2192 Reference\n   - Guides users from simple to complex\n   - Multiple entry points for different expertise levels\n\n4. **Balanced Structure**\n   - No single category dominates\n   - Each section has clear purpose\n   - Good distribution of content\n\n**What Could Be Better:**\n\n- \"Concepts\" is broad (could be subdivided)\n- Some overlap between Tasks and Tutorials\n- Reference section could be more granular\n\n**Lessons for API Documentation:**\n- \u2713 Separate content types clearly\n- \u2713 Use task-based organization for procedural content\n- \u2713 Provide multiple entry points for different expertise\n- \u2713 Balance breadth and depth appropriately\n<!-- END EXAMPLE-EX-105 -->\n\n---\n\n<!-- START EXAMPLE-EX-106: \"Stripe Documentation Case Study\" -->",
            "hydration_source_header": "4.1 Case Study: Kubernetes Documentation",
            "hydration_method": "title_match"
          },
          {
            "id": "stripe-docs-case",
            "title": "Stripe API Documentation",
            "url": "stripe.com/docs",
            "approach": "Feature/Product First",
            "lines": "1235-1330",
            "retrievalQuestions": [
              "How does Stripe organize documentation?"
            ],
            "content": "**URL:** stripe.com/docs\n\n**Taxonomy Structure:**\n\n```text\n\u251c\u2500\u2500 Get Started\n\u2502   \u251c\u2500\u2500 Quickstart\n\u2502   \u251c\u2500\u2500 Development Checklist\n\u2502   \u251c\u2500\u2500 Payment Flows\n\u2502   \u2514\u2500\u2500 Testing\n\u251c\u2500\u2500 Payments\n\u2502   \u251c\u2500\u2500 Accept a Payment\n\u2502   \u251c\u2500\u2500 Payment Methods\n\u2502   \u251c\u2500\u2500 Save and Reuse Payment Methods\n\u2502   \u251c\u2500\u2500 Payment Intents\n\u2502   \u251c\u2500\u2500 Payment Links\n\u2502   \u251c\u2500\u2500 Checkout\n\u2502   \u251c\u2500\u2500 Elements\n\u2502   \u2514\u2500\u2500 Mobile SDKs\n\u251c\u2500\u2500 Billing\n\u2502   \u251c\u2500\u2500 Subscriptions\n\u2502   \u251c\u2500\u2500 Invoices\n\u2502   \u251c\u2500\u2500 Quotes\n\u2502   \u251c\u2500\u2500 Usage-Based Billing\n\u2502   \u2514\u2500\u2500 Customer Portal\n\u251c\u2500\u2500 Connect (Platforms)\n\u2502   \u251c\u2500\u2500 Overview\n\u2502   \u251c\u2500\u2500 Onboarding\n\u2502   \u251c\u2500\u2500 Payouts\n\u2502   \u251c\u2500\u2500 Account Management\n\u2502   \u2514\u2500\u2500 Express Dashboard\n\u251c\u2500\u2500 Terminal (In-Person Payments)\n\u2502   \u251c\u2500\u2500 Overview\n\u2502   \u251c\u2500\u2500 Readers\n\u2502   \u2514\u2500\u2500 Payments\n\u251c\u2500\u2500 Financial Services\n\u2502   \u251c\u2500\u2500 Treasury\n\u2502   \u251c\u2500\u2500 Issuing\n\u2502   \u2514\u2500\u2500 Tax\n\u251c\u2500\u2500 Business Operations\n\u2502   \u251c\u2500\u2500 Radar (Fraud Prevention)\n\u2502   \u251c\u2500\u2500 Sigma (Analytics)\n\u2502   \u251c\u2500\u2500 Reporting\n\u2502   \u2514\u2500\u2500 Revenue Recognition\n\u251c\u2500\u2500 API Reference\n\u2502   \u251c\u2500\u2500 Core Resources\n\u2502   \u251c\u2500\u2500 Payment Methods\n\u2502   \u251c\u2500\u2500 Checkout\n\u2502   \u251c\u2500\u2500 Billing\n\u2502   \u251c\u2500\u2500 Connect\n\u2502   \u251c\u2500\u2500 Webhooks\n\u2502   \u2514\u2500\u2500 Errors\n\u2514\u2500\u2500 Resources\n    \u251c\u2500\u2500 Libraries & SDKs\n    \u251c\u2500\u2500 Plugins\n    \u251c\u2500\u2500 Testing\n    \u2514\u2500\u2500 Changelog\n```\n\n**What Works Well:**\n\n1. **Product-Feature Hybrid**\n   - Top level organized by product features (Payments, Billing, Connect)\n   - Matches how Stripe's products are marketed\n   - Aligns with user intent (\"I need to handle subscriptions\")\n\n2. **Clear Getting Started Path**\n   - Prominent \"Get Started\" section\n   - Quickstart for immediate action\n   - Progressive onboarding\n\n3. **Separate API Reference**\n   - Complete technical specs in dedicated section\n   - Doesn't mix learning content with reference\n   - Comprehensive and searchable\n\n4. **Practical \"Resources\" Section**\n   - SDKs, plugins, testing tools\n   - Supporting materials separate from main docs\n   - Easy to find implementation tools\n\n**What Could Be Better:**\n\n- Some feature sections get very large (Payments)\n- Distinction between \"Payments\" and \"Payment Methods\" could be clearer\n- Resources might be better integrated into relevant sections\n\n**Lessons for API Documentation:**\n\n- \u2713 Feature-based organization works for product APIs\n- \u2713 Keep reference separate from guides\n- \u2713 Provide clear getting started path\n- \u2713 Group by user intent (what they're trying to build)\n<!-- END EXAMPLE-EX-106 -->\n\n---\n\n<!-- START EXAMPLE-EX-107: \"Comparative Analysis Prompt\" -->",
            "hydration_source_header": "4.2 Case Study: Stripe API Documentation",
            "hydration_method": "title_match"
          },
          {
            "id": "twilio-docs-case",
            "title": "Twilio API Documentation",
            "url": "twilio.com/docs",
            "approach": "Hybrid (Product + Use Case)",
            "lines": "1385-1470",
            "retrievalQuestions": [
              "Example of hybrid documentation structure"
            ],
            "content": "**URL:** twilio.com/docs\n\n**Taxonomy Structure:**\n\n```text\n\u251c\u2500\u2500 Getting Started\n\u2502   \u251c\u2500\u2500 Try It Out\n\u2502   \u251c\u2500\u2500 Set Up Your Dev Environment\n\u2502   \u2514\u2500\u2500 Send Your First SMS\n\u251c\u2500\u2500 Products (Feature-Based)\n\u2502   \u251c\u2500\u2500 Messaging\n\u2502   \u2502   \u251c\u2500\u2500 SMS & MMS\n\u2502   \u2502   \u251c\u2500\u2500 WhatsApp\n\u2502   \u2502   \u251c\u2500\u2500 Programmable Messaging\n\u2502   \u2502   \u2514\u2500\u2500 Conversations API\n\u2502   \u251c\u2500\u2500 Voice & Video\n\u2502   \u2502   \u251c\u2500\u2500 Programmable Voice\n\u2502   \u2502   \u251c\u2500\u2500 SIP Trunking\n\u2502   \u2502   \u2514\u2500\u2500 Video API\n\u2502   \u251c\u2500\u2500 Email (SendGrid)\n\u2502   \u251c\u2500\u2500 Authentication (Verify, Authy)\n\u2502   \u2514\u2500\u2500 Customer Data Platform\n\u251c\u2500\u2500 Use Cases (Task-Based)\n\u2502   \u251c\u2500\u2500 Two-Factor Authentication\n\u2502   \u251c\u2500\u2500 Appointment Reminders\n\u2502   \u251c\u2500\u2500 Marketing Campaigns\n\u2502   \u2514\u2500\u2500 Customer Support\n\u251c\u2500\u2500 Tutorials\n\u2502   \u251c\u2500\u2500 Build a Contact Center\n\u2502   \u251c\u2500\u2500 Verify Phone Numbers\n\u2502   \u2514\u2500\u2500 Send Bulk Messages\n\u251c\u2500\u2500 API Reference\n\u2502   \u251c\u2500\u2500 REST API\n\u2502   \u251c\u2500\u2500 SDKs (Node, Python, Ruby, etc.)\n\u2502   \u2514\u2500\u2500 TwiML (Markup Language)\n\u2514\u2500\u2500 Resources\n    \u251c\u2500\u2500 Code Samples\n    \u251c\u2500\u2500 Changelog\n    \u2514\u2500\u2500 Support\n```\n\n**What Works Well:**\n\n1. **Hybrid Organization**\n   - Products (feature-based) for browsing\n   - Use Cases (task-based) for goal-oriented users\n   - Dual access paths serve different mental models\n   - Users can find content either way\n\n2. **Progressive Onboarding**\n   - \"Try It Out\" before environment setup\n   - Immediate gratification (\"Send Your First SMS\")\n   - Low barrier to entry\n   - Success in under 5 minutes\n\n3. **Clear Product Separation**\n   - Each product (SMS, Voice, Video) distinct\n   - No confusion between products\n   - Easy to find if you know product name\n   - Sub-products clearly nested\n\n4. **Real-World Use Cases**\n   - \"Two-Factor Authentication\" not \"Verify API\"\n   - Language matches user goals\n   - Shows practical applications\n   - Helps users discover features\n\n**What Could Be Better:**\n\n- Products section can be overwhelming (many sub-products)\n- Overlap between \"Products > Messaging\" and \"Use Cases > Marketing Campaigns\"\n- \"Resources\" category is broad catch-all\n\n**Lessons for API Documentation:**\n- \u2713 Hybrid organization works (Products + Use Cases)\n- \u2713 Show practical applications, not just features\n- \u2713 Use real-world language in \"Use Cases\"\n- \u2713 Immediate \"Try It Out\" reduces friction\n\n**AI Prompt for Similar Structure:**\n\n```text\nYou're an information architect analyzing Twilio's documentation structure.\n\nCreate a taxonomy that combines:\n1. Feature/product-based organization (for users who know what they want)\n2. Use-case-based organization (for users who know what they're trying to do)\n\nFor [YOUR API]:\n- Main products/features: [list]\n- Common use cases: [list]\n- User goals: [list]\n\nProvide dual access paths like Twilio:\n- Top level: Products + Use Cases + Getting Started + Reference\n- Products organized by feature area\n- Use Cases organized by real-world scenarios\n\nEnsure overlap is intentional and beneficial (same content accessible two ways).\n```\n<!-- END EXAMPLE-EX-108 -->\n\n---\n\n<!-- START EXAMPLE-EX-109: \"GitHub Documentation Case Study\" -->",
            "hydration_source_header": "4.3 Case Study: Twilio API Documentation",
            "hydration_method": "title_match"
          },
          {
            "id": "github-docs-case",
            "title": "GitHub Documentation",
            "url": "docs.github.com",
            "approach": "Role-Based",
            "lines": "1475-1570",
            "retrievalQuestions": [
              "Role-based documentation example"
            ],
            "content": "**URL:** docs.github.com\n\n**Taxonomy Structure:**\n\n```text\n\u251c\u2500\u2500 Get Started\n\u2502   \u251c\u2500\u2500 Quickstart\n\u2502   \u251c\u2500\u2500 Hello World Tutorial\n\u2502   \u2514\u2500\u2500 Set Up Git\n\u251c\u2500\u2500 GitHub (Core Product Features)\n\u2502   \u251c\u2500\u2500 Repositories\n\u2502   \u251c\u2500\u2500 Pull Requests & Code Review\n\u2502   \u251c\u2500\u2500 Issues & Projects\n\u2502   \u251c\u2500\u2500 GitHub Actions (CI/CD)\n\u2502   \u251c\u2500\u2500 Packages\n\u2502   \u2514\u2500\u2500 Security\n\u251c\u2500\u2500 GitHub Enterprise (Separate Product)\n\u2502   \u251c\u2500\u2500 Installation\n\u2502   \u251c\u2500\u2500 Administration\n\u2502   \u2514\u2500\u2500 Policies\n\u251c\u2500\u2500 Developers (Technical Integration)\n\u2502   \u251c\u2500\u2500 REST API\n\u2502   \u251c\u2500\u2500 GraphQL API\n\u2502   \u251c\u2500\u2500 Webhooks\n\u2502   \u251c\u2500\u2500 GitHub Apps\n\u2502   \u2514\u2500\u2500 OAuth Apps\n\u251c\u2500\u2500 Community & Support\n\u2502   \u251c\u2500\u2500 GitHub Community Guidelines\n\u2502   \u251c\u2500\u2500 GitHub Support\n\u2502   \u2514\u2500\u2500 GitHub Skills (Learning Lab)\n\u2514\u2500\u2500 Site Policy\n    \u251c\u2500\u2500 Privacy\n    \u251c\u2500\u2500 Terms\n    \u2514\u2500\u2500 Acceptable Use\n```\n\n**What Works Well:**\n\n1. **Role-Based Segmentation**\n   - \"GitHub\" for general users\n   - \"GitHub Enterprise\" for admins\n   - \"Developers\" for integrators\n   - Clear audience targeting\n\n2. **Feature Grouping**\n   - Related features grouped logically\n   - \"Pull Requests & Code Review\" together\n   - \"Issues & Projects\" together\n   - Reflects how features are used together\n\n3. **Separate Enterprise Documentation**\n   - Doesn't clutter main docs\n   - Clear entry point for enterprise users\n   - Different content, different audience\n   - Reduces confusion\n\n4. **Developer-Focused Section**\n   - All API docs in one place\n   - Webhooks, Apps, OAuth together\n   - Technical users know where to go\n   - No mixing with user-facing docs\n\n**What Could Be Better:**\n\n- \"GitHub\" (core product) is very broad\n- Could split into \"Collaboration\" and \"Automation\"\n- Some overlap between \"GitHub Actions\" and \"Developers > Webhooks\"\n\n**Lessons for API Documentation:**\n- \u2713 Separate content by user role (end-users vs. developers)\n- \u2713 Group related features together (how they're used, not tech stack)\n- \u2713 Keep enterprise/admin docs separate from general docs\n- \u2713 Consolidate all developer/API docs in one section\n\n**AI Prompt for Similar Structure:**\n\n```text\nYou're an information architect creating role-based documentation structure.\n\nFor [YOUR PRODUCT], identify distinct user roles:\n1. General users (using the UI)\n2. Administrators (managing the system)\n3. Developers (integrating via API)\n4. [Other roles specific to your product]\n\nCreate a taxonomy where:\n- Top-level categories reflect user roles/products\n- \"Get Started\" is universal\n- Developer/API docs are consolidated separately\n- Enterprise/admin docs don't clutter general docs\n\nEnsure:\n- Each role has clear entry point\n- Minimal cross-role navigation needed\n- Related features grouped by usage patterns\n```\n\n---",
            "hydration_source_header": "4.4 Case Study: GitHub Documentation",
            "hydration_method": "title_match"
          },
          {
            "id": "netlify-docs-case",
            "title": "Netlify Documentation",
            "url": "docs.netlify.com",
            "approach": "Framework/Tech-Stack First",
            "lines": "1575-1660",
            "retrievalQuestions": [
              "Framework-first documentation example"
            ],
            "content": "**URL:** docs.netlify.com\n\n**Taxonomy Structure:**\n\n```text\n\u251c\u2500\u2500 Get Started\n\u2502   \u251c\u2500\u2500 Deploy Your First Site\n\u2502   \u251c\u2500\u2500 Connect Your Repository\n\u2502   \u2514\u2500\u2500 Configure Your Build\n\u251c\u2500\u2500 Frameworks & Tools\n\u2502   \u251c\u2500\u2500 Next.js\n\u2502   \u251c\u2500\u2500 React\n\u2502   \u251c\u2500\u2500 Vue\n\u2502   \u251c\u2500\u2500 Gatsby\n\u2502   \u2514\u2500\u2500 [20+ framework guides]\n\u251c\u2500\u2500 Core Features\n\u2502   \u251c\u2500\u2500 Build & Deploy\n\u2502   \u2502   \u251c\u2500\u2500 Continuous Deployment\n\u2502   \u2502   \u251c\u2500\u2500 Deploy Previews\n\u2502   \u2502   \u2514\u2500\u2500 Build Configuration\n\u2502   \u251c\u2500\u2500 Custom Domains & HTTPS\n\u2502   \u251c\u2500\u2500 Forms\n\u2502   \u251c\u2500\u2500 Functions (Serverless)\n\u2502   \u251c\u2500\u2500 Edge Functions\n\u2502   \u2514\u2500\u2500 Analytics\n\u251c\u2500\u2500 Integrations\n\u2502   \u251c\u2500\u2500 Git Providers (GitHub, GitLab, Bitbucket)\n\u2502   \u251c\u2500\u2500 CMS Integrations\n\u2502   \u2514\u2500\u2500 Third-Party Services\n\u251c\u2500\u2500 CLI & API\n\u2502   \u251c\u2500\u2500 Netlify CLI\n\u2502   \u251c\u2500\u2500 API Documentation\n\u2502   \u2514\u2500\u2500 Build Plugins\n\u2514\u2500\u2500 Site Management\n    \u251c\u2500\u2500 Team Management\n    \u251c\u2500\u2500 Access Control\n    \u2514\u2500\u2500 Billing\n```\n\n**What Works Well:**\n\n1. **Framework-First Approach**\n   - Recognizes users arrive with tech stack in mind\n   - \"How do I deploy my Next.js site?\" \u2192 direct answer\n   - Reduces friction for opinionated developers\n   - 20+ framework-specific guides\n\n2. **Flat, Scannable Structure**\n   - Only 2-3 levels deep\n   - Easy to scan all options\n   - Not buried in nested categories\n   - Quick to find what you need\n\n3. **Feature-Complete Categories**\n   - \"Forms\" has everything about forms\n   - \"Functions\" has all serverless content\n   - No splitting related content\n   - One-stop shop per feature\n\n4. **Clear Separation: Features vs. Management**\n   - Core Features (what you build)\n   - Site Management (admin tasks)\n   - Different mental modes\n   - Different user needs\n\n**What Could Be Better:**\n\n- \"Frameworks & Tools\" can be overwhelming (20+ items)\n- Could have \"Popular Frameworks\" and \"All Frameworks\" split\n- Some overlap between \"Build & Deploy\" and \"CLI & API\"\n\n**Lessons for API Documentation:**\n- \u2713 **Framework/tech-specific docs** if your API serves multiple tech stacks\n- \u2713 Keep structure flat (2-3 levels) for scannability\n- \u2713 One category per feature (don't split related content)\n- \u2713 Separate \"using the product\" from \"managing the account\"\n\n**AI Prompt for Tech Stack-Specific Structure:**\n\n```text\nYou're an information architect for a platform serving multiple tech stacks.\n\nYour users arrive asking: \"How do I use [YOUR PRODUCT] with [THEIR TECH]?\"\n\nCreate a taxonomy that:\n1. Features prominent framework/language-specific guides\n2. Organizes by what users are trying to build (not internal features)\n3. Keeps depth to 2-3 levels maximum\n4. Separates product features from account management\n\nFor [YOUR PLATFORM] with users using:\n- [Framework 1, Framework 2, etc.]\n- [Language 1, Language 2, etc.]\n\nProvide:\n- Top-level \"Frameworks\" or \"Languages\" category\n- Feature-based categories (not implementation-based)\n- Getting started that doesn't assume tech stack\n- Clear path from \"I use X\" to \"I want to do Y\"\n```\n<!-- END EXAMPLE-EX-109 -->\n\n---\n\n<!-- START FIGURE-DG-38: \"Organizational Approach Decision Matrix\" -->",
            "hydration_source_header": "4.5 Case Study: Netlify Documentation",
            "hydration_method": "title_match"
          }
        ],
        "organizationalApproaches": [
          {
            "id": "content-type-first",
            "title": "Content-Type First (Di\u00e1taxis)",
            "bestFor": "Complex products with diverse content",
            "lines": "1735-1740",
            "content": "**From Kubernetes:**\n- \u2705 Separate content types clearly (Concepts, Tasks, Tutorials, Reference)\n- \u2705 Task-based organization for procedural content\n- \u2705 Progressive difficulty levels\n\n**From Stripe:**\n- \u2705 Feature/product-based top level (if API is feature-rich)\n- \u2705 Keep API reference comprehensive and separate\n- \u2705 Prominent getting started section\n\n**From Twilio:**\n- \u2705 Hybrid organization (Products + Use Cases) serves dual mental models\n- \u2705 Real-world use case language matches user intent\n- \u2705 Immediate \"Try It Out\" reduces onboarding friction\n\n**From GitHub:**\n- \u2705 Role-based segmentation (general users vs. developers vs. admins)\n- \u2705 Group features by usage patterns, not technical architecture\n- \u2705 Keep enterprise/admin docs separate to reduce clutter\n\n**From Netlify:**\n- \u2705 Framework-first for opinionated developers\n- \u2705 Flat structure (2-3 levels) for scannability\n- \u2705 Feature-complete categories (don't split related content)\n\n**Universal Principles:**\n- \u2705 Clear information scent (labels indicate contents)\n- \u2705 Multiple access paths for different user needs\n- \u2705 Balanced distribution of content\n- \u2705 Separation of learning vs. reference content\n- \u2705 Scalable structure (room to grow)\n<!-- END FIGURE-DG-39 -->\n\n---\n\n<!-- START FIGURE-DG-14: \"Di\u00e1taxis Framework Overview\" -->",
            "hydration_source_header": "4.7 Lessons for Your Taxonomy",
            "hydration_method": "line_proximity"
          },
          {
            "id": "feature-product-first",
            "title": "Feature/Product First",
            "bestFor": "Feature-rich platforms",
            "lines": "1741-1745",
            "content": "**From Kubernetes:**\n- \u2705 Separate content types clearly (Concepts, Tasks, Tutorials, Reference)\n- \u2705 Task-based organization for procedural content\n- \u2705 Progressive difficulty levels\n\n**From Stripe:**\n- \u2705 Feature/product-based top level (if API is feature-rich)\n- \u2705 Keep API reference comprehensive and separate\n- \u2705 Prominent getting started section\n\n**From Twilio:**\n- \u2705 Hybrid organization (Products + Use Cases) serves dual mental models\n- \u2705 Real-world use case language matches user intent\n- \u2705 Immediate \"Try It Out\" reduces onboarding friction\n\n**From GitHub:**\n- \u2705 Role-based segmentation (general users vs. developers vs. admins)\n- \u2705 Group features by usage patterns, not technical architecture\n- \u2705 Keep enterprise/admin docs separate to reduce clutter\n\n**From Netlify:**\n- \u2705 Framework-first for opinionated developers\n- \u2705 Flat structure (2-3 levels) for scannability\n- \u2705 Feature-complete categories (don't split related content)\n\n**Universal Principles:**\n- \u2705 Clear information scent (labels indicate contents)\n- \u2705 Multiple access paths for different user needs\n- \u2705 Balanced distribution of content\n- \u2705 Separation of learning vs. reference content\n- \u2705 Scalable structure (room to grow)\n<!-- END FIGURE-DG-39 -->\n\n---\n\n<!-- START FIGURE-DG-14: \"Di\u00e1taxis Framework Overview\" -->",
            "hydration_source_header": "4.7 Lessons for Your Taxonomy",
            "hydration_method": "line_proximity"
          },
          {
            "id": "hybrid-product-usecase",
            "title": "Hybrid (Product + Use Case)",
            "bestFor": "APIs with clear use cases",
            "lines": "1746-1750",
            "content": "**From Kubernetes:**\n- \u2705 Separate content types clearly (Concepts, Tasks, Tutorials, Reference)\n- \u2705 Task-based organization for procedural content\n- \u2705 Progressive difficulty levels\n\n**From Stripe:**\n- \u2705 Feature/product-based top level (if API is feature-rich)\n- \u2705 Keep API reference comprehensive and separate\n- \u2705 Prominent getting started section\n\n**From Twilio:**\n- \u2705 Hybrid organization (Products + Use Cases) serves dual mental models\n- \u2705 Real-world use case language matches user intent\n- \u2705 Immediate \"Try It Out\" reduces onboarding friction\n\n**From GitHub:**\n- \u2705 Role-based segmentation (general users vs. developers vs. admins)\n- \u2705 Group features by usage patterns, not technical architecture\n- \u2705 Keep enterprise/admin docs separate to reduce clutter\n\n**From Netlify:**\n- \u2705 Framework-first for opinionated developers\n- \u2705 Flat structure (2-3 levels) for scannability\n- \u2705 Feature-complete categories (don't split related content)\n\n**Universal Principles:**\n- \u2705 Clear information scent (labels indicate contents)\n- \u2705 Multiple access paths for different user needs\n- \u2705 Balanced distribution of content\n- \u2705 Separation of learning vs. reference content\n- \u2705 Scalable structure (room to grow)\n<!-- END FIGURE-DG-39 -->\n\n---\n\n<!-- START FIGURE-DG-14: \"Di\u00e1taxis Framework Overview\" -->",
            "hydration_source_header": "4.7 Lessons for Your Taxonomy",
            "hydration_method": "line_proximity"
          },
          {
            "id": "role-based-approach",
            "title": "Role-Based",
            "bestFor": "Multi-audience products",
            "lines": "1751-1755",
            "content": "**From Kubernetes:**\n- \u2705 Separate content types clearly (Concepts, Tasks, Tutorials, Reference)\n- \u2705 Task-based organization for procedural content\n- \u2705 Progressive difficulty levels\n\n**From Stripe:**\n- \u2705 Feature/product-based top level (if API is feature-rich)\n- \u2705 Keep API reference comprehensive and separate\n- \u2705 Prominent getting started section\n\n**From Twilio:**\n- \u2705 Hybrid organization (Products + Use Cases) serves dual mental models\n- \u2705 Real-world use case language matches user intent\n- \u2705 Immediate \"Try It Out\" reduces onboarding friction\n\n**From GitHub:**\n- \u2705 Role-based segmentation (general users vs. developers vs. admins)\n- \u2705 Group features by usage patterns, not technical architecture\n- \u2705 Keep enterprise/admin docs separate to reduce clutter\n\n**From Netlify:**\n- \u2705 Framework-first for opinionated developers\n- \u2705 Flat structure (2-3 levels) for scannability\n- \u2705 Feature-complete categories (don't split related content)\n\n**Universal Principles:**\n- \u2705 Clear information scent (labels indicate contents)\n- \u2705 Multiple access paths for different user needs\n- \u2705 Balanced distribution of content\n- \u2705 Separation of learning vs. reference content\n- \u2705 Scalable structure (room to grow)\n<!-- END FIGURE-DG-39 -->\n\n---\n\n<!-- START FIGURE-DG-14: \"Di\u00e1taxis Framework Overview\" -->",
            "hydration_source_header": "4.7 Lessons for Your Taxonomy",
            "hydration_method": "line_proximity"
          },
          {
            "id": "framework-techstack-first",
            "title": "Framework/Tech-Stack First",
            "bestFor": "Platform-agnostic tools",
            "lines": "1756-1760",
            "content": "The Di\u00e1taxis framework provides a powerful lens for organizing documentation. Let's learn how to integrate it with AI assistance.\n\n### 5.1 Understanding Di\u00e1taxis\n\n**The Four Content Types:**\n\n<CardGroup cols={2}>\n  <Card title=\"Tutorials\" icon=\"graduation-cap\">\n    **Learning-oriented**\n    \n    Teaches through hands-on practice\n    \n    **Examples:** \"Build Your First API Integration\", \"Getting Started Tutorial\"\n  </Card>\n  \n  <Card title=\"How-to Guides\" icon=\"screwdriver-wrench\">\n    **Task-oriented**\n    \n    Solves specific problems\n    \n    **Examples:** \"How to Handle Failed Payments\", \"Set Up Webhooks\"\n  </Card>\n  \n  <Card title=\"Reference\" icon=\"book\">\n    **Information-oriented**\n    \n    Technical descriptions\n    \n    **Examples:** \"API Endpoint Reference\", \"Error Codes\", \"Configuration Options\"\n  </Card>\n  \n  <Card title=\"Explanations\" icon=\"lightbulb\">\n    **Understanding-oriented**\n    \n    Clarifies and discusses\n    \n    **Examples:** \"Understanding OAuth 2.0\", \"How Webhooks Work\", \"Why Use Versioning\"\n  </Card>\n</CardGroup>\n\n---\n\n### 5.2 Two Approaches to Di\u00e1taxis Integration\n\n<!-- START EXAMPLE-EX-110: \"Di\u00e1taxis-First Approach\" -->\n**Approach 1: Di\u00e1taxis-First (Content Type at Top Level)**\n\n```text\n\u251c\u2500\u2500 Tutorials (Learning Path)\n\u2502   \u251c\u2500\u2500 Getting Started with API\n\u2502   \u251c\u2500\u2500 Build a Payment Integration\n\u2502   \u2514\u2500\u2500 Implement Webhooks\n\u251c\u2500\u2500 How-to Guides (Task Solutions)\n\u2502   \u251c\u2500\u2500 Handle Failed Payments\n\u2502   \u251c\u2500\u2500 Set Up Authentication\n\u2502   \u2514\u2500\u2500 Configure Retry Logic\n\u251c\u2500\u2500 Reference (Technical Specs)\n\u2502   \u251c\u2500\u2500 API Endpoints\n\u2502   \u251c\u2500\u2500 Error Codes\n\u2502   \u2514\u2500\u2500 SDKs\n\u2514\u2500\u2500 Explanations (Understanding)\n    \u251c\u2500\u2500 OAuth 2.0 Explained\n    \u251c\u2500\u2500 Understanding Rate Limits\n    \u2514\u2500\u2500 Payment Flow Architecture\n```\n\n**Pros:**\n- Very clear content type separation\n- Users know exactly what format to expect\n- Easy to maintain consistency\n\n**Cons:**\n- Users must know content type they need\n- Harder for mixed-need scenarios (learning + reference)\n- Less aligned with feature-based mental models\n\n**Best For:** Education-focused documentation, learning platforms\n<!-- END EXAMPLE-EX-110 -->\n\n---\n\n<!-- START EXAMPLE-EX-111: \"Feature-First with Di\u00e1taxis Approach\" -->\n**Approach 2: Feature-First with Di\u00e1taxis at Lower Levels (Recommended for APIs)**\n\n```text\n\u251c\u2500\u2500 Get Started\n\u2502   \u251c\u2500\u2500 Installation [Tutorial]\n\u2502   \u251c\u2500\u2500 First API Call [Tutorial]\n\u2502   \u2514\u2500\u2500 Core Concepts [Explanation]\n\u251c\u2500\u2500 Authentication\n\u2502   \u251c\u2500\u2500 OAuth Tutorial [Tutorial]\n\u2502   \u251c\u2500\u2500 How to Validate Tokens [How-to]\n\u2502   \u251c\u2500\u2500 Auth Endpoints [Reference]\n\u2502   \u2514\u2500\u2500 Understanding OAuth [Explanation]\n\u251c\u2500\u2500 Payments\n\u2502   \u251c\u2500\u2500 Payment Integration Tutorial [Tutorial]\n\u2502   \u251c\u2500\u2500 How to Handle Refunds [How-to]\n\u2502   \u251c\u2500\u2500 Payment API Reference [Reference]\n\u2502   \u2514\u2500\u2500 Payment Flows Explained [Explanation]\n\u2514\u2500\u2500 API Reference [Reference]\n    \u2514\u2500\u2500 Complete endpoint docs\n```\n\n**Pros:**\n- Aligned with user mental models (feature-based)\n- All content for a feature in one place\n- Supports mixed workflows (learn + implement + reference)\n\n**Cons:**\n- Requires disciplined labeling of content types\n- Risk of mixing types if not careful\n\n**Best For:** API documentation, feature-rich products\n<!-- END EXAMPLE-EX-111 -->\n<!-- END FIGURE-DG-14 -->\n\n---\n\n<!-- START REFERENCE-PP-7: \"Di\u00e1taxis Integration Prompt Pattern\" -->\n### 5.3 Di\u00e1taxis Integration Prompt\n\n```text\nYou're an information architect who specializes in the Di\u00e1taxis framework.\n\nCreate a 3-level taxonomy that integrates all four Di\u00e1taxis content types.\n\nContext:\n- Documentation for: [YOUR PRODUCT]\n- Content: [PAGE COUNT]\n  - X tutorials (learning-oriented)\n  - Y how-to guides (task-oriented)\n  - Z reference pages (information-oriented)\n  - W explanations (understanding-oriented)\n  \nFeatures/Topics:\n- [List main features or topics]\n\nApproach: Feature-first with Di\u00e1taxis at level 3\n- Level 1: Product features or user tasks\n- Level 2: Sub-features or aspects\n- Level 3: Content items tagged with [Tutorial], [How-to], [Reference], [Explanation]\n\nRequirements:\n- Each major feature should have multiple content types\n- Balance content types within each feature (not just reference)\n- Clear labels indicating both feature and content type\n- Support both learning paths and quick reference lookup\n\nOutput:\n1. Complete 3-level taxonomy with content type tags\n2. Content type distribution analysis per feature\n3. Sample user journeys through the structure\n4. Notes on maintaining balance as content grows\n```\n<!-- END REFERENCE-PP-7 -->\n\n---\n\n<!-- START EXAMPLE-EX-112: \"CloudStore API Tutorial Walkthrough\" -->",
            "hydration_source_header": "5. Di\u00e1taxis Framework Integration",
            "hydration_method": "line_proximity"
          },
          {
            "id": "task-goal-based",
            "title": "Task/Goal-Based",
            "bestFor": "Workflow-driven products",
            "lines": "1761-1765",
            "content": "The Di\u00e1taxis framework provides a powerful lens for organizing documentation. Let's learn how to integrate it with AI assistance.\n\n### 5.1 Understanding Di\u00e1taxis\n\n**The Four Content Types:**\n\n<CardGroup cols={2}>\n  <Card title=\"Tutorials\" icon=\"graduation-cap\">\n    **Learning-oriented**\n    \n    Teaches through hands-on practice\n    \n    **Examples:** \"Build Your First API Integration\", \"Getting Started Tutorial\"\n  </Card>\n  \n  <Card title=\"How-to Guides\" icon=\"screwdriver-wrench\">\n    **Task-oriented**\n    \n    Solves specific problems\n    \n    **Examples:** \"How to Handle Failed Payments\", \"Set Up Webhooks\"\n  </Card>\n  \n  <Card title=\"Reference\" icon=\"book\">\n    **Information-oriented**\n    \n    Technical descriptions\n    \n    **Examples:** \"API Endpoint Reference\", \"Error Codes\", \"Configuration Options\"\n  </Card>\n  \n  <Card title=\"Explanations\" icon=\"lightbulb\">\n    **Understanding-oriented**\n    \n    Clarifies and discusses\n    \n    **Examples:** \"Understanding OAuth 2.0\", \"How Webhooks Work\", \"Why Use Versioning\"\n  </Card>\n</CardGroup>\n\n---\n\n### 5.2 Two Approaches to Di\u00e1taxis Integration\n\n<!-- START EXAMPLE-EX-110: \"Di\u00e1taxis-First Approach\" -->\n**Approach 1: Di\u00e1taxis-First (Content Type at Top Level)**\n\n```text\n\u251c\u2500\u2500 Tutorials (Learning Path)\n\u2502   \u251c\u2500\u2500 Getting Started with API\n\u2502   \u251c\u2500\u2500 Build a Payment Integration\n\u2502   \u2514\u2500\u2500 Implement Webhooks\n\u251c\u2500\u2500 How-to Guides (Task Solutions)\n\u2502   \u251c\u2500\u2500 Handle Failed Payments\n\u2502   \u251c\u2500\u2500 Set Up Authentication\n\u2502   \u2514\u2500\u2500 Configure Retry Logic\n\u251c\u2500\u2500 Reference (Technical Specs)\n\u2502   \u251c\u2500\u2500 API Endpoints\n\u2502   \u251c\u2500\u2500 Error Codes\n\u2502   \u2514\u2500\u2500 SDKs\n\u2514\u2500\u2500 Explanations (Understanding)\n    \u251c\u2500\u2500 OAuth 2.0 Explained\n    \u251c\u2500\u2500 Understanding Rate Limits\n    \u2514\u2500\u2500 Payment Flow Architecture\n```\n\n**Pros:**\n- Very clear content type separation\n- Users know exactly what format to expect\n- Easy to maintain consistency\n\n**Cons:**\n- Users must know content type they need\n- Harder for mixed-need scenarios (learning + reference)\n- Less aligned with feature-based mental models\n\n**Best For:** Education-focused documentation, learning platforms\n<!-- END EXAMPLE-EX-110 -->\n\n---\n\n<!-- START EXAMPLE-EX-111: \"Feature-First with Di\u00e1taxis Approach\" -->\n**Approach 2: Feature-First with Di\u00e1taxis at Lower Levels (Recommended for APIs)**\n\n```text\n\u251c\u2500\u2500 Get Started\n\u2502   \u251c\u2500\u2500 Installation [Tutorial]\n\u2502   \u251c\u2500\u2500 First API Call [Tutorial]\n\u2502   \u2514\u2500\u2500 Core Concepts [Explanation]\n\u251c\u2500\u2500 Authentication\n\u2502   \u251c\u2500\u2500 OAuth Tutorial [Tutorial]\n\u2502   \u251c\u2500\u2500 How to Validate Tokens [How-to]\n\u2502   \u251c\u2500\u2500 Auth Endpoints [Reference]\n\u2502   \u2514\u2500\u2500 Understanding OAuth [Explanation]\n\u251c\u2500\u2500 Payments\n\u2502   \u251c\u2500\u2500 Payment Integration Tutorial [Tutorial]\n\u2502   \u251c\u2500\u2500 How to Handle Refunds [How-to]\n\u2502   \u251c\u2500\u2500 Payment API Reference [Reference]\n\u2502   \u2514\u2500\u2500 Payment Flows Explained [Explanation]\n\u2514\u2500\u2500 API Reference [Reference]\n    \u2514\u2500\u2500 Complete endpoint docs\n```\n\n**Pros:**\n- Aligned with user mental models (feature-based)\n- All content for a feature in one place\n- Supports mixed workflows (learn + implement + reference)\n\n**Cons:**\n- Requires disciplined labeling of content types\n- Risk of mixing types if not careful\n\n**Best For:** API documentation, feature-rich products\n<!-- END EXAMPLE-EX-111 -->\n<!-- END FIGURE-DG-14 -->\n\n---\n\n<!-- START REFERENCE-PP-7: \"Di\u00e1taxis Integration Prompt Pattern\" -->\n### 5.3 Di\u00e1taxis Integration Prompt\n\n```text\nYou're an information architect who specializes in the Di\u00e1taxis framework.\n\nCreate a 3-level taxonomy that integrates all four Di\u00e1taxis content types.\n\nContext:\n- Documentation for: [YOUR PRODUCT]\n- Content: [PAGE COUNT]\n  - X tutorials (learning-oriented)\n  - Y how-to guides (task-oriented)\n  - Z reference pages (information-oriented)\n  - W explanations (understanding-oriented)\n  \nFeatures/Topics:\n- [List main features or topics]\n\nApproach: Feature-first with Di\u00e1taxis at level 3\n- Level 1: Product features or user tasks\n- Level 2: Sub-features or aspects\n- Level 3: Content items tagged with [Tutorial], [How-to], [Reference], [Explanation]\n\nRequirements:\n- Each major feature should have multiple content types\n- Balance content types within each feature (not just reference)\n- Clear labels indicating both feature and content type\n- Support both learning paths and quick reference lookup\n\nOutput:\n1. Complete 3-level taxonomy with content type tags\n2. Content type distribution analysis per feature\n3. Sample user journeys through the structure\n4. Notes on maintaining balance as content grows\n```\n<!-- END REFERENCE-PP-7 -->\n\n---\n\n<!-- START EXAMPLE-EX-112: \"CloudStore API Tutorial Walkthrough\" -->",
            "hydration_source_header": "5. Di\u00e1taxis Framework Integration",
            "hydration_method": "line_proximity"
          }
        ],
        "tutorials": [
          {
            "id": "cloudstore-tutorial",
            "title": "Building a Taxonomy Tutorial (CloudStore)",
            "steps": 6,
            "lines": "1945-2280",
            "retrievalQuestions": [
              "Step-by-step taxonomy creation",
              "Tutorial for building taxonomy with AI"
            ],
            "content": "**Context:**\nYou're creating documentation for \"CloudStore API\" - a cloud storage API with features for:\n- File upload/download\n- Sharing and permissions\n- Versioning\n- Search and metadata\n- Webhooks for events\n\n**Content Inventory:** 60 pages\n- 12 tutorials\n- 20 how-to guides\n- 20 reference pages\n- 8 explanations\n\n**Target Users:** \n- Backend developers (70%)\n- Frontend developers (30%)\n- Mix of junior (40%) and senior (60%)\n\n**Business Goals:**\n- Reduce time-to-first-upload to under 10 minutes\n- Improve documentation satisfaction from 6.8 to 8.5\n- Reduce support tickets about \"how to\" questions by 40%\n\n---",
            "hydration_source_header": "Tutorial Scenario",
            "hydration_method": "line_proximity"
          }
        ],
        "tutorialSteps": [
          {
            "id": "step-1-generate-initial",
            "title": "Step 1: Generate Initial Taxonomy",
            "action": "AI generation from content sample",
            "lines": "1960-2100",
            "content": "**The Content Sample (20 of 60 pages):**\n\n```text\n1. \"Getting Started with CloudStore\"\n2. \"Upload Your First File\"\n3. \"File Upload API Endpoint\"\n4. \"Understanding Storage Classes\"\n5. \"How to Set File Permissions\"\n6. \"Share Files with Public Links\"\n7. \"File Object Reference\"\n8. \"Implementing File Versioning\"\n9. \"Search API Reference\"\n10. \"How to Search Files by Metadata\"\n11. \"Understanding Webhook Events\"\n12. \"Your First Webhook Integration\"\n13. \"Webhook Events Reference\"\n14. \"Error Codes Reference\"\n15. \"How to Handle Upload Failures\"\n16. \"File Encryption Explained\"\n17. \"Batch Upload Tutorial\"\n18. \"Permission Levels Reference\"\n19. \"How to Restore Previous Versions\"\n20. \"Why We Use Multipart Uploads\"\n```\n\n**Your Prompt:**\n\n```text\nYou're an information architect specializing in API documentation taxonomies \nand the Di\u00e1taxis framework.\n\nGenerate a 3-level taxonomy for CloudStore API documentation based on this \ncontent sample (20 of 60 total pages).\n\nContent sample:\n1. \"Getting Started with CloudStore\"\n2. \"Upload Your First File\"\n3. \"File Upload API Endpoint\"\n4. \"Understanding Storage Classes\"\n5. \"How to Set File Permissions\"\n6. \"Share Files with Public Links\"\n7. \"File Object Reference\"\n8. \"Implementing File Versioning\"\n9. \"Search API Reference\"\n10. \"How to Search Files by Metadata\"\n11. \"Understanding Webhook Events\"\n12. \"Your First Webhook Integration\"\n13. \"Webhook Events Reference\"\n14. \"Error Codes Reference\"\n15. \"How to Handle Upload Failures\"\n16. \"File Encryption Explained\"\n17. \"Batch Upload Tutorial\"\n18. \"Permission Levels Reference\"\n19. \"How to Restore Previous Versions\"\n20. \"Why We Use Multipart Uploads\"\n\nFull content inventory context:\n- 60 total pages: 12 tutorials, 20 how-tos, 20 reference, 8 explanations\n- Features: File management, sharing/permissions, versioning, search, webhooks\n- Users: Backend (70%) and frontend (30%) developers, 40% junior, 60% senior\n- Business goal: Reduce time to first upload to under 10 minutes\n\nOrganizational requirements:\n- Level 1: Feature-based (what users want to do)\n- Level 2: Mix of sub-features and content types as appropriate\n- Level 3: Specific content items\n- Include clear getting started section\n- Keep API reference consolidated but accessible\n- Make troubleshooting easy to find\n\nConstraints:\n- Top level: 5-7 categories\n- Maximum 3 levels\n- Labels under 30 characters\n- Balanced distribution (no category >40% of content)\n- Support both learning path and task-based access\n\nOutput:\n- Complete taxonomy with all 60 pages placed (estimate counts for non-sample pages)\n- Page counts at each level in (parentheses)\n- Brief rationale for top-level structure\n- Note any content that was hard to place\n- Indicate content types with [Tutorial], [How-to], [Reference], [Explanation] tags\n```\n\n---\n\n**AI Output (Example):**\n\n```text\nCloudStore API Documentation Taxonomy\n\n\u251c\u2500\u2500 \ud83d\udcd8 Get Started (10 pages, 17%)\n\u2502   Purpose: Guide new users from setup to first successful operations\n\u2502   \u251c\u2500\u2500 Quickstart\n\u2502   \u2502   \u251c\u2500\u2500 Getting Started with CloudStore [Tutorial] \u23f1\ufe0f 8min\n\u2502   \u2502   \u251c\u2500\u2500 Upload Your First File [Tutorial] \u23f1\ufe0f 5min\n\u2502   \u2502   \u2514\u2500\u2500 Your First Webhook [Tutorial] \u23f1\ufe0f 12min\n\u2502   \u2514\u2500\u2500 Core Concepts\n\u2502       \u251c\u2500\u2500 Understanding Storage Classes [Explanation]\n\u2502       \u251c\u2500\u2500 Why Multipart Uploads [Explanation]\n\u2502       \u2514\u2500\u2500 File Encryption Explained [Explanation]\n\u2502\n\u251c\u2500\u2500 \ud83d\udcc1 File Management (20 pages, 33%)\n\u2502   Purpose: Upload, download, version, and manage files\n\u2502   \u251c\u2500\u2500 Upload & Download\n\u2502   \u2502   \u251c\u2500\u2500 Batch Upload Tutorial [Tutorial]\n\u2502   \u2502   \u251c\u2500\u2500 How to Handle Upload Failures [How-to] \u26a0\ufe0f\n\u2502   \u2502   \u251c\u2500\u2500 File Upload Endpoint [Reference]\n\u2502   \u2502   \u2514\u2500\u2500 [Download guides, streaming]\n\u2502   \u251c\u2500\u2500 File Versioning\n\u2502   \u2502   \u251c\u2500\u2500 Implementing Versioning [Tutorial]\n\u2502   \u2502   \u251c\u2500\u2500 How to Restore Versions [How-to]\n\u2502   \u2502   \u2514\u2500\u2500 [Version API, limits]\n\u2502   \u2514\u2500\u2500 File Objects\n\u2502       \u2514\u2500\u2500 File Object Reference [Reference]\n\u2502\n\u251c\u2500\u2500 \ud83d\udd10 Sharing & Permissions (12 pages, 20%)\n\u2502   Purpose: Control access and collaborate on files\n\u2502   \u251c\u2500\u2500 How to Set Permissions [How-to]\n\u2502   \u251c\u2500\u2500 Share with Public Links [How-to]\n\u2502   \u251c\u2500\u2500 Permission Levels Reference [Reference]\n\u2502   \u2514\u2500\u2500 [Team sharing, expiring links]\n\u2502\n\u251c\u2500\u2500 \ud83d\udd0d Search & Metadata (8 pages, 13%)\n\u2502   Purpose: Find and organize your content\n\u2502   \u251c\u2500\u2500 How to Search by Metadata [How-to]\n\u2502   \u251c\u2500\u2500 Search API Reference [Reference]\n\u2502   \u2514\u2500\u2500 [Custom metadata, filters]\n\u2502\n\u251c\u2500\u2500 \ud83d\udd14 Webhooks (6 pages, 10%)\n\u2502   Purpose: Real-time event notifications\n\u2502   \u251c\u2500\u2500 Understanding Webhook Events [Explanation]\n\u2502   \u251c\u2500\u2500 Webhook Events Reference [Reference]\n\u2502   \u2514\u2500\u2500 [Setup guides, retry logic]\n\u2502\n\u2514\u2500\u2500 \ud83d\udcda Troubleshooting & Reference (4 pages, 7%)\n    Purpose: Debug issues and quick API lookup\n    \u251c\u2500\u2500 Error Codes Reference [Reference]\n    \u2514\u2500\u2500 [Common issues, debugging]\n\nRATIONALE:\n- Feature-based top level (matches \"I want to [upload/share/search]\" mental model)\n- Get Started prominently placed (business goal: <10min to first upload)\n- Balanced distribution (no category >35%)\n- Di\u00e1taxis types integrated at level 3 (supports multiple user needs)\n- Consolidated troubleshooting (easy to find when needed)\n\nCONTENT PLACEMENT NOTES:\n- \"Understanding Webhook Events\" could go in Get Started or Webhooks \n  \u2192 Placed in Webhooks (primary home), linked from Get Started\n- \"Error Codes Reference\" could go in Troubleshooting or API Reference\n  \u2192 Placed in Troubleshooting (more discoverable when debugging)\n```\n\n---\n\n<!-- START EXAMPLE-EX-113: \"Taxonomy Validation Walkthrough\" -->",
            "hydration_source_header": "Step 1: Generate Initial Taxonomy from Content Sample",
            "hydration_method": "title_match"
          },
          {
            "id": "step-2-validate-principles",
            "title": "Step 2: Validate Against IA Principles",
            "action": "5-check validation",
            "lines": "2105-2165",
            "content": "Use the 5-Check System from earlier:\n\n```text\nDEPTH CHECK\n\u2611 3 levels maximum - PASS\n\u2611 Appropriate for 60 pages - PASS\n\u2713 DEPTH: GOOD\n\nBALANCE CHECK\n\u2611 Largest category (File Management) at 33% - ACCEPTABLE\n\u2611 Distribution: 17%, 33%, 20%, 13%, 10%, 7% - REASONABLE\n\u26a0\ufe0f \"Troubleshooting\" at 7% (4 pages) is small but acceptable\n\u2713 BALANCE: GOOD\n\nGRANULARITY CHECK\n\u26a0\ufe0f Mixed principles at top level:\n   - Get Started (stage-based)\n   - Middle categories (feature-based)\n   - Troubleshooting (support-based)\n\u26a0\ufe0f GRANULARITY: REVIEW NEEDED\n\nEXCLUSIVITY CHECK\n\u26a0\ufe0f \"Understanding Webhook Events\" noted as ambiguous\n\u26a0\ufe0f \"Error Codes Reference\" could go multiple places\n\u2713 AI acknowledged these and made choices\n\u26a0\ufe0f EXCLUSIVITY: MINOR ISSUES\n\nLABEL CLARITY CHECK\n\u2713 All labels clear and under 30 characters\n\u2713 Emojis add visual distinction (optional)\n\u26a0\ufe0f \"Troubleshooting & Reference\" combines two concepts\n\u26a0\ufe0f LABELS: ONE ISSUE\n\nOVERALL:\nGood first draft with 3 issues to address in refinement.\n```\n<!-- END EXAMPLE-EX-113 -->\n\n---\n\n<!-- START EXAMPLE-EX-114: \"Taxonomy Refinement\" -->",
            "hydration_source_header": "Step 2: Validate Against IA Principles",
            "hydration_method": "title_match"
          },
          {
            "id": "step-3-refine-issues",
            "title": "Step 3: Refine Based on Issues",
            "action": "Iterative improvement",
            "lines": "2170-2200",
            "content": "**Refinement Prompt:**\n\n```text\nYou're refining a taxonomy based on validation feedback.\n\nOriginal taxonomy:\n[Paste AI output from Step 1]\n\nIssues to fix:\n1. \"Troubleshooting & Reference\" combines two distinct purposes (HIGH PRIORITY)\n   \u2192 Split or rename more specifically\n   \n2. Mixed organizational principles at top level (MEDIUM PRIORITY)\n   \u2192 Acceptable if justified, OR make consistent\n   \n3. Ambiguous content placement for edge cases (LOW PRIORITY)\n   \u2192 Establish clear rules for where these go\n\nRefinement requirements:\n- Fix the \"Troubleshooting & Reference\" issue (choose best solution)\n- Justify OR fix the mixed organizational principles\n- Establish clear placement rules for ambiguous content\n- Add Docusaurus implementation notes\n- Maintain all other strengths (balance, Di\u00e1taxis integration, etc.)\n\nProvide:\n- Refined taxonomy\n- Explanation of changes and rationale\n- Implementation recommendations\n- Migration notes (what changed)\n```\n\n---\n\n**AI Refined Output:**\n\n```text\nCloudStore API Documentation Taxonomy (REFINED v2)\n\n\u251c\u2500\u2500 \ud83d\udcd8 Get Started (10 pages, 17%)\n\u2502   Purpose: Onboarding path - zero to first successful operation in <10 minutes\n\u2502   \u251c\u2500\u2500 Quickstart\n\u2502   \u2502   \u251c\u2500\u2500 Getting Started with CloudStore [Tutorial] \u23f1\ufe0f 8min\n\u2502   \u2502   \u251c\u2500\u2500 Upload Your First File [Tutorial] \u23f1\ufe0f 5min\n\u2502   \u2502   \u2514\u2500\u2500 Your First Webhook [Tutorial] \u23f1\ufe0f 12min\n\u2502   \u2514\u2500\u2500 Core Concepts\n\u2502       \u251c\u2500\u2500 Understanding Storage Classes [Explanation]\n\u2502       \u251c\u2500\u2500 Why Multipart Uploads [Explanation]\n\u2502       \u251c\u2500\u2500 File Encryption Explained [Explanation]\n\u2502       \u2514\u2500\u2500 [API Overview, Auth Basics]\n\u2502\n\u251c\u2500\u2500 \ud83d\udcc1 File Management (20 pages, 33%)\n\u2502   Purpose: Upload, download, version, and manage files\n\u2502   \u251c\u2500\u2500 Upload & Download\n\u2502   \u2502   \u251c\u2500\u2500 Batch Upload Tutorial [Tutorial]\n\u2502   \u2502   \u251c\u2500\u2500 How to Handle Upload Failures [How-to] \u26a0\ufe0f\n\u2502   \u2502   \u251c\u2500\u2500 File Upload Endpoint [Reference]\n\u2502   \u2502   \u2514\u2500\u2500 [Download guides, streaming]\n\u2502   \u251c\u2500\u2500 File Versioning\n\u2502   \u2502   \u251c\u2500\u2500 Implementing Versioning [Tutorial]\n\u2502   \u2502   \u251c\u2500\u2500 How to Restore Versions [How-to]\n\u2502   \u2502   \u2514\u2500\u2500 [Version API, limits]\n\u2502   \u2514\u2500\u2500 File Objects\n\u2502       \u251c\u2500\u2500 File Object Reference [Reference]\n\u2502       \u2514\u2500\u2500 [Metadata, properties]\n\u2502\n\u251c\u2500\u2500 \ud83d\udd10 Sharing & Permissions (12 pages, 20%)\n\u2502   Purpose: Control access and collaborate on files\n\u2502   \u251c\u2500\u2500 How to Set Permissions [How-to]\n\u2502   \u251c\u2500\u2500 Share with Public Links [How-to]\n\u2502   \u251c\u2500\u2500 Permission Levels Reference [Reference]\n\u2502   \u2514\u2500\u2500 [Team sharing, expiring links, inheritance]\n\u2502\n\u251c\u2500\u2500 \ud83d\udd0d Search & Metadata (8 pages, 13%)\n\u2502   Purpose: Find and organize your content\n\u2502   \u251c\u2500\u2500 How to Search by Metadata [How-to]\n\u2502   \u251c\u2500\u2500 Search API Reference [Reference]\n\u2502   \u2514\u2500\u2500 [Custom metadata, filters, indexing]\n\u2502\n\u251c\u2500\u2500 \ud83d\udd14 Webhooks (6 pages, 10%)\n\u2502   Purpose: Real-time event notifications\n\u2502   \u251c\u2500\u2500 Understanding Webhook Events [Explanation]\n\u2502   \u251c\u2500\u2500 Webhook Events Reference [Reference]\n\u2502   \u2514\u2500\u2500 [Setup guides, retry logic, security]\n\u2502\n\u2514\u2500\u2500 \ud83d\udcda API Reference (4 pages, 7%)\n    Purpose: Complete technical specifications and troubleshooting\n    \u251c\u2500\u2500 Complete Endpoint Reference\n    \u251c\u2500\u2500 Error Codes & Messages\n    \u251c\u2500\u2500 Common Issues & Solutions\n    \u2514\u2500\u2500 [Rate limits, pagination, versioning]\n\nCHANGES MADE:\n\n1. \u2705 RENAMED: \"Troubleshooting & Reference\" \u2192 \"API Reference\"\n   - Rationale: Consolidated all reference + troubleshooting under single, clear label\n   - Troubleshooting now explicitly included (\"Common Issues & Solutions\")\n   - Primary purpose: Quick technical lookup + debugging\n\n2. \u2705 JUSTIFIED: Mixed organizational principles\n   - Get Started: Stage-based (onboarding journey)\n   - Middle sections: Feature-based (primary user mental model)\n   - API Reference: Access-based (quick lookup hub)\n   - Rationale: Hybrid approach serves multiple user needs effectively\n   - Precedent: Industry standard (Stripe, Kubernetes use similar pattern)\n\n3. \u2705 PLACEMENT RULES ESTABLISHED:\n   - \"Understanding Webhook Events\" \u2192 PRIMARY: Webhooks (conceptual home)\n     SECONDARY: Link from Get Started > Core Concepts\n   - \"Error Codes\" \u2192 PRIMARY: API Reference (technical lookup)\n     SECONDARY: Contextual links from how-to guides\n   - General rule: Choose primary home based on most common access pattern,\n     cross-link from secondary paths\n\nIMPLEMENTATION NOTES (Docusaurus):\n\nsidebar.js structure:\n```javascript\nmodule.exports = {\n  docs: [\n    {\n      type: 'category',\n      label: '\ud83d\udcd8 Get Started',\n      collapsed: false, // Always expanded\n      items: ['quickstart/intro', 'quickstart/first-upload', ...]\n    },\n    // Feature categories collapsed by default\n    {\n      type: 'category',\n      label: '\ud83d\udcc1 File Management',\n      items: ['files/upload', 'files/versioning', ...]\n    },\n    // ... more categories\n    {\n      type: 'category',\n      label: '\ud83d\udcda API Reference',\n      items: ['reference/endpoints', 'reference/errors', ...]\n    }\n  ]\n};\n```\n\nMIGRATION NOTES:\n- \"Troubleshooting & Reference\" renamed to \"API Reference\"\n- No page moves required (content stays in same structure)\n- Update navigation labels in config\n- Add cross-links as specified in placement rules\n\n<!-- END EXAMPLE-EX-114 -->\n\n---\n\n<!-- START EXAMPLE-EX-115: \"User Scenario Testing\" -->",
            "hydration_source_header": "Step 3: Refine with Constraints",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "step-4-add-di\u00e1taxis",
            "title": "Step 4: Add Di\u00e1taxis Tags",
            "action": "Content type integration",
            "lines": "2205-2230",
            "hydration_status": "failed"
          },
          {
            "id": "step-5-user-journey",
            "title": "Step 5: Map User Journeys",
            "action": "Path validation",
            "lines": "2235-2255",
            "hydration_status": "failed"
          },
          {
            "id": "step-6-finalize",
            "title": "Step 6: Finalize and Document",
            "action": "Documentation",
            "lines": "2260-2280",
            "hydration_status": "failed"
          }
        ],
        "checklists": [
          {
            "id": "red-flags-checklist",
            "title": "Red Flags Checklist",
            "items": "6 red flags",
            "time": "5 min",
            "lines": "555-590",
            "content": "When validating taxonomy balance, watch for these **automatic red flags**:\n\n```\n\ud83d\udeab RED FLAG #1: Mega-Category (>40%)\n\u251c\u2500\u2500 Indicates: Category is too broad, mixing multiple concepts\n\u2514\u2500\u2500 Fix: Split into 2-3 specific subcategories\n\n\ud83d\udeab RED FLAG #2: Micro-Category (<5%)\n\u251c\u2500\u2500 Indicates: Not enough content to warrant top-level status\n\u2514\u2500\u2500 Fix: Combine with related category OR demote to subcategory\n\n\ud83d\udeab RED FLAG #3: Catch-All Label (\"Other\", \"Miscellaneous\", \"Everything Else\")\n\u251c\u2500\u2500 Indicates: Lack of clear organizational principle\n\u2514\u2500\u2500 Fix: Identify patterns in \"other\" content, create specific categories\n\n\ud83d\udeab RED FLAG #4: Massive Spread (70+ percentage point gap)\n\u251c\u2500\u2500 Example: Smallest=5%, Largest=75% (70-point spread)\n\u2514\u2500\u2500 Fix: Split large categories, combine/demote small ones\n\n\ud83d\udeab RED FLAG #5: Ratio Imbalance (>10:1 ratio between largest and smallest)\n\u251c\u2500\u2500 Example: Largest=60 pages, Smallest=5 pages (12:1 ratio)\n\u2514\u2500\u2500 Fix: Indicates granularity mismatch, restructure levels\n\n\u26a0\ufe0f WARNING: Future Growth Pattern\n\u251c\u2500\u2500 Indicates: Category at 33-35% but expected to grow significantly\n\u2514\u2500\u2500 Fix: Proactively split before hitting 40% threshold\n```\n<!-- END EXAMPLE-EX-97 -->\n<!-- END CHECKLIST-CL-2 -->\n\n---\n\n<!-- START FIGURE-DG-12: \"Balance Validation Prompt\" -->\n**Validation Prompt (Enhanced):**\n\n```text\n[R] You are an information architect validating taxonomy balance.\n\n[I] Analyze this taxonomy for balance using these specific thresholds:\n\nBALANCE THRESHOLDS:\n- \u2705 Balanced: No category exceeds 35%\n- \u26a0\ufe0f Review: Any category 36-40%\n- \u274c Fail: Any category >40% OR <5%\n- \ud83d\udeab Red Flag: Catch-all labels, >10:1 size ratio\n\nCalculate:\n1. Percentage distribution for each top-level category\n2. Smallest vs. largest category spread\n3. Number of micro-categories (<8%)\n4. Ratio between largest and smallest categories\n\nFlag red flags and provide scored assessment (0-100).\n\n[C] Taxonomy to validate:\n[Paste taxonomy with page counts]\n\n[E] Output format:\nCategory | Pages | % | Status\nGet Started | 15 | 15% | \u2705 Balanced\n\n**Score:** /100\n**Red Flags:** [List any found]\n**Recommendation:** [Specific fixes if score <70]\n```\n<!-- END FIGURE-DG-12 -->\n\n---\n\n<!-- START CHECKLIST-CL-3: \"Granularity Check\" -->",
            "hydration_source_header": "Red Flags Checklist",
            "hydration_method": "title_match"
          },
          {
            "id": "accessibility-labels-checklist",
            "title": "Accessibility Check for Labels",
            "items": 4,
            "time": "5 min",
            "lines": "775-795",
            "content": "Let's validate a complete taxonomy using all 5 checks.\n\n**Taxonomy to Validate:**\n\n```text\nCloudStore API Documentation (60 pages)\n\n\u251c\u2500\u2500 Get Started (10 pages, 17%)\n\u2502   \u251c\u2500\u2500 Quickstart\n\u2502   \u2502   \u251c\u2500\u2500 Getting Started with CloudStore [Tutorial]\n\u2502   \u2502   \u251c\u2500\u2500 Upload Your First File [Tutorial]\n\u2502   \u2502   \u2514\u2500\u2500 Your First Webhook [Tutorial]\n\u2502   \u2514\u2500\u2500 Core Concepts\n\u2502       \u251c\u2500\u2500 Understanding Storage Classes [Explanation]\n\u2502       \u2514\u2500\u2500 File Encryption Explained [Explanation]\n\u2502\n\u251c\u2500\u2500 File Management (20 pages, 33%)\n\u2502   \u251c\u2500\u2500 Upload & Download\n\u2502   \u2502   \u251c\u2500\u2500 Batch Upload Tutorial [Tutorial]\n\u2502   \u2502   \u251c\u2500\u2500 File Upload Endpoint [Reference]\n\u2502   \u2502   \u2514\u2500\u2500 How to Handle Upload Failures [How-to]\n\u2502   \u251c\u2500\u2500 File Versioning\n\u2502   \u2502   \u251c\u2500\u2500 Implementing Versioning [Tutorial]\n\u2502   \u2502   \u2514\u2500\u2500 How to Restore Versions [How-to]\n\u2502   \u2514\u2500\u2500 File Objects\n\u2502       \u2514\u2500\u2500 File Object Reference [Reference]\n\u2502\n\u251c\u2500\u2500 Sharing & Permissions (12 pages, 20%)\n\u2502   \u251c\u2500\u2500 How to Set Permissions [How-to]\n\u2502   \u251c\u2500\u2500 Share with Public Links [How-to]\n\u2502   \u2514\u2500\u2500 Permission Levels Reference [Reference]\n\u2502\n\u251c\u2500\u2500 Search & Metadata (8 pages, 13%)\n\u2502   \u251c\u2500\u2500 How to Search by Metadata [How-to]\n\u2502   \u2514\u2500\u2500 Search API Reference [Reference]\n\u2502\n\u251c\u2500\u2500 Webhooks (6 pages, 10%)\n\u2502   \u251c\u2500\u2500 Understanding Webhook Events [Explanation]\n\u2502   \u2514\u2500\u2500 Webhook Events Reference [Reference]\n\u2502\n\u2514\u2500\u2500 Troubleshooting & Reference (4 pages, 7%)\n    \u251c\u2500\u2500 Error Codes Reference [Reference]\n    \u2514\u2500\u2500 Common Issues [How-to]\n```\n\n**Validation Process:**\n\n```text\nDEPTH CHECK\n\u2611 3 levels maximum - PASS\n\u2611 Appropriate for content volume - PASS\n\u2611 Could flatten? - NO, complexity warrants 3 levels\n\u2713 DEPTH: GOOD\n\nBALANCE CHECK\n\u2611 File Management at 33% (20/60) - ACCEPTABLE (under 40% threshold)\n\u2611 Get Started 17%, Sharing 20%, Search 13%, Webhooks 10%, Troubleshooting 7%\n\u2611 Distribution: 17%, 33%, 20%, 13%, 10%, 7% - GOOD BALANCE\n\u2611 No category <5 pages except Troubleshooting (intentionally lean)\n\u2713 BALANCE: GOOD\n\nGRANULARITY CHECK\n\u2611 Top-level categories parallel? \n   - Get Started (stage-based) \u2190 Different\n   - Features (File, Sharing, Search, Webhooks) - Feature-based\n   - Troubleshooting (support-based) \u2190 Different\n\u26a0\ufe0f ISSUE: Mixed principles at top level\n\u2713 Within feature categories, granularity is consistent\n\u26a0\ufe0f GRANULARITY: NEEDS REVIEW\n\nEXCLUSIVITY CHECK\n\u2611 Most content has clear home - PASS\n\u26a0\ufe0f \"Error Codes Reference\" - Could go multiple places\n\u26a0\ufe0f \"Understanding Webhook Events\" - Could be Get Started or Webhooks\n\u2611 Overlap is intentional (noted in rationale)\n\u26a0\ufe0f EXCLUSIVITY: MINOR ISSUES\n\nLABEL CLARITY CHECK\n\u2611 \"Get Started\", \"File Management\", \"Sharing & Permissions\" - CLEAR\n\u2611 \"Search & Metadata\", \"Webhooks\" - CLEAR\n\u2611 \"Troubleshooting & Reference\" - Combines two concepts\n\u26a0\ufe0f ISSUE: Last category mixes purposes\n\u2611 All labels under 30 characters - PASS\n\u2611 No vague terms like \"Other\" or \"Advanced\" - PASS\n\u26a0\ufe0f LABELS: ONE ISSUE TO FIX\n\nDI\u00c3TAXIS INTEGRATION\n\u2611 All four types represented and tagged - PASS\n\u2611 Types distributed appropriately (tutorials in Get Started, etc.)\n\u2611 Hybrid approach (types within features) - GOOD\n\u2713 DI\u00c3TAXIS: EXCELLENT\n\nOVERALL ASSESSMENT\n\u2611 Likely matches user mental models (feature-based)\n\u2611 Scalable (room in each category)\n\u2611 Supports business goal (Get Started \u2192 quick upload path)\n\u26a0\ufe0f Three issues identified for refinement\n```\n\n**Issues Summary:**\n\n1. **Mixed Organizational Principles** (PRIORITY: MEDIUM)\n   - Problem: Top level mixes stage-based (Get Started), feature-based (middle sections), and support-based (Troubleshooting)\n   - Impact: Slightly inconsistent, but arguably intentional\n   - Decision: Acceptable IF clearly justified, or could make consistent\n\n2. **\"Troubleshooting & Reference\" Combines Two Concepts** (PRIORITY: HIGH)\n   - Problem: Category serves two distinct purposes\n   - Impact: Unclear label, violates single responsibility\n   - Solution: Split OR rename to be more specific\n\n3. **Ambiguous Content Placement** (PRIORITY: LOW)\n   - Problem: \"Error Codes\" and some explanations could go multiple places\n   - Impact: Minor - can be resolved with cross-links\n   - Solution: Choose primary home, link from others\n<!-- END EXAMPLE-EX-102 -->\n\n---\n\n<!-- START REFERENCE-PP-38: \"Polyhierarchy Pattern\" -->",
            "hydration_source_header": "2.2 Complete Validation Example",
            "hydration_method": "line_proximity"
          }
        ]
      }
    },
    "2-2-content-modeling": {
      "file": "2-2-content-modeling.mdx",
      "focus": "Creating content models and metadata schemas with AI assistance, defining content types, designing schemas, mapping relationships, and implementing validation",
      "entityCount": 89,
      "entities": {
        "frameworks": [
          {
            "id": "content-modeling-process",
            "title": "Content Modeling Process",
            "type": "framework",
            "definition": "End-to-end process for content modeling including type discovery, schema generation, relationship mapping, and validation",
            "contains": [
              "content-type-discovery",
              "schema-generation-pattern",
              "relationship-mapping-framework",
              "validation-strategy"
            ],
            "lines": "1-3087",
            "crossModule": false,
            "retrievalQuestions": [
              "How do I create a content model for documentation?",
              "What steps are involved in content modeling?"
            ],
            "content": "**The Five-Step Framework:**\n\n<Steps>\n  <Step title=\"Identify Content Types\">\n    Analyze existing content patterns, look for natural groupings, define 4-7 distinct types, align with established frameworks (Di\u00e1taxis), consider user needs and use cases\n  </Step>\n  \n  <Step title=\"Design Base Schema\">\n    Common fields all types share, core metadata (ID, title, description), publishing workflow fields, versioning and localization support, SEO and search optimization, keep it lean - only truly universal fields\n  </Step>\n  \n  <Step title=\"Create Type-Specific Schemas\">\n    Fields unique to each type, appropriate data types, required vs. optional (be conservative with required), validation rules, rich examples and documentation, consider author experience\n  </Step>\n  \n  <Step title=\"Map Relationships\">\n    How content types connect, direction (uni or bidirectional), cardinality (one-to-one, one-to-many, many-to-many), implementation approach (references, arrays), validation rules (no circular dependencies), auto-generated backlinks where possible\n  </Step>\n  \n  <Step title=\"Implement Validation\">\n    JSON Schema for structural validation, custom business rules, relationship integrity checking, build-time validation (CI/CD), clear error messages with fixes, IDE integration for real-time feedback\n  </Step>\n</Steps>\n\n---",
            "hydration_source_header": "Content Modeling Process",
            "hydration_method": "title_match"
          },
          {
            "id": "di\u00e1taxis-content-model",
            "title": "Di\u00e1taxis Content Model",
            "type": "framework",
            "definition": "Content model based on Di\u00e1taxis framework with five content types",
            "contains": [
              "tutorial-type",
              "howto-type",
              "reference-type",
              "concept-type",
              "troubleshooting-type"
            ],
            "lines": "113-180",
            "crossModule": true,
            "retrievalQuestions": [
              "What content types should I use for API documentation?"
            ],
            "content": "**Scenario:** You have 80 API documentation pages with no formal structure.\n\n**Your Prompt:**\n\n```text\nYou're a content strategist analyzing documentation to create a content model.\n\nAnalyze this content inventory of 80 API documentation pages and identify \ndistinct content types.\n\nContent Inventory (sample of 30):\n1. \"Getting Started with Payments API\"\n2. \"Create Charge Endpoint Reference\"\n3. \"How to Handle Failed Payments\"\n4. \"Understanding Payment Intents\"\n5. \"Webhook Events List\"\n6. \"Build a Checkout Form Tutorial\"\n7. \"API Authentication Guide\"\n8. \"Charge Object Schema\"\n9. \"How to Test Webhooks Locally\"\n10. \"Why We Use Idempotency Keys\"\n11. \"Refund API Reference\"\n12. \"Setting Up Your Development Environment\"\n13. \"Payment Flow Overview\"\n14. \"How to Implement 3D Secure\"\n15. \"Error Codes Reference\"\n16. \"Subscription Billing Tutorial\"\n17. \"Customer Object Reference\"\n18. \"How to Handle Disputes\"\n19. \"Understanding PCI Compliance\"\n20. \"Create Customer Endpoint\"\n21. \"Building a Subscription System\"\n22. \"Rate Limiting Explained\"\n23. \"How to Migrate from v1 to v2\"\n24. \"Payment Methods Overview\"\n25. \"Invoice API Reference\"\n26. \"How to Customize Email Receipts\"\n27. \"Security Best Practices\"\n28. \"Pagination Guide\"\n29. \"Webhook Signature Verification\"\n30. \"Multi-Currency Support Tutorial\"\n\nFor each content type you identify:\n1. Name and clear definition\n2. Purpose (what does it do for users?)\n3. Target audience (who uses it?)\n4. Distinguishing characteristics (what makes it unique?)\n5. Examples from the sample (3-5 titles)\n6. Typical attributes this type would need\n7. Estimated percentage of total 80 pages\n\nAlso note any pages that don't fit clearly into a single type.\n```\n\n---\n\n**AI Output (Example):**\n\n```text\nCONTENT TYPE ANALYSIS - API DOCUMENTATION\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nCONTENT TYPE 1: TUTORIAL\nDefinition: Learning-oriented, step-by-step guides that teach through hands-on practice\nPurpose: Help users learn by building something real\nAudience: Developers (beginner to intermediate)\n\nDistinguishing Characteristics:\n- Progressive difficulty (starts simple, builds up)\n- Complete working examples included\n- Assumes little/no prior knowledge\n- \"Build\" or \"Create\" language\n- Includes expected outcomes/results\n- Usually 15-30 minutes to complete\n\nExamples from Sample:\n1. \"Build a Checkout Form Tutorial\"\n6. \"Subscription Billing Tutorial\"\n12. \"Setting Up Your Development Environment\"\n21. \"Building a Subscription System\"\n30. \"Multi-Currency Support Tutorial\"\n\nTypical Attributes Needed:\n- title, description\n- estimated_time (minutes)\n- difficulty (beginner/intermediate/advanced)\n- prerequisites (links to required knowledge)\n- learning_objectives (what you'll learn)\n- code_language (JavaScript, Python, etc.)\n- has_code_examples (boolean)\n- has_video (optional video URL)\n- completion_checklist (what success looks like)\n\nEstimated: 20 pages (25% of total)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nCONTENT TYPE 2: HOW-TO GUIDE\nDefinition: Task-oriented guides that solve specific problems\nPurpose: Help users accomplish a specific goal\nAudience: Developers (all levels, with some API knowledge)\n\nDistinguishing Characteristics:\n- Starts with \"How to...\"\n- Assumes some prior knowledge\n- Focused on one specific task\n- Practical, actionable steps\n- Problem-solution format\n- Shorter than tutorials (5-15 minutes)\n\nExamples from Sample:\n3. \"How to Handle Failed Payments\"\n9. \"How to Test Webhooks Locally\"\n14. \"How to Implement 3D Secure\"\n18. \"How to Handle Disputes\"\n23. \"How to Migrate from v1 to v2\"\n26. \"How to Customize Email Receipts\"\n\nTypical Attributes Needed:\n- title, description\n- problem_statement (what issue this solves)\n- prerequisites (required knowledge/setup)\n- estimated_time\n- step_count (number of steps)\n- common_issues (troubleshooting)\n- related_how_tos (similar tasks)\n- api_endpoints_used (list of endpoints)\n\nEstimated: 25 pages (31% of total)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nCONTENT TYPE 3: API REFERENCE\nDefinition: Technical specifications for API endpoints, objects, and parameters\nPurpose: Provide detailed technical information for implementation\nAudience: Developers (all levels, during implementation)\n\nDistinguishing Characteristics:\n- \"API\", \"Endpoint\", \"Reference\", \"Object\", or \"Schema\" in title\n- Dry, technical, comprehensive\n- Lists parameters, responses, errors\n- No step-by-step guidance\n- Information-dense\n- Quick lookup format\n\nExamples from Sample:\n2. \"Create Charge Endpoint Reference\"\n5. \"Webhook Events List\"\n8. \"Charge Object Schema\"\n11. \"Refund API Reference\"\n15. \"Error Codes Reference\"\n17. \"Customer Object Reference\"\n20. \"Create Customer Endpoint\"\n25. \"Invoice API Reference\"\n\nTypical Attributes Needed:\n- title, description\n- api_endpoint (URL path)\n- http_method (GET, POST, etc.)\n- parameters (array of param objects)\n- response_schema (expected response)\n- error_codes (possible errors)\n- api_version\n- authentication_required (boolean)\n- rate_limits\n- code_examples (multiple languages)\n\nEstimated: 20 pages (25% of total)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nCONTENT TYPE 4: EXPLANATION / CONCEPT\nDefinition: Understanding-oriented content that explains \"why\" and provides context\nPurpose: Build conceptual understanding and mental models\nAudience: Developers and technical decision-makers\n\nDistinguishing Characteristics:\n- \"Understanding\", \"Overview\", \"Explained\", or \"Why\" in title\n- Conceptual rather than procedural\n- Provides background and context\n- Discusses trade-offs and design decisions\n- Less code, more diagrams/explanations\n- Answers \"why\" questions\n\nExamples from Sample:\n4. \"Understanding Payment Intents\"\n10. \"Why We Use Idempotency Keys\"\n13. \"Payment Flow Overview\"\n19. \"Understanding PCI Compliance\"\n22. \"Rate Limiting Explained\"\n24. \"Payment Methods Overview\"\n27. \"Security Best Practices\"\n\nTypical Attributes Needed:\n- title, description\n- concept_name (what's being explained)\n- key_points (main takeaways)\n- related_concepts (links to related explanations)\n- diagrams_included (boolean)\n- further_reading (external resources)\n- practical_applications (links to tutorials/how-tos)\n\nEstimated: 10 pages (13% of total)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nCONTENT TYPE 5: TROUBLESHOOTING / FAQ\nDefinition: Problem diagnosis and resolution guides\nPurpose: Help users fix issues and answer common questions\nAudience: Developers encountering problems\n\nDistinguishing Characteristics:\n- Problem-focused (error messages, issues)\n- \"Troubleshooting\", \"Common Issues\", \"FAQ\"\n- Diagnostic flow (if X, then Y)\n- Multiple solutions for same problem\n- Links to related how-tos\n\nExamples from Sample:\n(Not many in this sample - might include:)\n- Debug webhook delivery issues\n- Resolve authentication errors\n- Fix common integration mistakes\n\nTypical Attributes Needed:\n- title, description\n- problem_description (what's wrong)\n- symptoms (how users recognize this)\n- causes (why it happens)\n- solutions (array of fixes)\n- related_errors (error codes)\n- prevention_tips\n\nEstimated: 5 pages (6% of total)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nAMBIGUOUS PAGES (Need Classification Decision):\n\n1. \"API Authentication Guide\" - Could be Tutorial OR How-to OR Explanation\n   \u2192 Depends on format: step-by-step tutorial vs. task guide vs. conceptual overview\n   \n2. \"Pagination Guide\" - Could be How-to OR Explanation\n   \u2192 Implementation guide (how-to) vs. conceptual overview (explanation)\n   \n3. \"Webhook Signature Verification\" - Could be How-to OR Reference\n   \u2192 Task guide (how-to) vs. technical spec (reference)\n\nRECOMMENDATION: Review these pages individually and classify based on actual content format.\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nDISTRIBUTION SUMMARY:\n\n| Content Type    | Count | Percentage |\n|-----------------|-------|------------|\n| Tutorial        | 20    | 25%        |\n| How-to Guide    | 25    | 31%        |\n| API Reference   | 20    | 25%        |\n| Explanation     | 10    | 13%        |\n| Troubleshooting | 5     | 6%         |\n| **TOTAL**       | **80**| **100%**   |\n\nThis distribution aligns well with the Di\u00e1taxis framework and supports multiple user needs:\n- Learning (Tutorials: 25%)\n- Problem-solving (How-tos: 31%)\n- Information lookup (Reference: 25%)\n- Understanding (Explanations: 13%)\n- Debugging (Troubleshooting: 6%)\n```\n\n<Tip>\n  **Why This Analysis is Valuable:** AI quickly identifies patterns across 80 pages that would take hours manually. It provides structure, percentages, and clear definitions you can refine.\n</Tip>\n\n---",
            "hydration_source_header": "1.2 Example: Content Type Discovery",
            "hydration_method": "line_proximity"
          },
          {
            "id": "five-step-modeling-framework",
            "title": "Five-Step Content Modeling Framework",
            "type": "framework",
            "definition": "Framework: identify content types, design base schema, create type schemas, map relationships, implement validation",
            "contains": [
              "identify-content-types",
              "design-base-schema",
              "create-type-schemas",
              "map-relationships",
              "implement-validation"
            ],
            "lines": "2815-2875",
            "crossModule": false,
            "retrievalQuestions": [
              "What are the steps to design a metadata schema?"
            ],
            "content": "**The Five-Step Framework:**\n\n<Steps>\n  <Step title=\"Identify Content Types\">\n    Analyze existing content patterns, look for natural groupings, define 4-7 distinct types, align with established frameworks (Di\u00e1taxis), consider user needs and use cases\n  </Step>\n  \n  <Step title=\"Design Base Schema\">\n    Common fields all types share, core metadata (ID, title, description), publishing workflow fields, versioning and localization support, SEO and search optimization, keep it lean - only truly universal fields\n  </Step>\n  \n  <Step title=\"Create Type-Specific Schemas\">\n    Fields unique to each type, appropriate data types, required vs. optional (be conservative with required), validation rules, rich examples and documentation, consider author experience\n  </Step>\n  \n  <Step title=\"Map Relationships\">\n    How content types connect, direction (uni or bidirectional), cardinality (one-to-one, one-to-many, many-to-many), implementation approach (references, arrays), validation rules (no circular dependencies), auto-generated backlinks where possible\n  </Step>\n  \n  <Step title=\"Implement Validation\">\n    JSON Schema for structural validation, custom business rules, relationship integrity checking, build-time validation (CI/CD), clear error messages with fixes, IDE integration for real-time feedback\n  </Step>\n</Steps>\n\n---",
            "hydration_source_header": "Content Modeling Process",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "docs-as-code-framework",
            "title": "Docs-as-Code Framework",
            "type": "framework",
            "definition": "Framework for treating documentation like software with version control, CI/CD, and metadata strategies",
            "contains": [
              "version-control-principles",
              "metadata-strategies",
              "platform-strategies"
            ],
            "lines": "1499-1700",
            "crossModule": false,
            "retrievalQuestions": [
              "What is docs-as-code and how does metadata fit?"
            ],
            "hydration_status": "failed"
          }
        ],
        "principles": [
          {
            "id": "start-simple-add-later",
            "title": "Start Simple, Add Complexity Later",
            "partOf": "five-step-modeling-framework",
            "lines": "2893-2908",
            "retrievalQuestions": [
              "Should I start with a complex or simple content model?"
            ],
            "content": "### Content Modeling Process\n\n**The Five-Step Framework:**\n\n<Steps>\n  <Step title=\"Identify Content Types\">\n    Analyze existing content patterns, look for natural groupings, define 4-7 distinct types, align with established frameworks (Di\u00e1taxis), consider user needs and use cases\n  </Step>\n  \n  <Step title=\"Design Base Schema\">\n    Common fields all types share, core metadata (ID, title, description), publishing workflow fields, versioning and localization support, SEO and search optimization, keep it lean - only truly universal fields\n  </Step>\n  \n  <Step title=\"Create Type-Specific Schemas\">\n    Fields unique to each type, appropriate data types, required vs. optional (be conservative with required), validation rules, rich examples and documentation, consider author experience\n  </Step>\n  \n  <Step title=\"Map Relationships\">\n    How content types connect, direction (uni or bidirectional), cardinality (one-to-one, one-to-many, many-to-many), implementation approach (references, arrays), validation rules (no circular dependencies), auto-generated backlinks where possible\n  </Step>\n  \n  <Step title=\"Implement Validation\">\n    JSON Schema for structural validation, custom business rules, relationship integrity checking, build-time validation (CI/CD), clear error messages with fixes, IDE integration for real-time feedback\n  </Step>\n</Steps>\n\n---\n\n### AI Strengths and Limitations\n\n<CardGroup cols={2}>\n  <Card title=\"Where AI Excels\" icon=\"robot\">\n    - \u2705 **Pattern Recognition:** Analyzing content to identify types\n    - \u2705 **Comprehensive Listing:** Generating extensive field lists\n    - \u2705 **Schema Generation:** Creating structured schema definitions\n    - \u2705 **Relationship Identification:** Suggesting connections between types\n    - \u2705 **Validation Rules:** Writing validation logic\n    - \u2705 **Example Creation:** Generating example frontmatter\n    - \u2705 **Documentation:** Explaining fields and their purposes\n  </Card>\n  \n  <Card title=\"Where Human Judgment is Essential\" icon=\"user\">\n    - \u2713 **Business Requirements:** Understanding organizational needs\n    - \u2713 **Workflow Knowledge:** Knowing author processes and pain points\n    - \u2713 **Trade-off Decisions:** Balancing completeness vs. simplicity\n    - \u2713 **Platform Constraints:** Understanding technical limitations\n    - \u2713 **Author Experience:** Ensuring schemas are usable\n    - \u2713 **Maintenance Planning:** Long-term sustainability\n    - \u2713 **Stakeholder Alignment:** Getting organizational buy-in\n    - \u2713 **Migration Strategy:** Practical implementation planning\n  </Card>\n</CardGroup>\n\n**The Optimal Approach:**\nUse AI to generate options and details \u2192 Apply human judgment to refine and validate \u2192 Iterate based on real-world testing\n\n---\n\n### Best Practices\n\n**Schema Design:**\n\n**DO:**\n- \u2705 Start simple, add complexity only when needed\n- \u2705 Make fields required only when absolutely necessary\n- \u2705 Use enums for controlled vocabularies\n- \u2705 Document every field's purpose clearly\n- \u2705 Provide examples for every field\n- \u2705 Use consistent naming conventions (camelCase or snake_case)\n- \u2705 Group related fields logically\n- \u2705 Consider author experience (time to fill)\n- \u2705 Plan for validation from day one\n- \u2705 Design migration strategy before implementing\n\n**DON'T:**\n- \u274c Require 20+ fields (author burden)\n- \u274c Use vague field names (\"misc\", \"other\")\n- \u274c Mix naming conventions\n- \u274c Create fields \"just in case\"\n- \u274c Ignore existing author workflows\n- \u274c Deploy without validation\n- \u274c Forget about migration\n- \u274c Copy schemas without customization\n\n---",
            "hydration_source_header": "Summary: Key Takeaways",
            "hydration_method": "line_proximity"
          },
          {
            "id": "required-field-minimalism",
            "title": "Required Field Minimalism",
            "partOf": "schema-design-principles",
            "lines": "2560-2575, 2893",
            "retrievalQuestions": [
              "How many required fields should I have in a schema?"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "consistency-over-completeness",
            "title": "Consistency Over Completeness",
            "partOf": "schema-design-principles",
            "lines": "2893-2908",
            "retrievalQuestions": [
              "Why is consistency important in content modeling?"
            ],
            "content": "### Content Modeling Process\n\n**The Five-Step Framework:**\n\n<Steps>\n  <Step title=\"Identify Content Types\">\n    Analyze existing content patterns, look for natural groupings, define 4-7 distinct types, align with established frameworks (Di\u00e1taxis), consider user needs and use cases\n  </Step>\n  \n  <Step title=\"Design Base Schema\">\n    Common fields all types share, core metadata (ID, title, description), publishing workflow fields, versioning and localization support, SEO and search optimization, keep it lean - only truly universal fields\n  </Step>\n  \n  <Step title=\"Create Type-Specific Schemas\">\n    Fields unique to each type, appropriate data types, required vs. optional (be conservative with required), validation rules, rich examples and documentation, consider author experience\n  </Step>\n  \n  <Step title=\"Map Relationships\">\n    How content types connect, direction (uni or bidirectional), cardinality (one-to-one, one-to-many, many-to-many), implementation approach (references, arrays), validation rules (no circular dependencies), auto-generated backlinks where possible\n  </Step>\n  \n  <Step title=\"Implement Validation\">\n    JSON Schema for structural validation, custom business rules, relationship integrity checking, build-time validation (CI/CD), clear error messages with fixes, IDE integration for real-time feedback\n  </Step>\n</Steps>\n\n---\n\n### AI Strengths and Limitations\n\n<CardGroup cols={2}>\n  <Card title=\"Where AI Excels\" icon=\"robot\">\n    - \u2705 **Pattern Recognition:** Analyzing content to identify types\n    - \u2705 **Comprehensive Listing:** Generating extensive field lists\n    - \u2705 **Schema Generation:** Creating structured schema definitions\n    - \u2705 **Relationship Identification:** Suggesting connections between types\n    - \u2705 **Validation Rules:** Writing validation logic\n    - \u2705 **Example Creation:** Generating example frontmatter\n    - \u2705 **Documentation:** Explaining fields and their purposes\n  </Card>\n  \n  <Card title=\"Where Human Judgment is Essential\" icon=\"user\">\n    - \u2713 **Business Requirements:** Understanding organizational needs\n    - \u2713 **Workflow Knowledge:** Knowing author processes and pain points\n    - \u2713 **Trade-off Decisions:** Balancing completeness vs. simplicity\n    - \u2713 **Platform Constraints:** Understanding technical limitations\n    - \u2713 **Author Experience:** Ensuring schemas are usable\n    - \u2713 **Maintenance Planning:** Long-term sustainability\n    - \u2713 **Stakeholder Alignment:** Getting organizational buy-in\n    - \u2713 **Migration Strategy:** Practical implementation planning\n  </Card>\n</CardGroup>\n\n**The Optimal Approach:**\nUse AI to generate options and details \u2192 Apply human judgment to refine and validate \u2192 Iterate based on real-world testing\n\n---\n\n### Best Practices\n\n**Schema Design:**\n\n**DO:**\n- \u2705 Start simple, add complexity only when needed\n- \u2705 Make fields required only when absolutely necessary\n- \u2705 Use enums for controlled vocabularies\n- \u2705 Document every field's purpose clearly\n- \u2705 Provide examples for every field\n- \u2705 Use consistent naming conventions (camelCase or snake_case)\n- \u2705 Group related fields logically\n- \u2705 Consider author experience (time to fill)\n- \u2705 Plan for validation from day one\n- \u2705 Design migration strategy before implementing\n\n**DON'T:**\n- \u274c Require 20+ fields (author burden)\n- \u274c Use vague field names (\"misc\", \"other\")\n- \u274c Mix naming conventions\n- \u274c Create fields \"just in case\"\n- \u274c Ignore existing author workflows\n- \u274c Deploy without validation\n- \u274c Forget about migration\n- \u274c Copy schemas without customization\n\n---",
            "hydration_source_header": "Summary: Key Takeaways",
            "hydration_method": "line_proximity"
          },
          {
            "id": "content-type-distinction",
            "title": "Clear Content Type Distinction",
            "partOf": "di\u00e1taxis-content-model",
            "lines": "2040-2060",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I distinguish between content types?"
            ],
            "content": "**Scenario:** You have 80 API documentation pages with no formal structure.\n\n**Your Prompt:**\n\n```text\nYou're a content strategist analyzing documentation to create a content model.\n\nAnalyze this content inventory of 80 API documentation pages and identify \ndistinct content types.\n\nContent Inventory (sample of 30):\n1. \"Getting Started with Payments API\"\n2. \"Create Charge Endpoint Reference\"\n3. \"How to Handle Failed Payments\"\n4. \"Understanding Payment Intents\"\n5. \"Webhook Events List\"\n6. \"Build a Checkout Form Tutorial\"\n7. \"API Authentication Guide\"\n8. \"Charge Object Schema\"\n9. \"How to Test Webhooks Locally\"\n10. \"Why We Use Idempotency Keys\"\n11. \"Refund API Reference\"\n12. \"Setting Up Your Development Environment\"\n13. \"Payment Flow Overview\"\n14. \"How to Implement 3D Secure\"\n15. \"Error Codes Reference\"\n16. \"Subscription Billing Tutorial\"\n17. \"Customer Object Reference\"\n18. \"How to Handle Disputes\"\n19. \"Understanding PCI Compliance\"\n20. \"Create Customer Endpoint\"\n21. \"Building a Subscription System\"\n22. \"Rate Limiting Explained\"\n23. \"How to Migrate from v1 to v2\"\n24. \"Payment Methods Overview\"\n25. \"Invoice API Reference\"\n26. \"How to Customize Email Receipts\"\n27. \"Security Best Practices\"\n28. \"Pagination Guide\"\n29. \"Webhook Signature Verification\"\n30. \"Multi-Currency Support Tutorial\"\n\nFor each content type you identify:\n1. Name and clear definition\n2. Purpose (what does it do for users?)\n3. Target audience (who uses it?)\n4. Distinguishing characteristics (what makes it unique?)\n5. Examples from the sample (3-5 titles)\n6. Typical attributes this type would need\n7. Estimated percentage of total 80 pages\n\nAlso note any pages that don't fit clearly into a single type.\n```\n\n---\n\n**AI Output (Example):**\n\n```text\nCONTENT TYPE ANALYSIS - API DOCUMENTATION\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nCONTENT TYPE 1: TUTORIAL\nDefinition: Learning-oriented, step-by-step guides that teach through hands-on practice\nPurpose: Help users learn by building something real\nAudience: Developers (beginner to intermediate)\n\nDistinguishing Characteristics:\n- Progressive difficulty (starts simple, builds up)\n- Complete working examples included\n- Assumes little/no prior knowledge\n- \"Build\" or \"Create\" language\n- Includes expected outcomes/results\n- Usually 15-30 minutes to complete\n\nExamples from Sample:\n1. \"Build a Checkout Form Tutorial\"\n6. \"Subscription Billing Tutorial\"\n12. \"Setting Up Your Development Environment\"\n21. \"Building a Subscription System\"\n30. \"Multi-Currency Support Tutorial\"\n\nTypical Attributes Needed:\n- title, description\n- estimated_time (minutes)\n- difficulty (beginner/intermediate/advanced)\n- prerequisites (links to required knowledge)\n- learning_objectives (what you'll learn)\n- code_language (JavaScript, Python, etc.)\n- has_code_examples (boolean)\n- has_video (optional video URL)\n- completion_checklist (what success looks like)\n\nEstimated: 20 pages (25% of total)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nCONTENT TYPE 2: HOW-TO GUIDE\nDefinition: Task-oriented guides that solve specific problems\nPurpose: Help users accomplish a specific goal\nAudience: Developers (all levels, with some API knowledge)\n\nDistinguishing Characteristics:\n- Starts with \"How to...\"\n- Assumes some prior knowledge\n- Focused on one specific task\n- Practical, actionable steps\n- Problem-solution format\n- Shorter than tutorials (5-15 minutes)\n\nExamples from Sample:\n3. \"How to Handle Failed Payments\"\n9. \"How to Test Webhooks Locally\"\n14. \"How to Implement 3D Secure\"\n18. \"How to Handle Disputes\"\n23. \"How to Migrate from v1 to v2\"\n26. \"How to Customize Email Receipts\"\n\nTypical Attributes Needed:\n- title, description\n- problem_statement (what issue this solves)\n- prerequisites (required knowledge/setup)\n- estimated_time\n- step_count (number of steps)\n- common_issues (troubleshooting)\n- related_how_tos (similar tasks)\n- api_endpoints_used (list of endpoints)\n\nEstimated: 25 pages (31% of total)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nCONTENT TYPE 3: API REFERENCE\nDefinition: Technical specifications for API endpoints, objects, and parameters\nPurpose: Provide detailed technical information for implementation\nAudience: Developers (all levels, during implementation)\n\nDistinguishing Characteristics:\n- \"API\", \"Endpoint\", \"Reference\", \"Object\", or \"Schema\" in title\n- Dry, technical, comprehensive\n- Lists parameters, responses, errors\n- No step-by-step guidance\n- Information-dense\n- Quick lookup format\n\nExamples from Sample:\n2. \"Create Charge Endpoint Reference\"\n5. \"Webhook Events List\"\n8. \"Charge Object Schema\"\n11. \"Refund API Reference\"\n15. \"Error Codes Reference\"\n17. \"Customer Object Reference\"\n20. \"Create Customer Endpoint\"\n25. \"Invoice API Reference\"\n\nTypical Attributes Needed:\n- title, description\n- api_endpoint (URL path)\n- http_method (GET, POST, etc.)\n- parameters (array of param objects)\n- response_schema (expected response)\n- error_codes (possible errors)\n- api_version\n- authentication_required (boolean)\n- rate_limits\n- code_examples (multiple languages)\n\nEstimated: 20 pages (25% of total)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nCONTENT TYPE 4: EXPLANATION / CONCEPT\nDefinition: Understanding-oriented content that explains \"why\" and provides context\nPurpose: Build conceptual understanding and mental models\nAudience: Developers and technical decision-makers\n\nDistinguishing Characteristics:\n- \"Understanding\", \"Overview\", \"Explained\", or \"Why\" in title\n- Conceptual rather than procedural\n- Provides background and context\n- Discusses trade-offs and design decisions\n- Less code, more diagrams/explanations\n- Answers \"why\" questions\n\nExamples from Sample:\n4. \"Understanding Payment Intents\"\n10. \"Why We Use Idempotency Keys\"\n13. \"Payment Flow Overview\"\n19. \"Understanding PCI Compliance\"\n22. \"Rate Limiting Explained\"\n24. \"Payment Methods Overview\"\n27. \"Security Best Practices\"\n\nTypical Attributes Needed:\n- title, description\n- concept_name (what's being explained)\n- key_points (main takeaways)\n- related_concepts (links to related explanations)\n- diagrams_included (boolean)\n- further_reading (external resources)\n- practical_applications (links to tutorials/how-tos)\n\nEstimated: 10 pages (13% of total)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nCONTENT TYPE 5: TROUBLESHOOTING / FAQ\nDefinition: Problem diagnosis and resolution guides\nPurpose: Help users fix issues and answer common questions\nAudience: Developers encountering problems\n\nDistinguishing Characteristics:\n- Problem-focused (error messages, issues)\n- \"Troubleshooting\", \"Common Issues\", \"FAQ\"\n- Diagnostic flow (if X, then Y)\n- Multiple solutions for same problem\n- Links to related how-tos\n\nExamples from Sample:\n(Not many in this sample - might include:)\n- Debug webhook delivery issues\n- Resolve authentication errors\n- Fix common integration mistakes\n\nTypical Attributes Needed:\n- title, description\n- problem_description (what's wrong)\n- symptoms (how users recognize this)\n- causes (why it happens)\n- solutions (array of fixes)\n- related_errors (error codes)\n- prevention_tips\n\nEstimated: 5 pages (6% of total)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nAMBIGUOUS PAGES (Need Classification Decision):\n\n1. \"API Authentication Guide\" - Could be Tutorial OR How-to OR Explanation\n   \u2192 Depends on format: step-by-step tutorial vs. task guide vs. conceptual overview\n   \n2. \"Pagination Guide\" - Could be How-to OR Explanation\n   \u2192 Implementation guide (how-to) vs. conceptual overview (explanation)\n   \n3. \"Webhook Signature Verification\" - Could be How-to OR Reference\n   \u2192 Task guide (how-to) vs. technical spec (reference)\n\nRECOMMENDATION: Review these pages individually and classify based on actual content format.\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nDISTRIBUTION SUMMARY:\n\n| Content Type    | Count | Percentage |\n|-----------------|-------|------------|\n| Tutorial        | 20    | 25%        |\n| How-to Guide    | 25    | 31%        |\n| API Reference   | 20    | 25%        |\n| Explanation     | 10    | 13%        |\n| Troubleshooting | 5     | 6%         |\n| **TOTAL**       | **80**| **100%**   |\n\nThis distribution aligns well with the Di\u00e1taxis framework and supports multiple user needs:\n- Learning (Tutorials: 25%)\n- Problem-solving (How-tos: 31%)\n- Information lookup (Reference: 25%)\n- Understanding (Explanations: 13%)\n- Debugging (Troubleshooting: 6%)\n```\n\n<Tip>\n  **Why This Analysis is Valuable:** AI quickly identifies patterns across 80 pages that would take hours manually. It provides structure, percentages, and clear definitions you can refine.\n</Tip>\n\n---",
            "hydration_source_header": "1.2 Example: Content Type Discovery",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "inheritance-in-schemas",
            "title": "Schema Inheritance (Base + Type-Specific)",
            "partOf": "schema-generation-pattern",
            "lines": "2165-2260",
            "retrievalQuestions": [
              "How do base and type-specific schemas relate?"
            ],
            "content": "status:\n    type: enum\n    required: true\n    allowed_values: [\"draft\", \"review\", \"published\", \"archived\"]\n    default: \"draft\"\n  \n  version:\n    type: string\n    required: true\n    pattern: \"^v?[0-9]+\\\\.[0-9]+$\"\n    description: \"Product version compatibility\"\n    example: \"v2.5\"\n  \n  published_date:\n    type: date\n    required: true\n    format: \"YYYY-MM-DD\"\n  \n  last_updated:\n    type: date\n    required: true\n    format: \"YYYY-MM-DD\"\n    auto_update: true\n  \n  author:\n    type: string\n    required: true\n    description: \"Author name or username\"",
            "hydration_source_header": "Publishing",
            "hydration_method": "line_proximity"
          },
          {
            "id": "bidirectionality-for-discovery",
            "title": "Bidirectionality Enables Discovery",
            "partOf": "relationship-mapping-framework",
            "lines": "1530-1550",
            "retrievalQuestions": [
              "Should relationships be bidirectional?"
            ],
            "content": "description:\n    type: string\n    required: true\n    min_length: 50\n    max_length: 160\n    description: \"SEO meta description and preview text\"\n  \n  keywords:\n    type: array\n    items: string\n    required: false\n    max_items: 10\n    description: \"Search keywords\"\n  \n  category:\n    type: string\n    required: true\n    description: \"Primary category for navigation\"\n  \n  tags:\n    type: array\n    items: string\n    required: false\n    max_items: 5\n    description: \"Topic tags for filtering\"",
            "hydration_source_header": "Discovery",
            "hydration_method": "title_match"
          },
          {
            "id": "validation-as-prevention",
            "title": "Validation Prevents Errors",
            "partOf": "validation-strategy",
            "lines": "2450-2500",
            "retrievalQuestions": [
              "Why validate content model metadata?"
            ],
            "content": "**What You're Doing:** Create validation rules to catch errors before content goes live.\n\n**Validation Layers:**\n\n**Layer 1: Schema Validation (JSON Schema)**\n- Required fields present\n- Data types correct\n- Enum values valid\n- String lengths within limits\n\n**Layer 2: Business Logic**\n- Estimated time matches difficulty\n- Prerequisites actually exist\n- No circular dependencies\n- Version format valid\n\n**Your AI Prompt:**\n\n```text\nYou're implementing validation for DevTools content model.\n\nCreate:\n1. JSON Schema for the Tutorial type (base + type-specific fields)\n2. Custom validation function for business rules:\n   - Beginner tutorials: 5-30 minutes\n   - Intermediate: 15-60 minutes\n   - Advanced: 30-120 minutes\n3. Validation for prerequisites:\n   - All referenced URLs exist\n   - No circular dependencies\n4. Build script pseudocode that runs these checks\n\nProvide working code examples (JavaScript).\n```\n\n**Expected Output:**\n\n```javascript\n// JSON Schema for Tutorial\nconst tutorialSchema = {\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"type\": \"object\",\n  \"required\": [\"title\", \"description\", \"content_type\", \"difficulty\", \"estimated_time\"],\n  \"properties\": {\n    \"title\": {\n      \"type\": \"string\",\n      \"minLength\": 10,\n      \"maxLength\": 80\n    },\n    \"difficulty\": {\n      \"type\": \"string\",\n      \"enum\": [\"beginner\", \"intermediate\", \"advanced\"]\n    },\n    \"estimated_time\": {\n      \"type\": \"integer\",\n      \"minimum\": 5,\n      \"maximum\": 120\n    }\n  }\n};\n\n// Custom Business Logic Validation\nfunction validateTimeVsDifficulty(frontmatter) {\n  const { difficulty, estimated_time } = frontmatter;\n  const timeLimits = {\n    beginner: { min: 5, max: 30 },\n    intermediate: { min: 15, max: 60 },\n    advanced: { min: 30, max: 120 }\n  };\n  \n  const { min, max } = timeLimits[difficulty];\n  if (estimated_time < min || estimated_time > max) {\n    return {\n      valid: false,\n      error: `${difficulty} tutorials should be ${min}-${max} minutes. Got ${estimated_time}.`\n    };\n  }\n  return { valid: true };\n}\n\n// Build-time Validation Script\nconst fs = require('fs');\nconst yaml = require('js-yaml');\nconst Ajv = require('ajv');\n\nconst ajv = new Ajv();\nconst validate = ajv.compile(tutorialSchema);\n\nconst errors = [];\n\n// Read all docs\nfs.readdirSync('./docs/tutorials').forEach(file => {\n  const content = fs.readFileSync(`./docs/tutorials/${file}`, 'utf8');\n  const frontmatter = yaml.load(content.match(/---\\n([\\s\\S]*?)\\n---/)[1]);\n  \n  // Schema validation\n  if (!validate(frontmatter)) {\n    validate.errors.forEach(err => {\n      errors.push({ file, error: err.message });\n    });\n  }\n  \n  // Business logic validation\n  const timeCheck = validateTimeVsDifficulty(frontmatter);\n  if (!timeCheck.valid) {\n    errors.push({ file, error: timeCheck.error });\n  }\n});\n\n// Report\nif (errors.length > 0) {\n  console.error('Validation failed:');\n  errors.forEach(e => console.error(`${e.file}: ${e.error}`));\n  process.exit(1);\n}\n\nconsole.log('All validations passed!');\n```\n\n**Your Action:** \n1. Add this to your build pipeline (CI/CD)\n2. Set up pre-commit hooks for immediate feedback\n3. Configure IDE validation (VS Code with YAML/JSON schema support)\n\n---",
            "hydration_source_header": "Step 6: Implement Validation",
            "hydration_method": "line_proximity"
          }
        ],
        "patterns": [
          {
            "id": "content-type-discovery-pattern",
            "title": "Content Type Discovery Pattern",
            "implements": "di\u00e1taxis-content-model",
            "taskType": "analysis",
            "lines": "113-370",
            "retrievalQuestions": [
              "How do I use AI to identify content types?"
            ],
            "content": "**Use When:** You have existing content but no formal content model\n\n**Prompt Structure:**\n```text\nAnalyze this content inventory and identify distinct content types.\n\nFor each type identified:\n- Name the content type\n- Define its purpose\n- List characteristics that distinguish it\n- Provide 3-5 examples from the inventory\n- Estimate % of total content\n\n[Paste content inventory]\n```\n\n---",
            "hydration_source_header": "1.1 The Content Type Discovery Pattern",
            "hydration_method": "title_match"
          },
          {
            "id": "schema-generation-pattern",
            "title": "Schema Generation Pattern",
            "implements": "inheritance-in-schemas",
            "taskType": "generation",
            "lines": "371-1000",
            "retrievalQuestions": [
              "What prompt do I use to generate a schema?"
            ],
            "content": "**Prompt Structure:**\n```text\nYou're a content architect designing metadata schemas.\n\nFor the \"[CONTENT TYPE]\" content type, define all necessary attributes.\n\nContext:\n- Platform: [PLATFORM]\n- Use cases: [WHAT METADATA ENABLES]\n- Constraints: [TECHNICAL LIMITS]\n\n[CONTENT TYPE DEFINITION]\n\nFor each attribute specify:\n- Field name\n- Data type\n- Required or optional\n- Description\n- Validation rules\n- Default value (if applicable)\n- Examples\n\nAlso consider:\n- What enables search/filtering?\n- What enables automation?\n- What supports content reuse?\n- What helps authors?\n```\n\n---",
            "hydration_source_header": "2.1 The Schema Generation Pattern",
            "hydration_method": "title_match"
          },
          {
            "id": "batch-schema-generation",
            "title": "Batch Schema Generation Pattern",
            "implements": "schema-generation-pattern",
            "taskType": "generation",
            "lines": "935-970",
            "content": "**Prompt Structure:**\n```text\nYou're a content architect designing metadata schemas.\n\nFor the \"[CONTENT TYPE]\" content type, define all necessary attributes.\n\nContext:\n- Platform: [PLATFORM]\n- Use cases: [WHAT METADATA ENABLES]\n- Constraints: [TECHNICAL LIMITS]\n\n[CONTENT TYPE DEFINITION]\n\nFor each attribute specify:\n- Field name\n- Data type\n- Required or optional\n- Description\n- Validation rules\n- Default value (if applicable)\n- Examples\n\nAlso consider:\n- What enables search/filtering?\n- What enables automation?\n- What supports content reuse?\n- What helps authors?\n```\n\n---",
            "hydration_source_header": "2.1 The Schema Generation Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "relationship-mapping-pattern",
            "title": "Relationship Mapping Pattern",
            "implements": "bidirectionality-for-discovery",
            "taskType": "analysis",
            "lines": "1127-1170",
            "retrievalQuestions": [
              "How do I map relationships between content types?"
            ],
            "content": "**Prompt Structure:**\n```text\nYou're a content architect mapping relationships between content types.\n\nContent types:\n- [List types]\n\nFor each pair of content types, identify:\n1. What relationships exist between them?\n2. Direction (A \u2192 B, B \u2192 A, or bidirectional)\n3. Cardinality (one-to-one, one-to-many, many-to-many)\n4. How to implement (reference fields, arrays, etc.)\n5. Use cases (why this relationship matters)\n\nThen create a relationship diagram showing all connections.\n```\n\n---",
            "hydration_source_header": "3.2 Relationship Mapping Prompt Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "validation-prompt-pattern",
            "title": "Validation Schema Generation Pattern",
            "implements": "validation-as-prevention",
            "taskType": "generation",
            "lines": "1675-1700",
            "retrievalQuestions": [
              "How do I create validation schemas with AI?"
            ],
            "content": "**Prompt Structure:**\n```text\nYou're a content architect designing metadata schemas.\n\nFor the \"[CONTENT TYPE]\" content type, define all necessary attributes.\n\nContext:\n- Platform: [PLATFORM]\n- Use cases: [WHAT METADATA ENABLES]\n- Constraints: [TECHNICAL LIMITS]\n\n[CONTENT TYPE DEFINITION]\n\nFor each attribute specify:\n- Field name\n- Data type\n- Required or optional\n- Description\n- Validation rules\n- Default value (if applicable)\n- Examples\n\nAlso consider:\n- What enables search/filtering?\n- What enables automation?\n- What supports content reuse?\n- What helps authors?\n```\n\n---",
            "hydration_source_header": "2.1 The Schema Generation Pattern",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "promptPatterns": [
          {
            "id": "content-type-identification-prompt",
            "title": "Content Type Identification Prompt",
            "taskType": "analysis",
            "lines": "115-158",
            "standalone": true,
            "retrievalQuestions": [
              "Give me a prompt to identify content types from existing docs"
            ],
            "content": "id:\n    type: string\n    required: true\n    pattern: \"^[a-z0-9-]+$\"\n    description: \"Unique identifier, URL-safe\"\n    example: \"setup-ci-integration\"\n  \n  title:\n    type: string\n    required: true\n    min_length: 10\n    max_length: 80\n    description: \"Page title, shown in navigation and SEO\"\n    example: \"How to Set Up CI/CD Integration\"\n  \n  content_type:\n    type: enum\n    required: true\n    allowed_values: [\"tutorial\", \"howto\", \"reference\", \"concept\", \"integration\"]\n    description: \"Content type for rendering and filtering\"",
            "hydration_source_header": "Identification",
            "hydration_method": "title_match"
          },
          {
            "id": "schema-generation-prompt",
            "title": "Metadata Schema Generation Prompt",
            "taskType": "generation",
            "lines": "475-530",
            "standalone": true,
            "retrievalQuestions": [
              "What prompt generates a metadata schema?"
            ],
            "content": "**Prompt Structure:**\n```text\nYou're a content architect designing metadata schemas.\n\nFor the \"[CONTENT TYPE]\" content type, define all necessary attributes.\n\nContext:\n- Platform: [PLATFORM]\n- Use cases: [WHAT METADATA ENABLES]\n- Constraints: [TECHNICAL LIMITS]\n\n[CONTENT TYPE DEFINITION]\n\nFor each attribute specify:\n- Field name\n- Data type\n- Required or optional\n- Description\n- Validation rules\n- Default value (if applicable)\n- Examples\n\nAlso consider:\n- What enables search/filtering?\n- What enables automation?\n- What supports content reuse?\n- What helps authors?\n```\n\n---",
            "hydration_source_header": "2.1 The Schema Generation Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "batch-schema-prompt",
            "title": "Batch Schema Generation Prompt",
            "taskType": "generation",
            "lines": "935-970",
            "standalone": true,
            "content": "**Prompt Structure:**\n```text\nYou're a content architect designing metadata schemas.\n\nFor the \"[CONTENT TYPE]\" content type, define all necessary attributes.\n\nContext:\n- Platform: [PLATFORM]\n- Use cases: [WHAT METADATA ENABLES]\n- Constraints: [TECHNICAL LIMITS]\n\n[CONTENT TYPE DEFINITION]\n\nFor each attribute specify:\n- Field name\n- Data type\n- Required or optional\n- Description\n- Validation rules\n- Default value (if applicable)\n- Examples\n\nAlso consider:\n- What enables search/filtering?\n- What enables automation?\n- What supports content reuse?\n- What helps authors?\n```\n\n---",
            "hydration_source_header": "2.1 The Schema Generation Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "relationship-mapping-prompt",
            "title": "Relationship Mapping Prompt",
            "taskType": "analysis",
            "lines": "1127-1170",
            "standalone": true,
            "retrievalQuestions": [
              "How do I prompt AI to map content relationships?"
            ],
            "content": "**Prompt Structure:**\n```text\nYou're a content architect mapping relationships between content types.\n\nContent types:\n- [List types]\n\nFor each pair of content types, identify:\n1. What relationships exist between them?\n2. Direction (A \u2192 B, B \u2192 A, or bidirectional)\n3. Cardinality (one-to-one, one-to-many, many-to-many)\n4. How to implement (reference fields, arrays, etc.)\n5. Use cases (why this relationship matters)\n\nThen create a relationship diagram showing all connections.\n```\n\n---",
            "hydration_source_header": "3.2 Relationship Mapping Prompt Pattern",
            "hydration_method": "title_match"
          },
          {
            "id": "validation-schema-prompt",
            "title": "Validation Implementation Prompt",
            "taskType": "generation",
            "lines": "1675-1700",
            "standalone": true,
            "retrievalQuestions": [
              "Show me a prompt for validation schema creation"
            ],
            "content": "weight: 1  # Ordering\ntype: \"tutorial\"  # Content type (affects layout)\nlayout: \"single\"  # Template\n---\n```\n\n**Key Features:**\n- Built-in taxonomies (categories, tags, series)\n- Weight for ordering\n- Type and layout for template selection\n- Params for custom metadata\n\n---\n\n### 4.3 Metadata Validation Strategy\n\n**Validation Prompt:**\n\n```text\nYou're implementing metadata validation for Docs-as-Code.\n\nCreate a validation schema that:\n1. Defines required vs. optional fields\n2. Specifies data types and allowed values\n3. Checks relationships (all URLs exist)\n4. Validates against business rules\n\nPlatform: Docusaurus\nContent types: Tutorial, How-to, Reference, Concept, Troubleshooting\n\nProvide:\n1. JSON Schema for each content type\n2. Custom validation rules (beyond JSON Schema)\n3. Build script pseudocode for validation\n4. Error messages for common issues\n5. How to integrate with CI/CD\n```\n\n<Accordion title=\"Example Validation Implementation (JSON Schema + Custom Rules)\">\n\n```javascript\n// JSON Schema for Tutorial Content Type\nconst tutorialSchema = {\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"type\": \"object\",\n  \"required\": [\"title\", \"description\", \"content_type\", \"difficulty\", \"estimated_time\"],\n  \"properties\": {\n    \"title\": {\n      \"type\": \"string\",\n      \"minLength\": 10,\n      \"maxLength\": 80\n    },\n    \"description\": {\n      \"type\": \"string\",\n      \"minLength\": 50,\n      \"maxLength\": 160\n    },\n    \"difficulty\": {\n      \"type\": \"string\",\n      \"enum\": [\"beginner\", \"intermediate\", \"advanced\"]\n    },\n    \"estimated_time\": {\n      \"type\": \"integer\",\n      \"minimum\": 5,\n      \"maximum\": 120\n    }\n    // ... more fields\n  }\n};\n\n// Custom Validation Rules\nfunction validateTimeVsDifficulty(frontmatter) {\n  const { difficulty, estimated_time } = frontmatter;\n  const limits = {\n    beginner: { min: 5, max: 30 },\n    intermediate: { min: 15, max: 60 },\n    advanced: { min: 30, max: 120 }\n  };\n  \n  const { min, max } = limits[difficulty];\n  if (estimated_time < min || estimated_time > max) {\n    return {\n      valid: true,  // Warning only\n      warning: `${difficulty} tutorials typically take ${min}-${max} minutes. This is ${estimated_time} minutes.`\n    };\n  }\n  return { valid: true };\n}\n\n// Build Script Pseudocode\nconst fs = require('fs');\nconst yaml = require('js-yaml');\nconst Ajv = require('ajv');\n\nconst ajv = new Ajv();\nconst schemas = {\n  tutorial: ajv.compile(tutorialSchema),\n  howto: ajv.compile(howtoSchema),\n  // ... more schemas\n};\n\nlet errors = [];\nlet warnings = [];\n\n// Validate all docs\nconst allDocs = {};\nfs.readdirSync('./docs').forEach(file => {\n  const content = fs.readFileSync(`./docs/${file}`, 'utf8');\n  const match = content.match(/---\\n([\\s\\S]*?)\\n---/);\n  \n  if (!match) {\n    errors.push({file, error: 'Missing frontmatter'});\n    return;\n  }\n  \n  const frontmatter = yaml.load(match[1]);\n  const contentType = frontmatter.content_type;\n  const validate = schemas[contentType];\n  \n  if (!validate(frontmatter)) {\n    validate.errors.forEach(err => {\n      errors.push({file, error: err.message});\n    });\n  }\n  \n  // Custom validations\n  const timeValidation = validateTimeVsDifficulty(frontmatter);\n  if (timeValidation.warning) {\n    warnings.push({file, warning: timeValidation.warning});\n  }\n});\n\n// Report and exit\nconsole.log(`Errors: ${errors.length}, Warnings: ${warnings.length}`);\nprocess.exit(errors.length > 0 ? 1 : 0);\n```\n\n</Accordion>\n\n---\n\n### Check Your Understanding: Validation Error Detection\n\n<Warning>\n**Quick Practice (5 minutes):** Identify validation errors in frontmatter to solidify your understanding of metadata validation.\n</Warning>\n\n**Scenario:** You're reviewing frontmatter for a tutorial content type. The schema requires:\n- `title` (string, required, max 60 chars)\n- `difficulty` (enum: \"beginner\", \"intermediate\", \"advanced\", required)\n- `estimated_time_minutes` (number, required, min: 5, max: 120)\n- `prerequisites` (array of strings, optional)\n- `content_type` (string, must be \"tutorial\")\n\n**Question:** Find **all validation errors** in this frontmatter:\n\n```yaml\n---\ntitle: \"Building a Complete Authentication System with OAuth 2.0, JWT, and Multi-Factor Authentication\"\ndifficulty: \"easy\"\nestimated_time_minutes: 150\nprerequisites: \"basic JavaScript\"\ncontent_type: \"how-to\"\n---\n```\n\n<details>\n<summary>Show Answer</summary>\n\n**Validation Errors Found (5 total):**\n\n**Error 1: `title` too long** \u274c\n- **Current:** 98 characters\n- **Maximum:** 60 characters\n- **Problem:** Exceeds character limit by 38 characters\n- **Fix:**\n  ```yaml\n  title: \"Build OAuth 2.0 Authentication with JWT and MFA\"",
            "hydration_source_header": "Hugo features",
            "hydration_method": "line_proximity"
          },
          {
            "id": "content-inventory-analysis-prompt",
            "title": "Content Inventory Analysis Prompt",
            "taskType": "analysis",
            "lines": "2020-2055",
            "standalone": true,
            "hydration_status": "failed"
          },
          {
            "id": "type-refinement-prompt",
            "title": "Content Type Refinement Prompt",
            "taskType": "refinement",
            "lines": "2055-2075",
            "standalone": true,
            "content": "**What You're Doing:** Refine AI suggestions into 4-6 final content types that match your documentation strategy.\n\n**Validation Checklist:**\n\n**Check Against Di\u00e1taxis Framework:**\n- Do you have learning content? (Tutorials)\n- Do you have task-based content? (How-to guides)\n- Do you have reference material? (API specs, SDKs)\n- Do you have explanatory content? (Concepts, architecture)\n\n**Check Practical Distribution:**\n- Is any type dominating (>50% of content)? Consider splitting it\n- Are any types too small (less than 5% of content)? Consider merging or eliminating\n- Does each type have a clear, unique purpose?\n\n**Your Refinement Prompt:**\n\n```text\nBased on your analysis, I'm considering these content types:\n\n1. Tutorial - [Brief definition]\n2. How-to Guide - [Brief definition]\n3. API Reference - [Brief definition]\n4. Concept/Explanation - [Brief definition]\n\nReview these for:\n- Clear distinction between types\n- Whether \"Integration Guide\" should be separate or merged\n- How to handle edge cases like \"Troubleshooting\" content\n\nProvide recommendations with rationale.\n```\n\n**Decision Point:** Choose your final 4-6 content types. For DevTools, you might settle on:\n1. **Tutorial** (20 pages, 25%)\n2. **How-to Guide** (18 pages, 23%)\n3. **API Reference** (22 pages, 28%)\n4. **Concept** (12 pages, 15%)\n5. **Integration Guide** (8 pages, 10%)\n\n---",
            "hydration_source_header": "Step 2: Identify Content Types",
            "hydration_method": "line_proximity"
          },
          {
            "id": "base-schema-design-prompt",
            "title": "Base Schema Design Prompt",
            "taskType": "generation",
            "lines": "2120-2160",
            "standalone": true,
            "content": "base_schema:",
            "hydration_source_header": "Base Schema (All Content Types)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "type-specific-schema-prompt",
            "title": "Type-Specific Schema Design Prompt",
            "taskType": "generation",
            "lines": "2180-2230",
            "standalone": true,
            "content": "**What You're Doing:** Define unique attributes for each content type that extend the base schema.\n\n**Your AI Prompt (for each type):**\n\n```text\nYou're designing a type-specific schema for the \"Tutorial\" content type in DevTools docs.\n\nA Tutorial is:\n- Learning-oriented, step-by-step\n- Assumes little prior knowledge\n- Includes complete working examples\n- Takes 15-45 minutes to complete\n\nBased on the base schema (which handles ID, title, status, dates, etc.), \ndefine ADDITIONAL fields unique to tutorials:\n\nConsider:\n- Difficulty level\n- Time estimate\n- Prerequisites\n- Learning objectives\n- Tools/dependencies needed\n- Completion criteria\n- Code examples presence\n\nFor each field:\n- Field name\n- Data type\n- Required or optional\n- Validation rules\n- Purpose\n- Example value\n\nExample frontmatter at the end showing all base + type-specific fields.\n```\n\n**Expected Output Example (Tutorial Type):**\n\n```yaml",
            "hydration_source_header": "Step 4: Create Type-Specific Schemas",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "relationship-definition-prompt",
            "title": "Relationship Definition Prompt",
            "taskType": "analysis",
            "lines": "2310-2355",
            "standalone": true,
            "content": "**Prompt Structure:**\n```text\nYou're a content architect mapping relationships between content types.\n\nContent types:\n- [List types]\n\nFor each pair of content types, identify:\n1. What relationships exist between them?\n2. Direction (A \u2192 B, B \u2192 A, or bidirectional)\n3. Cardinality (one-to-one, one-to-many, many-to-many)\n4. How to implement (reference fields, arrays, etc.)\n5. Use cases (why this relationship matters)\n\nThen create a relationship diagram showing all connections.\n```\n\n---",
            "hydration_source_header": "3.2 Relationship Mapping Prompt Pattern",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "workflows": [
          {
            "id": "tutorial-content-modeling",
            "title": "Tutorial: Building a Content Model (6 steps)",
            "steps": 6,
            "uses": [
              "content-type-discovery-pattern",
              "schema-generation-pattern",
              "relationship-mapping-pattern"
            ],
            "lines": "1980-2520",
            "retrievalQuestions": [
              "Walk me through creating a content model from scratch"
            ],
            "content": "Let's walk through creating a complete content model from scratch using AI assistance.\n\n### Tutorial Scenario\n\nYou're the IA lead for \"DevTools\"\u2014a code quality and CI/CD platform. You have 80 pages of existing documentation with no formal content model. Your task: create a structured content model that supports better navigation, search, and maintenance.\n\n**Your Goals:**\n- Identify distinct content types\n- Design reusable metadata schemas\n- Establish clear relationships between content\n- Implement validation\n\n---\n\n### Step 1: Analyze Content Inventory\n\n**What You're Doing:** Review existing content to identify natural patterns and groupings.\n\n**Sample Content (20 of 80 pages):**\n\n```text\n1. \"Getting Started with DevTools\"\n2. \"Code Quality API Reference\"\n3. \"How to Set Up CI/CD Integration\"\n4. \"Understanding Code Metrics\"\n5. \"GitHub Actions Integration Guide\"\n6. \"Webhook Events API\"\n7. \"Build a Custom Quality Gate Tutorial\"\n8. \"Why We Use Static Analysis\"\n9. \"Troubleshooting Build Failures\"\n10. \"Python SDK Documentation\"\n11. \"How to Create Custom Rules\"\n12. \"Security Scanning Overview\"\n13. \"API Authentication Guide\"\n14. \"Optimizing Build Performance\"\n15. \"Branch Analysis Reference\"\n16. \"Setting Up Quality Profiles\"\n17. \"Understanding Technical Debt\"\n18. \"How to Integrate with Slack\"\n19. \"Code Coverage Metrics Explained\"\n20. \"Billing and Usage API\"\n```\n\n**Your AI Prompt:**\n\n```text\nYou're a content strategist analyzing documentation to create a content model.\n\nAnalyze these 20 sample pages (representing 80 total) and identify 4-6 distinct \ncontent types.\n\n[Paste the 20 page titles above]\n\nFor each content type you identify:\n1. Name and clear definition\n2. Purpose (what problem does it solve?)\n3. Target audience\n4. Distinguishing characteristics\n5. Examples from the sample (3-5 titles)\n6. Estimated percentage of the 80 pages\n\nAlso note:\n- Pages that don't fit clearly into one type\n- Patterns you observe (naming, structure, intent)\n```\n\n**Expected AI Output Pattern:**\n\nThe AI should identify types like:\n- **Tutorials** (learning-oriented, step-by-step, \"Build...\")\n- **How-to Guides** (task-oriented, problem-solving, \"How to...\")\n- **Reference** (information-oriented, technical specs, \"API...\")\n- **Explanations** (understanding-oriented, concepts, \"Understanding...\")\n\n**Your Action:** Review the AI's suggestions and validate against your full 80-page inventory. Adjust based on business needs.\n\n---\n\n### Step 2: Identify Content Types\n\n**What You're Doing:** Refine AI suggestions into 4-6 final content types that match your documentation strategy.\n\n**Validation Checklist:**\n\n**Check Against Di\u00e1taxis Framework:**\n- Do you have learning content? (Tutorials)\n- Do you have task-based content? (How-to guides)\n- Do you have reference material? (API specs, SDKs)\n- Do you have explanatory content? (Concepts, architecture)\n\n**Check Practical Distribution:**\n- Is any type dominating (>50% of content)? Consider splitting it\n- Are any types too small (less than 5% of content)? Consider merging or eliminating\n- Does each type have a clear, unique purpose?\n\n**Your Refinement Prompt:**\n\n```text\nBased on your analysis, I'm considering these content types:\n\n1. Tutorial - [Brief definition]\n2. How-to Guide - [Brief definition]\n3. API Reference - [Brief definition]\n4. Concept/Explanation - [Brief definition]\n\nReview these for:\n- Clear distinction between types\n- Whether \"Integration Guide\" should be separate or merged\n- How to handle edge cases like \"Troubleshooting\" content\n\nProvide recommendations with rationale.\n```\n\n**Decision Point:** Choose your final 4-6 content types. For DevTools, you might settle on:\n1. **Tutorial** (20 pages, 25%)\n2. **How-to Guide** (18 pages, 23%)\n3. **API Reference** (22 pages, 28%)\n4. **Concept** (12 pages, 15%)\n5. **Integration Guide** (8 pages, 10%)\n\n---\n\n### Step 3: Design Base Schema\n\n**What You're Doing:** Create common fields that ALL content types inherit. This ensures consistency and enables site-wide features.\n\n**Core Categories to Consider:**\n\n**Identification Fields:**\n- Unique ID, title, slug, content type designation\n\n**Publishing Metadata:**\n- Author, dates (created, updated), version, status\n\n**Discovery & SEO:**\n- Description, keywords, categories/tags\n\n**Relationships:**\n- Related content, prerequisites, part-of collections\n\n**Your AI Prompt:**\n\n```text\nYou're designing a base content schema for DevTools documentation.\n\nCreate a base schema that ALL content types will inherit. Include:\n\nREQUIRED:\n- Identification fields (ID, title, slug, content_type)\n- Publishing workflow (author, dates, status, version)\n- SEO (description, keywords)\n- Basic relationships (tags, category)\n\nFor each field specify:\n- Field name (use snake_case)\n- Data type (string, date, array, enum, etc.)\n- Required or optional\n- Validation rules (min/max length, allowed values)\n- Purpose (how it's used)\n- Example value\n\nKeep it lean\u2014only truly universal fields. Be conservative with \"required.\"\n```\n\n**Expected Output Structure:**\n\n```yaml",
            "hydration_source_header": "5. Step-by-Step Tutorial: Building a Content Model",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "step-1-analyze-inventory",
            "title": "Step 1: Analyze Content Inventory",
            "uses": "content-inventory-analysis-prompt",
            "lines": "1985-2040",
            "content": "**What You're Doing:** Review existing content to identify natural patterns and groupings.\n\n**Sample Content (20 of 80 pages):**\n\n```text\n1. \"Getting Started with DevTools\"\n2. \"Code Quality API Reference\"\n3. \"How to Set Up CI/CD Integration\"\n4. \"Understanding Code Metrics\"\n5. \"GitHub Actions Integration Guide\"\n6. \"Webhook Events API\"\n7. \"Build a Custom Quality Gate Tutorial\"\n8. \"Why We Use Static Analysis\"\n9. \"Troubleshooting Build Failures\"\n10. \"Python SDK Documentation\"\n11. \"How to Create Custom Rules\"\n12. \"Security Scanning Overview\"\n13. \"API Authentication Guide\"\n14. \"Optimizing Build Performance\"\n15. \"Branch Analysis Reference\"\n16. \"Setting Up Quality Profiles\"\n17. \"Understanding Technical Debt\"\n18. \"How to Integrate with Slack\"\n19. \"Code Coverage Metrics Explained\"\n20. \"Billing and Usage API\"\n```\n\n**Your AI Prompt:**\n\n```text\nYou're a content strategist analyzing documentation to create a content model.\n\nAnalyze these 20 sample pages (representing 80 total) and identify 4-6 distinct \ncontent types.\n\n[Paste the 20 page titles above]\n\nFor each content type you identify:\n1. Name and clear definition\n2. Purpose (what problem does it solve?)\n3. Target audience\n4. Distinguishing characteristics\n5. Examples from the sample (3-5 titles)\n6. Estimated percentage of the 80 pages\n\nAlso note:\n- Pages that don't fit clearly into one type\n- Patterns you observe (naming, structure, intent)\n```\n\n**Expected AI Output Pattern:**\n\nThe AI should identify types like:\n- **Tutorials** (learning-oriented, step-by-step, \"Build...\")\n- **How-to Guides** (task-oriented, problem-solving, \"How to...\")\n- **Reference** (information-oriented, technical specs, \"API...\")\n- **Explanations** (understanding-oriented, concepts, \"Understanding...\")\n\n**Your Action:** Review the AI's suggestions and validate against your full 80-page inventory. Adjust based on business needs.\n\n---",
            "hydration_source_header": "Step 1: Analyze Content Inventory",
            "hydration_method": "title_match"
          },
          {
            "id": "step-2-identify-types",
            "title": "Step 2: Identify Content Types",
            "uses": "type-refinement-prompt",
            "lines": "2040-2110",
            "content": "**What You're Doing:** Refine AI suggestions into 4-6 final content types that match your documentation strategy.\n\n**Validation Checklist:**\n\n**Check Against Di\u00e1taxis Framework:**\n- Do you have learning content? (Tutorials)\n- Do you have task-based content? (How-to guides)\n- Do you have reference material? (API specs, SDKs)\n- Do you have explanatory content? (Concepts, architecture)\n\n**Check Practical Distribution:**\n- Is any type dominating (>50% of content)? Consider splitting it\n- Are any types too small (less than 5% of content)? Consider merging or eliminating\n- Does each type have a clear, unique purpose?\n\n**Your Refinement Prompt:**\n\n```text\nBased on your analysis, I'm considering these content types:\n\n1. Tutorial - [Brief definition]\n2. How-to Guide - [Brief definition]\n3. API Reference - [Brief definition]\n4. Concept/Explanation - [Brief definition]\n\nReview these for:\n- Clear distinction between types\n- Whether \"Integration Guide\" should be separate or merged\n- How to handle edge cases like \"Troubleshooting\" content\n\nProvide recommendations with rationale.\n```\n\n**Decision Point:** Choose your final 4-6 content types. For DevTools, you might settle on:\n1. **Tutorial** (20 pages, 25%)\n2. **How-to Guide** (18 pages, 23%)\n3. **API Reference** (22 pages, 28%)\n4. **Concept** (12 pages, 15%)\n5. **Integration Guide** (8 pages, 10%)\n\n---",
            "hydration_source_header": "Step 2: Identify Content Types",
            "hydration_method": "title_match"
          },
          {
            "id": "step-3-design-base-schema",
            "title": "Step 3: Design Base Schema",
            "uses": "base-schema-design-prompt",
            "lines": "2115-2175",
            "content": "**What You're Doing:** Create common fields that ALL content types inherit. This ensures consistency and enables site-wide features.\n\n**Core Categories to Consider:**\n\n**Identification Fields:**\n- Unique ID, title, slug, content type designation\n\n**Publishing Metadata:**\n- Author, dates (created, updated), version, status\n\n**Discovery & SEO:**\n- Description, keywords, categories/tags\n\n**Relationships:**\n- Related content, prerequisites, part-of collections\n\n**Your AI Prompt:**\n\n```text\nYou're designing a base content schema for DevTools documentation.\n\nCreate a base schema that ALL content types will inherit. Include:\n\nREQUIRED:\n- Identification fields (ID, title, slug, content_type)\n- Publishing workflow (author, dates, status, version)\n- SEO (description, keywords)\n- Basic relationships (tags, category)\n\nFor each field specify:\n- Field name (use snake_case)\n- Data type (string, date, array, enum, etc.)\n- Required or optional\n- Validation rules (min/max length, allowed values)\n- Purpose (how it's used)\n- Example value\n\nKeep it lean\u2014only truly universal fields. Be conservative with \"required.\"\n```\n\n**Expected Output Structure:**\n\n```yaml",
            "hydration_source_header": "Step 3: Design Base Schema",
            "hydration_method": "title_match"
          },
          {
            "id": "step-4-type-specific-schemas",
            "title": "Step 4: Create Type-Specific Schemas",
            "uses": "type-specific-schema-prompt",
            "lines": "2175-2305",
            "content": "**What You're Doing:** Define unique attributes for each content type that extend the base schema.\n\n**Your AI Prompt (for each type):**\n\n```text\nYou're designing a type-specific schema for the \"Tutorial\" content type in DevTools docs.\n\nA Tutorial is:\n- Learning-oriented, step-by-step\n- Assumes little prior knowledge\n- Includes complete working examples\n- Takes 15-45 minutes to complete\n\nBased on the base schema (which handles ID, title, status, dates, etc.), \ndefine ADDITIONAL fields unique to tutorials:\n\nConsider:\n- Difficulty level\n- Time estimate\n- Prerequisites\n- Learning objectives\n- Tools/dependencies needed\n- Completion criteria\n- Code examples presence\n\nFor each field:\n- Field name\n- Data type\n- Required or optional\n- Validation rules\n- Purpose\n- Example value\n\nExample frontmatter at the end showing all base + type-specific fields.\n```\n\n**Expected Output Example (Tutorial Type):**\n\n```yaml",
            "hydration_source_header": "Step 4: Create Type-Specific Schemas",
            "hydration_method": "title_match"
          },
          {
            "id": "step-5-map-relationships",
            "title": "Step 5: Map Relationships",
            "uses": "relationship-definition-prompt",
            "lines": "2305-2400",
            "content": "relatedTutorials:\n  - \"/docs/tutorials/accept-recurring-payments\"\n  - \"/docs/tutorials/handle-webhooks\"\nrelatedGuides:\n  - \"/docs/how-to/customize-checkout\"\nrelatedReference:\n  - \"/docs/api/payment-intents\"\npartOfLearningPath: \"/learning-paths/accepting-payments\"",
            "hydration_source_header": "Relationships",
            "hydration_method": "title_match"
          },
          {
            "id": "step-6-implement-validation",
            "title": "Step 6: Implement Validation",
            "uses": "validation-schema-prompt",
            "lines": "2400-2505",
            "content": "**What You're Doing:** Create validation rules to catch errors before content goes live.\n\n**Validation Layers:**\n\n**Layer 1: Schema Validation (JSON Schema)**\n- Required fields present\n- Data types correct\n- Enum values valid\n- String lengths within limits\n\n**Layer 2: Business Logic**\n- Estimated time matches difficulty\n- Prerequisites actually exist\n- No circular dependencies\n- Version format valid\n\n**Your AI Prompt:**\n\n```text\nYou're implementing validation for DevTools content model.\n\nCreate:\n1. JSON Schema for the Tutorial type (base + type-specific fields)\n2. Custom validation function for business rules:\n   - Beginner tutorials: 5-30 minutes\n   - Intermediate: 15-60 minutes\n   - Advanced: 30-120 minutes\n3. Validation for prerequisites:\n   - All referenced URLs exist\n   - No circular dependencies\n4. Build script pseudocode that runs these checks\n\nProvide working code examples (JavaScript).\n```\n\n**Expected Output:**\n\n```javascript\n// JSON Schema for Tutorial\nconst tutorialSchema = {\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"type\": \"object\",\n  \"required\": [\"title\", \"description\", \"content_type\", \"difficulty\", \"estimated_time\"],\n  \"properties\": {\n    \"title\": {\n      \"type\": \"string\",\n      \"minLength\": 10,\n      \"maxLength\": 80\n    },\n    \"difficulty\": {\n      \"type\": \"string\",\n      \"enum\": [\"beginner\", \"intermediate\", \"advanced\"]\n    },\n    \"estimated_time\": {\n      \"type\": \"integer\",\n      \"minimum\": 5,\n      \"maximum\": 120\n    }\n  }\n};\n\n// Custom Business Logic Validation\nfunction validateTimeVsDifficulty(frontmatter) {\n  const { difficulty, estimated_time } = frontmatter;\n  const timeLimits = {\n    beginner: { min: 5, max: 30 },\n    intermediate: { min: 15, max: 60 },\n    advanced: { min: 30, max: 120 }\n  };\n  \n  const { min, max } = timeLimits[difficulty];\n  if (estimated_time < min || estimated_time > max) {\n    return {\n      valid: false,\n      error: `${difficulty} tutorials should be ${min}-${max} minutes. Got ${estimated_time}.`\n    };\n  }\n  return { valid: true };\n}\n\n// Build-time Validation Script\nconst fs = require('fs');\nconst yaml = require('js-yaml');\nconst Ajv = require('ajv');\n\nconst ajv = new Ajv();\nconst validate = ajv.compile(tutorialSchema);\n\nconst errors = [];\n\n// Read all docs\nfs.readdirSync('./docs/tutorials').forEach(file => {\n  const content = fs.readFileSync(`./docs/tutorials/${file}`, 'utf8');\n  const frontmatter = yaml.load(content.match(/---\\n([\\s\\S]*?)\\n---/)[1]);\n  \n  // Schema validation\n  if (!validate(frontmatter)) {\n    validate.errors.forEach(err => {\n      errors.push({ file, error: err.message });\n    });\n  }\n  \n  // Business logic validation\n  const timeCheck = validateTimeVsDifficulty(frontmatter);\n  if (!timeCheck.valid) {\n    errors.push({ file, error: timeCheck.error });\n  }\n});\n\n// Report\nif (errors.length > 0) {\n  console.error('Validation failed:');\n  errors.forEach(e => console.error(`${e.file}: ${e.error}`));\n  process.exit(1);\n}\n\nconsole.log('All validations passed!');\n```\n\n**Your Action:** \n1. Add this to your build pipeline (CI/CD)\n2. Set up pre-commit hooks for immediate feedback\n3. Configure IDE validation (VS Code with YAML/JSON schema support)\n\n---",
            "hydration_source_header": "Step 6: Implement Validation",
            "hydration_method": "title_match"
          }
        ],
        "concepts": [
          {
            "id": "content-type",
            "term": "Content Type",
            "definition": "A category of content with distinct purpose, structure, and attributes",
            "lines": "113-120",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "metadata-schema",
            "term": "Metadata Schema",
            "definition": "Structured definition of attributes for a content type",
            "lines": "371-380",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "base-schema",
            "term": "Base Schema",
            "definition": "Common fields all content types inherit",
            "lines": "2120-2175",
            "retrievalQuestions": [
              "What's the difference between base schema and type-specific schema?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "type-specific-schema",
            "term": "Type-Specific Schema",
            "definition": "Additional fields unique to one content type",
            "lines": "2175-2305",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "frontmatter",
            "term": "Frontmatter",
            "definition": "YAML/JSON metadata at top of Markdown files",
            "lines": "820-850",
            "retrievalQuestions": [
              "What is frontmatter in documentation?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "relationship-cardinality",
            "term": "Relationship Cardinality",
            "definition": "One-to-one, one-to-many, many-to-many",
            "lines": "1005-1020",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "relationship-directionality",
            "term": "Relationship Directionality",
            "definition": "Unidirectional or bidirectional connections",
            "lines": "1020-1035",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "docs-as-code",
            "term": "Docs-as-Code",
            "definition": "Treating documentation like software (version control, CI/CD)",
            "lines": "1499-1515",
            "retrievalQuestions": [
              "What is docs-as-code?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "json-schema-validation",
            "term": "JSON Schema Validation",
            "definition": "Structural validation using JSON Schema standard",
            "lines": "1715-1750",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "business-logic-validation",
            "term": "Business Logic Validation",
            "definition": "Custom validation rules beyond schema structure",
            "lines": "1750-1800",
            "retrievalQuestions": [
              "What's the difference between JSON Schema and business logic validation?"
            ],
            "hydration_status": "skipped_unknown"
          }
        ],
        "examples": [
          {
            "id": "stripe-api-content-analysis",
            "title": "Stripe API Documentation Analysis",
            "demonstrates": "content-type-discovery-pattern",
            "lines": "160-370",
            "retrievalQuestions": [
              "Show me an example content type analysis"
            ],
            "content": "**Your Prompt:**\n\n```text\nYou're mapping relationships between API documentation content types.\n\nContent types:\n1. Tutorial - Learning-oriented, step-by-step\n2. How-to Guide - Task-oriented, problem-solving\n3. API Reference - Technical specifications\n4. Concept/Explanation - Understanding-oriented\n5. Troubleshooting - Problem diagnosis and fixes\n\nFor each meaningful relationship:\n1. Relationship name and direction\n2. Cardinality\n3. Implementation approach\n4. Example\n5. Use case (why it matters)\n\nThen provide:\n- Visual relationship diagram (text-based)\n- Implementation recommendations\n- Example queries users might want (\"Show me all tutorials that use this API endpoint\")\n```\n\n---\n\n**AI Output (Example):**\n\n```text\nCONTENT TYPE RELATIONSHIP MAP\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 1: Tutorial \u2192 How-to Guide\nName: \"leads-to\" or \"next-steps\"\nDirection: Tutorial \u2192 How-to (unidirectional)\nCardinality: One-to-many (one tutorial can lead to multiple how-tos)\nImplementation: Array field in Tutorial: relatedGuides: string[]\nExample:\n  Tutorial: \"Build Your First Payment Integration\"\n  \u2192 How-to: \"How to Customize Checkout UI\"\n  \u2192 How-to: \"How to Handle Payment Failures\"\nUse Case: After learning basics (tutorial), users want practical applications (how-tos)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 2: Tutorial \u2192 API Reference\nName: \"uses\" or \"references\"\nDirection: Tutorial \u2192 API Reference (unidirectional)\nCardinality: Many-to-many (tutorial uses multiple endpoints, endpoint used by multiple tutorials)\nImplementation: Array field in Tutorial: relatedReference: string[]\nExample:\n  Tutorial: \"Build Your First Payment Integration\"\n  \u2192 API Ref: \"Payment Intents API\"\n  \u2192 API Ref: \"Charges API\"\nUse Case: Users want technical details about APIs used in tutorial\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 3: Concept \u2192 Tutorial\nName: \"applied-in\" or \"demonstrated-by\"\nDirection: Concept \u2192 Tutorial (unidirectional)\nCardinality: One-to-many (one concept demonstrated by multiple tutorials)\nImplementation: Array field in Concept: relatedTutorials: string[]\nExample:\n  Concept: \"Understanding Payment Intents\"\n  \u2192 Tutorial: \"Build Your First Payment Integration\"\n  \u2192 Tutorial: \"Accept Recurring Payments\"\nUse Case: After understanding concept, users want hands-on practice\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 4: Tutorial \u2192 Tutorial\nName: \"prerequisite\" or \"builds-on\"\nDirection: Tutorial A \u2192 Tutorial B (unidirectional, could be bidirectional for \"related\")\nCardinality: Many-to-many\nImplementation: \n  - prerequisites: {title: string, url: string, required: boolean}[]\n  - relatedTutorials: string[]\nExample:\n  Tutorial: \"Build Your First Payment Integration\"\n  \u2190 prerequisite: \"API Authentication Basics\"\n  \u2192 next: \"Accept Recurring Payments\"\nUse Case: Learning path sequencing, ensuring users have required knowledge\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 5: How-to Guide \u2192 Troubleshooting\nName: \"troubleshoots\" or \"solves-problems-in\"\nDirection: How-to \u2192 Troubleshooting (unidirectional)\nCardinality: One-to-many\nImplementation: Array field in How-to: commonIssues: string[]\nExample:\n  How-to: \"How to Implement Webhooks\"\n  \u2192 Troubleshooting: \"Webhook Not Receiving Events\"\n  \u2192 Troubleshooting: \"Webhook Signature Verification Failed\"\nUse Case: Proactively link to common problems users might encounter\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP DEFINITIONS\n\n```yaml\nrelationships:",
            "hydration_source_header": "3.3 Example: API Documentation Relationships",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "tutorial-schema-example",
            "title": "Tutorial Content Type Schema",
            "demonstrates": "schema-generation-pattern",
            "lines": "540-900",
            "retrievalQuestions": [
              "What does a tutorial schema look like?"
            ],
            "content": "**Your Prompt:**\n\n```text\nYou're a content architect designing a metadata schema for API documentation.\n\nDefine all necessary attributes for the \"Tutorial\" content type.\n\nContext:\n- Platform: Docusaurus (Markdown with YAML frontmatter)\n- Use cases: \n  * Display tutorials with time estimates and difficulty\n  * Filter tutorials by topic and difficulty\n  * Show prerequisites and next steps\n  * Track completion in learning paths\n  * Generate table of contents automatically\n  \n- Constraints:\n  * Frontmatter must be valid YAML\n  * File-based (no database)\n  * All metadata in frontmatter or markdown\n  * Must work with static site generation\n\nTutorial Definition:\n- Purpose: Teach users through hands-on, step-by-step practice\n- Assumes little/no prior knowledge\n- Includes complete working examples\n- Shows expected outcomes\n\nFor each attribute specify:\n- Field name (camelCase for consistency)\n- Data type\n- Required or optional\n- Description\n- Validation rules\n- Examples\n- How it's used (search, display, automation, etc.)\n\nConsider attributes for:\n- Basic information (title, description)\n- Learning metadata (difficulty, time, prerequisites)\n- Organization (category, tags, order)\n- Relationships (related content, next steps)\n- Technical details (code language, API version)\n- Publishing (author, date, status)\n```\n\n---\n\n**AI Output (Example):**\n\n```yaml\nTUTORIAL CONTENT TYPE - METADATA SCHEMA\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nBASIC INFORMATION\n\n1. title\n   Type: string\n   Required: YES\n   Description: Tutorial title shown in navigation and page header\n   Validation: 10-80 characters, no special characters except - and :\n   Example: \"Build Your First Payment Integration\"\n   Used for: Page title, SEO, navigation, search\n   \n2. description\n   Type: string\n   Required: YES\n   Description: Brief summary of what the tutorial teaches (for previews and SEO)\n   Validation: 50-160 characters\n   Example: \"Learn how to accept payments by building a complete checkout flow from scratch\"\n   Used for: Meta description, preview cards, search results\n\n3. slug\n   Type: string\n   Required: NO (auto-generated from title if not provided)\n   Description: URL-friendly version of title\n   Validation: lowercase, hyphens only, no spaces\n   Example: \"build-first-payment-integration\"\n   Used for: URL generation\n   Default: Auto-generated from title\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nLEARNING METADATA\n\n4. difficulty\n   Type: enum\n   Required: YES\n   Description: Skill level required to complete tutorial\n   Allowed values: \"beginner\" | \"intermediate\" | \"advanced\"\n   Example: \"beginner\"\n   Used for: Filtering, badges, learning path progression\n   \n5. estimatedTime\n   Type: integer\n   Required: YES\n   Description: Completion time in minutes\n   Validation: 5-120 minutes (tutorials >2 hours should be split)\n   Example: 15\n   Used for: Time estimates, filtering, user expectations\n   \n6. prerequisites\n   Type: array of objects\n   Required: HIGHLY RECOMMENDED\n   Description: Required knowledge or setup before starting\n   Structure:\n     - title: string\n     - url: string\n     - required: boolean (true if mandatory, false if helpful)\n   Example:\n     - title: \"API Authentication Basics\"\n       url: \"/docs/auth-basics\"\n       required: true\n     - title: \"JavaScript Fundamentals\"\n       url: \"/docs/js-basics\"\n       required: false\n   Used for: Prerequisites alerts, learning path validation, navigation\n\n7. learningObjectives\n   Type: array of strings\n   Required: YES\n   Description: What users will learn/accomplish (3-5 items)\n   Validation: 3-5 items, each 10-100 characters\n   Example:\n     - \"Create a payment intent\"\n     - \"Handle payment success and failures\"\n     - \"Test payments in sandbox mode\"\n   Used for: Preview section, completion tracking, SEO\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nTECHNICAL DETAILS\n\n8. codeLanguage\n   Type: array of enums\n   Required: YES\n   Description: Programming languages covered in tutorial\n   Allowed values: [\"javascript\", \"python\", \"ruby\", \"java\", \"php\", \"go\", \"curl\"]\n   Example: [\"javascript\", \"python\"]\n   Used for: Filtering, code language switcher, recommendations\n   \n9. apiVersion\n   Type: string\n   Required: YES\n   Description: Which API version this tutorial covers\n   Validation: Semantic versioning (e.g., \"2.0\", \"3.1\")\n   Example: \"2.0\"\n   Used for: Version switcher, compatibility warnings\n   \n10. requiredTools\n    Type: array of strings\n    Required: RECOMMENDED\n    Description: Tools/software needed to complete tutorial\n    Example: [\"npm\", \"Stripe CLI\", \"ngrok\"]\n    Used for: Prerequisites section, setup guidance\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nORGANIZATION\n\n11. category\n    Type: enum\n    Required: YES\n    Description: Primary category for organization\n    Allowed values: [\"payments\", \"billing\", \"connect\", \"identity\", \"webhooks\", \"testing\"]\n    Example: \"payments\"\n    Used for: Navigation, filtering, organization\n    \n12. tags\n    Type: array of strings\n    Required: OPTIONAL\n    Description: Additional topics/keywords for discovery\n    Validation: 3-8 tags, each 2-20 characters\n    Example: [\"checkout\", \"credit-cards\", \"quickstart\"]\n    Used for: Search, filtering, related content suggestions\n    \n13. featured\n    Type: boolean\n    Required: OPTIONAL\n    Description: Whether to feature prominently on homepage/category page\n    Default: false\n    Example: true\n    Used for: Homepage display, promotional purposes\n    \n14. order\n    Type: integer\n    Required: OPTIONAL\n    Description: Sort order within category (lower numbers first)\n    Validation: 1-1000\n    Example: 1\n    Used for: Navigation ordering, learning path sequence\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIPS\n\n15. relatedTutorials\n    Type: array of strings (URLs)\n    Required: RECOMMENDED\n    Description: Links to related tutorials (next steps)\n    Validation: Valid internal URLs\n    Example:\n      - \"/docs/tutorials/accept-recurring-payments\"\n      - \"/docs/tutorials/handle-webhooks\"\n    Used for: \"Next steps\" section, learning paths\n    \n16. relatedGuides\n    Type: array of strings (URLs)\n    Required: OPTIONAL\n    Description: Links to related how-to guides\n    Example: [\"/docs/how-to/customize-checkout\"]\n    Used for: \"Related content\" sidebar\n    \n17. relatedReference\n    Type: array of strings (URLs)\n    Required: OPTIONAL\n    Description: Links to API reference docs used in tutorial\n    Example: [\"/docs/api/payment-intents\"]\n    Used for: \"API Reference\" links, technical details\n    \n18. partOfLearningPath\n    Type: string (URL)\n    Required: OPTIONAL\n    Description: Learning path this tutorial belongs to\n    Example: \"/learning-paths/accepting-payments\"\n    Used for: Learning path navigation, progress tracking\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nCONTENT METADATA\n\n19. hasCodeExamples\n    Type: boolean\n    Required: OPTIONAL\n    Description: Whether tutorial includes downloadable code\n    Default: true (assumed for tutorials)\n    Example: true\n    Used for: Display \"Download code\" button, expectations\n    \n20. hasVideo\n    Type: string (URL)\n    Required: OPTIONAL\n    Description: Link to accompanying video tutorial\n    Validation: Valid YouTube/Vimeo URL\n    Example: \"https://youtube.com/watch?v=abc123\"\n    Used for: Embed video player, alternative learning format\n    \n21. completionCriteria\n    Type: array of strings\n    Required: RECOMMENDED\n    Description: Checklist of what constitutes completion\n    Example:\n      - \"Successfully create a test payment\"\n      - \"Handle payment confirmation\"\n      - \"Test error scenarios\"\n    Used for: Completion tracking, success validation\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nPUBLISHING METADATA\n\n22. author\n    Type: object\n    Required: YES\n    Description: Tutorial author information\n    Structure:\n      name: string\n      title: string (optional)\n      avatar: string URL (optional)\n    Example:\n      name: \"Sarah Johnson\"\n      title: \"Developer Advocate\"\n      avatar: \"/images/authors/sarah.jpg\"\n    Used for: Author byline, credibility, contact\n    \n23. publishedDate\n    Type: date\n    Required: YES\n    Description: When tutorial was first published\n    Format: ISO 8601 (YYYY-MM-DD)\n    Example: \"2024-01-15\"\n    Used for: Display date, sorting, freshness indicators\n    \n24. lastUpdated\n    Type: date\n    Required: YES\n    Description: When tutorial was last modified\n    Format: ISO 8601 (YYYY-MM-DD)\n    Example: \"2024-03-20\"\n    Auto-update: Should be auto-updated on save\n    Used for: \"Last updated\" badge, freshness, maintenance tracking\n    \n25. status\n    Type: enum\n    Required: OPTIONAL\n    Description: Publishing workflow status\n    Allowed values: \"draft\" | \"review\" | \"published\" | \"archived\"\n    Default: \"draft\"\n    Example: \"published\"\n    Used for: Workflow management, display logic\n    \n26. reviewedBy\n    Type: string\n    Required: OPTIONAL BUT RECOMMENDED\n    Description: Technical reviewer name\n    Example: \"Alex Chen, Senior Engineer\"\n    Used for: Quality assurance, internal tracking\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nSEO & SEARCH\n\n27. searchKeywords\n    Type: array of strings\n    Required: OPTIONAL\n    Description: Additional keywords for search optimization\n    Example: [\"payment\", \"checkout\", \"credit card\", \"accept payments\", \"integration\"]\n    Used for: Search indexing, SEO\n    \n28. internalNotes\n    Type: string\n    Required: OPTIONAL\n    Description: Editorial notes not displayed to users\n    Example: \"Update code examples when v3 API releases. Waiting for API v3 release.\"\n    Used for: Content planning, editorial workflow\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nEXAMPLE FRONTMATTER:\n\n```yaml\n---\ntitle: \"Build Your First Payment Integration\"\ndescription: \"Learn how to accept payments by building a complete checkout flow from scratch\"\nslug: \"build-first-payment-integration\"",
            "hydration_source_header": "2.2 Example: Tutorial Content Type Schema",
            "hydration_method": "title_match"
          },
          {
            "id": "complete-frontmatter-example",
            "title": "Complete Tutorial Frontmatter",
            "demonstrates": "frontmatter",
            "lines": "820-895",
            "retrievalQuestions": [
              "Give me an example of frontmatter for documentation"
            ],
            "content": "difficulty: \"beginner\"\nestimatedTime: 15\nprerequisites:\n  - title: \"API Authentication Basics\"\n    url: \"/docs/auth-basics\"\n    required: true\nlearningObjectives:\n  - \"Create a payment intent\"\n  - \"Handle payment success and failures\"\n  - \"Test payments in sandbox mode\"",
            "hydration_source_header": "Learning metadata",
            "hydration_method": "line_proximity"
          },
          {
            "id": "api-docs-relationship-map",
            "title": "API Documentation Relationship Map",
            "demonstrates": "relationship-mapping-pattern",
            "lines": "1173-1450",
            "retrievalQuestions": [
              "Show me how content types relate to each other"
            ],
            "content": "**Your Prompt:**\n\n```text\nYou're mapping relationships between API documentation content types.\n\nContent types:\n1. Tutorial - Learning-oriented, step-by-step\n2. How-to Guide - Task-oriented, problem-solving\n3. API Reference - Technical specifications\n4. Concept/Explanation - Understanding-oriented\n5. Troubleshooting - Problem diagnosis and fixes\n\nFor each meaningful relationship:\n1. Relationship name and direction\n2. Cardinality\n3. Implementation approach\n4. Example\n5. Use case (why it matters)\n\nThen provide:\n- Visual relationship diagram (text-based)\n- Implementation recommendations\n- Example queries users might want (\"Show me all tutorials that use this API endpoint\")\n```\n\n---\n\n**AI Output (Example):**\n\n```text\nCONTENT TYPE RELATIONSHIP MAP\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 1: Tutorial \u2192 How-to Guide\nName: \"leads-to\" or \"next-steps\"\nDirection: Tutorial \u2192 How-to (unidirectional)\nCardinality: One-to-many (one tutorial can lead to multiple how-tos)\nImplementation: Array field in Tutorial: relatedGuides: string[]\nExample:\n  Tutorial: \"Build Your First Payment Integration\"\n  \u2192 How-to: \"How to Customize Checkout UI\"\n  \u2192 How-to: \"How to Handle Payment Failures\"\nUse Case: After learning basics (tutorial), users want practical applications (how-tos)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 2: Tutorial \u2192 API Reference\nName: \"uses\" or \"references\"\nDirection: Tutorial \u2192 API Reference (unidirectional)\nCardinality: Many-to-many (tutorial uses multiple endpoints, endpoint used by multiple tutorials)\nImplementation: Array field in Tutorial: relatedReference: string[]\nExample:\n  Tutorial: \"Build Your First Payment Integration\"\n  \u2192 API Ref: \"Payment Intents API\"\n  \u2192 API Ref: \"Charges API\"\nUse Case: Users want technical details about APIs used in tutorial\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 3: Concept \u2192 Tutorial\nName: \"applied-in\" or \"demonstrated-by\"\nDirection: Concept \u2192 Tutorial (unidirectional)\nCardinality: One-to-many (one concept demonstrated by multiple tutorials)\nImplementation: Array field in Concept: relatedTutorials: string[]\nExample:\n  Concept: \"Understanding Payment Intents\"\n  \u2192 Tutorial: \"Build Your First Payment Integration\"\n  \u2192 Tutorial: \"Accept Recurring Payments\"\nUse Case: After understanding concept, users want hands-on practice\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 4: Tutorial \u2192 Tutorial\nName: \"prerequisite\" or \"builds-on\"\nDirection: Tutorial A \u2192 Tutorial B (unidirectional, could be bidirectional for \"related\")\nCardinality: Many-to-many\nImplementation: \n  - prerequisites: {title: string, url: string, required: boolean}[]\n  - relatedTutorials: string[]\nExample:\n  Tutorial: \"Build Your First Payment Integration\"\n  \u2190 prerequisite: \"API Authentication Basics\"\n  \u2192 next: \"Accept Recurring Payments\"\nUse Case: Learning path sequencing, ensuring users have required knowledge\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 5: How-to Guide \u2192 Troubleshooting\nName: \"troubleshoots\" or \"solves-problems-in\"\nDirection: How-to \u2192 Troubleshooting (unidirectional)\nCardinality: One-to-many\nImplementation: Array field in How-to: commonIssues: string[]\nExample:\n  How-to: \"How to Implement Webhooks\"\n  \u2192 Troubleshooting: \"Webhook Not Receiving Events\"\n  \u2192 Troubleshooting: \"Webhook Signature Verification Failed\"\nUse Case: Proactively link to common problems users might encounter\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP DEFINITIONS\n\n```yaml\nrelationships:",
            "hydration_source_header": "3.3 Example: API Documentation Relationships",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "recipe-schema-exercise",
            "title": "Recipe Website Schema Exercise",
            "demonstrates": "schema-generation-pattern",
            "lines": "975-1075",
            "content": "<Warning>\n**Quick Practice (7 minutes):** Complete a partial schema to reinforce attribute thinking.\n</Warning>\n\n**Scenario:** You're creating a content model for a recipe website. Below is a **partial schema** for the \"Recipe\" content type. Some attributes are missing.\n\n**Partial Recipe Schema:**\n```yaml\n---\ntitle: \"Homemade Margherita Pizza\"\ndescription: \"Classic Italian pizza with fresh basil and mozzarella\"\nauthor: \"Chef Maria\"\ndate_published: \"2024-03-15\"\ndifficulty: \"intermediate\"\nprep_time_minutes: 30\ncook_time_minutes: 15",
            "hydration_source_header": "Check Your Understanding: Schema Completion",
            "hydration_method": "line_proximity"
          },
          {
            "id": "cooking-relationship-exercise",
            "title": "Cooking Website Relationship Mapping",
            "demonstrates": "relationship-mapping-pattern",
            "lines": "1450-1600",
            "content": "Content doesn't exist in isolation. Defining relationships between content types is crucial for navigation, recommendations, and learning paths.\n\n### 3.1 Types of Relationships\n\n**Common Relationship Types:**\n\n<CardGroup cols={2}>\n  <Card title=\"Hierarchical (Parent-Child)\" icon=\"sitemap\">\n    **Examples:**\n    - Tutorial \u2192 Steps (has-many)\n    - Category \u2192 Tutorials (contains)\n    \n    **Implementation:** Nested structure or parent_id field\n  </Card>\n  \n  <Card title=\"Sequential (Ordering)\" icon=\"arrow-right-arrow-left\">\n    **Examples:**\n    - Tutorial 1 \u2192 Tutorial 2 (next-in-sequence)\n    - Beginner \u2192 Intermediate \u2192 Advanced\n    \n    **Implementation:** order field + next/previous links\n  </Card>\n  \n  <Card title=\"Prerequisite (Dependency)\" icon=\"link\">\n    **Examples:**\n    - Advanced Tutorial requires Basic Tutorial\n    - How-to assumes Concept knowledge\n    \n    **Implementation:** prerequisites array with required flag\n  </Card>\n  \n  <Card title=\"Related/Similar\" icon=\"arrows-split-up-and-left\">\n    **Examples:**\n    - Similar topics\n    - Alternative approaches\n    \n    **Implementation:** related_content array\n  </Card>\n  \n  <Card title=\"Cross-Reference\" icon=\"arrow-right-from-bracket\">\n    **Examples:**\n    - Tutorial references API endpoint\n    - How-to links to Troubleshooting\n    \n    **Implementation:** Reference arrays by type\n  </Card>\n</CardGroup>\n\n---\n\n### 3.2 Relationship Mapping Prompt Pattern\n\n**Prompt Structure:**\n```text\nYou're a content architect mapping relationships between content types.\n\nContent types:\n- [List types]\n\nFor each pair of content types, identify:\n1. What relationships exist between them?\n2. Direction (A \u2192 B, B \u2192 A, or bidirectional)\n3. Cardinality (one-to-one, one-to-many, many-to-many)\n4. How to implement (reference fields, arrays, etc.)\n5. Use cases (why this relationship matters)\n\nThen create a relationship diagram showing all connections.\n```\n\n---\n\n### 3.3 Example: API Documentation Relationships\n\n**Your Prompt:**\n\n```text\nYou're mapping relationships between API documentation content types.\n\nContent types:\n1. Tutorial - Learning-oriented, step-by-step\n2. How-to Guide - Task-oriented, problem-solving\n3. API Reference - Technical specifications\n4. Concept/Explanation - Understanding-oriented\n5. Troubleshooting - Problem diagnosis and fixes\n\nFor each meaningful relationship:\n1. Relationship name and direction\n2. Cardinality\n3. Implementation approach\n4. Example\n5. Use case (why it matters)\n\nThen provide:\n- Visual relationship diagram (text-based)\n- Implementation recommendations\n- Example queries users might want (\"Show me all tutorials that use this API endpoint\")\n```\n\n---\n\n**AI Output (Example):**\n\n```text\nCONTENT TYPE RELATIONSHIP MAP\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 1: Tutorial \u2192 How-to Guide\nName: \"leads-to\" or \"next-steps\"\nDirection: Tutorial \u2192 How-to (unidirectional)\nCardinality: One-to-many (one tutorial can lead to multiple how-tos)\nImplementation: Array field in Tutorial: relatedGuides: string[]\nExample:\n  Tutorial: \"Build Your First Payment Integration\"\n  \u2192 How-to: \"How to Customize Checkout UI\"\n  \u2192 How-to: \"How to Handle Payment Failures\"\nUse Case: After learning basics (tutorial), users want practical applications (how-tos)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 2: Tutorial \u2192 API Reference\nName: \"uses\" or \"references\"\nDirection: Tutorial \u2192 API Reference (unidirectional)\nCardinality: Many-to-many (tutorial uses multiple endpoints, endpoint used by multiple tutorials)\nImplementation: Array field in Tutorial: relatedReference: string[]\nExample:\n  Tutorial: \"Build Your First Payment Integration\"\n  \u2192 API Ref: \"Payment Intents API\"\n  \u2192 API Ref: \"Charges API\"\nUse Case: Users want technical details about APIs used in tutorial\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 3: Concept \u2192 Tutorial\nName: \"applied-in\" or \"demonstrated-by\"\nDirection: Concept \u2192 Tutorial (unidirectional)\nCardinality: One-to-many (one concept demonstrated by multiple tutorials)\nImplementation: Array field in Concept: relatedTutorials: string[]\nExample:\n  Concept: \"Understanding Payment Intents\"\n  \u2192 Tutorial: \"Build Your First Payment Integration\"\n  \u2192 Tutorial: \"Accept Recurring Payments\"\nUse Case: After understanding concept, users want hands-on practice\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 4: Tutorial \u2192 Tutorial\nName: \"prerequisite\" or \"builds-on\"\nDirection: Tutorial A \u2192 Tutorial B (unidirectional, could be bidirectional for \"related\")\nCardinality: Many-to-many\nImplementation: \n  - prerequisites: {title: string, url: string, required: boolean}[]\n  - relatedTutorials: string[]\nExample:\n  Tutorial: \"Build Your First Payment Integration\"\n  \u2190 prerequisite: \"API Authentication Basics\"\n  \u2192 next: \"Accept Recurring Payments\"\nUse Case: Learning path sequencing, ensuring users have required knowledge\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 5: How-to Guide \u2192 Troubleshooting\nName: \"troubleshoots\" or \"solves-problems-in\"\nDirection: How-to \u2192 Troubleshooting (unidirectional)\nCardinality: One-to-many\nImplementation: Array field in How-to: commonIssues: string[]\nExample:\n  How-to: \"How to Implement Webhooks\"\n  \u2192 Troubleshooting: \"Webhook Not Receiving Events\"\n  \u2192 Troubleshooting: \"Webhook Signature Verification Failed\"\nUse Case: Proactively link to common problems users might encounter\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP DEFINITIONS\n\n```yaml\nrelationships:",
            "hydration_source_header": "3. Relationship Mapping",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "docusaurus-metadata",
            "title": "Docusaurus Metadata Example",
            "demonstrates": "docs-as-code-framework",
            "lines": "1565-1595",
            "retrievalQuestions": [
              "Example of Docusaurus metadata"
            ],
            "content": "id: tutorial-first-payment\nsidebar_label: \"First Payment\"\nsidebar_position: 1\ntitle: \"Build Your First Payment Integration\"\ndescription: \"Step-by-step tutorial for accepting payments\"",
            "hydration_source_header": "Docusaurus-specific metadata",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "mkdocs-metadata",
            "title": "MkDocs Metadata Example",
            "demonstrates": "docs-as-code-framework",
            "lines": "1600-1630",
            "content": "content_type: \"tutorial\"\ndifficulty: \"beginner\"\nestimated_time: 15\ncode_language: [\"javascript\", \"python\"]",
            "hydration_source_header": "Custom metadata (available via frontmatter)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "hugo-metadata",
            "title": "Hugo Metadata Example",
            "demonstrates": "docs-as-code-framework",
            "lines": "1635-1675",
            "content": "search:\n  boost: 2\n  exclude: false\n---\n```\n\n**Key Features:**\n- Template selection for different layouts\n- Icon specification for navigation\n- Search boosting and exclusion\n- Material theme extensions\n\n---\n\n#### Hugo (Go-based SSG)\n\n```yaml\n---\ntitle: \"Build Your First Payment Integration\"\ndescription: \"Step-by-step tutorial for accepting payments\"\ndate: 2024-01-15\nlastmod: 2024-03-20\ndraft: false",
            "hydration_source_header": "Search metadata",
            "hydration_method": "line_proximity"
          },
          {
            "id": "devtools-tutorial",
            "title": "DevTools Tutorial Content Model",
            "demonstrates": "tutorial-content-modeling",
            "lines": "1980-2520",
            "content": "You're the IA lead for \"DevTools\"\u2014a code quality and CI/CD platform. You have 80 pages of existing documentation with no formal content model. Your task: create a structured content model that supports better navigation, search, and maintenance.\n\n**Your Goals:**\n- Identify distinct content types\n- Design reusable metadata schemas\n- Establish clear relationships between content\n- Implement validation\n\n---",
            "hydration_source_header": "Tutorial Scenario",
            "hydration_method": "line_proximity"
          },
          {
            "id": "validation-script-example",
            "title": "Validation Script Implementation",
            "demonstrates": "validation-strategy",
            "lines": "2450-2505",
            "content": "**What You're Doing:** Create validation rules to catch errors before content goes live.\n\n**Validation Layers:**\n\n**Layer 1: Schema Validation (JSON Schema)**\n- Required fields present\n- Data types correct\n- Enum values valid\n- String lengths within limits\n\n**Layer 2: Business Logic**\n- Estimated time matches difficulty\n- Prerequisites actually exist\n- No circular dependencies\n- Version format valid\n\n**Your AI Prompt:**\n\n```text\nYou're implementing validation for DevTools content model.\n\nCreate:\n1. JSON Schema for the Tutorial type (base + type-specific fields)\n2. Custom validation function for business rules:\n   - Beginner tutorials: 5-30 minutes\n   - Intermediate: 15-60 minutes\n   - Advanced: 30-120 minutes\n3. Validation for prerequisites:\n   - All referenced URLs exist\n   - No circular dependencies\n4. Build script pseudocode that runs these checks\n\nProvide working code examples (JavaScript).\n```\n\n**Expected Output:**\n\n```javascript\n// JSON Schema for Tutorial\nconst tutorialSchema = {\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"type\": \"object\",\n  \"required\": [\"title\", \"description\", \"content_type\", \"difficulty\", \"estimated_time\"],\n  \"properties\": {\n    \"title\": {\n      \"type\": \"string\",\n      \"minLength\": 10,\n      \"maxLength\": 80\n    },\n    \"difficulty\": {\n      \"type\": \"string\",\n      \"enum\": [\"beginner\", \"intermediate\", \"advanced\"]\n    },\n    \"estimated_time\": {\n      \"type\": \"integer\",\n      \"minimum\": 5,\n      \"maximum\": 120\n    }\n  }\n};\n\n// Custom Business Logic Validation\nfunction validateTimeVsDifficulty(frontmatter) {\n  const { difficulty, estimated_time } = frontmatter;\n  const timeLimits = {\n    beginner: { min: 5, max: 30 },\n    intermediate: { min: 15, max: 60 },\n    advanced: { min: 30, max: 120 }\n  };\n  \n  const { min, max } = timeLimits[difficulty];\n  if (estimated_time < min || estimated_time > max) {\n    return {\n      valid: false,\n      error: `${difficulty} tutorials should be ${min}-${max} minutes. Got ${estimated_time}.`\n    };\n  }\n  return { valid: true };\n}\n\n// Build-time Validation Script\nconst fs = require('fs');\nconst yaml = require('js-yaml');\nconst Ajv = require('ajv');\n\nconst ajv = new Ajv();\nconst validate = ajv.compile(tutorialSchema);\n\nconst errors = [];\n\n// Read all docs\nfs.readdirSync('./docs/tutorials').forEach(file => {\n  const content = fs.readFileSync(`./docs/tutorials/${file}`, 'utf8');\n  const frontmatter = yaml.load(content.match(/---\\n([\\s\\S]*?)\\n---/)[1]);\n  \n  // Schema validation\n  if (!validate(frontmatter)) {\n    validate.errors.forEach(err => {\n      errors.push({ file, error: err.message });\n    });\n  }\n  \n  // Business logic validation\n  const timeCheck = validateTimeVsDifficulty(frontmatter);\n  if (!timeCheck.valid) {\n    errors.push({ file, error: timeCheck.error });\n  }\n});\n\n// Report\nif (errors.length > 0) {\n  console.error('Validation failed:');\n  errors.forEach(e => console.error(`${e.file}: ${e.error}`));\n  process.exit(1);\n}\n\nconsole.log('All validations passed!');\n```\n\n**Your Action:** \n1. Add this to your build pipeline (CI/CD)\n2. Set up pre-commit hooks for immediate feedback\n3. Configure IDE validation (VS Code with YAML/JSON schema support)\n\n---",
            "hydration_source_header": "Step 6: Implement Validation",
            "hydration_method": "line_proximity"
          }
        ],
        "caseStudies": [
          {
            "id": "stripe-api-docs",
            "title": "Stripe API Documentation Model",
            "applies": "di\u00e1taxis-content-model",
            "domain": "API documentation",
            "lines": "160-370",
            "retrievalQuestions": [
              "How would I model API documentation like Stripe?"
            ],
            "content": "**Your Prompt:**\n\n```text\nYou're mapping relationships between API documentation content types.\n\nContent types:\n1. Tutorial - Learning-oriented, step-by-step\n2. How-to Guide - Task-oriented, problem-solving\n3. API Reference - Technical specifications\n4. Concept/Explanation - Understanding-oriented\n5. Troubleshooting - Problem diagnosis and fixes\n\nFor each meaningful relationship:\n1. Relationship name and direction\n2. Cardinality\n3. Implementation approach\n4. Example\n5. Use case (why it matters)\n\nThen provide:\n- Visual relationship diagram (text-based)\n- Implementation recommendations\n- Example queries users might want (\"Show me all tutorials that use this API endpoint\")\n```\n\n---\n\n**AI Output (Example):**\n\n```text\nCONTENT TYPE RELATIONSHIP MAP\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 1: Tutorial \u2192 How-to Guide\nName: \"leads-to\" or \"next-steps\"\nDirection: Tutorial \u2192 How-to (unidirectional)\nCardinality: One-to-many (one tutorial can lead to multiple how-tos)\nImplementation: Array field in Tutorial: relatedGuides: string[]\nExample:\n  Tutorial: \"Build Your First Payment Integration\"\n  \u2192 How-to: \"How to Customize Checkout UI\"\n  \u2192 How-to: \"How to Handle Payment Failures\"\nUse Case: After learning basics (tutorial), users want practical applications (how-tos)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 2: Tutorial \u2192 API Reference\nName: \"uses\" or \"references\"\nDirection: Tutorial \u2192 API Reference (unidirectional)\nCardinality: Many-to-many (tutorial uses multiple endpoints, endpoint used by multiple tutorials)\nImplementation: Array field in Tutorial: relatedReference: string[]\nExample:\n  Tutorial: \"Build Your First Payment Integration\"\n  \u2192 API Ref: \"Payment Intents API\"\n  \u2192 API Ref: \"Charges API\"\nUse Case: Users want technical details about APIs used in tutorial\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 3: Concept \u2192 Tutorial\nName: \"applied-in\" or \"demonstrated-by\"\nDirection: Concept \u2192 Tutorial (unidirectional)\nCardinality: One-to-many (one concept demonstrated by multiple tutorials)\nImplementation: Array field in Concept: relatedTutorials: string[]\nExample:\n  Concept: \"Understanding Payment Intents\"\n  \u2192 Tutorial: \"Build Your First Payment Integration\"\n  \u2192 Tutorial: \"Accept Recurring Payments\"\nUse Case: After understanding concept, users want hands-on practice\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 4: Tutorial \u2192 Tutorial\nName: \"prerequisite\" or \"builds-on\"\nDirection: Tutorial A \u2192 Tutorial B (unidirectional, could be bidirectional for \"related\")\nCardinality: Many-to-many\nImplementation: \n  - prerequisites: {title: string, url: string, required: boolean}[]\n  - relatedTutorials: string[]\nExample:\n  Tutorial: \"Build Your First Payment Integration\"\n  \u2190 prerequisite: \"API Authentication Basics\"\n  \u2192 next: \"Accept Recurring Payments\"\nUse Case: Learning path sequencing, ensuring users have required knowledge\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 5: How-to Guide \u2192 Troubleshooting\nName: \"troubleshoots\" or \"solves-problems-in\"\nDirection: How-to \u2192 Troubleshooting (unidirectional)\nCardinality: One-to-many\nImplementation: Array field in How-to: commonIssues: string[]\nExample:\n  How-to: \"How to Implement Webhooks\"\n  \u2192 Troubleshooting: \"Webhook Not Receiving Events\"\n  \u2192 Troubleshooting: \"Webhook Signature Verification Failed\"\nUse Case: Proactively link to common problems users might encounter\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP DEFINITIONS\n\n```yaml\nrelationships:",
            "hydration_source_header": "3.3 Example: API Documentation Relationships",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "devtools-docs",
            "title": "DevTools Documentation Model",
            "applies": "five-step-modeling-framework",
            "domain": "Developer tools",
            "lines": "1980-2520",
            "retrievalQuestions": [
              "Show me a complete content modeling project"
            ],
            "content": "You're the IA lead for \"DevTools\"\u2014a code quality and CI/CD platform. You have 80 pages of existing documentation with no formal content model. Your task: create a structured content model that supports better navigation, search, and maintenance.\n\n**Your Goals:**\n- Identify distinct content types\n- Design reusable metadata schemas\n- Establish clear relationships between content\n- Implement validation\n\n---",
            "hydration_source_header": "Tutorial Scenario",
            "hydration_method": "line_proximity"
          },
          {
            "id": "cloudmonitor-api",
            "title": "CloudMonitor API Project",
            "applies": "five-step-modeling-framework",
            "domain": "Monitoring/observability",
            "lines": "2635-2790",
            "retrievalQuestions": [
              "What does a real-world content model look like?"
            ],
            "content": "Learn from common mistakes when creating content models with AI.\n\n<AccordionGroup>\n  <Accordion title=\"Pitfall 1: Too Many Required Fields\">\n    **Problem:** Every possible field is marked \"required\"\n    \n    **Symptom:** Authors spend 30+ minutes filling metadata, skip fields\n    \n    **Fix:**\n    - Only require fields that are absolutely essential\n    - Make 80% of fields optional\n    - Use \"recommended\" designation for important-but-not-critical fields\n    - Provide good defaults\n  </Accordion>\n  \n  <Accordion title=\"Pitfall 2: Overly Complex Schemas\">\n    **Problem:** Schemas with 50+ fields, nested objects 5 levels deep\n    \n    **Symptom:** Authors confused, errors frequent, adoption low\n    \n    **Fix:**\n    - Start with 10-15 core fields\n    - Add complexity only when proven necessary\n    - Flatten nested structures where possible\n    - Provide examples and documentation\n  </Accordion>\n  \n  <Accordion title=\"Pitfall 3: Inconsistent Field Names\">\n    **Problem:** `code_language` in one type, `codeLanguage` in another, `language` in third\n    \n    **Symptom:** Build errors, confusion, maintenance nightmares\n    \n    **Fix:**\n    - Choose naming convention (camelCase or snake_case)\n    - Document it clearly\n    - Use consistent names across ALL types\n    - Validate with linters\n  </Accordion>\n  \n  <Accordion title=\"Pitfall 4: No Validation\">\n    **Problem:** Authors enter anything, no checks until deployment fails\n    \n    **Symptom:** Broken links, invalid enum values, missing required fields\n    \n    **Fix:**\n    - JSON Schema validation in build pipeline\n    - IDE integration (real-time validation)\n    - Clear error messages with examples\n    - Pre-commit hooks\n  </Accordion>\n  \n  <Accordion title=\"Pitfall 5: Ignoring Migration\">\n    **Problem:** New schema designed, but 500 existing pages need updating\n    \n    **Symptom:** Months-long migration, never completed, two schemas coexist\n    \n    **Fix:**\n    - Design migration scripts FIRST\n    - Migrate in phases (high-priority content first)\n    - Support both old and new temporarily\n    - Automated migration where possible\n  </Accordion>\n</AccordionGroup>\n\n---",
            "hydration_source_header": "6. Common Pitfalls and How to Avoid Them",
            "hydration_method": "line_proximity"
          }
        ],
        "checklists": [
          {
            "id": "content-type-validation-checklist",
            "title": "Content Type Validation Checklist",
            "validates": "content-type-distinction",
            "items": 4,
            "lines": "2045-2070",
            "retrievalQuestions": [
              "How do I validate my content types are correct?"
            ],
            "content": "Before moving to the next module, ensure you can:\n\n```text\n\u2610 Identify content types from existing documentation\n\u2610 Design comprehensive metadata schemas\n\u2610 Define relationships between content types\n\u2610 Implement validation strategies\n\u2610 Create base schemas with inheritance\n\u2610 Understand platform-specific metadata needs\n\u2610 Map content to user needs and use cases\n\u2610 Design migration strategies for existing content\n\u2610 Complete the self-assessment project successfully\n```\n\n**Congratulations on completing Module 2.2!** You now have practical skills for creating content models and metadata schemas with AI assistance.",
            "hydration_source_header": "Module Completion Checklist",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "schema-design-best-practices",
            "title": "Schema Design Best Practices (DO/DON'T)",
            "validates": "schema-design-principles",
            "items": 18,
            "lines": "2893-2940",
            "retrievalQuestions": [
              "What are best practices for schema design?"
            ],
            "content": "**Schema Design:**\n\n**DO:**\n- \u2705 Start simple, add complexity only when needed\n- \u2705 Make fields required only when absolutely necessary\n- \u2705 Use enums for controlled vocabularies\n- \u2705 Document every field's purpose clearly\n- \u2705 Provide examples for every field\n- \u2705 Use consistent naming conventions (camelCase or snake_case)\n- \u2705 Group related fields logically\n- \u2705 Consider author experience (time to fill)\n- \u2705 Plan for validation from day one\n- \u2705 Design migration strategy before implementing\n\n**DON'T:**\n- \u274c Require 20+ fields (author burden)\n- \u274c Use vague field names (\"misc\", \"other\")\n- \u274c Mix naming conventions\n- \u274c Create fields \"just in case\"\n- \u274c Ignore existing author workflows\n- \u274c Deploy without validation\n- \u274c Forget about migration\n- \u274c Copy schemas without customization\n\n---",
            "hydration_source_header": "Best Practices",
            "hydration_method": "title_match"
          },
          {
            "id": "module-completion-checklist",
            "title": "Module Completion Checklist",
            "validates": "full-module",
            "items": 9,
            "lines": "3060-3075",
            "content": "Before moving to the next module, ensure you can:\n\n```text\n\u2610 Identify content types from existing documentation\n\u2610 Design comprehensive metadata schemas\n\u2610 Define relationships between content types\n\u2610 Implement validation strategies\n\u2610 Create base schemas with inheritance\n\u2610 Understand platform-specific metadata needs\n\u2610 Map content to user needs and use cases\n\u2610 Design migration strategies for existing content\n\u2610 Complete the self-assessment project successfully\n```\n\n**Congratulations on completing Module 2.2!** You now have practical skills for creating content models and metadata schemas with AI assistance.",
            "hydration_source_header": "Module Completion Checklist",
            "hydration_method": "title_match"
          }
        ],
        "decisionMatrices": [
          {
            "id": "relationship-implementation-options",
            "title": "Relationship Implementation Options",
            "helpsChoose": "Store in both directions vs. query dynamically",
            "lines": "1545-1585",
            "content": "",
            "hydration_source_header": "Runtime query: \"Find all recipes where author=chef-maria\"",
            "hydration_method": "line_proximity"
          },
          {
            "id": "platform-metadata-comparison",
            "title": "Platform Metadata Comparison",
            "helpsChoose": "Docusaurus vs. MkDocs vs. Hugo",
            "lines": "1565-1675",
            "retrievalQuestions": [
              "Which documentation platform should I use for metadata?"
            ],
            "content": "**Core Principles:**\n- Documentation lives in Git with code\n- Written in plain text (Markdown, reStructuredText, AsciiDoc)\n- Metadata in frontmatter or separate files\n- Build process generates final documentation\n- CI/CD validates and deploys docs\n\n**Why Metadata Matters:**\n- Enables automated validation\n- Powers build-time features\n- Supports multiple output formats\n- Enables content reuse\n- Facilitates collaboration\n\n---",
            "hydration_source_header": "4.1 Understanding Docs-as-Code",
            "hydration_method": "line_proximity"
          }
        ],
        "warnings": [
          {
            "id": "too-many-required-fields",
            "title": "Too Many Required Fields Pitfall",
            "prevents": "Author burden, low adoption",
            "lines": "2560-2575",
            "retrievalQuestions": [
              "What are common mistakes in content modeling?"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "overly-complex-schemas",
            "title": "Overly Complex Schemas Pitfall",
            "prevents": "Author confusion, errors",
            "lines": "2575-2590",
            "retrievalQuestions": [
              "How do I avoid schema complexity problems?"
            ],
            "content": "You now have:\n\n**\u2705 Content Type Definitions**\n- 5 distinct types with clear purposes\n- Aligned with Di\u00e1taxis framework\n- Validated against your content inventory\n\n**\u2705 Base Schema**\n- Universal fields all content shares\n- Publishing workflow support\n- SEO and discovery optimized\n\n**\u2705 Type-Specific Schemas**\n- Detailed attributes for each type\n- Example frontmatter for authors\n- Clear required vs. optional fields\n\n**\u2705 Relationship Mapping**\n- Connections between types defined\n- Learning paths enabled\n- Discovery improved\n\n**\u2705 Validation Strategy**\n- Automated schema checking\n- Business logic enforcement\n- Build-time error prevention\n\n**Next Steps:**\n1. **Document for Authors:** Create a style guide showing how to fill each field\n2. **Create Templates:** Provide starter files for each content type\n3. **Migrate Existing Content:** Use AI to suggest frontmatter for existing pages\n4. **Monitor and Iterate:** Gather feedback, adjust schemas as needed\n\n---",
            "hydration_source_header": "Tutorial Complete: What You've Built",
            "hydration_method": "line_proximity"
          },
          {
            "id": "inconsistent-field-names",
            "title": "Inconsistent Field Names Pitfall",
            "prevents": "Build errors, maintenance issues",
            "lines": "2590-2605",
            "content": "You now have:\n\n**\u2705 Content Type Definitions**\n- 5 distinct types with clear purposes\n- Aligned with Di\u00e1taxis framework\n- Validated against your content inventory\n\n**\u2705 Base Schema**\n- Universal fields all content shares\n- Publishing workflow support\n- SEO and discovery optimized\n\n**\u2705 Type-Specific Schemas**\n- Detailed attributes for each type\n- Example frontmatter for authors\n- Clear required vs. optional fields\n\n**\u2705 Relationship Mapping**\n- Connections between types defined\n- Learning paths enabled\n- Discovery improved\n\n**\u2705 Validation Strategy**\n- Automated schema checking\n- Business logic enforcement\n- Build-time error prevention\n\n**Next Steps:**\n1. **Document for Authors:** Create a style guide showing how to fill each field\n2. **Create Templates:** Provide starter files for each content type\n3. **Migrate Existing Content:** Use AI to suggest frontmatter for existing pages\n4. **Monitor and Iterate:** Gather feedback, adjust schemas as needed\n\n---",
            "hydration_source_header": "Tutorial Complete: What You've Built",
            "hydration_method": "line_proximity"
          },
          {
            "id": "no-validation",
            "title": "No Validation Pitfall",
            "prevents": "Broken links, invalid data",
            "lines": "2605-2620",
            "retrievalQuestions": [
              "What happens if I don't validate metadata?"
            ],
            "content": "You now have:\n\n**\u2705 Content Type Definitions**\n- 5 distinct types with clear purposes\n- Aligned with Di\u00e1taxis framework\n- Validated against your content inventory\n\n**\u2705 Base Schema**\n- Universal fields all content shares\n- Publishing workflow support\n- SEO and discovery optimized\n\n**\u2705 Type-Specific Schemas**\n- Detailed attributes for each type\n- Example frontmatter for authors\n- Clear required vs. optional fields\n\n**\u2705 Relationship Mapping**\n- Connections between types defined\n- Learning paths enabled\n- Discovery improved\n\n**\u2705 Validation Strategy**\n- Automated schema checking\n- Business logic enforcement\n- Build-time error prevention\n\n**Next Steps:**\n1. **Document for Authors:** Create a style guide showing how to fill each field\n2. **Create Templates:** Provide starter files for each content type\n3. **Migrate Existing Content:** Use AI to suggest frontmatter for existing pages\n4. **Monitor and Iterate:** Gather feedback, adjust schemas as needed\n\n---",
            "hydration_source_header": "Tutorial Complete: What You've Built",
            "hydration_method": "line_proximity"
          },
          {
            "id": "ignoring-migration",
            "title": "Ignoring Migration Pitfall",
            "prevents": "Incomplete migrations, technical debt",
            "lines": "2620-2635",
            "retrievalQuestions": [
              "How do I plan for content migration?"
            ],
            "content": "Learn from common mistakes when creating content models with AI.\n\n<AccordionGroup>\n  <Accordion title=\"Pitfall 1: Too Many Required Fields\">\n    **Problem:** Every possible field is marked \"required\"\n    \n    **Symptom:** Authors spend 30+ minutes filling metadata, skip fields\n    \n    **Fix:**\n    - Only require fields that are absolutely essential\n    - Make 80% of fields optional\n    - Use \"recommended\" designation for important-but-not-critical fields\n    - Provide good defaults\n  </Accordion>\n  \n  <Accordion title=\"Pitfall 2: Overly Complex Schemas\">\n    **Problem:** Schemas with 50+ fields, nested objects 5 levels deep\n    \n    **Symptom:** Authors confused, errors frequent, adoption low\n    \n    **Fix:**\n    - Start with 10-15 core fields\n    - Add complexity only when proven necessary\n    - Flatten nested structures where possible\n    - Provide examples and documentation\n  </Accordion>\n  \n  <Accordion title=\"Pitfall 3: Inconsistent Field Names\">\n    **Problem:** `code_language` in one type, `codeLanguage` in another, `language` in third\n    \n    **Symptom:** Build errors, confusion, maintenance nightmares\n    \n    **Fix:**\n    - Choose naming convention (camelCase or snake_case)\n    - Document it clearly\n    - Use consistent names across ALL types\n    - Validate with linters\n  </Accordion>\n  \n  <Accordion title=\"Pitfall 4: No Validation\">\n    **Problem:** Authors enter anything, no checks until deployment fails\n    \n    **Symptom:** Broken links, invalid enum values, missing required fields\n    \n    **Fix:**\n    - JSON Schema validation in build pipeline\n    - IDE integration (real-time validation)\n    - Clear error messages with examples\n    - Pre-commit hooks\n  </Accordion>\n  \n  <Accordion title=\"Pitfall 5: Ignoring Migration\">\n    **Problem:** New schema designed, but 500 existing pages need updating\n    \n    **Symptom:** Months-long migration, never completed, two schemas coexist\n    \n    **Fix:**\n    - Design migration scripts FIRST\n    - Migrate in phases (high-priority content first)\n    - Support both old and new temporarily\n    - Automated migration where possible\n  </Accordion>\n</AccordionGroup>\n\n---",
            "hydration_source_header": "6. Common Pitfalls and How to Avoid Them",
            "hydration_method": "line_proximity"
          }
        ],
        "contentTypeDefinitions": [
          {
            "id": "tutorial-type",
            "title": "Tutorial Content Type",
            "definition": "Learning-oriented, step-by-step, hands-on",
            "keyAttributes": [
              "difficulty",
              "estimated_time",
              "prerequisites",
              "learning_objectives"
            ],
            "lines": "160-180, 540-900",
            "retrievalQuestions": [
              "What attributes does a tutorial need?"
            ],
            "content": "**Your Prompt:**\n\n```text\nYou're a content architect designing a metadata schema for API documentation.\n\nDefine all necessary attributes for the \"Tutorial\" content type.\n\nContext:\n- Platform: Docusaurus (Markdown with YAML frontmatter)\n- Use cases: \n  * Display tutorials with time estimates and difficulty\n  * Filter tutorials by topic and difficulty\n  * Show prerequisites and next steps\n  * Track completion in learning paths\n  * Generate table of contents automatically\n  \n- Constraints:\n  * Frontmatter must be valid YAML\n  * File-based (no database)\n  * All metadata in frontmatter or markdown\n  * Must work with static site generation\n\nTutorial Definition:\n- Purpose: Teach users through hands-on, step-by-step practice\n- Assumes little/no prior knowledge\n- Includes complete working examples\n- Shows expected outcomes\n\nFor each attribute specify:\n- Field name (camelCase for consistency)\n- Data type\n- Required or optional\n- Description\n- Validation rules\n- Examples\n- How it's used (search, display, automation, etc.)\n\nConsider attributes for:\n- Basic information (title, description)\n- Learning metadata (difficulty, time, prerequisites)\n- Organization (category, tags, order)\n- Relationships (related content, next steps)\n- Technical details (code language, API version)\n- Publishing (author, date, status)\n```\n\n---\n\n**AI Output (Example):**\n\n```yaml\nTUTORIAL CONTENT TYPE - METADATA SCHEMA\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nBASIC INFORMATION\n\n1. title\n   Type: string\n   Required: YES\n   Description: Tutorial title shown in navigation and page header\n   Validation: 10-80 characters, no special characters except - and :\n   Example: \"Build Your First Payment Integration\"\n   Used for: Page title, SEO, navigation, search\n   \n2. description\n   Type: string\n   Required: YES\n   Description: Brief summary of what the tutorial teaches (for previews and SEO)\n   Validation: 50-160 characters\n   Example: \"Learn how to accept payments by building a complete checkout flow from scratch\"\n   Used for: Meta description, preview cards, search results\n\n3. slug\n   Type: string\n   Required: NO (auto-generated from title if not provided)\n   Description: URL-friendly version of title\n   Validation: lowercase, hyphens only, no spaces\n   Example: \"build-first-payment-integration\"\n   Used for: URL generation\n   Default: Auto-generated from title\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nLEARNING METADATA\n\n4. difficulty\n   Type: enum\n   Required: YES\n   Description: Skill level required to complete tutorial\n   Allowed values: \"beginner\" | \"intermediate\" | \"advanced\"\n   Example: \"beginner\"\n   Used for: Filtering, badges, learning path progression\n   \n5. estimatedTime\n   Type: integer\n   Required: YES\n   Description: Completion time in minutes\n   Validation: 5-120 minutes (tutorials >2 hours should be split)\n   Example: 15\n   Used for: Time estimates, filtering, user expectations\n   \n6. prerequisites\n   Type: array of objects\n   Required: HIGHLY RECOMMENDED\n   Description: Required knowledge or setup before starting\n   Structure:\n     - title: string\n     - url: string\n     - required: boolean (true if mandatory, false if helpful)\n   Example:\n     - title: \"API Authentication Basics\"\n       url: \"/docs/auth-basics\"\n       required: true\n     - title: \"JavaScript Fundamentals\"\n       url: \"/docs/js-basics\"\n       required: false\n   Used for: Prerequisites alerts, learning path validation, navigation\n\n7. learningObjectives\n   Type: array of strings\n   Required: YES\n   Description: What users will learn/accomplish (3-5 items)\n   Validation: 3-5 items, each 10-100 characters\n   Example:\n     - \"Create a payment intent\"\n     - \"Handle payment success and failures\"\n     - \"Test payments in sandbox mode\"\n   Used for: Preview section, completion tracking, SEO\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nTECHNICAL DETAILS\n\n8. codeLanguage\n   Type: array of enums\n   Required: YES\n   Description: Programming languages covered in tutorial\n   Allowed values: [\"javascript\", \"python\", \"ruby\", \"java\", \"php\", \"go\", \"curl\"]\n   Example: [\"javascript\", \"python\"]\n   Used for: Filtering, code language switcher, recommendations\n   \n9. apiVersion\n   Type: string\n   Required: YES\n   Description: Which API version this tutorial covers\n   Validation: Semantic versioning (e.g., \"2.0\", \"3.1\")\n   Example: \"2.0\"\n   Used for: Version switcher, compatibility warnings\n   \n10. requiredTools\n    Type: array of strings\n    Required: RECOMMENDED\n    Description: Tools/software needed to complete tutorial\n    Example: [\"npm\", \"Stripe CLI\", \"ngrok\"]\n    Used for: Prerequisites section, setup guidance\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nORGANIZATION\n\n11. category\n    Type: enum\n    Required: YES\n    Description: Primary category for organization\n    Allowed values: [\"payments\", \"billing\", \"connect\", \"identity\", \"webhooks\", \"testing\"]\n    Example: \"payments\"\n    Used for: Navigation, filtering, organization\n    \n12. tags\n    Type: array of strings\n    Required: OPTIONAL\n    Description: Additional topics/keywords for discovery\n    Validation: 3-8 tags, each 2-20 characters\n    Example: [\"checkout\", \"credit-cards\", \"quickstart\"]\n    Used for: Search, filtering, related content suggestions\n    \n13. featured\n    Type: boolean\n    Required: OPTIONAL\n    Description: Whether to feature prominently on homepage/category page\n    Default: false\n    Example: true\n    Used for: Homepage display, promotional purposes\n    \n14. order\n    Type: integer\n    Required: OPTIONAL\n    Description: Sort order within category (lower numbers first)\n    Validation: 1-1000\n    Example: 1\n    Used for: Navigation ordering, learning path sequence\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIPS\n\n15. relatedTutorials\n    Type: array of strings (URLs)\n    Required: RECOMMENDED\n    Description: Links to related tutorials (next steps)\n    Validation: Valid internal URLs\n    Example:\n      - \"/docs/tutorials/accept-recurring-payments\"\n      - \"/docs/tutorials/handle-webhooks\"\n    Used for: \"Next steps\" section, learning paths\n    \n16. relatedGuides\n    Type: array of strings (URLs)\n    Required: OPTIONAL\n    Description: Links to related how-to guides\n    Example: [\"/docs/how-to/customize-checkout\"]\n    Used for: \"Related content\" sidebar\n    \n17. relatedReference\n    Type: array of strings (URLs)\n    Required: OPTIONAL\n    Description: Links to API reference docs used in tutorial\n    Example: [\"/docs/api/payment-intents\"]\n    Used for: \"API Reference\" links, technical details\n    \n18. partOfLearningPath\n    Type: string (URL)\n    Required: OPTIONAL\n    Description: Learning path this tutorial belongs to\n    Example: \"/learning-paths/accepting-payments\"\n    Used for: Learning path navigation, progress tracking\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nCONTENT METADATA\n\n19. hasCodeExamples\n    Type: boolean\n    Required: OPTIONAL\n    Description: Whether tutorial includes downloadable code\n    Default: true (assumed for tutorials)\n    Example: true\n    Used for: Display \"Download code\" button, expectations\n    \n20. hasVideo\n    Type: string (URL)\n    Required: OPTIONAL\n    Description: Link to accompanying video tutorial\n    Validation: Valid YouTube/Vimeo URL\n    Example: \"https://youtube.com/watch?v=abc123\"\n    Used for: Embed video player, alternative learning format\n    \n21. completionCriteria\n    Type: array of strings\n    Required: RECOMMENDED\n    Description: Checklist of what constitutes completion\n    Example:\n      - \"Successfully create a test payment\"\n      - \"Handle payment confirmation\"\n      - \"Test error scenarios\"\n    Used for: Completion tracking, success validation\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nPUBLISHING METADATA\n\n22. author\n    Type: object\n    Required: YES\n    Description: Tutorial author information\n    Structure:\n      name: string\n      title: string (optional)\n      avatar: string URL (optional)\n    Example:\n      name: \"Sarah Johnson\"\n      title: \"Developer Advocate\"\n      avatar: \"/images/authors/sarah.jpg\"\n    Used for: Author byline, credibility, contact\n    \n23. publishedDate\n    Type: date\n    Required: YES\n    Description: When tutorial was first published\n    Format: ISO 8601 (YYYY-MM-DD)\n    Example: \"2024-01-15\"\n    Used for: Display date, sorting, freshness indicators\n    \n24. lastUpdated\n    Type: date\n    Required: YES\n    Description: When tutorial was last modified\n    Format: ISO 8601 (YYYY-MM-DD)\n    Example: \"2024-03-20\"\n    Auto-update: Should be auto-updated on save\n    Used for: \"Last updated\" badge, freshness, maintenance tracking\n    \n25. status\n    Type: enum\n    Required: OPTIONAL\n    Description: Publishing workflow status\n    Allowed values: \"draft\" | \"review\" | \"published\" | \"archived\"\n    Default: \"draft\"\n    Example: \"published\"\n    Used for: Workflow management, display logic\n    \n26. reviewedBy\n    Type: string\n    Required: OPTIONAL BUT RECOMMENDED\n    Description: Technical reviewer name\n    Example: \"Alex Chen, Senior Engineer\"\n    Used for: Quality assurance, internal tracking\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nSEO & SEARCH\n\n27. searchKeywords\n    Type: array of strings\n    Required: OPTIONAL\n    Description: Additional keywords for search optimization\n    Example: [\"payment\", \"checkout\", \"credit card\", \"accept payments\", \"integration\"]\n    Used for: Search indexing, SEO\n    \n28. internalNotes\n    Type: string\n    Required: OPTIONAL\n    Description: Editorial notes not displayed to users\n    Example: \"Update code examples when v3 API releases. Waiting for API v3 release.\"\n    Used for: Content planning, editorial workflow\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nEXAMPLE FRONTMATTER:\n\n```yaml\n---\ntitle: \"Build Your First Payment Integration\"\ndescription: \"Learn how to accept payments by building a complete checkout flow from scratch\"\nslug: \"build-first-payment-integration\"",
            "hydration_source_header": "2.2 Example: Tutorial Content Type Schema",
            "hydration_method": "title_match"
          },
          {
            "id": "howto-type",
            "title": "How-To Guide Content Type",
            "definition": "Task-oriented, problem-solving, goal-focused",
            "keyAttributes": [
              "task_goal",
              "use_case",
              "prerequisites"
            ],
            "lines": "160-180",
            "retrievalQuestions": [
              "How is how-to different from tutorial?"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "reference-type",
            "title": "API Reference Content Type",
            "definition": "Information-oriented, technical specifications",
            "keyAttributes": [
              "endpoint",
              "parameters",
              "responses",
              "code_examples"
            ],
            "lines": "160-180",
            "retrievalQuestions": [
              "What makes a good reference content type?"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "concept-type",
            "title": "Concept/Explanation Content Type",
            "definition": "Understanding-oriented, conceptual",
            "keyAttributes": [
              "related_concepts",
              "key_terms"
            ],
            "lines": "160-180",
            "hydration_status": "failed"
          },
          {
            "id": "troubleshooting-type",
            "title": "Troubleshooting Content Type",
            "definition": "Problem diagnosis and fixes",
            "keyAttributes": [
              "symptoms",
              "causes",
              "solutions"
            ],
            "lines": "160-180",
            "hydration_status": "failed"
          }
        ],
        "relationshipTypes": [
          {
            "id": "leads-to",
            "relationship": "Tutorial \u2192 How-To",
            "description": "After learning, apply practically",
            "implementation": "next_steps: string[]",
            "lines": "1180-1195",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "uses",
            "relationship": "How-To \u2192 API Reference",
            "description": "Practical tasks use APIs",
            "implementation": "api_references: string[]",
            "lines": "1195-1215",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "prerequisite",
            "relationship": "Tutorial \u2192 Tutorial",
            "description": "Learning sequence",
            "implementation": "prerequisites: object[]",
            "lines": "1215-1235",
            "retrievalQuestions": [
              "How do I implement prerequisites?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "troubleshoots",
            "relationship": "How-To \u2192 Troubleshooting",
            "description": "Link to common problems",
            "implementation": "common_issues: string[]",
            "lines": "1235-1255",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "applied-in",
            "relationship": "Concept \u2192 Tutorial",
            "description": "Concepts demonstrated",
            "implementation": "practical_applications: object[]",
            "lines": "1255-1275",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "part-of",
            "relationship": "Content \u2192 Learning Path",
            "description": "Collection membership",
            "implementation": "part_of_learning_path: string",
            "lines": "1275-1290",
            "retrievalQuestions": [
              "How do I create learning paths?"
            ],
            "hydration_status": "skipped_unknown"
          }
        ],
        "exercises": [
          {
            "id": "schema-completion-exercise",
            "title": "Schema Completion Exercise (Recipe)",
            "skillPracticed": "Attribute identification",
            "time": "7 min",
            "lines": "975-1075",
            "retrievalQuestions": [
              "Give me a practice exercise for content modeling"
            ],
            "content": "<Warning>\n**Quick Practice (7 minutes):** Complete a partial schema to reinforce attribute thinking.\n</Warning>\n\n**Scenario:** You're creating a content model for a recipe website. Below is a **partial schema** for the \"Recipe\" content type. Some attributes are missing.\n\n**Partial Recipe Schema:**\n```yaml\n---\ntitle: \"Homemade Margherita Pizza\"\ndescription: \"Classic Italian pizza with fresh basil and mozzarella\"\nauthor: \"Chef Maria\"\ndate_published: \"2024-03-15\"\ndifficulty: \"intermediate\"\nprep_time_minutes: 30\ncook_time_minutes: 15",
            "hydration_source_header": "Check Your Understanding: Schema Completion",
            "hydration_method": "line_proximity"
          },
          {
            "id": "relationship-mapping-exercise",
            "title": "Relationship Mapping Exercise (Cooking)",
            "skillPracticed": "Relationship analysis",
            "time": "6 min",
            "lines": "1450-1500",
            "retrievalQuestions": [
              "How can I practice schema design?"
            ],
            "content": "Content doesn't exist in isolation. Defining relationships between content types is crucial for navigation, recommendations, and learning paths.\n\n### 3.1 Types of Relationships\n\n**Common Relationship Types:**\n\n<CardGroup cols={2}>\n  <Card title=\"Hierarchical (Parent-Child)\" icon=\"sitemap\">\n    **Examples:**\n    - Tutorial \u2192 Steps (has-many)\n    - Category \u2192 Tutorials (contains)\n    \n    **Implementation:** Nested structure or parent_id field\n  </Card>\n  \n  <Card title=\"Sequential (Ordering)\" icon=\"arrow-right-arrow-left\">\n    **Examples:**\n    - Tutorial 1 \u2192 Tutorial 2 (next-in-sequence)\n    - Beginner \u2192 Intermediate \u2192 Advanced\n    \n    **Implementation:** order field + next/previous links\n  </Card>\n  \n  <Card title=\"Prerequisite (Dependency)\" icon=\"link\">\n    **Examples:**\n    - Advanced Tutorial requires Basic Tutorial\n    - How-to assumes Concept knowledge\n    \n    **Implementation:** prerequisites array with required flag\n  </Card>\n  \n  <Card title=\"Related/Similar\" icon=\"arrows-split-up-and-left\">\n    **Examples:**\n    - Similar topics\n    - Alternative approaches\n    \n    **Implementation:** related_content array\n  </Card>\n  \n  <Card title=\"Cross-Reference\" icon=\"arrow-right-from-bracket\">\n    **Examples:**\n    - Tutorial references API endpoint\n    - How-to links to Troubleshooting\n    \n    **Implementation:** Reference arrays by type\n  </Card>\n</CardGroup>\n\n---\n\n### 3.2 Relationship Mapping Prompt Pattern\n\n**Prompt Structure:**\n```text\nYou're a content architect mapping relationships between content types.\n\nContent types:\n- [List types]\n\nFor each pair of content types, identify:\n1. What relationships exist between them?\n2. Direction (A \u2192 B, B \u2192 A, or bidirectional)\n3. Cardinality (one-to-one, one-to-many, many-to-many)\n4. How to implement (reference fields, arrays, etc.)\n5. Use cases (why this relationship matters)\n\nThen create a relationship diagram showing all connections.\n```\n\n---\n\n### 3.3 Example: API Documentation Relationships\n\n**Your Prompt:**\n\n```text\nYou're mapping relationships between API documentation content types.\n\nContent types:\n1. Tutorial - Learning-oriented, step-by-step\n2. How-to Guide - Task-oriented, problem-solving\n3. API Reference - Technical specifications\n4. Concept/Explanation - Understanding-oriented\n5. Troubleshooting - Problem diagnosis and fixes\n\nFor each meaningful relationship:\n1. Relationship name and direction\n2. Cardinality\n3. Implementation approach\n4. Example\n5. Use case (why it matters)\n\nThen provide:\n- Visual relationship diagram (text-based)\n- Implementation recommendations\n- Example queries users might want (\"Show me all tutorials that use this API endpoint\")\n```\n\n---\n\n**AI Output (Example):**\n\n```text\nCONTENT TYPE RELATIONSHIP MAP\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 1: Tutorial \u2192 How-to Guide\nName: \"leads-to\" or \"next-steps\"\nDirection: Tutorial \u2192 How-to (unidirectional)\nCardinality: One-to-many (one tutorial can lead to multiple how-tos)\nImplementation: Array field in Tutorial: relatedGuides: string[]\nExample:\n  Tutorial: \"Build Your First Payment Integration\"\n  \u2192 How-to: \"How to Customize Checkout UI\"\n  \u2192 How-to: \"How to Handle Payment Failures\"\nUse Case: After learning basics (tutorial), users want practical applications (how-tos)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 2: Tutorial \u2192 API Reference\nName: \"uses\" or \"references\"\nDirection: Tutorial \u2192 API Reference (unidirectional)\nCardinality: Many-to-many (tutorial uses multiple endpoints, endpoint used by multiple tutorials)\nImplementation: Array field in Tutorial: relatedReference: string[]\nExample:\n  Tutorial: \"Build Your First Payment Integration\"\n  \u2192 API Ref: \"Payment Intents API\"\n  \u2192 API Ref: \"Charges API\"\nUse Case: Users want technical details about APIs used in tutorial\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 3: Concept \u2192 Tutorial\nName: \"applied-in\" or \"demonstrated-by\"\nDirection: Concept \u2192 Tutorial (unidirectional)\nCardinality: One-to-many (one concept demonstrated by multiple tutorials)\nImplementation: Array field in Concept: relatedTutorials: string[]\nExample:\n  Concept: \"Understanding Payment Intents\"\n  \u2192 Tutorial: \"Build Your First Payment Integration\"\n  \u2192 Tutorial: \"Accept Recurring Payments\"\nUse Case: After understanding concept, users want hands-on practice\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 4: Tutorial \u2192 Tutorial\nName: \"prerequisite\" or \"builds-on\"\nDirection: Tutorial A \u2192 Tutorial B (unidirectional, could be bidirectional for \"related\")\nCardinality: Many-to-many\nImplementation: \n  - prerequisites: {title: string, url: string, required: boolean}[]\n  - relatedTutorials: string[]\nExample:\n  Tutorial: \"Build Your First Payment Integration\"\n  \u2190 prerequisite: \"API Authentication Basics\"\n  \u2192 next: \"Accept Recurring Payments\"\nUse Case: Learning path sequencing, ensuring users have required knowledge\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP 5: How-to Guide \u2192 Troubleshooting\nName: \"troubleshoots\" or \"solves-problems-in\"\nDirection: How-to \u2192 Troubleshooting (unidirectional)\nCardinality: One-to-many\nImplementation: Array field in How-to: commonIssues: string[]\nExample:\n  How-to: \"How to Implement Webhooks\"\n  \u2192 Troubleshooting: \"Webhook Not Receiving Events\"\n  \u2192 Troubleshooting: \"Webhook Signature Verification Failed\"\nUse Case: Proactively link to common problems users might encounter\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRELATIONSHIP DEFINITIONS\n\n```yaml\nrelationships:",
            "hydration_source_header": "3. Relationship Mapping",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "validation-error-detection",
            "title": "Validation Error Detection Exercise",
            "skillPracticed": "Error identification",
            "time": "5 min",
            "lines": "1840-1960",
            "content": "```\n\n**Error 2: Invalid `difficulty` value** \u274c\n- **Current:** \"easy\"\n- **Allowed values:** \"beginner\", \"intermediate\", \"advanced\"\n- **Problem:** \"easy\" is not in the enum\n- **Fix:**\n  ```yaml\n  difficulty: \"beginner\"",
            "hydration_source_header": "Now 48 characters \u2713",
            "hydration_method": "line_proximity"
          },
          {
            "id": "self-assessment-project",
            "title": "Self-Assessment Project (CloudMonitor)",
            "skillPracticed": "Full content model",
            "time": "2-3 hrs",
            "lines": "2635-2810",
            "retrievalQuestions": [
              "Self-assessment for content modeling skills"
            ],
            "content": "Create a complete content model and metadata schema for a documentation site.\n\n### Project Brief\n\n**Scenario:**\n\"CloudMonitor API\" - Application monitoring and observability platform\n\n**Features:**\n- Application performance monitoring\n- Log aggregation and search\n- Distributed tracing\n- Alerting and notifications\n- Custom dashboards\n\n**Content:** 100 pages to be organized\n\n**Sample Content (20 pages):**\n```text\n1. \"Getting Started with CloudMonitor\"\n2. \"APM Agent Installation\"\n3. \"Metrics API Reference\"\n4. \"How to Create Custom Dashboards\"\n5. \"Understanding Distributed Tracing\"\n6. \"Alert Rules Configuration\"\n7. \"Log Query Language Guide\"\n8. \"How to Set Up Slack Notifications\"\n9. \"Python Agent Documentation\"\n10. \"Trace Span Reference\"\n11. \"Dashboard Widgets API\"\n12. \"How to Optimize Query Performance\"\n13. \"Data Retention Policies\"\n14. \"Webhook Integration Tutorial\"\n15. \"Troubleshooting Missing Metrics\"\n16. \"Security and Compliance Overview\"\n17. \"How to Export Data\"\n18. \"Service Map Concepts\"\n19. \"Anomaly Detection Setup\"\n20. \"Billing and Usage Tracking\"\n```\n\n---\n\n### Your Assignment\n\n<Tabs>\n  <Tab title=\"Part 1: Content Types (20 min)\">\n    **Task:** Analyze the sample content and identify 4-6 content types.\n\n    **Deliverable:**\n    1. Content type definitions\n    2. Example pages for each type\n    3. Estimated distribution across 100 pages\n    4. Rationale for each type\n  </Tab>\n  \n  <Tab title=\"Part 2: Base Schema (25 min)\">\n    **Task:** Create a base schema that all content types will inherit.\n\n    **Requirements:**\n    - Include core identification fields\n    - Add versioning support (product has versions 1.x, 2.x, 3.x)\n    - Include publishing metadata\n    - Add SEO fields\n    - Support relationships\n\n    **Deliverable:**\n    1. Complete base schema with all fields defined\n    2. Data types and validation rules\n    3. Required vs. optional designation\n    4. Example YAML showing all fields\n  </Tab>\n  \n  <Tab title=\"Part 3: Type-Specific (30 min)\">\n    **Task:** Create detailed schemas for your top 3 content types.\n\n    **For each type, define:**\n    - All type-specific fields\n    - Validation rules\n    - Example frontmatter\n    - How fields are used (search, display, automation)\n\n    **Deliverable:**\n    1. Complete schema for Type 1\n    2. Complete schema for Type 2\n    3. Complete schema for Type 3\n    4. Comparison table showing unique fields per type\n  </Tab>\n  \n  <Tab title=\"Part 4: Relationships (20 min)\">\n    **Task:** Define relationships between your content types.\n\n    **Define for each relationship:**\n    - Relationship name and type\n    - Direction (unidirectional/bidirectional)\n    - Cardinality (one-to-one, one-to-many, many-to-many)\n    - Implementation approach\n    - Example\n    - Use case\n\n    **Deliverable:**\n    1. Relationship matrix or diagram\n    2. Implementation strategy (field names, auto-generation)\n    3. Validation rules for relationships\n    4. Example queries enabled by relationships\n  </Tab>\n  \n  <Tab title=\"Part 5: Validation (15 min)\">\n    **Task:** Design a validation approach for your content model.\n\n    **Include:**\n    - JSON Schema validation\n    - Custom business rules\n    - Relationship validation\n    - Build-time checks\n    - Example error messages\n\n    **Deliverable:**\n    1. Validation rules document\n    2. Example validation script pseudocode\n    3. Error message examples with fixes\n    4. CI/CD integration approach\n  </Tab>\n  \n  <Tab title=\"Part 6: Implementation (20 min)\">\n    **Task:** Create an implementation roadmap.\n\n    **Include:**\n    - Migration strategy for existing content\n    - Tooling requirements\n    - Timeline (phases and milestones)\n    - Team roles and responsibilities\n    - Success metrics\n\n    **Deliverable:**\n    1. Phase-by-phase implementation plan\n    2. Migration script approach\n    3. Training plan for content authors\n    4. Success criteria and metrics\n  </Tab>\n</Tabs>\n\n---\n\n### Evaluation Rubric (Self-Assessment)\n\n| Category | Points | Criteria |\n|----------|--------|----------|\n| **Part 1: Content Types** | 15 | 4-6 distinct types (5 pts), Clear definitions (5 pts), Realistic distribution (5 pts) |\n| **Part 2: Base Schema** | 20 | Comprehensive fields (8 pts), Data types & validation (6 pts), Required/optional clarity (6 pts) |\n| **Part 3: Type-Specific** | 25 | Detailed fields (12 pts), Validation rules (7 pts), Examples (6 pts) |\n| **Part 4: Relationships** | 20 | All relationships identified (8 pts), Clear implementation (7 pts), Validation rules (5 pts) |\n| **Part 5: Validation** | 10 | Comprehensive rules (5 pts), Error handling (3 pts), CI/CD integration (2 pts) |\n| **Part 6: Implementation** | 10 | Realistic timeline (4 pts), Migration strategy (4 pts), Success metrics (2 pts) |\n| **TOTAL** | **100** | |\n\n**Scoring:**\n- **90-100:** Excellent content model, production-ready\n- **80-89:** Good work, minor refinements needed\n- **70-79:** Adequate, significant improvements needed\n- **Below 70:** Review module content and revise\n\n---\n\n### Bonus Challenges (Optional)\n\n<AccordionGroup>\n  <Accordion title=\"Bonus 1: Multi-Language Support\">\n    Design how your content model handles multiple languages:\n    - Translation workflow\n    - Language-specific metadata\n    - Cross-language relationships\n    - Search and navigation\n\n    **Deliverable:** Multi-language content model extension with language field definitions, translation status tracking, localized metadata handling, and example frontmatter in English and Spanish.\n  </Accordion>\n  \n  <Accordion title=\"Bonus 2: Version Management\">\n    Design how content tracks product version compatibility:\n    - Version-specific content\n    - Deprecation warnings\n    - Version switcher UI\n    - Migration guides\n\n    **Deliverable:** Versioning strategy including version compatibility fields, deprecation workflow, version selector implementation, and migration guide template.\n  </Accordion>\n  \n  <Accordion title=\"Bonus 3: Content Reuse Strategy\">\n    Design how content can be reused across contexts:\n    - Reusable components/snippets\n    - Variable content substitution\n    - Multiple output formats\n    - Single-source publishing\n\n    **Deliverable:** Content reuse framework with reusable component schema, variable substitution approach, output format specifications, and example use cases.\n  </Accordion>\n  \n  <Accordion title=\"Bonus 4: Analytics Integration\">\n    Design metadata to support content analytics:\n    - Usage tracking\n    - Effectiveness measurement\n    - A/B testing support\n    - User feedback collection\n\n    **Deliverable:** Analytics metadata schema with tracking fields, event definitions, success metrics, and reporting queries.\n  </Accordion>\n</AccordionGroup>\n\n---",
            "hydration_source_header": "7. Self-Assessment Project",
            "hydration_method": "fuzzy_title_match"
          }
        ]
      }
    },
    "2-3-navigation-design": {
      "file": "2-3-navigation-design.mdx",
      "focus": "Designing navigation structures with AI assistance, optimizing information scent, SEO considerations, depth vs. breadth trade-offs, and mobile navigation patterns",
      "entityCount": 110,
      "entities": {
        "frameworks": [
          {
            "id": "navigation-design-framework",
            "title": "Navigation Design Framework",
            "type": "framework",
            "definition": "Framework for AI-assisted navigation generation, information scent evaluation, SEO optimization, depth/breadth balance, and mobile patterns",
            "contains": [
              "nav-generation-patterns",
              "info-scent-evaluation",
              "seo-navigation-principles",
              "depth-breadth-balance",
              "mobile-nav-patterns"
            ],
            "lines": "1-3323",
            "crossModule": false,
            "retrievalQuestions": [
              "How do I design navigation for documentation?",
              "What makes navigation effective?"
            ],
            "content": "**The Five Core Principles:**\n\n1. **Respect Miller's Law**\n   - 5-7 top-level items (sweet spot)\n   - 5-9 items per section\n   - Maximum 3 levels deep for most sites\n\n2. **Optimize Information Scent**\n   - Every label should score 4-5/5 for clarity\n   - Users should predict destination confidently\n   - Avoid vague terms (Resources, More, Stuff)\n\n3. **Balance Depth and Breadth**\n   - Too shallow = overwhelming\n   - Too deep = frustrating maze\n   - 2-3 levels = optimal for most content\n\n4. **Design for Mobile First**\n   - Collapsible navigation\n   - Touch-friendly spacing\n   - Priority items visible\n   - Test on actual devices\n\n5. **Integrate SEO from Start**\n   - Keyword-rich labels\n   - Hierarchical URL structure\n   - Schema markup\n   - Match search intent\n\n---",
            "hydration_source_header": "Navigation Design Principles",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "five-core-nav-principles",
            "title": "Five Core Navigation Principles",
            "type": "framework",
            "definition": "Miller's Law, Information Scent, Depth/Breadth Balance, Mobile-First, SEO Integration",
            "contains": [
              "millers-law-principle",
              "info-scent-optimization",
              "depth-breadth-balance",
              "mobile-first-design",
              "seo-integration"
            ],
            "lines": "2560-2630",
            "crossModule": false,
            "retrievalQuestions": [
              "What are the principles of good navigation design?"
            ],
            "content": "**1. Use Keyword-Rich Labels**\n- Labels should include target keywords\n- Match common search queries\n- Balance user language and SEO terms\n\n**Example:**\n- \u274c Weak: \"Resources\"\n- \u2705 Strong: \"API Documentation\"\n\n**2. Create Hierarchical URL Structure**\n- URLs should mirror navigation\n- Use descriptive paths\n- Maintain consistent depth\n\n**Example:**\n```text\nNavigation:        URL:\nGet Started  \u2192     /get-started/\n  Quickstart \u2192     /get-started/quickstart/\n  Auth Guide \u2192     /get-started/authentication/\n```\n\n**3. Implement Schema Markup**\n- Use BreadcrumbList schema\n- Add SiteNavigationElement markup\n- Help search engines understand structure\n\n<CodeGroup>\n\n```json Schema: Breadcrumbs\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"BreadcrumbList\",\n  \"itemListElement\": [\n    {\n      \"@type\": \"ListItem\",\n      \"position\": 1,\n      \"name\": \"Get Started\",\n      \"item\": \"https://docs.example.com/get-started\"\n    },\n    {\n      \"@type\": \"ListItem\",\n      \"position\": 2,\n      \"name\": \"Authentication\",\n      \"item\": \"https://docs.example.com/get-started/authentication\"\n    }\n  ]\n}\n```\n\n```json Schema: Site Navigation\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"SiteNavigationElement\",\n  \"name\": \"Main Navigation\",\n  \"url\": \"https://docs.example.com\",\n  \"hasPart\": [\n    {\n      \"@type\": \"SiteNavigationElement\",\n      \"name\": \"Get Started\",\n      \"url\": \"https://docs.example.com/get-started\"\n    },\n    {\n      \"@type\": \"SiteNavigationElement\",\n      \"name\": \"API Reference\",\n      \"url\": \"https://docs.example.com/api-reference\"\n    }\n  ]\n}\n```\n\n</CodeGroup>\n\n<Tip>\n**Validation:** Test your Schema.org markup using [Google's Rich Results Test](https://search.google.com/test/rich-results) to verify it's correctly structured before deploying to production.\n</Tip>\n\n---",
            "hydration_source_header": "3.1 SEO-Friendly Navigation Principles",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "info-scent-rating-scale",
            "title": "Information Scent Rating Scale (1-5)",
            "type": "framework",
            "definition": "5-point scale for evaluating navigation label clarity and predictability",
            "contains": [
              "clarity-rating",
              "predictability-rating",
              "specificity-rating"
            ],
            "lines": "610-670",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I rate information scent?",
              "What is information scent in navigation?"
            ],
            "content": "**Prompt Structure:**\n\n```text\nYou're a UX researcher evaluating information scent in navigation.\n\nEvaluate these navigation labels for information scent:\n\nLabels:\n[List of navigation labels with brief context]\n\nFor each label, evaluate:\n1. Clarity (1-5): How clear is the label?\n2. Predictability (1-5): Can users predict the destination?\n3. Specificity (1-5): How specific vs. vague?\n4. Alternatives: What would improve scent?\n5. Issues: What might confuse users?\n```\n\n<Info>\n**Validation Checklist:** After AI evaluates information scent, verify the analysis:\n\n**Rating Accuracy:**\n- \u2610 5/5 ratings are justified (truly crystal clear, universally understood)\n- \u2610 1-2/5 ratings have specific confusion points identified\n- \u2610 Ratings are consistent (similar labels get similar scores)\n\n**Recommendations Quality:**\n- \u2610 Alternatives provided for weak labels (less than 3/5)\n- \u2610 Improvements are specific (not just \"make it clearer\")\n- \u2610 Strong labels (4-5/5) properly identified as keepers\n\n**Reality Check:**\n- \u2610 \"Confusion points\" are realistic (not contrived)\n- \u2610 Alternatives actually improve information scent\n- \u2610 Analysis considers your specific audience\n\n**Validation Test:** Pick 2-3 labels AI rated highly (4-5/5). Show them to colleagues without context. If they can't predict destination, the AI ratings are inflated\u2014revise criteria and re-evaluate.\n</Info>\n\n---",
            "hydration_source_header": "2.2 Information Scent Evaluation Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "navigation-validation-framework",
            "title": "Navigation Validation Framework",
            "type": "framework",
            "definition": "Framework for validating navigation structure, labels, and usability",
            "contains": [
              "structure-quality-checks",
              "label-quality-checks",
              "usability-red-flags"
            ],
            "lines": "1105-1150",
            "crossModule": false,
            "retrievalQuestions": [
              "How do I evaluate navigation quality?"
            ],
            "hydration_status": "failed"
          }
        ],
        "principles": [
          {
            "id": "millers-law-nav",
            "title": "Miller's Law (5-7 Items)",
            "partOf": "five-core-nav-principles",
            "lines": "250-260, 1760-1780",
            "crossModule": true,
            "retrievalQuestions": [
              "How many navigation items should I have?"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "info-scent-principle",
            "title": "Information Scent Optimization",
            "partOf": "five-core-nav-principles",
            "lines": "610-780",
            "crossModule": false,
            "retrievalQuestions": [
              "What is information scent in navigation?"
            ],
            "content": "Information scent is how well navigation labels predict their destination. Strong scent means users confidently know where to click.\n\n### 2.1 Understanding Information Scent\n\n**Definition:** The extent to which users can predict what they'll find if they follow a path (label/link).\n\n**Rating Scale (1-5):**\n- **5/5** = Immediately clear, crystal clear destination\n- **4/5** = Very clear, highly predictable\n- **3/5** = Somewhat clear, requires interpretation\n- **2/5** = Unclear, multiple interpretations\n- **1/5** = Very confusing, no clear prediction\n\n**Target:** Aim for 4-5/5 on all navigation labels.\n\n**Strong Scent Example:**\n- Label: \"Getting Started Guide\"\n- User thinks: \"This will show me how to begin\"\n- Destination: Step-by-step tutorial for beginners\n- Result: \u2705 Expectation met\n\n**Weak Scent Example:**\n- Label: \"Resources\"\n- User thinks: \"What kind of resources? Documents? Tools? Community?\"\n- Destination: Mixed bag of downloads, links, and articles\n- Result: \u274c Unclear, requires guessing\n\n<CardGroup cols={2}>\n  <Card title=\"Strong Information Scent\" icon=\"check\">\n    - Specific, descriptive labels\n    - Predictable destinations\n    - Matches user mental models\n    - Reduces clicks to find content\n    - Increases task success\n  </Card>\n  \n  <Card title=\"Weak Information Scent\" icon=\"xmark\">\n    - Vague, generic labels\n    - Unpredictable content\n    - Requires trial and error\n    - Increases time on task\n    - Reduces user confidence\n  </Card>\n</CardGroup>\n\n---\n\n### 2.2 Information Scent Evaluation Pattern\n\n**Prompt Structure:**\n\n```text\nYou're a UX researcher evaluating information scent in navigation.\n\nEvaluate these navigation labels for information scent:\n\nLabels:\n[List of navigation labels with brief context]\n\nFor each label, evaluate:\n1. Clarity (1-5): How clear is the label?\n2. Predictability (1-5): Can users predict the destination?\n3. Specificity (1-5): How specific vs. vague?\n4. Alternatives: What would improve scent?\n5. Issues: What might confuse users?\n```\n\n<Info>\n**Validation Checklist:** After AI evaluates information scent, verify the analysis:\n\n**Rating Accuracy:**\n- \u2610 5/5 ratings are justified (truly crystal clear, universally understood)\n- \u2610 1-2/5 ratings have specific confusion points identified\n- \u2610 Ratings are consistent (similar labels get similar scores)\n\n**Recommendations Quality:**\n- \u2610 Alternatives provided for weak labels (less than 3/5)\n- \u2610 Improvements are specific (not just \"make it clearer\")\n- \u2610 Strong labels (4-5/5) properly identified as keepers\n\n**Reality Check:**\n- \u2610 \"Confusion points\" are realistic (not contrived)\n- \u2610 Alternatives actually improve information scent\n- \u2610 Analysis considers your specific audience\n\n**Validation Test:** Pick 2-3 labels AI rated highly (4-5/5). Show them to colleagues without context. If they can't predict destination, the AI ratings are inflated\u2014revise criteria and re-evaluate.\n</Info>\n\n---\n\n### 2.3 Example: Evaluating Documentation Navigation\n\n**Your Prompt:**\n\n```text\nYou're a UX researcher evaluating information scent for developer documentation navigation.\n\nEvaluate these navigation labels:\n\nContext: REST API documentation site\nAudience: Backend developers (40% junior, 60% senior)\n\nNavigation labels to evaluate:\n1. \"Resources\"\n2. \"Get Started\"\n3. \"Docs\"\n4. \"API Reference\"\n5. \"Learn More\"\n6. \"Guides & Tutorials\"\n7. \"Developer Tools\"\n8. \"FAQ\"\n9. \"Advanced\"\n10. \"Support\"\n\nFor each label:\n1. Information scent rating (1-5, where 5 = crystal clear)\n2. What users will expect to find\n3. Potential confusion points\n4. Recommendations for improvement\n5. Alternative labels if needed\n```\n\n**AI Output Example:**\n\n```text\nINFORMATION SCENT EVALUATION\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nLABEL 1: \"Resources\"\nInformation Scent: 1/5 \u274c WEAK\n\nUser Expectations:\n- Could be anything: downloads, tools, links, documents\n- No clear indication of content type\n- Generic catch-all term\n\nConfusion Points:\n- Too broad - \"resources\" could mean 20 different things\n- Users must click to discover actual content\n- Creates cognitive load (guess and check)\n- Often becomes dumping ground for misc content\n\nRecommendations:\n- AVOID: This is one of the weakest navigation labels\n- Be specific about what \"resources\" contains\n- Break into specific categories\n\nAlternative Labels:\n- If contains downloads: \"Downloads\" or \"SDKs & Tools\"\n- If contains links: \"External Links\" or \"Community\"\n- If contains docs: Use specific doc type \"Guides\" or \"References\"\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 2: \"Get Started\"\nInformation Scent: 5/5 \u2705 STRONG\n\nUser Expectations:\n- Beginner-friendly content\n- Step-by-step instructions\n- Quick path to first success\n- Installation and setup\n\nConfusion Points:\n- None - universally understood\n- Clear action-oriented label\n- Signals starting point\n\nRecommendations:\n- KEEP: Excellent information scent\n- Consider adding time estimate: \"Get Started (5 min)\"\n- Could be even clearer: \"Quick Start Guide\"\n\nAlternative Labels:\n- \"Quickstart\" (more concise)\n- \"Getting Started Guide\" (more formal)\n- \"Start Here\" (more direct)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 3: \"Docs\"\nInformation Scent: 2/5 \u26a0\ufe0f WEAK-TO-MODERATE\n\nUser Expectations:\n- Some kind of documentation (but what kind?)\n- Could be tutorials, references, guides, or all of above\n- Abbreviation feels casual\n\nConfusion Points:\n- Too generic - \"docs\" is entire documentation site\n- Doesn't differentiate types of documentation\n- Seems redundant if already on docs site\n- Abbreviation might not fit formal brands\n\nRecommendations:\n- REPLACE: Too vague for navigation\n- Be specific about doc type\n- Use if this is generic entry to all docs from another site\n\nAlternative Labels:\n- \"Documentation\" (more formal, but still vague)\n- \"API Reference\" (if that's what it is)\n- \"Guides\" (if mostly how-tos)\n- \"Technical Docs\" (slightly more specific)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 4: \"API Reference\"\nInformation Scent: 5/5 \u2705 STRONG\n\nUser Expectations:\n- Technical specifications\n- Endpoint documentation\n- Parameter details\n- Request/response examples\n\nConfusion Points:\n- None for developers\n- Industry standard term\n- Clear and specific\n\nRecommendations:\n- KEEP: Excellent clarity\n- Perfect for developer audience\n- Immediately recognizable\n\nAlternative Labels:\n- \"API Documentation\" (slightly more formal)\n- \"Endpoint Reference\" (more specific)\n- \"API Specs\" (more casual)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 5: \"Learn More\"\nInformation Scent: 1/5 \u274c VERY WEAK\n\nUser Expectations:\n- Vague call-to-action\n- Could be anything\n- Sounds like marketing copy, not navigation\n\nConfusion Points:\n- \"Learn more\" about what?\n- Too generic to be useful\n- Feels like a button, not a navigation item\n- Could lead anywhere\n\nRecommendations:\n- AVOID: Nearly meaningless as navigation\n- Never use without clear object (\"Learn more about X\")\n- Acceptable as CTA button, not navigation label\n\nAlternative Labels:\n- If tutorials: \"Tutorials\" or \"Learning Path\"\n- If concepts: \"Concepts\" or \"Understanding [Product]\"\n- If courses: \"Training\" or \"Courses\"\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 6: \"Guides & Tutorials\"\nInformation Scent: 4/5 \u2705 GOOD\n\nUser Expectations:\n- How-to content\n- Step-by-step instructions\n- Educational material\n- Practical application\n\nConfusion Points:\n- Minor: Difference between \"guide\" and \"tutorial\" unclear\n- Both are instructional content\n- Some might wonder which to choose\n\nRecommendations:\n- GOOD: Clear information scent\n- Consider separating if truly different:\n  * \"Guides\" = task-oriented\n  * \"Tutorials\" = learning-oriented\n- Or combine as \"Guides & Tutorials\" (current)\n\nAlternative Labels:\n- \"Guides\" (simpler)\n- \"Tutorials\" (if all are learning-oriented)\n- \"How-To Guides\" (more specific)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 7: \"Developer Tools\"\nInformation Scent: 4/5 \u2705 GOOD\n\nUser Expectations:\n- SDKs and libraries\n- CLI tools\n- Testing utilities\n- Development aids\n\nConfusion Points:\n- Could include IDE plugins, browser extensions\n- Might be downloadable tools OR documentation about tools\n- Breadth of \"tools\" could vary\n\nRecommendations:\n- GOOD: Generally clear\n- Consider being more specific if needed\n- Add description in submenu if ambiguous\n\nAlternative Labels:\n- \"SDKs & Tools\" (more specific)\n- \"Libraries & SDKs\" (if that's the focus)\n- \"Development Tools\" (more formal)\n- \"Tooling\" (more casual)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 8: \"FAQ\"\nInformation Scent: 5/5 \u2705 STRONG\n\nUser Expectations:\n- Common questions and answers\n- Quick information lookup\n- Organized by topic\n- Concise answers\n\nConfusion Points:\n- None - universally understood\n- Standard abbreviation\n- Clear purpose\n\nRecommendations:\n- KEEP: Excellent clarity\n- Standard location expectations (often in support/help)\n- Consider icon (question mark)\n\nAlternative Labels:\n- \"Frequently Asked Questions\" (more formal, longer)\n- \"Common Questions\" (more natural)\n- \"Q&A\" (more casual)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 9: \"Advanced\"\nInformation Scent: 2/5 \u26a0\ufe0f WEAK\n\nUser Expectations:\n- Complex features?\n- Expert-level content?\n- Less common use cases?\n- Unclear without context\n\nConfusion Points:\n- Subjective term (advanced to whom?)\n- Doesn't indicate content type\n- Users must guess what's inside\n- Creates artificial barrier (beginners might skip)\n- What makes something \"advanced\"?\n\nRecommendations:\n- AVOID: Vague and subjective\n- Describe what makes it advanced\n- Or organize by feature, not skill level\n\nAlternative Labels:\n- If complex features: Name the feature (\"GraphQL API\")\n- If optimization: \"Performance & Optimization\"\n- If enterprise: \"Enterprise Features\"\n- If deep concepts: \"Advanced Concepts\" (slightly better)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 10: \"Support\"\nInformation Scent: 5/5 \u2705 STRONG\n\nUser Expectations:\n- Help resources\n- Contact information\n- Troubleshooting\n- Community forums\n- Status page\n\nConfusion Points:\n- None - universal understanding\n- Clear purpose\n- Expected location for help\n\nRecommendations:\n- KEEP: Excellent clarity\n- Standard placement (often far right)\n- Consider icon (question mark or lifebuoy)\n\nAlternative Labels:\n- \"Help & Support\" (more explicit)\n- \"Help\" (more concise)\n- \"Get Help\" (more action-oriented)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nOVERALL ANALYSIS:\n\nSTRONG INFORMATION SCENT (Keep):\n\u2705 \"Get Started\" - 5/5\n\u2705 \"API Reference\" - 5/5\n\u2705 \"FAQ\" - 5/5\n\u2705 \"Support\" - 5/5\n\nGOOD INFORMATION SCENT (Minor improvements):\n\u2713 \"Guides & Tutorials\" - 4/5\n\u2713 \"Developer Tools\" - 4/5\n\nWEAK INFORMATION SCENT (Revise):\n\u26a0\ufe0f \"Docs\" - 2/5 (too generic)\n\u26a0\ufe0f \"Advanced\" - 2/5 (subjective, vague)\n\nVERY WEAK INFORMATION SCENT (Replace):\n\u274c \"Resources\" - 1/5 (meaningless)\n\u274c \"Learn More\" - 1/5 (vague CTA)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nREVISED NAVIGATION (After improvements):\n\nBEFORE:\n1. Resources\n2. Get Started\n3. Docs\n4. API Reference\n5. Learn More\n6. Guides & Tutorials\n7. Developer Tools\n8. FAQ\n9. Advanced\n10. Support\n\nAFTER:\n1. Get Started \u2190 Keep\n2. API Reference \u2190 Keep\n3. SDKs & Tools \u2190 Improved from \"Developer Tools\"\n4. Guides & Tutorials \u2190 Keep\n5. Code Examples \u2190 Improved from \"Learn More\"\n6. Community & Support \u2190 Improved from \"Support\" (more specific)\n7. FAQ \u2190 Keep\n\nREMOVED:\n- \"Resources\" \u2192 Content distributed to specific sections\n- \"Docs\" \u2192 Redundant (entire site is docs)\n- \"Advanced\" \u2192 Features organized by name, not skill level\n\nRESULT:\n- 7 clear navigation items (down from 10)\n- All items score 4-5/5 for information scent\n- No vague or ambiguous labels\n- Each label clearly indicates destination\n- Better scannability and decision-making\n```\n\n<Info>\n  **Information Scent Tip:** Aim for 4-5/5 rating on all navigation labels. Anything below 3/5 should be revised. Test labels with 5-second tests: Can users predict where they'll go in 5 seconds?\n</Info>\n\n---",
            "hydration_source_header": "2. Information Scent Evaluation",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "depth-breadth-principle",
            "title": "Balance Depth and Breadth",
            "partOf": "five-core-nav-principles",
            "lines": "1590-1720",
            "crossModule": false,
            "retrievalQuestions": [
              "How deep should my navigation be?"
            ],
            "content": "**Prompt Structure:**\n\n```text\nYou're an SEO specialist and information architect.\n\nOptimize this navigation structure for search engines:\n\nCurrent navigation:\n[List current structure]\n\nRequirements:\n- Include target keywords: [list keywords]\n- Match common search queries\n- Create clear hierarchy for crawlers\n- Maintain strong information scent\n- URLs should be descriptive\n\nProvide:\n1. Revised navigation with keyword-rich labels\n2. Proposed URL structure\n3. Schema markup recommendations\n4. Internal linking strategy\n```\n\n<Info>\n**Validation Checklist:** After AI optimizes navigation for SEO, verify:\n\n**Keyword Integration:**\n- \u2610 Target keywords appear in navigation labels naturally (not forced)\n- \u2610 Keywords front-loaded where possible (\"API Reference\" not \"Reference for APIs\")\n- \u2610 Labels still make sense to humans (UX > SEO always)\n\n**URL Quality:**\n- \u2610 URLs are descriptive (`/api-reference/authentication` not `/docs/page2`)\n- \u2610 URLs match navigation hierarchy\n- \u2610 Hyphens used for multi-word paths (not underscores or camelCase)\n- \u2610 URLs are lowercase and consistent\n\n**Schema Markup:**\n- \u2610 BreadcrumbList schema included with correct syntax\n- \u2610 SiteNavigationElement schema provided\n- \u2610 Markup validates at [schema.org validator](https://validator.schema.org/)\n\n**Balance Check:**\n- \u2610 Information scent not sacrificed for keywords (4-5/5 rating maintained)\n- \u2610 Labels don't sound like keyword stuffing\n- \u2610 User needs prioritized over search engines\n\n**Red Flag:** If labels become awkward for SEO (\"Documentation API Reference Guide Resources\"), reject the suggestion. User clarity always comes first.\n</Info>\n\n---",
            "hydration_source_header": "3.2 AI Prompt for SEO-Optimized Navigation",
            "hydration_method": "line_proximity"
          },
          {
            "id": "mobile-first-nav",
            "title": "Mobile-First Navigation Design",
            "partOf": "five-core-nav-principles",
            "lines": "1720-1850",
            "crossModule": false,
            "retrievalQuestions": [
              "Should I design mobile navigation first?"
            ],
            "content": "<AccordionGroup>\n  <Accordion title=\"Hamburger Menu (Most Common)\">\n    **When to Use:** Standard approach for most documentation\n    \n    **Pros:**\n    - Hides complexity\n    - Familiar pattern\n    - Saves screen space\n    \n    **Cons:**\n    - Requires tap to reveal\n    - Lower discoverability\n    - Can hide too much\n    \n    **Implementation:**\n    - Collapsible sections\n    - Swipe to close\n    - Persistent \"close\" button\n  </Accordion>\n  \n  <Accordion title=\"Bottom Navigation\">\n    **When to Use:** App-like documentation experiences\n    \n    **Pros:**\n    - Easy thumb reach\n    - Always visible\n    - Fast switching\n    \n    **Cons:**\n    - Limited to 3-5 items\n    - Takes screen space\n    - Not standard for docs\n    \n    **Implementation:**\n    - Use for top 3-5 sections only\n    - Icons + labels\n    - Active state indicators\n  </Accordion>\n  \n  <Accordion title=\"Priority+ Pattern\">\n    **When to Use:** When some nav items are more important\n    \n    **Pros:**\n    - Shows priority items\n    - Hides less important\n    - Adaptive to screen size\n    \n    **Cons:**\n    - Complex to implement\n    - Less predictable\n    - Requires JS\n    \n    **Implementation:**\n    - Show 4-5 priority items\n    - \"More\" menu for rest\n    - Calculate based on viewport\n  </Accordion>\n</AccordionGroup>\n\n---",
            "hydration_source_header": "5.1 Mobile Navigation Patterns",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "seo-integration-nav",
            "title": "SEO Integration from Start",
            "partOf": "five-core-nav-principles",
            "lines": "1460-1590",
            "crossModule": false,
            "retrievalQuestions": [
              "How do I make navigation SEO-friendly?"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "label-clarity-principle",
            "title": "Every Label Score 4-5/5",
            "partOf": "info-scent-evaluation",
            "lines": "680-700",
            "crossModule": false,
            "hydration_status": "failed"
          },
          {
            "id": "avoid-vague-labels",
            "title": "Avoid Vague Terms (Resources, More, Stuff)",
            "partOf": "info-scent-evaluation",
            "lines": "590-610, 770-795",
            "crossModule": false,
            "retrievalQuestions": [
              "What navigation labels should I avoid?"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "3-click-rule",
            "title": "80% Content in \u22643 Clicks",
            "partOf": "depth-breadth-balance",
            "lines": "1680-1700",
            "crossModule": false,
            "content": "**Optimal Structure for Documentation:**\n- **5-7 top-level items** (respects Miller's Law)\n- **2-3 levels maximum** (reduces clicks)\n- **5-9 items per section** (scannable groups)\n\n**Example Balanced Structure:**\n\n**Text alternative:** Navigation structure showing Documentation as the root with 5 main sections (Get Started, API Reference, Guides, SDKs, Support). Each section has 2-3 subsections. Get Started includes Quickstart, Authentication, and First API Call. API Reference includes Users API, Products API, and Orders API. Guides includes Payment Integration, Webhook Setup, and Error Handling. This demonstrates optimal balance of 5 top-level items with maximum 2 levels of depth.\n\n```mermaid\ngraph TD\n    A[Documentation] --> B[Get Started]\n    A --> C[API Reference]\n    A --> D[Guides]\n    A --> E[SDKs]\n    A --> F[Support]\n    \n    B --> B1[Quickstart]\n    B --> B2[Authentication]\n    B --> B3[First API Call]\n    \n    C --> C1[Users API]\n    C --> C2[Products API]\n    C --> C3[Orders API]\n    \n    D --> D1[Payment Integration]\n    D --> D2[Webhook Setup]\n    D --> D3[Error Handling]\n    \n    style A fill:#4A90E2,color:#fff\n    style B fill:#7ED321,color:#fff\n    style C fill:#7ED321,color:#fff\n    style D fill:#7ED321,color:#fff\n    style E fill:#7ED321,color:#fff\n    style F fill:#7ED321,color:#fff\n```\n\n<Tip>\n  **Rule of Thumb:** If users need more than 3 clicks to reach 80% of content, your navigation is too deep. If your top-level has more than 9 items, it's too broad.\n</Tip>\n\n---",
            "hydration_source_header": "4.2 The Sweet Spot: Balanced Navigation",
            "hydration_method": "line_proximity"
          },
          {
            "id": "keyword-rich-labels",
            "title": "Use Keyword-Rich Labels",
            "partOf": "seo-navigation-principles",
            "lines": "1470-1490",
            "crossModule": false,
            "hydration_status": "failed"
          }
        ],
        "patterns": [
          {
            "id": "basic-nav-generation-pattern",
            "title": "Basic Navigation Generation Pattern",
            "implements": "navigation-design-framework",
            "taskType": "generation",
            "lines": "70-100",
            "content": "**Use When:** You need to create primary navigation from scratch\n\n**Prompt Structure:**\n\n```text\nYou're a UX designer specializing in navigation design and information architecture.\n\nGenerate navigation for [SITE/PRODUCT] with these characteristics:\n\nStructure:\n- [NUMBER] top-level items\n- [DEPTH] levels maximum\n- [BREADTH] items per level\n\nContent to include:\n- [List major content areas]\n\nAudience:\n- [User type and expertise level]\n\nConstraints:\n- [Technical limitations]\n- [Design requirements]\n- [Accessibility needs]\n\nOutput format:\n- [How you want the navigation presented]\n```\n\n<Info>\n**Validation Checklist:** After AI generates navigation, verify quality using these criteria:\n\n**Structure Quality:**\n- \u2610 5-7 top-level items (not too few, not too many)\n- \u2610 Consistent depth across sections (no 1-level next to 5-level)\n- \u2610 Each section has logical grouping (items relate to each other)\n\n**Label Quality:**\n- \u2610 All labels score 4-5/5 for information scent (can you predict destination?)\n- \u2610 Labels are specific (avoid \"Resources\", \"More\", \"Stuff\")\n- \u2610 Character counts meet constraints (check mobile display)\n\n**Completeness:**\n- \u2610 All content areas from your input are included\n- \u2610 No critical content hidden or missing\n- \u2610 Rationale provided for organizational decisions\n\n**Red Flags to Fix Immediately:**\n- \u274c Labels like \"Other\", \"Miscellaneous\", \"More\" (weak information scent)\n- \u274c Unbalanced depth (some sections 1 level, others 4+ levels)\n- \u274c More than 9 top-level items (cognitive overload)\n</Info>\n\n---",
            "hydration_source_header": "1.1 The Basic Navigation Generation Pattern",
            "hydration_method": "title_match"
          },
          {
            "id": "label-variation-pattern",
            "title": "Label Variation Pattern",
            "implements": "info-scent-evaluation",
            "taskType": "generation",
            "lines": "350-400",
            "content": "**Use When:** You need multiple label options to test\n\n**Prompt Structure:**\n\n```text\nYou're a UX writer specializing in navigation labels.\n\nGenerate [NUMBER] label variations for [SECTION/CONTENT].\n\nContent this section contains:\n- [List items]\n\nLabel requirements:\n- Maximum [NUMBER] characters\n- [Style guidelines]\n- Must be [characteristics]\n\nFor each variation provide:\n1. Label text\n2. Character count\n3. Pros and cons\n4. Information scent rating (1-5)\n5. Target audience fit\n```\n\n<Info>\n**Validation Checklist:** After AI generates label variations, assess quality:\n\n**Variety Check:**\n- \u2610 Labels show real diversity (not just \"API Docs\", \"API Documentation\", \"API Reference\" - too similar)\n- \u2610 Different approaches represented (action-oriented, noun-based, user-focused)\n- \u2610 At least 3 labels score 4-5/5 for information scent\n\n**Accuracy Check:**\n- \u2610 Character counts are correct (recount if needed)\n- \u2610 Information scent ratings are justified (5/5 should be crystal clear)\n- \u2610 Pros/cons are specific, not generic\n\n**Practical Usefulness:**\n- \u2610 Labels are actually testable (avoid overly similar options)\n- \u2610 Trade-offs are clear (helps decision-making)\n- \u2610 Target audience fits are realistic\n\n**Quick Test:** Show top 3 labels (without context) to a colleague. Can they predict the destination? If not, those labels score too high for information scent.\n</Info>\n\n---",
            "hydration_source_header": "1.3 The Label Variation Pattern",
            "hydration_method": "title_match"
          },
          {
            "id": "info-scent-evaluation-pattern",
            "title": "Information Scent Evaluation Pattern",
            "implements": "info-scent-principle",
            "taskType": "analysis",
            "lines": "680-720",
            "retrievalQuestions": [
              "How do I evaluate information scent with AI?"
            ],
            "content": "**Prompt Structure:**\n\n```text\nYou're a UX researcher evaluating information scent in navigation.\n\nEvaluate these navigation labels for information scent:\n\nLabels:\n[List of navigation labels with brief context]\n\nFor each label, evaluate:\n1. Clarity (1-5): How clear is the label?\n2. Predictability (1-5): Can users predict the destination?\n3. Specificity (1-5): How specific vs. vague?\n4. Alternatives: What would improve scent?\n5. Issues: What might confuse users?\n```\n\n<Info>\n**Validation Checklist:** After AI evaluates information scent, verify the analysis:\n\n**Rating Accuracy:**\n- \u2610 5/5 ratings are justified (truly crystal clear, universally understood)\n- \u2610 1-2/5 ratings have specific confusion points identified\n- \u2610 Ratings are consistent (similar labels get similar scores)\n\n**Recommendations Quality:**\n- \u2610 Alternatives provided for weak labels (less than 3/5)\n- \u2610 Improvements are specific (not just \"make it clearer\")\n- \u2610 Strong labels (4-5/5) properly identified as keepers\n\n**Reality Check:**\n- \u2610 \"Confusion points\" are realistic (not contrived)\n- \u2610 Alternatives actually improve information scent\n- \u2610 Analysis considers your specific audience\n\n**Validation Test:** Pick 2-3 labels AI rated highly (4-5/5). Show them to colleagues without context. If they can't predict destination, the AI ratings are inflated\u2014revise criteria and re-evaluate.\n</Info>\n\n---",
            "hydration_source_header": "2.2 Information Scent Evaluation Pattern",
            "hydration_method": "title_match"
          },
          {
            "id": "nav-validation-pattern",
            "title": "Navigation Validation Prompt Pattern",
            "implements": "navigation-validation-framework",
            "taskType": "analysis",
            "lines": "1105-1150",
            "content": "**Use When:** You need to objectively evaluate AI-generated navigation before committing to it.\n\n**Prompt Structure:**\n\n```text\nYou're a UX auditor evaluating navigation design quality.\n\nReview this AI-generated navigation for quality issues:\n\n[PASTE AI-GENERATED NAVIGATION]\n\nAudit against these criteria:\n\n1. STRUCTURE QUALITY\n   - Count top-level items (optimal: 5-7)\n   - Measure depth consistency\n   - Identify any unbalanced sections\n\n2. LABEL QUALITY\n   - Rate information scent for each label (1-5)\n   - Flag vague terms (Resources, More, Other)\n   - Check character counts vs. mobile constraints\n\n3. COMPLETENESS\n   - Verify all required content areas included\n   - Identify any missing critical paths\n   - Check for logical gaps\n\n4. USABILITY RED FLAGS\n   - Overlapping categories\n   - Ambiguous labels\n   - Excessive depth (>3 levels)\n   - Poor mobile scalability\n\nFor each issue found, provide:\n- Severity (Critical/High/Medium/Low)\n- Specific problem\n- Concrete fix\n\nEnd with: Pass/Fail recommendation with justification.\n```\n\n---",
            "hydration_source_header": "The Validation Prompt Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "seo-nav-optimization-pattern",
            "title": "SEO-Optimized Navigation Pattern",
            "implements": "seo-integration-nav",
            "taskType": "generation",
            "lines": "1545-1590",
            "content": "<AccordionGroup>\n  <Accordion title=\"Hamburger Menu (Most Common)\">\n    **When to Use:** Standard approach for most documentation\n    \n    **Pros:**\n    - Hides complexity\n    - Familiar pattern\n    - Saves screen space\n    \n    **Cons:**\n    - Requires tap to reveal\n    - Lower discoverability\n    - Can hide too much\n    \n    **Implementation:**\n    - Collapsible sections\n    - Swipe to close\n    - Persistent \"close\" button\n  </Accordion>\n  \n  <Accordion title=\"Bottom Navigation\">\n    **When to Use:** App-like documentation experiences\n    \n    **Pros:**\n    - Easy thumb reach\n    - Always visible\n    - Fast switching\n    \n    **Cons:**\n    - Limited to 3-5 items\n    - Takes screen space\n    - Not standard for docs\n    \n    **Implementation:**\n    - Use for top 3-5 sections only\n    - Icons + labels\n    - Active state indicators\n  </Accordion>\n  \n  <Accordion title=\"Priority+ Pattern\">\n    **When to Use:** When some nav items are more important\n    \n    **Pros:**\n    - Shows priority items\n    - Hides less important\n    - Adaptive to screen size\n    \n    **Cons:**\n    - Complex to implement\n    - Less predictable\n    - Requires JS\n    \n    **Implementation:**\n    - Show 4-5 priority items\n    - \"More\" menu for rest\n    - Calculate based on viewport\n  </Accordion>\n</AccordionGroup>\n\n---",
            "hydration_source_header": "5.1 Mobile Navigation Patterns",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "depth-analysis-pattern",
            "title": "Navigation Depth Analysis Pattern",
            "implements": "depth-breadth-principle",
            "taskType": "analysis",
            "lines": "1700-1720",
            "content": "**Your Prompt:**\n\n```text\nYou're a UX designer analyzing navigation structure.\n\nEvaluate this navigation for depth vs. breadth balance:\n\n[Paste your navigation structure]\n\nAnalyze:\n1. Current depth (number of levels)\n2. Current breadth (items per level)\n3. Is it too shallow, too deep, or balanced?\n4. What percentage of content requires 1, 2, 3, or 4+ clicks?\n5. Recommendations for optimization\n\nContext:\n- Total pages: [number]\n- Primary user tasks: [list tasks]\n- Device usage: [desktop/mobile split]\n```\n\n<Info>\n**Validation Checklist:** After AI analyzes depth/breadth, verify recommendations:\n\n**Analysis Accuracy:**\n- \u2610 Depth count is correct (manually verify level count)\n- \u2610 Breadth metrics match your structure (count items per level)\n- \u2610 Click depth percentages add up to 100%\n\n**Recommendation Quality:**\n- \u2610 Specific items identified for restructuring (not vague \"flatten it\")\n- \u2610 Recommendations maintain logical groupings\n- \u2610 Mobile impact considered (deep nav worse on mobile)\n\n**Balance Standards:**\n- \u2610 Optimal: 5-7 top-level items, 2-3 levels max \u2705\n- \u2610 Acceptable: 4-9 top-level items, 3 levels max \u26a0\ufe0f\n- \u2610 Problematic: 10+ top-level items OR 4+ levels \u274c\n\n**User Task Check:**\n- \u2610 Primary tasks (80% of usage) reachable in \u22642 clicks\n- \u2610 Secondary tasks (15% of usage) reachable in \u22643 clicks\n- \u2610 No common tasks buried 4+ levels deep\n\nIf AI suggests flattening to 15+ top-level items, reject\u2014that's too broad.\n</Info>\n\n---",
            "hydration_source_header": "4.3 AI Prompt for Navigation Depth Analysis",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "promptPatterns": [
          {
            "id": "nav-generation-prompt",
            "title": "Navigation Generation Prompt",
            "taskType": "generation",
            "lines": "70-100",
            "standalone": true,
            "retrievalQuestions": [
              "Give me a prompt to generate documentation navigation"
            ],
            "content": "**Use When:** You need to create primary navigation from scratch\n\n**Prompt Structure:**\n\n```text\nYou're a UX designer specializing in navigation design and information architecture.\n\nGenerate navigation for [SITE/PRODUCT] with these characteristics:\n\nStructure:\n- [NUMBER] top-level items\n- [DEPTH] levels maximum\n- [BREADTH] items per level\n\nContent to include:\n- [List major content areas]\n\nAudience:\n- [User type and expertise level]\n\nConstraints:\n- [Technical limitations]\n- [Design requirements]\n- [Accessibility needs]\n\nOutput format:\n- [How you want the navigation presented]\n```\n\n<Info>\n**Validation Checklist:** After AI generates navigation, verify quality using these criteria:\n\n**Structure Quality:**\n- \u2610 5-7 top-level items (not too few, not too many)\n- \u2610 Consistent depth across sections (no 1-level next to 5-level)\n- \u2610 Each section has logical grouping (items relate to each other)\n\n**Label Quality:**\n- \u2610 All labels score 4-5/5 for information scent (can you predict destination?)\n- \u2610 Labels are specific (avoid \"Resources\", \"More\", \"Stuff\")\n- \u2610 Character counts meet constraints (check mobile display)\n\n**Completeness:**\n- \u2610 All content areas from your input are included\n- \u2610 No critical content hidden or missing\n- \u2610 Rationale provided for organizational decisions\n\n**Red Flags to Fix Immediately:**\n- \u274c Labels like \"Other\", \"Miscellaneous\", \"More\" (weak information scent)\n- \u274c Unbalanced depth (some sections 1 level, others 4+ levels)\n- \u274c More than 9 top-level items (cognitive overload)\n</Info>\n\n---",
            "hydration_source_header": "1.1 The Basic Navigation Generation Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "api-docs-nav-prompt",
            "title": "API Documentation Navigation Prompt",
            "taskType": "generation",
            "lines": "115-165",
            "standalone": true,
            "content": "**Your Prompt:**\n\n```text\nYou're a UX designer specializing in developer documentation navigation.\n\nGenerate primary navigation for a REST API documentation site.\n\nStructure:\n- 5-7 top-level items\n- Maximum 2 levels deep\n- 3-8 items per section\n\nContent to include:\n- Getting started content\n- API endpoint reference\n- Authentication documentation\n- SDKs and code libraries\n- Tutorials and guides\n- Best practices\n- Troubleshooting\n\nAudience:\n- Backend developers (40% junior, 60% senior)\n- Need to find information quickly\n- Mobile and desktop users\n\nConstraints:\n- Must work in collapsible mobile menu\n- All labels under 20 characters\n- SEO-friendly structure\n- Accessible (ARIA labels)\n\nOutput format:\n- Hierarchical list showing structure\n- Brief description of what each section contains\n- Rationale for organization\n```\n\n**AI Output Example:**\n\n```text\nPROPOSED NAVIGATION STRUCTURE\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nTOP-LEVEL NAVIGATION (7 items)\n\n1. GET STARTED\n   \u2514\u2500 Purpose: Entry point for new users\n   \u2514\u2500 Contains: Quickstart, authentication, first API call\n   \u2514\u2500 Why first: Natural starting point for all users\n   \n   Subsections:\n   - Quickstart (5-min tutorial)\n   - Authentication\n   - Make Your First Call\n   - API Keys & Security\n\n2. API REFERENCE\n   \u2514\u2500 Purpose: Technical specifications for all endpoints\n   \u2514\u2500 Contains: Complete endpoint documentation\n   \u2514\u2500 Why second: Most-used section for working developers\n   \n   Subsections (by resource):\n   - Users API\n   - Products API\n   - Orders API\n   - Webhooks API\n   - Rate Limits\n\n3. SDKs & TOOLS\n   \u2514\u2500 Purpose: Language-specific libraries and utilities\n   \u2514\u2500 Contains: SDK docs, CLI tools, testing tools\n   \u2514\u2500 Why third: Common next step after understanding API\n   \n   Subsections:\n   - JavaScript SDK\n   - Python SDK\n   - Ruby SDK\n   - CLI Tools\n   - Postman Collection\n\n4. GUIDES\n   \u2514\u2500 Purpose: Task-oriented how-to content\n   \u2514\u2500 Contains: Common integration patterns\n   \u2514\u2500 Why fourth: Practical applications once basics understood\n   \n   Subsections:\n   - Payment Integration\n   - Webhook Setup\n   - Error Handling\n   - Rate Limit Management\n   - Testing Strategies\n\n5. CODE EXAMPLES\n   \u2514\u2500 Purpose: Working code for common use cases\n   \u2514\u2500 Contains: Copy-paste ready examples\n   \u2514\u2500 Why fifth: Supports guides, frequently referenced\n   \n   Subsections:\n   - Authentication Examples\n   - CRUD Operations\n   - Advanced Queries\n   - Batch Operations\n   - Real-World Patterns\n\n6. FAQ\n   \u2514\u2500 Purpose: Quick answers to common questions\n   \u2514\u2500 Contains: Categorized Q&A\n   \u2514\u2500 Why sixth: Support resource, not primary path\n   \n   Subsections (auto-organized):\n   - Authentication FAQ\n   - Billing FAQ\n   - Troubleshooting FAQ\n   - Best Practices FAQ\n\n7. SUPPORT\n   \u2514\u2500 Purpose: Help resources and contact\n   \u2514\u2500 Contains: Status, contact, community links\n   \u2514\u2500 Why last: Safety net when other paths don't work\n   \n   Subsections:\n   - API Status\n   - Contact Support\n   - Community Forum\n   - Report Bug\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRATIONALE & DESIGN DECISIONS:\n\nSTRUCTURE:\n\u2713 7 top-level items (within 5-9 range, respects Miller's Law)\n\u2713 Max 2 levels (easy navigation, no deep drilling)\n\u2713 Logical flow: Learn \u2192 Reference \u2192 Build \u2192 Support\n\nLABELS:\n\u2713 All under 20 characters\n\u2713 Action-oriented where appropriate (Get Started, not \"Introduction\")\n\u2713 Clear differentiation (Guides vs. Code Examples)\n\u2713 No jargon or ambiguous terms\n\nMOBILE CONSIDERATIONS:\n\u2713 Subsections collapse cleanly\n\u2713 Top-level menu fits standard mobile viewport\n\u2713 Touch-friendly spacing assumed\n\u2713 Can implement hamburger menu with full structure\n\nSEO OPTIMIZATION:\n\u2713 Keyword-rich labels (API Reference, SDKs, Guides)\n\u2713 Hierarchical structure matches sitemap\n\u2713 Breadcrumb trail possible\n\u2713 Schema.org markup supported\n\nACCESSIBILITY:\n\u2713 Clear ARIA labels possible (\"Main navigation, 7 items\")\n\u2713 Logical tab order (1-7 top-level, then subsections)\n\u2713 Screen reader friendly (descriptive labels)\n\u2713 Keyboard navigation: Enter expands, Escape collapses\n\nSCALABILITY:\n\u2713 New subsections easily added (e.g., new SDK language)\n\u2713 Structure accommodates growth\n\u2713 Top-level remains stable (users learn it)\n\nALTERNATIVE ORGANIZATIONS CONSIDERED:\n\nBy User Journey:\n\u251c\u2500\u2500 Getting Started\n\u251c\u2500\u2500 Building\n\u251c\u2500\u2500 Deploying\n\u2514\u2500\u2500 Optimizing\n\u274c Rejected: Too abstract, doesn't match how developers think\n\nBy Content Type Only:\n\u251c\u2500\u2500 Tutorials\n\u251c\u2500\u2500 References\n\u251c\u2500\u2500 Guides\n\u2514\u2500\u2500 Examples\n\u274c Rejected: Artificial separation, users want features not formats\n\nFlat (All Top-Level):\n\u251c\u2500\u2500 Quickstart\n\u251c\u2500\u2500 Authentication\n\u251c\u2500\u2500 Users API\n\u251c\u2500\u2500 Products API\n[...20 items...]\n\u274c Rejected: Too many items, cognitive overload\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nIMPLEMENTATION NOTES:\n\nMARKUP STRUCTURE:\n<nav aria-label=\"Primary navigation\">\n  <ul>\n    <li><a href=\"/get-started\">Get Started</a>\n      <ul aria-label=\"Get Started submenu\">\n        <li><a href=\"/get-started/quickstart\">Quickstart</a></li>\n        ...\n      </ul>\n    </li>\n    ...\n  </ul>\n</nav>\n\nURL STRUCTURE:\n/get-started/\n/get-started/quickstart/\n/get-started/authentication/\n/api-reference/\n/api-reference/users/\n/sdks/javascript/\n...\n\nBREADCRUMBS:\nHome > Get Started > Quickstart\n\nANALYTICS TRACKING:\n- Track clicks on each nav item\n- Measure time to find information\n- Identify unused sections\n- A/B test label variations\n\nThis navigation structure balances findability, scalability, and usability \nwhile maintaining strong information scent throughout.\n```\n\n<Tip>\n  **Navigation Design Tip:** Always start with 5-7 top-level items. This range respects Miller's Law (humans can hold 5-9 items in working memory) and provides enough structure without overwhelming users.\n</Tip>\n\n---",
            "hydration_source_header": "1.2 Example: API Documentation Navigation",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "label-variation-prompt",
            "title": "Label Variation Generation Prompt",
            "taskType": "generation",
            "lines": "350-400",
            "standalone": true,
            "retrievalQuestions": [
              "What prompt creates label alternatives?"
            ],
            "content": "After AI generates navigation, use these validation prompts to systematically assess quality before implementation.\n\n### The Validation Prompt Pattern\n\n**Use When:** You need to objectively evaluate AI-generated navigation before committing to it.\n\n**Prompt Structure:**\n\n```text\nYou're a UX auditor evaluating navigation design quality.\n\nReview this AI-generated navigation for quality issues:\n\n[PASTE AI-GENERATED NAVIGATION]\n\nAudit against these criteria:\n\n1. STRUCTURE QUALITY\n   - Count top-level items (optimal: 5-7)\n   - Measure depth consistency\n   - Identify any unbalanced sections\n\n2. LABEL QUALITY\n   - Rate information scent for each label (1-5)\n   - Flag vague terms (Resources, More, Other)\n   - Check character counts vs. mobile constraints\n\n3. COMPLETENESS\n   - Verify all required content areas included\n   - Identify any missing critical paths\n   - Check for logical gaps\n\n4. USABILITY RED FLAGS\n   - Overlapping categories\n   - Ambiguous labels\n   - Excessive depth (>3 levels)\n   - Poor mobile scalability\n\nFor each issue found, provide:\n- Severity (Critical/High/Medium/Low)\n- Specific problem\n- Concrete fix\n\nEnd with: Pass/Fail recommendation with justification.\n```\n\n---\n\n### Example: Validating API Documentation Navigation\n\n**Your Validation Prompt:**\n\n```text\nYou're a UX auditor evaluating navigation design quality.\n\nReview this AI-generated navigation for an API documentation site:\n\n```\nDocumentation\n\u251c\u2500\u2500 Overview\n\u251c\u2500\u2500 Getting Started\n\u2502   \u251c\u2500\u2500 Installation\n\u2502   \u251c\u2500\u2500 Configuration\n\u2502   \u2514\u2500\u2500 First Steps\n\u251c\u2500\u2500 API Reference\n\u2502   \u251c\u2500\u2500 Authentication\n\u2502   \u251c\u2500\u2500 Endpoints\n\u2502   \u2502   \u251c\u2500\u2500 Users\n\u2502   \u2502   \u251c\u2500\u2500 Products\n\u2502   \u2502   \u251c\u2500\u2500 Orders\n\u2502   \u2502   \u2514\u2500\u2500 Webhooks\n\u2502   \u251c\u2500\u2500 Rate Limits\n\u2502   \u2514\u2500\u2500 Error Codes\n\u251c\u2500\u2500 Guides\n\u2502   \u251c\u2500\u2500 Integration Guides\n\u2502   \u251c\u2500\u2500 Best Practices\n\u2502   \u2514\u2500\u2500 Tutorials\n\u251c\u2500\u2500 SDKs\n\u2502   \u251c\u2500\u2500 JavaScript\n\u2502   \u251c\u2500\u2500 Python\n\u2502   \u2514\u2500\u2500 Ruby\n\u251c\u2500\u2500 Resources\n\u2502   \u251c\u2500\u2500 FAQ\n\u2502   \u251c\u2500\u2500 Glossary\n\u2502   \u2514\u2500\u2500 Changelog\n\u2514\u2500\u2500 Support\n    \u251c\u2500\u2500 Contact\n    \u251c\u2500\u2500 Community\n    \u2514\u2500\u2500 Status\n```\n\nAudit against these criteria:\n\n1. STRUCTURE QUALITY - Count top-level items, measure depth, identify imbalances\n2. LABEL QUALITY - Rate information scent, flag vague terms, check lengths\n3. COMPLETENESS - Verify coverage, identify gaps\n4. USABILITY RED FLAGS - Overlapping categories, ambiguous labels, excessive depth\n\nFor each issue: Severity, problem, fix.\nEnd with Pass/Fail recommendation.\n```\n\n**AI Validation Output Example:**\n\n```text\nNAVIGATION QUALITY AUDIT\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nOVERALL ASSESSMENT: FAIL (Requires revisions before implementation)\n\nTotal Issues Found: 5\n- Critical: 1\n- High: 2\n- Medium: 2\n- Low: 0\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n1. STRUCTURE QUALITY AUDIT\n\nTop-Level Item Count: 8 items\nAssessment: \u26a0\ufe0f ABOVE OPTIMAL (Target: 5-7 items)\n\nItems:\n1. Overview\n2. Getting Started\n3. API Reference\n4. Guides\n5. SDKs\n6. Resources \u2190 WEAK LABEL\n7. Support\n8. Documentation (wait, this IS documentation)\n\n**CRITICAL ISSUE #1: Redundant \"Documentation\" parent**\nSeverity: CRITICAL\nProblem: Navigation shows \"Documentation\" as root, but this IS the docs site. Redundant and confusing.\nFix: Remove \"Documentation\" parent. Make the 7 sections top-level.\n\nDepth Analysis:\n- Level 1: 8 items (target: 5-7) \u274c\n- Level 2: Varies (Getting Started: 3, API Reference: 4, etc.)\n- Level 3: Endpoints subsection goes to level 4 \u26a0\ufe0f\n- Maximum depth: 4 levels (Overview \u2192 Endpoints \u2192 Users \u2192 [details])\n\n**HIGH ISSUE #2: Excessive depth in API Reference**\nSeverity: HIGH\nProblem: API Reference \u2192 Endpoints \u2192 Users is 3 levels, likely goes to 4+ for individual endpoints. Too many clicks.\nFix: Flatten to API Reference \u2192 Users API, Products API, Orders API (eliminate \"Endpoints\" grouping)\n\nDepth Distribution:\n- 1 click: ~10% of content (top-level pages)\n- 2 clicks: ~40% of content\n- 3 clicks: ~35% of content\n- 4+ clicks: ~15% of content \u274c (Target: <5%)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n2. LABEL QUALITY AUDIT\n\nInformation Scent Ratings:\n\n| Label | Scent (1-5) | Assessment |\n|-------|-------------|------------|\n| Overview | 3/5 | Vague - overview of what? |\n| Getting Started | 5/5 | \u2705 Excellent |\n| API Reference | 5/5 | \u2705 Excellent |\n| Guides | 4/5 | \u2705 Good |\n| SDKs | 5/5 | \u2705 Excellent |\n| Resources | 1/5 | \u274c WEAK - meaningless catch-all |\n| Support | 5/5 | \u2705 Excellent |\n\n**HIGH ISSUE #3: \"Resources\" is a junk drawer**\nSeverity: HIGH\nProblem: \"Resources\" has 1/5 information scent. Could mean anything. Currently contains FAQ, Glossary, Changelog\u2014unrelated items.\nFix:\n- Move FAQ \u2192 Troubleshooting or Support\n- Move Glossary \u2192 As needed inline, or Getting Started\n- Keep Changelog separate as top-level (developers expect this)\n\n**MEDIUM ISSUE #4: \"Overview\" too vague**\nSeverity: MEDIUM\nProblem: Users won't know if this is product marketing, architecture overview, or getting started content.\nFix: Rename based on actual content:\n- If product intro \u2192 \"What is [Product]?\"\n- If architecture \u2192 Merge with \"Getting Started \u2192 Core Concepts\"\n- If both \u2192 Split appropriately\n\nCharacter Length Check:\nAll labels under 20 characters \u2705\nLongest: \"Getting Started\" (15 chars)\nMobile-friendly \u2705\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n3. COMPLETENESS AUDIT\n\nRequired Content Areas:\n\u2705 Getting started content (present)\n\u2705 API technical reference (present)\n\u2705 SDKs and tools (present)\n\u2705 Tutorials/guides (present)\n\u2705 Support resources (present)\n\u26a0\ufe0f Troubleshooting (partially present in Support)\n\n**MEDIUM ISSUE #5: No dedicated Troubleshooting section**\nSeverity: MEDIUM\nProblem: Common errors, debugging guides scattered. Support contains contact info but not self-serve troubleshooting.\nFix: Add \"Troubleshooting\" as dedicated section OR expand \"Support\" to \"Troubleshooting & Support\"\n\nMissing Critical Paths:\n- Clear path to troubleshoot auth errors (should be 2 clicks max)\n- Migration guides (if applicable)\n- Security best practices\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n4. USABILITY RED FLAGS\n\n\ud83d\udea9 RED FLAG #1: Overlapping Categories\n- \"Guides\" contains both Integration Guides AND Tutorials\n- \"Getting Started\" likely overlaps with basic Tutorials\n- Unclear whether beginner should start in \"Overview\", \"Getting Started\", or \"Guides \u2192 Tutorials\"\n\nRecommendation: Clarify distinction or merge\n\n\ud83d\udea9 RED FLAG #2: \"Resources\" Catch-All\nAlready flagged above as HIGH issue\n\n\ud83d\udea9 RED FLAG #3: Mobile Experience\nWith 8 top-level items + deep nesting:\n- Hamburger menu will be long\n- Hard to scan quickly\n- 4+ clicks on mobile is frustrating\n\nRecommendation: Reduce to 6 top-level items max\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nSEVERITY SUMMARY:\n\nCRITICAL (Must Fix):\n1. Remove redundant \"Documentation\" parent wrapper\n\nHIGH (Should Fix):\n2. Flatten API Reference depth (remove \"Endpoints\" grouping)\n3. Replace \"Resources\" with specific labels\n\nMEDIUM (Good to Fix):\n4. Clarify \"Overview\" label\n5. Add dedicated Troubleshooting section\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nREVISED STRUCTURE (After Fixes):\n\n```\n1. Get Started\n   \u251c\u2500\u2500 Quickstart\n   \u251c\u2500\u2500 Core Concepts\n   \u2514\u2500\u2500 Authentication Guide\n\n2. API Reference\n   \u251c\u2500\u2500 Users API\n   \u251c\u2500\u2500 Products API\n   \u251c\u2500\u2500 Orders API\n   \u251c\u2500\u2500 Webhooks API\n   \u251c\u2500\u2500 Rate Limits\n   \u2514\u2500\u2500 Error Codes\n\n3. Guides & Tutorials\n   \u251c\u2500\u2500 Integration Guides\n   \u251c\u2500\u2500 Best Practices\n   \u2514\u2500\u2500 Step-by-Step Tutorials\n\n4. SDKs & Tools\n   \u251c\u2500\u2500 JavaScript SDK\n   \u251c\u2500\u2500 Python SDK\n   \u251c\u2500\u2500 Ruby SDK\n   \u2514\u2500\u2500 CLI Tool\n\n5. Troubleshooting\n   \u251c\u2500\u2500 Common Errors\n   \u251c\u2500\u2500 Debugging Guide\n   \u251c\u2500\u2500 FAQ\n   \u2514\u2500\u2500 API Status\n\n6. Support\n   \u251c\u2500\u2500 Contact Us\n   \u251c\u2500\u2500 Community Forum\n   \u2514\u2500\u2500 Changelog\n\n```\n\nIMPROVEMENTS:\n\u2705 6 top-level items (was 8)\n\u2705 All labels score 4-5/5 for information scent\n\u2705 Maximum 2 levels depth (was 4)\n\u2705 No \"Resources\" catch-all\n\u2705 Clear troubleshooting path\n\u2705 Eliminated redundancy\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nFINAL RECOMMENDATION: PASS (After applying above revisions)\n\nThe original navigation had good bones but needed structural fixes:\n- Too many top-level items\n- Vague labels (\"Resources\")\n- Excessive depth\n- Missing troubleshooting\n\nThe revised structure addresses all critical and high issues.\n\nNEXT STEPS:\n1. Implement revised structure\n2. Test with tree testing (5 user tasks)\n3. Validate information scent with 5-second tests\n4. A/B test label variations if needed\n```\n\n<Tip>\n**Validation Pro Tip:** Always run AI-generated navigation through a validation prompt before implementation. It catches structural issues, vague labels, and usability problems you might miss when reviewing manually.\n</Tip>\n\n---",
            "hydration_source_header": "2.4 Validating AI-Generated Navigation with Prompts",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "api-label-variation-prompt",
            "title": "API Reference Label Variation Prompt",
            "taskType": "generation",
            "lines": "405-445",
            "standalone": true,
            "content": "**Use When:** You need multiple label options to test\n\n**Prompt Structure:**\n\n```text\nYou're a UX writer specializing in navigation labels.\n\nGenerate [NUMBER] label variations for [SECTION/CONTENT].\n\nContent this section contains:\n- [List items]\n\nLabel requirements:\n- Maximum [NUMBER] characters\n- [Style guidelines]\n- Must be [characteristics]\n\nFor each variation provide:\n1. Label text\n2. Character count\n3. Pros and cons\n4. Information scent rating (1-5)\n5. Target audience fit\n```\n\n<Info>\n**Validation Checklist:** After AI generates label variations, assess quality:\n\n**Variety Check:**\n- \u2610 Labels show real diversity (not just \"API Docs\", \"API Documentation\", \"API Reference\" - too similar)\n- \u2610 Different approaches represented (action-oriented, noun-based, user-focused)\n- \u2610 At least 3 labels score 4-5/5 for information scent\n\n**Accuracy Check:**\n- \u2610 Character counts are correct (recount if needed)\n- \u2610 Information scent ratings are justified (5/5 should be crystal clear)\n- \u2610 Pros/cons are specific, not generic\n\n**Practical Usefulness:**\n- \u2610 Labels are actually testable (avoid overly similar options)\n- \u2610 Trade-offs are clear (helps decision-making)\n- \u2610 Target audience fits are realistic\n\n**Quick Test:** Show top 3 labels (without context) to a colleague. Can they predict the destination? If not, those labels score too high for information scent.\n</Info>\n\n---",
            "hydration_source_header": "1.3 The Label Variation Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "info-scent-eval-prompt",
            "title": "Information Scent Evaluation Prompt",
            "taskType": "analysis",
            "lines": "680-720",
            "standalone": true,
            "retrievalQuestions": [
              "How do I prompt AI to evaluate navigation clarity?"
            ],
            "content": "Information scent is how well navigation labels predict their destination. Strong scent means users confidently know where to click.\n\n### 2.1 Understanding Information Scent\n\n**Definition:** The extent to which users can predict what they'll find if they follow a path (label/link).\n\n**Rating Scale (1-5):**\n- **5/5** = Immediately clear, crystal clear destination\n- **4/5** = Very clear, highly predictable\n- **3/5** = Somewhat clear, requires interpretation\n- **2/5** = Unclear, multiple interpretations\n- **1/5** = Very confusing, no clear prediction\n\n**Target:** Aim for 4-5/5 on all navigation labels.\n\n**Strong Scent Example:**\n- Label: \"Getting Started Guide\"\n- User thinks: \"This will show me how to begin\"\n- Destination: Step-by-step tutorial for beginners\n- Result: \u2705 Expectation met\n\n**Weak Scent Example:**\n- Label: \"Resources\"\n- User thinks: \"What kind of resources? Documents? Tools? Community?\"\n- Destination: Mixed bag of downloads, links, and articles\n- Result: \u274c Unclear, requires guessing\n\n<CardGroup cols={2}>\n  <Card title=\"Strong Information Scent\" icon=\"check\">\n    - Specific, descriptive labels\n    - Predictable destinations\n    - Matches user mental models\n    - Reduces clicks to find content\n    - Increases task success\n  </Card>\n  \n  <Card title=\"Weak Information Scent\" icon=\"xmark\">\n    - Vague, generic labels\n    - Unpredictable content\n    - Requires trial and error\n    - Increases time on task\n    - Reduces user confidence\n  </Card>\n</CardGroup>\n\n---\n\n### 2.2 Information Scent Evaluation Pattern\n\n**Prompt Structure:**\n\n```text\nYou're a UX researcher evaluating information scent in navigation.\n\nEvaluate these navigation labels for information scent:\n\nLabels:\n[List of navigation labels with brief context]\n\nFor each label, evaluate:\n1. Clarity (1-5): How clear is the label?\n2. Predictability (1-5): Can users predict the destination?\n3. Specificity (1-5): How specific vs. vague?\n4. Alternatives: What would improve scent?\n5. Issues: What might confuse users?\n```\n\n<Info>\n**Validation Checklist:** After AI evaluates information scent, verify the analysis:\n\n**Rating Accuracy:**\n- \u2610 5/5 ratings are justified (truly crystal clear, universally understood)\n- \u2610 1-2/5 ratings have specific confusion points identified\n- \u2610 Ratings are consistent (similar labels get similar scores)\n\n**Recommendations Quality:**\n- \u2610 Alternatives provided for weak labels (less than 3/5)\n- \u2610 Improvements are specific (not just \"make it clearer\")\n- \u2610 Strong labels (4-5/5) properly identified as keepers\n\n**Reality Check:**\n- \u2610 \"Confusion points\" are realistic (not contrived)\n- \u2610 Alternatives actually improve information scent\n- \u2610 Analysis considers your specific audience\n\n**Validation Test:** Pick 2-3 labels AI rated highly (4-5/5). Show them to colleagues without context. If they can't predict destination, the AI ratings are inflated\u2014revise criteria and re-evaluate.\n</Info>\n\n---\n\n### 2.3 Example: Evaluating Documentation Navigation\n\n**Your Prompt:**\n\n```text\nYou're a UX researcher evaluating information scent for developer documentation navigation.\n\nEvaluate these navigation labels:\n\nContext: REST API documentation site\nAudience: Backend developers (40% junior, 60% senior)\n\nNavigation labels to evaluate:\n1. \"Resources\"\n2. \"Get Started\"\n3. \"Docs\"\n4. \"API Reference\"\n5. \"Learn More\"\n6. \"Guides & Tutorials\"\n7. \"Developer Tools\"\n8. \"FAQ\"\n9. \"Advanced\"\n10. \"Support\"\n\nFor each label:\n1. Information scent rating (1-5, where 5 = crystal clear)\n2. What users will expect to find\n3. Potential confusion points\n4. Recommendations for improvement\n5. Alternative labels if needed\n```\n\n**AI Output Example:**\n\n```text\nINFORMATION SCENT EVALUATION\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nLABEL 1: \"Resources\"\nInformation Scent: 1/5 \u274c WEAK\n\nUser Expectations:\n- Could be anything: downloads, tools, links, documents\n- No clear indication of content type\n- Generic catch-all term\n\nConfusion Points:\n- Too broad - \"resources\" could mean 20 different things\n- Users must click to discover actual content\n- Creates cognitive load (guess and check)\n- Often becomes dumping ground for misc content\n\nRecommendations:\n- AVOID: This is one of the weakest navigation labels\n- Be specific about what \"resources\" contains\n- Break into specific categories\n\nAlternative Labels:\n- If contains downloads: \"Downloads\" or \"SDKs & Tools\"\n- If contains links: \"External Links\" or \"Community\"\n- If contains docs: Use specific doc type \"Guides\" or \"References\"\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 2: \"Get Started\"\nInformation Scent: 5/5 \u2705 STRONG\n\nUser Expectations:\n- Beginner-friendly content\n- Step-by-step instructions\n- Quick path to first success\n- Installation and setup\n\nConfusion Points:\n- None - universally understood\n- Clear action-oriented label\n- Signals starting point\n\nRecommendations:\n- KEEP: Excellent information scent\n- Consider adding time estimate: \"Get Started (5 min)\"\n- Could be even clearer: \"Quick Start Guide\"\n\nAlternative Labels:\n- \"Quickstart\" (more concise)\n- \"Getting Started Guide\" (more formal)\n- \"Start Here\" (more direct)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 3: \"Docs\"\nInformation Scent: 2/5 \u26a0\ufe0f WEAK-TO-MODERATE\n\nUser Expectations:\n- Some kind of documentation (but what kind?)\n- Could be tutorials, references, guides, or all of above\n- Abbreviation feels casual\n\nConfusion Points:\n- Too generic - \"docs\" is entire documentation site\n- Doesn't differentiate types of documentation\n- Seems redundant if already on docs site\n- Abbreviation might not fit formal brands\n\nRecommendations:\n- REPLACE: Too vague for navigation\n- Be specific about doc type\n- Use if this is generic entry to all docs from another site\n\nAlternative Labels:\n- \"Documentation\" (more formal, but still vague)\n- \"API Reference\" (if that's what it is)\n- \"Guides\" (if mostly how-tos)\n- \"Technical Docs\" (slightly more specific)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 4: \"API Reference\"\nInformation Scent: 5/5 \u2705 STRONG\n\nUser Expectations:\n- Technical specifications\n- Endpoint documentation\n- Parameter details\n- Request/response examples\n\nConfusion Points:\n- None for developers\n- Industry standard term\n- Clear and specific\n\nRecommendations:\n- KEEP: Excellent clarity\n- Perfect for developer audience\n- Immediately recognizable\n\nAlternative Labels:\n- \"API Documentation\" (slightly more formal)\n- \"Endpoint Reference\" (more specific)\n- \"API Specs\" (more casual)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 5: \"Learn More\"\nInformation Scent: 1/5 \u274c VERY WEAK\n\nUser Expectations:\n- Vague call-to-action\n- Could be anything\n- Sounds like marketing copy, not navigation\n\nConfusion Points:\n- \"Learn more\" about what?\n- Too generic to be useful\n- Feels like a button, not a navigation item\n- Could lead anywhere\n\nRecommendations:\n- AVOID: Nearly meaningless as navigation\n- Never use without clear object (\"Learn more about X\")\n- Acceptable as CTA button, not navigation label\n\nAlternative Labels:\n- If tutorials: \"Tutorials\" or \"Learning Path\"\n- If concepts: \"Concepts\" or \"Understanding [Product]\"\n- If courses: \"Training\" or \"Courses\"\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 6: \"Guides & Tutorials\"\nInformation Scent: 4/5 \u2705 GOOD\n\nUser Expectations:\n- How-to content\n- Step-by-step instructions\n- Educational material\n- Practical application\n\nConfusion Points:\n- Minor: Difference between \"guide\" and \"tutorial\" unclear\n- Both are instructional content\n- Some might wonder which to choose\n\nRecommendations:\n- GOOD: Clear information scent\n- Consider separating if truly different:\n  * \"Guides\" = task-oriented\n  * \"Tutorials\" = learning-oriented\n- Or combine as \"Guides & Tutorials\" (current)\n\nAlternative Labels:\n- \"Guides\" (simpler)\n- \"Tutorials\" (if all are learning-oriented)\n- \"How-To Guides\" (more specific)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 7: \"Developer Tools\"\nInformation Scent: 4/5 \u2705 GOOD\n\nUser Expectations:\n- SDKs and libraries\n- CLI tools\n- Testing utilities\n- Development aids\n\nConfusion Points:\n- Could include IDE plugins, browser extensions\n- Might be downloadable tools OR documentation about tools\n- Breadth of \"tools\" could vary\n\nRecommendations:\n- GOOD: Generally clear\n- Consider being more specific if needed\n- Add description in submenu if ambiguous\n\nAlternative Labels:\n- \"SDKs & Tools\" (more specific)\n- \"Libraries & SDKs\" (if that's the focus)\n- \"Development Tools\" (more formal)\n- \"Tooling\" (more casual)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 8: \"FAQ\"\nInformation Scent: 5/5 \u2705 STRONG\n\nUser Expectations:\n- Common questions and answers\n- Quick information lookup\n- Organized by topic\n- Concise answers\n\nConfusion Points:\n- None - universally understood\n- Standard abbreviation\n- Clear purpose\n\nRecommendations:\n- KEEP: Excellent clarity\n- Standard location expectations (often in support/help)\n- Consider icon (question mark)\n\nAlternative Labels:\n- \"Frequently Asked Questions\" (more formal, longer)\n- \"Common Questions\" (more natural)\n- \"Q&A\" (more casual)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 9: \"Advanced\"\nInformation Scent: 2/5 \u26a0\ufe0f WEAK\n\nUser Expectations:\n- Complex features?\n- Expert-level content?\n- Less common use cases?\n- Unclear without context\n\nConfusion Points:\n- Subjective term (advanced to whom?)\n- Doesn't indicate content type\n- Users must guess what's inside\n- Creates artificial barrier (beginners might skip)\n- What makes something \"advanced\"?\n\nRecommendations:\n- AVOID: Vague and subjective\n- Describe what makes it advanced\n- Or organize by feature, not skill level\n\nAlternative Labels:\n- If complex features: Name the feature (\"GraphQL API\")\n- If optimization: \"Performance & Optimization\"\n- If enterprise: \"Enterprise Features\"\n- If deep concepts: \"Advanced Concepts\" (slightly better)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nLABEL 10: \"Support\"\nInformation Scent: 5/5 \u2705 STRONG\n\nUser Expectations:\n- Help resources\n- Contact information\n- Troubleshooting\n- Community forums\n- Status page\n\nConfusion Points:\n- None - universal understanding\n- Clear purpose\n- Expected location for help\n\nRecommendations:\n- KEEP: Excellent clarity\n- Standard placement (often far right)\n- Consider icon (question mark or lifebuoy)\n\nAlternative Labels:\n- \"Help & Support\" (more explicit)\n- \"Help\" (more concise)\n- \"Get Help\" (more action-oriented)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nOVERALL ANALYSIS:\n\nSTRONG INFORMATION SCENT (Keep):\n\u2705 \"Get Started\" - 5/5\n\u2705 \"API Reference\" - 5/5\n\u2705 \"FAQ\" - 5/5\n\u2705 \"Support\" - 5/5\n\nGOOD INFORMATION SCENT (Minor improvements):\n\u2713 \"Guides & Tutorials\" - 4/5\n\u2713 \"Developer Tools\" - 4/5\n\nWEAK INFORMATION SCENT (Revise):\n\u26a0\ufe0f \"Docs\" - 2/5 (too generic)\n\u26a0\ufe0f \"Advanced\" - 2/5 (subjective, vague)\n\nVERY WEAK INFORMATION SCENT (Replace):\n\u274c \"Resources\" - 1/5 (meaningless)\n\u274c \"Learn More\" - 1/5 (vague CTA)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nREVISED NAVIGATION (After improvements):\n\nBEFORE:\n1. Resources\n2. Get Started\n3. Docs\n4. API Reference\n5. Learn More\n6. Guides & Tutorials\n7. Developer Tools\n8. FAQ\n9. Advanced\n10. Support\n\nAFTER:\n1. Get Started \u2190 Keep\n2. API Reference \u2190 Keep\n3. SDKs & Tools \u2190 Improved from \"Developer Tools\"\n4. Guides & Tutorials \u2190 Keep\n5. Code Examples \u2190 Improved from \"Learn More\"\n6. Community & Support \u2190 Improved from \"Support\" (more specific)\n7. FAQ \u2190 Keep\n\nREMOVED:\n- \"Resources\" \u2192 Content distributed to specific sections\n- \"Docs\" \u2192 Redundant (entire site is docs)\n- \"Advanced\" \u2192 Features organized by name, not skill level\n\nRESULT:\n- 7 clear navigation items (down from 10)\n- All items score 4-5/5 for information scent\n- No vague or ambiguous labels\n- Each label clearly indicates destination\n- Better scannability and decision-making\n```\n\n<Info>\n  **Information Scent Tip:** Aim for 4-5/5 rating on all navigation labels. Anything below 3/5 should be revised. Test labels with 5-second tests: Can users predict where they'll go in 5 seconds?\n</Info>\n\n---",
            "hydration_source_header": "2. Information Scent Evaluation",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "docs-nav-scent-prompt",
            "title": "Documentation Navigation Scent Prompt",
            "taskType": "analysis",
            "lines": "730-770",
            "standalone": true,
            "content": "**Your Prompt:**\n\n```text\nYou're a UX designer specializing in developer documentation navigation.\n\nGenerate primary navigation for a REST API documentation site.\n\nStructure:\n- 5-7 top-level items\n- Maximum 2 levels deep\n- 3-8 items per section\n\nContent to include:\n- Getting started content\n- API endpoint reference\n- Authentication documentation\n- SDKs and code libraries\n- Tutorials and guides\n- Best practices\n- Troubleshooting\n\nAudience:\n- Backend developers (40% junior, 60% senior)\n- Need to find information quickly\n- Mobile and desktop users\n\nConstraints:\n- Must work in collapsible mobile menu\n- All labels under 20 characters\n- SEO-friendly structure\n- Accessible (ARIA labels)\n\nOutput format:\n- Hierarchical list showing structure\n- Brief description of what each section contains\n- Rationale for organization\n```\n\n**AI Output Example:**\n\n```text\nPROPOSED NAVIGATION STRUCTURE\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nTOP-LEVEL NAVIGATION (7 items)\n\n1. GET STARTED\n   \u2514\u2500 Purpose: Entry point for new users\n   \u2514\u2500 Contains: Quickstart, authentication, first API call\n   \u2514\u2500 Why first: Natural starting point for all users\n   \n   Subsections:\n   - Quickstart (5-min tutorial)\n   - Authentication\n   - Make Your First Call\n   - API Keys & Security\n\n2. API REFERENCE\n   \u2514\u2500 Purpose: Technical specifications for all endpoints\n   \u2514\u2500 Contains: Complete endpoint documentation\n   \u2514\u2500 Why second: Most-used section for working developers\n   \n   Subsections (by resource):\n   - Users API\n   - Products API\n   - Orders API\n   - Webhooks API\n   - Rate Limits\n\n3. SDKs & TOOLS\n   \u2514\u2500 Purpose: Language-specific libraries and utilities\n   \u2514\u2500 Contains: SDK docs, CLI tools, testing tools\n   \u2514\u2500 Why third: Common next step after understanding API\n   \n   Subsections:\n   - JavaScript SDK\n   - Python SDK\n   - Ruby SDK\n   - CLI Tools\n   - Postman Collection\n\n4. GUIDES\n   \u2514\u2500 Purpose: Task-oriented how-to content\n   \u2514\u2500 Contains: Common integration patterns\n   \u2514\u2500 Why fourth: Practical applications once basics understood\n   \n   Subsections:\n   - Payment Integration\n   - Webhook Setup\n   - Error Handling\n   - Rate Limit Management\n   - Testing Strategies\n\n5. CODE EXAMPLES\n   \u2514\u2500 Purpose: Working code for common use cases\n   \u2514\u2500 Contains: Copy-paste ready examples\n   \u2514\u2500 Why fifth: Supports guides, frequently referenced\n   \n   Subsections:\n   - Authentication Examples\n   - CRUD Operations\n   - Advanced Queries\n   - Batch Operations\n   - Real-World Patterns\n\n6. FAQ\n   \u2514\u2500 Purpose: Quick answers to common questions\n   \u2514\u2500 Contains: Categorized Q&A\n   \u2514\u2500 Why sixth: Support resource, not primary path\n   \n   Subsections (auto-organized):\n   - Authentication FAQ\n   - Billing FAQ\n   - Troubleshooting FAQ\n   - Best Practices FAQ\n\n7. SUPPORT\n   \u2514\u2500 Purpose: Help resources and contact\n   \u2514\u2500 Contains: Status, contact, community links\n   \u2514\u2500 Why last: Safety net when other paths don't work\n   \n   Subsections:\n   - API Status\n   - Contact Support\n   - Community Forum\n   - Report Bug\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRATIONALE & DESIGN DECISIONS:\n\nSTRUCTURE:\n\u2713 7 top-level items (within 5-9 range, respects Miller's Law)\n\u2713 Max 2 levels (easy navigation, no deep drilling)\n\u2713 Logical flow: Learn \u2192 Reference \u2192 Build \u2192 Support\n\nLABELS:\n\u2713 All under 20 characters\n\u2713 Action-oriented where appropriate (Get Started, not \"Introduction\")\n\u2713 Clear differentiation (Guides vs. Code Examples)\n\u2713 No jargon or ambiguous terms\n\nMOBILE CONSIDERATIONS:\n\u2713 Subsections collapse cleanly\n\u2713 Top-level menu fits standard mobile viewport\n\u2713 Touch-friendly spacing assumed\n\u2713 Can implement hamburger menu with full structure\n\nSEO OPTIMIZATION:\n\u2713 Keyword-rich labels (API Reference, SDKs, Guides)\n\u2713 Hierarchical structure matches sitemap\n\u2713 Breadcrumb trail possible\n\u2713 Schema.org markup supported\n\nACCESSIBILITY:\n\u2713 Clear ARIA labels possible (\"Main navigation, 7 items\")\n\u2713 Logical tab order (1-7 top-level, then subsections)\n\u2713 Screen reader friendly (descriptive labels)\n\u2713 Keyboard navigation: Enter expands, Escape collapses\n\nSCALABILITY:\n\u2713 New subsections easily added (e.g., new SDK language)\n\u2713 Structure accommodates growth\n\u2713 Top-level remains stable (users learn it)\n\nALTERNATIVE ORGANIZATIONS CONSIDERED:\n\nBy User Journey:\n\u251c\u2500\u2500 Getting Started\n\u251c\u2500\u2500 Building\n\u251c\u2500\u2500 Deploying\n\u2514\u2500\u2500 Optimizing\n\u274c Rejected: Too abstract, doesn't match how developers think\n\nBy Content Type Only:\n\u251c\u2500\u2500 Tutorials\n\u251c\u2500\u2500 References\n\u251c\u2500\u2500 Guides\n\u2514\u2500\u2500 Examples\n\u274c Rejected: Artificial separation, users want features not formats\n\nFlat (All Top-Level):\n\u251c\u2500\u2500 Quickstart\n\u251c\u2500\u2500 Authentication\n\u251c\u2500\u2500 Users API\n\u251c\u2500\u2500 Products API\n[...20 items...]\n\u274c Rejected: Too many items, cognitive overload\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nIMPLEMENTATION NOTES:\n\nMARKUP STRUCTURE:\n<nav aria-label=\"Primary navigation\">\n  <ul>\n    <li><a href=\"/get-started\">Get Started</a>\n      <ul aria-label=\"Get Started submenu\">\n        <li><a href=\"/get-started/quickstart\">Quickstart</a></li>\n        ...\n      </ul>\n    </li>\n    ...\n  </ul>\n</nav>\n\nURL STRUCTURE:\n/get-started/\n/get-started/quickstart/\n/get-started/authentication/\n/api-reference/\n/api-reference/users/\n/sdks/javascript/\n...\n\nBREADCRUMBS:\nHome > Get Started > Quickstart\n\nANALYTICS TRACKING:\n- Track clicks on each nav item\n- Measure time to find information\n- Identify unused sections\n- A/B test label variations\n\nThis navigation structure balances findability, scalability, and usability \nwhile maintaining strong information scent throughout.\n```\n\n<Tip>\n  **Navigation Design Tip:** Always start with 5-7 top-level items. This range respects Miller's Law (humans can hold 5-9 items in working memory) and provides enough structure without overwhelming users.\n</Tip>\n\n---",
            "hydration_source_header": "1.2 Example: API Documentation Navigation",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "nav-validation-prompt",
            "title": "Navigation Quality Audit Prompt",
            "taskType": "analysis",
            "lines": "1105-1150",
            "standalone": true,
            "hydration_status": "failed"
          },
          {
            "id": "api-nav-validation-prompt",
            "title": "API Navigation Validation Prompt",
            "taskType": "analysis",
            "lines": "1160-1195",
            "standalone": true,
            "hydration_status": "failed"
          },
          {
            "id": "seo-nav-prompt",
            "title": "SEO-Optimized Navigation Prompt",
            "taskType": "generation",
            "lines": "1545-1590",
            "standalone": true,
            "retrievalQuestions": [
              "Show me a prompt for SEO navigation optimization"
            ],
            "content": "**Prompt Structure:**\n\n```text\nYou're an SEO specialist and information architect.\n\nOptimize this navigation structure for search engines:\n\nCurrent navigation:\n[List current structure]\n\nRequirements:\n- Include target keywords: [list keywords]\n- Match common search queries\n- Create clear hierarchy for crawlers\n- Maintain strong information scent\n- URLs should be descriptive\n\nProvide:\n1. Revised navigation with keyword-rich labels\n2. Proposed URL structure\n3. Schema markup recommendations\n4. Internal linking strategy\n```\n\n<Info>\n**Validation Checklist:** After AI optimizes navigation for SEO, verify:\n\n**Keyword Integration:**\n- \u2610 Target keywords appear in navigation labels naturally (not forced)\n- \u2610 Keywords front-loaded where possible (\"API Reference\" not \"Reference for APIs\")\n- \u2610 Labels still make sense to humans (UX > SEO always)\n\n**URL Quality:**\n- \u2610 URLs are descriptive (`/api-reference/authentication` not `/docs/page2`)\n- \u2610 URLs match navigation hierarchy\n- \u2610 Hyphens used for multi-word paths (not underscores or camelCase)\n- \u2610 URLs are lowercase and consistent\n\n**Schema Markup:**\n- \u2610 BreadcrumbList schema included with correct syntax\n- \u2610 SiteNavigationElement schema provided\n- \u2610 Markup validates at [schema.org validator](https://validator.schema.org/)\n\n**Balance Check:**\n- \u2610 Information scent not sacrificed for keywords (4-5/5 rating maintained)\n- \u2610 Labels don't sound like keyword stuffing\n- \u2610 User needs prioritized over search engines\n\n**Red Flag:** If labels become awkward for SEO (\"Documentation API Reference Guide Resources\"), reject the suggestion. User clarity always comes first.\n</Info>\n\n---",
            "hydration_source_header": "3.2 AI Prompt for SEO-Optimized Navigation",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "depth-analysis-prompt",
            "title": "Depth vs. Breadth Analysis Prompt",
            "taskType": "analysis",
            "lines": "1700-1720",
            "standalone": true,
            "content": "**Optimal Structure for Documentation:**\n- **5-7 top-level items** (respects Miller's Law)\n- **2-3 levels maximum** (reduces clicks)\n- **5-9 items per section** (scannable groups)\n\n**Example Balanced Structure:**\n\n**Text alternative:** Navigation structure showing Documentation as the root with 5 main sections (Get Started, API Reference, Guides, SDKs, Support). Each section has 2-3 subsections. Get Started includes Quickstart, Authentication, and First API Call. API Reference includes Users API, Products API, and Orders API. Guides includes Payment Integration, Webhook Setup, and Error Handling. This demonstrates optimal balance of 5 top-level items with maximum 2 levels of depth.\n\n```mermaid\ngraph TD\n    A[Documentation] --> B[Get Started]\n    A --> C[API Reference]\n    A --> D[Guides]\n    A --> E[SDKs]\n    A --> F[Support]\n    \n    B --> B1[Quickstart]\n    B --> B2[Authentication]\n    B --> B3[First API Call]\n    \n    C --> C1[Users API]\n    C --> C2[Products API]\n    C --> C3[Orders API]\n    \n    D --> D1[Payment Integration]\n    D --> D2[Webhook Setup]\n    D --> D3[Error Handling]\n    \n    style A fill:#4A90E2,color:#fff\n    style B fill:#7ED321,color:#fff\n    style C fill:#7ED321,color:#fff\n    style D fill:#7ED321,color:#fff\n    style E fill:#7ED321,color:#fff\n    style F fill:#7ED321,color:#fff\n```\n\n<Tip>\n  **Rule of Thumb:** If users need more than 3 clicks to reach 80% of content, your navigation is too deep. If your top-level has more than 9 items, it's too broad.\n</Tip>\n\n---",
            "hydration_source_header": "4.2 The Sweet Spot: Balanced Navigation",
            "hydration_method": "line_proximity"
          }
        ],
        "workflows": [
          {
            "id": "nav-design-workflow",
            "title": "Navigation Design Workflow",
            "steps": 4,
            "uses": [
              "nav-generation",
              "label-variation",
              "info-scent-eval",
              "validation"
            ],
            "lines": "implicit throughout",
            "retrievalQuestions": [
              "What's the process for designing navigation?"
            ],
            "content": "**The Five Core Principles:**\n\n1. **Respect Miller's Law**\n   - 5-7 top-level items (sweet spot)\n   - 5-9 items per section\n   - Maximum 3 levels deep for most sites\n\n2. **Optimize Information Scent**\n   - Every label should score 4-5/5 for clarity\n   - Users should predict destination confidently\n   - Avoid vague terms (Resources, More, Stuff)\n\n3. **Balance Depth and Breadth**\n   - Too shallow = overwhelming\n   - Too deep = frustrating maze\n   - 2-3 levels = optimal for most content\n\n4. **Design for Mobile First**\n   - Collapsible navigation\n   - Touch-friendly spacing\n   - Priority items visible\n   - Test on actual devices\n\n5. **Integrate SEO from Start**\n   - Keyword-rich labels\n   - Hierarchical URL structure\n   - Schema markup\n   - Match search intent\n\n---",
            "hydration_source_header": "Navigation Design Principles",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "label-testing-workflow",
            "title": "Label Testing Workflow",
            "steps": 3,
            "uses": [
              "label-variation-pattern",
              "info-scent-evaluation-pattern"
            ],
            "lines": "350-600",
            "retrievalQuestions": [
              "How do I test navigation labels?"
            ],
            "content": "**Use When:** You need multiple label options to test\n\n**Prompt Structure:**\n\n```text\nYou're a UX writer specializing in navigation labels.\n\nGenerate [NUMBER] label variations for [SECTION/CONTENT].\n\nContent this section contains:\n- [List items]\n\nLabel requirements:\n- Maximum [NUMBER] characters\n- [Style guidelines]\n- Must be [characteristics]\n\nFor each variation provide:\n1. Label text\n2. Character count\n3. Pros and cons\n4. Information scent rating (1-5)\n5. Target audience fit\n```\n\n<Info>\n**Validation Checklist:** After AI generates label variations, assess quality:\n\n**Variety Check:**\n- \u2610 Labels show real diversity (not just \"API Docs\", \"API Documentation\", \"API Reference\" - too similar)\n- \u2610 Different approaches represented (action-oriented, noun-based, user-focused)\n- \u2610 At least 3 labels score 4-5/5 for information scent\n\n**Accuracy Check:**\n- \u2610 Character counts are correct (recount if needed)\n- \u2610 Information scent ratings are justified (5/5 should be crystal clear)\n- \u2610 Pros/cons are specific, not generic\n\n**Practical Usefulness:**\n- \u2610 Labels are actually testable (avoid overly similar options)\n- \u2610 Trade-offs are clear (helps decision-making)\n- \u2610 Target audience fits are realistic\n\n**Quick Test:** Show top 3 labels (without context) to a colleague. Can they predict the destination? If not, those labels score too high for information scent.\n</Info>\n\n---",
            "hydration_source_header": "1.3 The Label Variation Pattern",
            "hydration_method": "line_proximity"
          },
          {
            "id": "nav-validation-workflow",
            "title": "Navigation Validation Workflow",
            "steps": 3,
            "uses": [
              "nav-validation-pattern",
              "structure-audit",
              "label-audit"
            ],
            "lines": "1100-1500",
            "retrievalQuestions": [
              "Steps to validate navigation design"
            ],
            "hydration_status": "failed"
          }
        ],
        "concepts": [
          {
            "id": "information-scent",
            "term": "Information Scent",
            "definition": "How well navigation labels predict their destination",
            "lines": "610-640",
            "retrievalQuestions": [
              "What is information scent?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "info-scent-rating",
            "term": "Information Scent Rating",
            "definition": "1-5 scale measuring label clarity and predictability",
            "lines": "640-670",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "nav-depth",
            "term": "Navigation Depth",
            "definition": "Number of levels in navigation hierarchy",
            "lines": "1590-1620",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "nav-breadth",
            "term": "Navigation Breadth",
            "definition": "Number of items at each navigation level",
            "lines": "1620-1650",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "miller-law",
            "term": "Miller's Law",
            "definition": "Humans can hold 5-9 items in working memory",
            "lines": "250-260, 1760",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "hierarchical-url",
            "term": "Hierarchical URL Structure",
            "definition": "URLs that mirror navigation structure",
            "lines": "1490-1520",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "schema-markup-nav",
            "term": "Schema Markup for Navigation",
            "definition": "Structured data for search engines (BreadcrumbList, SiteNavigationElement)",
            "lines": "1520-1545",
            "hydration_status": "skipped_unknown"
          }
        ],
        "seoEntities": [
          {
            "id": "seo-nav-principles",
            "title": "SEO-Friendly Navigation Principles",
            "purpose": "3 principles for SEO",
            "lines": "1460-1530",
            "retrievalQuestions": [
              "How do I make navigation SEO-friendly?"
            ],
            "content": "**1. Use Keyword-Rich Labels**\n- Labels should include target keywords\n- Match common search queries\n- Balance user language and SEO terms\n\n**Example:**\n- \u274c Weak: \"Resources\"\n- \u2705 Strong: \"API Documentation\"\n\n**2. Create Hierarchical URL Structure**\n- URLs should mirror navigation\n- Use descriptive paths\n- Maintain consistent depth\n\n**Example:**\n```text\nNavigation:        URL:\nGet Started  \u2192     /get-started/\n  Quickstart \u2192     /get-started/quickstart/\n  Auth Guide \u2192     /get-started/authentication/\n```\n\n**3. Implement Schema Markup**\n- Use BreadcrumbList schema\n- Add SiteNavigationElement markup\n- Help search engines understand structure\n\n<CodeGroup>\n\n```json Schema: Breadcrumbs\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"BreadcrumbList\",\n  \"itemListElement\": [\n    {\n      \"@type\": \"ListItem\",\n      \"position\": 1,\n      \"name\": \"Get Started\",\n      \"item\": \"https://docs.example.com/get-started\"\n    },\n    {\n      \"@type\": \"ListItem\",\n      \"position\": 2,\n      \"name\": \"Authentication\",\n      \"item\": \"https://docs.example.com/get-started/authentication\"\n    }\n  ]\n}\n```\n\n```json Schema: Site Navigation\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"SiteNavigationElement\",\n  \"name\": \"Main Navigation\",\n  \"url\": \"https://docs.example.com\",\n  \"hasPart\": [\n    {\n      \"@type\": \"SiteNavigationElement\",\n      \"name\": \"Get Started\",\n      \"url\": \"https://docs.example.com/get-started\"\n    },\n    {\n      \"@type\": \"SiteNavigationElement\",\n      \"name\": \"API Reference\",\n      \"url\": \"https://docs.example.com/api-reference\"\n    }\n  ]\n}\n```\n\n</CodeGroup>\n\n<Tip>\n**Validation:** Test your Schema.org markup using [Google's Rich Results Test](https://search.google.com/test/rich-results) to verify it's correctly structured before deploying to production.\n</Tip>\n\n---",
            "hydration_source_header": "3.1 SEO-Friendly Navigation Principles",
            "hydration_method": "title_match"
          },
          {
            "id": "keyword-labels",
            "title": "Keyword-Rich Label Strategy",
            "purpose": "Label SEO optimization",
            "lines": "1470-1490",
            "hydration_status": "failed"
          },
          {
            "id": "hierarchical-urls",
            "title": "Hierarchical URL Structure",
            "purpose": "URL-navigation alignment",
            "lines": "1490-1520",
            "content": "Navigation design impacts SEO significantly. Search engines use navigation to understand site structure and content hierarchy.\n\n### 3.1 SEO-Friendly Navigation Principles\n\n**1. Use Keyword-Rich Labels**\n- Labels should include target keywords\n- Match common search queries\n- Balance user language and SEO terms\n\n**Example:**\n- \u274c Weak: \"Resources\"\n- \u2705 Strong: \"API Documentation\"\n\n**2. Create Hierarchical URL Structure**\n- URLs should mirror navigation\n- Use descriptive paths\n- Maintain consistent depth\n\n**Example:**\n```text\nNavigation:        URL:\nGet Started  \u2192     /get-started/\n  Quickstart \u2192     /get-started/quickstart/\n  Auth Guide \u2192     /get-started/authentication/\n```\n\n**3. Implement Schema Markup**\n- Use BreadcrumbList schema\n- Add SiteNavigationElement markup\n- Help search engines understand structure\n\n<CodeGroup>\n\n```json Schema: Breadcrumbs\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"BreadcrumbList\",\n  \"itemListElement\": [\n    {\n      \"@type\": \"ListItem\",\n      \"position\": 1,\n      \"name\": \"Get Started\",\n      \"item\": \"https://docs.example.com/get-started\"\n    },\n    {\n      \"@type\": \"ListItem\",\n      \"position\": 2,\n      \"name\": \"Authentication\",\n      \"item\": \"https://docs.example.com/get-started/authentication\"\n    }\n  ]\n}\n```\n\n```json Schema: Site Navigation\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"SiteNavigationElement\",\n  \"name\": \"Main Navigation\",\n  \"url\": \"https://docs.example.com\",\n  \"hasPart\": [\n    {\n      \"@type\": \"SiteNavigationElement\",\n      \"name\": \"Get Started\",\n      \"url\": \"https://docs.example.com/get-started\"\n    },\n    {\n      \"@type\": \"SiteNavigationElement\",\n      \"name\": \"API Reference\",\n      \"url\": \"https://docs.example.com/api-reference\"\n    }\n  ]\n}\n```\n\n</CodeGroup>\n\n<Tip>\n**Validation:** Test your Schema.org markup using [Google's Rich Results Test](https://search.google.com/test/rich-results) to verify it's correctly structured before deploying to production.\n</Tip>\n\n---\n\n### 3.2 AI Prompt for SEO-Optimized Navigation\n\n**Prompt Structure:**\n\n```text\nYou're an SEO specialist and information architect.\n\nOptimize this navigation structure for search engines:\n\nCurrent navigation:\n[List current structure]\n\nRequirements:\n- Include target keywords: [list keywords]\n- Match common search queries\n- Create clear hierarchy for crawlers\n- Maintain strong information scent\n- URLs should be descriptive\n\nProvide:\n1. Revised navigation with keyword-rich labels\n2. Proposed URL structure\n3. Schema markup recommendations\n4. Internal linking strategy\n```\n\n<Info>\n**Validation Checklist:** After AI optimizes navigation for SEO, verify:\n\n**Keyword Integration:**\n- \u2610 Target keywords appear in navigation labels naturally (not forced)\n- \u2610 Keywords front-loaded where possible (\"API Reference\" not \"Reference for APIs\")\n- \u2610 Labels still make sense to humans (UX > SEO always)\n\n**URL Quality:**\n- \u2610 URLs are descriptive (`/api-reference/authentication` not `/docs/page2`)\n- \u2610 URLs match navigation hierarchy\n- \u2610 Hyphens used for multi-word paths (not underscores or camelCase)\n- \u2610 URLs are lowercase and consistent\n\n**Schema Markup:**\n- \u2610 BreadcrumbList schema included with correct syntax\n- \u2610 SiteNavigationElement schema provided\n- \u2610 Markup validates at [schema.org validator](https://validator.schema.org/)\n\n**Balance Check:**\n- \u2610 Information scent not sacrificed for keywords (4-5/5 rating maintained)\n- \u2610 Labels don't sound like keyword stuffing\n- \u2610 User needs prioritized over search engines\n\n**Red Flag:** If labels become awkward for SEO (\"Documentation API Reference Guide Resources\"), reject the suggestion. User clarity always comes first.\n</Info>\n\n---",
            "hydration_source_header": "3. SEO Considerations in Navigation",
            "hydration_method": "line_proximity"
          },
          {
            "id": "breadcrumblist-schema",
            "title": "BreadcrumbList Schema",
            "purpose": "Breadcrumb structured data",
            "lines": "1520-1540",
            "content": "**1. Use Keyword-Rich Labels**\n- Labels should include target keywords\n- Match common search queries\n- Balance user language and SEO terms\n\n**Example:**\n- \u274c Weak: \"Resources\"\n- \u2705 Strong: \"API Documentation\"\n\n**2. Create Hierarchical URL Structure**\n- URLs should mirror navigation\n- Use descriptive paths\n- Maintain consistent depth\n\n**Example:**\n```text\nNavigation:        URL:\nGet Started  \u2192     /get-started/\n  Quickstart \u2192     /get-started/quickstart/\n  Auth Guide \u2192     /get-started/authentication/\n```\n\n**3. Implement Schema Markup**\n- Use BreadcrumbList schema\n- Add SiteNavigationElement markup\n- Help search engines understand structure\n\n<CodeGroup>\n\n```json Schema: Breadcrumbs\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"BreadcrumbList\",\n  \"itemListElement\": [\n    {\n      \"@type\": \"ListItem\",\n      \"position\": 1,\n      \"name\": \"Get Started\",\n      \"item\": \"https://docs.example.com/get-started\"\n    },\n    {\n      \"@type\": \"ListItem\",\n      \"position\": 2,\n      \"name\": \"Authentication\",\n      \"item\": \"https://docs.example.com/get-started/authentication\"\n    }\n  ]\n}\n```\n\n```json Schema: Site Navigation\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"SiteNavigationElement\",\n  \"name\": \"Main Navigation\",\n  \"url\": \"https://docs.example.com\",\n  \"hasPart\": [\n    {\n      \"@type\": \"SiteNavigationElement\",\n      \"name\": \"Get Started\",\n      \"url\": \"https://docs.example.com/get-started\"\n    },\n    {\n      \"@type\": \"SiteNavigationElement\",\n      \"name\": \"API Reference\",\n      \"url\": \"https://docs.example.com/api-reference\"\n    }\n  ]\n}\n```\n\n</CodeGroup>\n\n<Tip>\n**Validation:** Test your Schema.org markup using [Google's Rich Results Test](https://search.google.com/test/rich-results) to verify it's correctly structured before deploying to production.\n</Tip>\n\n---",
            "hydration_source_header": "3.1 SEO-Friendly Navigation Principles",
            "hydration_method": "line_proximity"
          },
          {
            "id": "sitenavigationelement",
            "title": "SiteNavigationElement Schema",
            "purpose": "Navigation structured data",
            "lines": "1540-1555",
            "retrievalQuestions": [
              "What schema markup for navigation?"
            ],
            "content": "**1. Use Keyword-Rich Labels**\n- Labels should include target keywords\n- Match common search queries\n- Balance user language and SEO terms\n\n**Example:**\n- \u274c Weak: \"Resources\"\n- \u2705 Strong: \"API Documentation\"\n\n**2. Create Hierarchical URL Structure**\n- URLs should mirror navigation\n- Use descriptive paths\n- Maintain consistent depth\n\n**Example:**\n```text\nNavigation:        URL:\nGet Started  \u2192     /get-started/\n  Quickstart \u2192     /get-started/quickstart/\n  Auth Guide \u2192     /get-started/authentication/\n```\n\n**3. Implement Schema Markup**\n- Use BreadcrumbList schema\n- Add SiteNavigationElement markup\n- Help search engines understand structure\n\n<CodeGroup>\n\n```json Schema: Breadcrumbs\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"BreadcrumbList\",\n  \"itemListElement\": [\n    {\n      \"@type\": \"ListItem\",\n      \"position\": 1,\n      \"name\": \"Get Started\",\n      \"item\": \"https://docs.example.com/get-started\"\n    },\n    {\n      \"@type\": \"ListItem\",\n      \"position\": 2,\n      \"name\": \"Authentication\",\n      \"item\": \"https://docs.example.com/get-started/authentication\"\n    }\n  ]\n}\n```\n\n```json Schema: Site Navigation\n{\n  \"@context\": \"https://schema.org\",\n  \"@type\": \"SiteNavigationElement\",\n  \"name\": \"Main Navigation\",\n  \"url\": \"https://docs.example.com\",\n  \"hasPart\": [\n    {\n      \"@type\": \"SiteNavigationElement\",\n      \"name\": \"Get Started\",\n      \"url\": \"https://docs.example.com/get-started\"\n    },\n    {\n      \"@type\": \"SiteNavigationElement\",\n      \"name\": \"API Reference\",\n      \"url\": \"https://docs.example.com/api-reference\"\n    }\n  ]\n}\n```\n\n</CodeGroup>\n\n<Tip>\n**Validation:** Test your Schema.org markup using [Google's Rich Results Test](https://search.google.com/test/rich-results) to verify it's correctly structured before deploying to production.\n</Tip>\n\n---",
            "hydration_source_header": "3.1 SEO-Friendly Navigation Principles",
            "hydration_method": "line_proximity"
          }
        ],
        "mobileNavEntities": [
          {
            "id": "hamburger-pattern",
            "title": "Hamburger Menu Pattern",
            "whenToUse": "Standard for most docs",
            "proscons": "Familiar, hides complexity",
            "lines": "1770-1790",
            "retrievalQuestions": [
              "When should I use hamburger menu?"
            ],
            "content": "With mobile traffic dominating, navigation must work seamlessly on small screens.\n\n### 5.1 Mobile Navigation Patterns\n\n<AccordionGroup>\n  <Accordion title=\"Hamburger Menu (Most Common)\">\n    **When to Use:** Standard approach for most documentation\n    \n    **Pros:**\n    - Hides complexity\n    - Familiar pattern\n    - Saves screen space\n    \n    **Cons:**\n    - Requires tap to reveal\n    - Lower discoverability\n    - Can hide too much\n    \n    **Implementation:**\n    - Collapsible sections\n    - Swipe to close\n    - Persistent \"close\" button\n  </Accordion>\n  \n  <Accordion title=\"Bottom Navigation\">\n    **When to Use:** App-like documentation experiences\n    \n    **Pros:**\n    - Easy thumb reach\n    - Always visible\n    - Fast switching\n    \n    **Cons:**\n    - Limited to 3-5 items\n    - Takes screen space\n    - Not standard for docs\n    \n    **Implementation:**\n    - Use for top 3-5 sections only\n    - Icons + labels\n    - Active state indicators\n  </Accordion>\n  \n  <Accordion title=\"Priority+ Pattern\">\n    **When to Use:** When some nav items are more important\n    \n    **Pros:**\n    - Shows priority items\n    - Hides less important\n    - Adaptive to screen size\n    \n    **Cons:**\n    - Complex to implement\n    - Less predictable\n    - Requires JS\n    \n    **Implementation:**\n    - Show 4-5 priority items\n    - \"More\" menu for rest\n    - Calculate based on viewport\n  </Accordion>\n</AccordionGroup>\n\n---",
            "hydration_source_header": "5. Mobile Navigation Considerations",
            "hydration_method": "line_proximity"
          },
          {
            "id": "bottom-nav-pattern",
            "title": "Bottom Navigation Pattern",
            "whenToUse": "App-like experiences",
            "proscons": "Thumb-friendly, limited items",
            "lines": "1790-1810",
            "content": "<AccordionGroup>\n  <Accordion title=\"Hamburger Menu (Most Common)\">\n    **When to Use:** Standard approach for most documentation\n    \n    **Pros:**\n    - Hides complexity\n    - Familiar pattern\n    - Saves screen space\n    \n    **Cons:**\n    - Requires tap to reveal\n    - Lower discoverability\n    - Can hide too much\n    \n    **Implementation:**\n    - Collapsible sections\n    - Swipe to close\n    - Persistent \"close\" button\n  </Accordion>\n  \n  <Accordion title=\"Bottom Navigation\">\n    **When to Use:** App-like documentation experiences\n    \n    **Pros:**\n    - Easy thumb reach\n    - Always visible\n    - Fast switching\n    \n    **Cons:**\n    - Limited to 3-5 items\n    - Takes screen space\n    - Not standard for docs\n    \n    **Implementation:**\n    - Use for top 3-5 sections only\n    - Icons + labels\n    - Active state indicators\n  </Accordion>\n  \n  <Accordion title=\"Priority+ Pattern\">\n    **When to Use:** When some nav items are more important\n    \n    **Pros:**\n    - Shows priority items\n    - Hides less important\n    - Adaptive to screen size\n    \n    **Cons:**\n    - Complex to implement\n    - Less predictable\n    - Requires JS\n    \n    **Implementation:**\n    - Show 4-5 priority items\n    - \"More\" menu for rest\n    - Calculate based on viewport\n  </Accordion>\n</AccordionGroup>\n\n---",
            "hydration_source_header": "5.1 Mobile Navigation Patterns",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "priority-plus",
            "title": "Priority+ Pattern",
            "whenToUse": "Some items more important",
            "proscons": "Adaptive, complex to implement",
            "lines": "1810-1830",
            "retrievalQuestions": [
              "What is Priority+ navigation?"
            ],
            "content": "<AccordionGroup>\n  <Accordion title=\"Hamburger Menu (Most Common)\">\n    **When to Use:** Standard approach for most documentation\n    \n    **Pros:**\n    - Hides complexity\n    - Familiar pattern\n    - Saves screen space\n    \n    **Cons:**\n    - Requires tap to reveal\n    - Lower discoverability\n    - Can hide too much\n    \n    **Implementation:**\n    - Collapsible sections\n    - Swipe to close\n    - Persistent \"close\" button\n  </Accordion>\n  \n  <Accordion title=\"Bottom Navigation\">\n    **When to Use:** App-like documentation experiences\n    \n    **Pros:**\n    - Easy thumb reach\n    - Always visible\n    - Fast switching\n    \n    **Cons:**\n    - Limited to 3-5 items\n    - Takes screen space\n    - Not standard for docs\n    \n    **Implementation:**\n    - Use for top 3-5 sections only\n    - Icons + labels\n    - Active state indicators\n  </Accordion>\n  \n  <Accordion title=\"Priority+ Pattern\">\n    **When to Use:** When some nav items are more important\n    \n    **Pros:**\n    - Shows priority items\n    - Hides less important\n    - Adaptive to screen size\n    \n    **Cons:**\n    - Complex to implement\n    - Less predictable\n    - Requires JS\n    \n    **Implementation:**\n    - Show 4-5 priority items\n    - \"More\" menu for rest\n    - Calculate based on viewport\n  </Accordion>\n</AccordionGroup>\n\n---",
            "hydration_source_header": "5.1 Mobile Navigation Patterns",
            "hydration_method": "line_proximity"
          }
        ]
      }
    },
    "3-1-content-audit": {
      "file": "3-1-content-audit.mdx",
      "focus": "Conducting AI-assisted content audits at scale, identifying gaps and redundancies, prioritizing improvements, and mapping content to user journeys",
      "entityCount": 105,
      "entities": {
        "frameworks": [
          {
            "id": "ai-assisted-audit-framework",
            "title": "AI-Assisted Content Audit Framework",
            "type": "framework",
            "definition": "End-to-end framework for conducting content audits with AI including prepare, analyze, validate, prioritize, and document phases",
            "contains": [
              "prepare-phase",
              "analyze-phase",
              "validate-phase",
              "prioritize-phase",
              "document-phase"
            ],
            "lines": "1-1976",
            "crossModule": false,
            "retrievalQuestions": [
              "How do I conduct a content audit with AI?",
              "What are the steps in an AI-assisted audit?"
            ],
            "content": "This foundational prompt establishes context for all your audit work.\n\n**Your Prompt:**\n\n```text\nYou're a content strategist helping audit developer documentation.\n\nAudit scope and objectives:\n[Paste your audit charter]\n\nQuality criteria:\n[Paste your quality criteria]\n\nI'll be sharing content inventory data and asking you to help identify:\n- Duplicates and overlapping content\n- Content gaps based on user journeys\n- Quality issues and improvement priorities\n- Structural and organizational issues\n\nI have [number] total items. I'll start with a sample to ensure you understand \nthe content domain, then share the full inventory.\n\nPlease confirm you understand the audit scope and ask any clarifying questions \nbefore we begin analysis.\n```\n\n**Why this works:**\n- Establishes AI as an expert collaborator\n- Provides full context upfront\n- Sets clear expectations\n- Invites questions (catches misunderstandings early)\n\n---",
            "hydration_source_header": "2.1 The Content Audit Framework Prompt",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "five-step-audit-process",
            "title": "Five-Step Audit Process",
            "type": "framework",
            "definition": "Prepare, Analyze, Validate, Prioritize, Document",
            "contains": [
              "prepare",
              "analyze",
              "validate",
              "prioritize",
              "document"
            ],
            "lines": "1940-1955",
            "crossModule": false,
            "content": "**Five Core Steps:**\n\n1. **Prepare** - Build inventory, define quality criteria, set scope\n2. **Analyze** - Use AI for duplicates, gaps, quality at scale\n3. **Validate** - Spot-check AI findings against actual content\n4. **Prioritize** - Use impact and effort to rank improvements\n5. **Document** - Create actionable recommendations with clear metrics\n\n---",
            "hydration_source_header": "The AI-Assisted Audit Process",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "quality-criteria-framework",
            "title": "Content Quality Criteria Framework",
            "type": "framework",
            "definition": "Six quality criteria: completeness, currency, clarity, accuracy, actionability, discoverability",
            "contains": [
              "completeness",
              "currency",
              "clarity",
              "accuracy",
              "actionability",
              "discoverability"
            ],
            "lines": "158-220",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I define quality criteria for documentation?"
            ],
            "content": "AI needs clear criteria to assess content quality. Define what \"good\" looks like for your documentation.\n\n**Sample quality criteria:**\n\n<AccordionGroup>\n  <Accordion title=\"Completeness\">\n    **Indicators:**\n    - Covers topic comprehensively\n    - Includes code examples\n    - Has prerequisites listed\n    - Links to related content\n    \n    **Quality scale:**\n    - \u2b50\u2b50\u2b50\u2b50\u2b50 Complete with examples and context\n    - \u2b50\u2b50\u2b50 Covers basics but missing examples\n    - \u2b50 Incomplete or skeletal content\n  </Accordion>\n  \n  <Accordion title=\"Currency\">\n    **Indicators:**\n    - Updated within last 6 months\n    - References current product version\n    - No deprecated information\n    - Matches current UI/API\n    \n    **Quality scale:**\n    - \u2b50\u2b50\u2b50\u2b50\u2b50 Updated within 3 months\n    - \u2b50\u2b50\u2b50 3-12 months old but still accurate\n    - \u2b50 Over 12 months, likely outdated\n  </Accordion>\n  \n  <Accordion title=\"Clarity\">\n    **Indicators:**\n    - Clear, concise writing\n    - Logical structure\n    - Appropriate for target audience\n    - Good use of headings/formatting\n    \n    **Quality scale:**\n    - \u2b50\u2b50\u2b50\u2b50\u2b50 Crystal clear, well-structured\n    - \u2b50\u2b50\u2b50 Understandable but could improve\n    - \u2b50 Confusing or poorly organized\n  </Accordion>\n  \n  <Accordion title=\"Accuracy\">\n    **Indicators:**\n    - Technically correct\n    - Code examples work\n    - No conflicting information\n    - Matches product behavior\n    \n    **Quality scale:**\n    - \u2b50\u2b50\u2b50\u2b50\u2b50 Verified accurate\n    - \u2b50\u2b50\u2b50 Generally accurate, minor issues\n    - \u2b50 Contains errors or outdated info\n  </Accordion>\n</AccordionGroup>\n\n**Your AI Prompt Template:**\n\n```text\nI'm conducting a content audit and need to establish quality criteria.\n\nMy documentation covers: [Brief description]\nPrimary audience: [User type and level]\nKey user goals: [What users need to accomplish]\n\nHelp me define 5-7 quality criteria appropriate for this content and audience.\n\nFor each criterion:\n1. Name and definition\n2. What \"good\" looks like\n3. What \"poor\" looks like\n4. How to measure it (quantitative or qualitative indicators)\n5. Why it matters to users\n\nFocus on criteria that can be consistently applied across 200+ pages.\n```\n\n---",
            "hydration_source_header": "1.2 Defining Quality Criteria",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "gap-prioritization-framework",
            "title": "Gap Prioritization Framework (P0-P3)",
            "type": "framework",
            "definition": "Priority levels from P0 (critical blocking) to P3 (low impact)",
            "contains": [
              "p0-blocking",
              "p1-significant",
              "p2-nice-to-have",
              "p3-low-impact"
            ],
            "lines": "1140-1175",
            "crossModule": false,
            "retrievalQuestions": [
              "How do I prioritize content gaps?"
            ],
            "content": "Not all gaps are equal\u2014prioritize based on user impact and business value.\n\n**Gap Prioritization Framework Prompt:**\n\n```text\nPrioritize these identified content gaps:\n\n[Paste list of gaps identified]\n\nFor each gap, assess:\n1. User impact: How many users are affected? How severely?\n2. Business impact: Effect on adoption, retention, support costs\n3. Urgency: Is this blocking current users? Upcoming product launch?\n4. Effort: Content creation complexity and resource requirements\n5. Dependencies: Does this gap block other improvements?\n\nAssign priority level (P0/P1/P2/P3) and recommend sequence for addressing gaps.\n\nP0 = Blocking critical user paths, address immediately\nP1 = Significant user friction, address this quarter\nP2 = Nice to have, address this year\nP3 = Low impact, address opportunistically\n\nFor P0 and P1 gaps, provide:\n- Recommended content format (tutorial/guide/reference)\n- Estimated effort (hours)\n- Key messages to cover\n- Success metrics\n```\n\n<CardGroup cols={2}>\n  <Card title=\"High-Impact Gaps\" icon=\"fire\">\n    **Prioritize when:**\n    - Blocks critical user goals\n    - Generates support tickets\n    - Affects many users\n    - Quick to address\n    \n    Example: Missing error code reference\n  </Card>\n  \n  <Card title=\"Low-Priority Gaps\" icon=\"clock\">\n    **Defer when:**\n    - Nice-to-have only\n    - Affects few users\n    - Workarounds exist\n    - High effort required\n    \n    Example: Edge case documentation\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "4.3 Prioritizing Gap Remediation",
            "hydration_method": "line_proximity"
          },
          {
            "id": "multi-pass-audit-strategy",
            "title": "Multi-Pass Audit Strategy",
            "type": "framework",
            "definition": "Three-pass strategy: structure pass, category pass, relationships pass",
            "contains": [
              "pass-1-structure",
              "pass-2-category",
              "pass-3-relationships"
            ],
            "lines": "870-920",
            "crossModule": false,
            "content": "For complex audits, use a phased approach with increasingly focused prompts.\n\n**Pass 1: High-Level Structure**\n\n```text\nFirst pass review - focus on structure and organization only:\n\n[Paste inventory]\n\nAssess:\n1. Overall information architecture (logical grouping?)\n2. Navigation and hierarchy (clear paths?)\n3. Major structural gaps\n4. Sections that seem misplaced\n\nDon't evaluate individual page quality yet\u2014stay at the structural level.\n```\n\n**Pass 2: Category-Level Analysis**\n\n```text\nSecond pass - analyze the \"Getting Started\" category in detail:\n\n[Paste Getting Started inventory items]\n\nEvaluate:\n1. Completeness for user onboarding\n2. Logical sequence and progression\n3. Overlap or redundancy within this category\n4. Quality red flags (based on titles/descriptions)\n5. Missing elements compared to user journey\n\nProvide specific, actionable recommendations.\n```\n\n**Pass 3: Cross-Category Relationships**\n\n```text\nThird pass - analyze relationships between categories:\n\nCategories: [List main categories]\nRepresentative items: [Paste sample from each category]\n\nIdentify:\n1. Content that should be connected but isn't\n2. Duplicate coverage across categories\n3. Logical progression paths users would follow\n4. Navigation or wayfinding gaps between categories\n\nMap the top 5 priority cross-category improvements.\n```\n\n---",
            "hydration_source_header": "2.7 Multi-Pass Audit Strategies",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "principles": [
          {
            "id": "ai-amplifies-not-replaces",
            "title": "AI Amplifies, Not Replaces Human Judgment",
            "partOf": "ai-assisted-audit-framework",
            "lines": "55-75",
            "crossModule": true,
            "retrievalQuestions": [
              "Should I trust AI audit findings without checking?"
            ],
            "content": "AI doesn't replace human judgment in content audits\u2014it amplifies your analytical capacity. Think of AI as your research assistant who never gets tired, can read hundreds of pages in seconds, and maintains perfectly consistent evaluation criteria.\n\n<CardGroup cols={2}>\n  <Card title=\"Where AI Excels\" icon=\"robot\">\n    - **Rapid inventory** - Analyzing large content sets in minutes\n    - **Pattern detection** - Identifying subtle patterns across hundreds of documents\n    - **Consistency** - Applying the same criteria uniformly\n    - **Multi-dimensional analysis** - Evaluating against multiple criteria simultaneously\n    - **Comparative analysis** - Identifying outliers and clusters\n  </Card>\n  \n  <Card title=\"Where Humans Are Essential\" icon=\"user\">\n    - **Defining audit objectives** - Setting success criteria\n    - **Validating AI findings** - Against real user needs\n    - **Strategic prioritization** - Making business decisions\n    - **Understanding context** - Organizational constraints\n    - **Final quality judgment** - Recommendations and sign-off\n  </Card>\n</CardGroup>\n\n**AI-assisted audit timeline:**\n```text\nAI-assisted audit of 300-page documentation site:\n- Content inventory: 2-4 hours\n- AI-assisted analysis: 3-4 hours\n- Validation & refinement: 2-3 hours\n- Report writing: 2-3 hours\nTotal: 9-14 hours (60-80% time savings)\n```\n\n---",
            "hydration_source_header": "How AI Transforms the Audit Process",
            "hydration_method": "line_proximity"
          },
          {
            "id": "validation-is-critical",
            "title": "Always Validate AI Findings",
            "partOf": "ai-assisted-audit-framework",
            "lines": "550-560, 1665",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I validate AI content analysis?"
            ],
            "content": "The most meaningful gaps are those that block users from accomplishing their goals.\n\n**Your Prompt:**\n\n```text\nAssess content gaps for this user journey:\n\nUSER JOURNEY: First-Time Integration\nUser: Backend developer integrating CloudAPI for the first time\nGoal: Successfully make authenticated API calls within 60 minutes\n\nJourney stages:\n1. Discovery: Understand what CloudAPI does and if it fits needs\n   Goals: Learn capabilities, see use cases, understand pricing/limits\n   \n2. Setup: Get access and set up development environment\n   Goals: Create account, get API keys, install SDK/tools\n   \n3. Authentication: Implement authentication correctly\n   Goals: Understand auth flow, implement securely, test auth\n   \n4. First API Call: Make first successful API request\n   Goals: Choose right endpoint, construct request, handle response\n   \n5. Validation: Confirm integration works and understand next steps\n   Goals: Test thoroughly, handle errors, know where to go next\n\nCurrent inventory:\n[Paste relevant portion of inventory, or reference the full inventory]\n\nFor each journey stage:\n1. What content supports it?\n2. What critical gaps would block users?\n3. What nice-to-have content is missing?\n4. Is existing content at the right depth/format?\n\nPrioritize gaps by user impact and create a gap matrix showing current vs. \nneeded coverage.\n```\n\n**Expected AI Output Example:**\n\n```text\nCONTENT GAP ANALYSIS - First-Time Integration Journey\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nSTAGE 1: DISCOVERY\nGoal: Understand what CloudAPI does and if it fits needs\n\nCurrent Coverage:\n\u2705 \"What is CloudAPI\" overview (exists)\n\u2705 \"Key Features\" page (exists)\n\u274c Use case examples (MISSING)\n\u274c Comparison to alternatives (MISSING)\n\u274c Rate limits/pricing overview (MISSING in docs, on pricing page only)\n\nCRITICAL GAPS:\n1. Use Case Library (P0)\n   - Impact: HIGH - Users can't assess fit without real examples\n   - What's needed: 5-7 concrete use case examples with code\n   - Where: New section \"Use Cases\" in Get Started\n   - Effort: 6-8 hours\n   - Why critical: Prevents wasted time for users CloudAPI doesn't fit\n\n2. Pricing & Limits Overview (P1)\n   - Impact: MEDIUM - Users fear surprise costs\n   - What's needed: Link to pricing + summary of free tier limits\n   - Where: Callout box in \"What is CloudAPI\"\n   - Effort: 1-2 hours\n   - Why critical: Common blocker in adoption decisions\n\nNICE-TO-HAVE:\n- Comparison guide (vs. competitors): P2, Low priority\n  Users can evaluate without this, but it would help\n\nCurrent content assessment:\n- \"What is CloudAPI\" is comprehensive but doesn't address use cases\n- Missing the \"Is this right for me?\" angle\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nSTAGE 2: SETUP\nGoal: Get access and set up development environment\n\nCurrent Coverage:\n\u2705 Account creation (exists - links to signup)\n\u2705 API key generation (exists)\n\u274c SDK installation (MISSING for Python, Ruby)\n\u274c Development environment setup (MISSING)\n\u2705 Postman collection (exists)\n\nCRITICAL GAPS:\n1. SDK Installation Guides (P0)\n   - Impact: HIGH - Many users prefer SDKs over raw HTTP\n   - What's needed: Installation + basic setup for Node.js, Python, Ruby\n   - Where: New \"SDK Quickstarts\" section\n   - Effort: 4-6 hours total (1-2 hours per SDK)\n   - Why critical: Reduces time-to-first-call dramatically\n\n2. Environment Setup Guide (P1)\n   - Impact: MEDIUM - Some users struggle with dev environment\n   - What's needed: Environment variables, testing vs. production setup\n   - Where: Expand \"Getting Started\" section\n   - Effort: 2-3 hours\n   - Why critical: Prevents common early mistakes (using prod keys in dev)\n\nCurrent content assessment:\n- \"Getting API Keys\" is clear but doesn't explain key management\n- No guidance on environment setup best practices\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nSTAGE 3: AUTHENTICATION\nGoal: Implement authentication correctly\n\nCurrent Coverage:\n\u2705 OAuth 2.0 documentation (exists - very detailed)\n\u2705 API key authentication (exists)\n\u274c Authentication quick comparison (MISSING)\n\u274c Common auth errors troubleshooting (MISSING)\n\u274c Security best practices (MISSING)\n\nCRITICAL GAPS:\n1. \"Which Auth Method?\" Decision Guide (P0)\n   - Impact: HIGH - Users waste time choosing wrong auth method\n   - What's needed: Flow chart or decision tree + comparison table\n   - Where: Before detailed auth docs, in overview\n   - Effort: 2-3 hours\n   - Why critical: Prevents users from implementing OAuth when API keys sufficient\n\n2. Authentication Troubleshooting (P0)\n   - Impact: HIGH - Auth errors are top support issue\n   - What's needed: Common errors, causes, solutions\n   - Where: New \"Troubleshooting Auth\" page\n   - Effort: 3-4 hours\n   - Why critical: Reduces support tickets by 20-30%\n\nNICE-TO-HAVE:\n- Security best practices: P2, should be covered but not blocking\n\nCurrent content assessment:\n- OAuth docs are too detailed for beginners (intimidating)\n- Need progressive disclosure: simple path, then advanced options\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nSTAGE 4: FIRST API CALL\nGoal: Make first successful API request\n\nCurrent Coverage:\n\u2705 API endpoints documented (exists)\n\u2705 \"Your First API Call\" tutorial (exists)\n\u274c Response handling guide (MISSING)\n\u274c Error code reference (MISSING)\n\u274c Quick reference / cheat sheet (MISSING)\n\nCRITICAL GAPS:\n1. Error Code Reference (P0)\n   - Impact: HIGH - Users stuck when things go wrong\n   - What's needed: All HTTP errors, CloudAPI-specific codes, solutions\n   - Where: New \"Error Reference\" page\n   - Effort: 4-5 hours\n   - Why critical: Unblocks users immediately when errors occur\n\n2. API Cheat Sheet (P1)\n   - Impact: MEDIUM - Convenient but not blocking\n   - What's needed: One-page quick reference of common endpoints/patterns\n   - Where: Standalone page + PDF download\n   - Effort: 3-4 hours\n   - Why critical: Reduces time searching docs once users are productive\n\nCurrent content assessment:\n- \"Your First API Call\" is excellent (clear, comprehensive)\n- But doesn't prepare users for what happens when it fails\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nSTAGE 5: VALIDATION\nGoal: Confirm integration works and understand next steps\n\nCurrent Coverage:\n\u274c Testing strategies (MISSING)\n\u274c Integration checklist (MISSING)\n\u274c \"What's next?\" recommendations (MISSING)\n\u274c Sample applications (MISSING)\n\nCRITICAL GAPS:\n1. Integration Testing Guide (P0)\n   - Impact: HIGH - Users ship untested integrations, cause issues\n   - What's needed: How to test API integration, common pitfalls, test checklist\n   - Where: New \"Testing Your Integration\" guide\n   - Effort: 4-5 hours\n   - Why critical: Prevents production issues, reduces support burden\n\n2. \"Next Steps\" Navigation (P1)\n   - Impact: MEDIUM - Users unsure what to learn next\n   - What's needed: Curated learning paths based on use case\n   - Where: End of \"First API Call\" tutorial + standalone page\n   - Effort: 2-3 hours\n   - Why critical: Increases depth of integration, engagement\n\nNICE-TO-HAVE:\n- Sample applications: P2, helpful but users can build from docs\n\nCurrent content assessment:\n- Journey essentially \"ends\" after first call\n- No guidance on production readiness or next steps\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nGAP MATRIX SUMMARY:\n\nLegend: \u2705 Adequate | \u26a0\ufe0f Partial | \u274c Missing\n\n| Journey Stage | Coverage | Critical Gaps | Priority |\n|--------------|----------|---------------|----------|\n| Discovery    | \u26a0\ufe0f Partial | Use cases (P0), Pricing (P1) | HIGH |\n| Setup        | \u26a0\ufe0f Partial | SDK setup (P0), Env setup (P1) | HIGH |\n| Authentication | \u2705 Adequate | Auth decision (P0), Troubleshooting (P0) | CRITICAL |\n| First Call   | \u2705 Adequate | Error reference (P0), Cheat sheet (P1) | HIGH |\n| Validation   | \u274c Missing | Testing guide (P0), Next steps (P1) | CRITICAL |\n\nPRIORITY GAPS (P0 - Address Immediately):\n1. Authentication decision guide - 2-3 hours\n2. Use case library - 6-8 hours\n3. Authentication troubleshooting - 3-4 hours\n4. Error code reference - 4-5 hours\n5. SDK installation guides - 4-6 hours\n6. Integration testing guide - 4-5 hours\n\nTotal P0 effort: ~24-33 hours\nExpected impact: Reduce time-to-first-call by 40%, reduce auth support tickets by 30%\n\nSECONDARY GAPS (P1 - Address This Quarter):\n[Listed with effort estimates...]\n\nOVERALL ASSESSMENT:\nJourney coverage: 60% adequate\nMajor blocker: Authentication and validation stages need significant work\nStrengths: First API call tutorial is excellent foundation\nOpportunity: Build validation stage from scratch (currently 0% coverage)\n```\n\n<Warning>\n  **Gap Analysis Reality Check:** Not every gap needs to be filled immediately. Prioritize gaps that:\n  1. Block users from accomplishing critical goals\n  2. Cause frequent support tickets\n  3. Have high impact relative to effort\n  \n  Some \"nice-to-have\" gaps can stay unfilled indefinitely if resources are limited.\n</Warning>\n\n---",
            "hydration_source_header": "2.4 Gap Analysis Against User Journeys",
            "hydration_method": "line_proximity"
          },
          {
            "id": "prioritize-by-user-impact",
            "title": "Prioritize by User Impact",
            "partOf": "gap-prioritization-framework",
            "lines": "1140-1175",
            "crossModule": false,
            "content": "Not all gaps are equal\u2014prioritize based on user impact and business value.\n\n**Gap Prioritization Framework Prompt:**\n\n```text\nPrioritize these identified content gaps:\n\n[Paste list of gaps identified]\n\nFor each gap, assess:\n1. User impact: How many users are affected? How severely?\n2. Business impact: Effect on adoption, retention, support costs\n3. Urgency: Is this blocking current users? Upcoming product launch?\n4. Effort: Content creation complexity and resource requirements\n5. Dependencies: Does this gap block other improvements?\n\nAssign priority level (P0/P1/P2/P3) and recommend sequence for addressing gaps.\n\nP0 = Blocking critical user paths, address immediately\nP1 = Significant user friction, address this quarter\nP2 = Nice to have, address this year\nP3 = Low impact, address opportunistically\n\nFor P0 and P1 gaps, provide:\n- Recommended content format (tutorial/guide/reference)\n- Estimated effort (hours)\n- Key messages to cover\n- Success metrics\n```\n\n<CardGroup cols={2}>\n  <Card title=\"High-Impact Gaps\" icon=\"fire\">\n    **Prioritize when:**\n    - Blocks critical user goals\n    - Generates support tickets\n    - Affects many users\n    - Quick to address\n    \n    Example: Missing error code reference\n  </Card>\n  \n  <Card title=\"Low-Priority Gaps\" icon=\"clock\">\n    **Defer when:**\n    - Nice-to-have only\n    - Affects few users\n    - Workarounds exist\n    - High effort required\n    \n    Example: Edge case documentation\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "4.3 Prioritizing Gap Remediation",
            "hydration_method": "line_proximity"
          },
          {
            "id": "scope-focus",
            "title": "Stay Focused on Defined Scope",
            "partOf": "ai-assisted-audit-framework",
            "lines": "295-305",
            "crossModule": false,
            "content": "Now that your inventory is ready, let's use AI to analyze it systematically.\n\n### 2.1 The Content Audit Framework Prompt\n\nThis foundational prompt establishes context for all your audit work.\n\n**Your Prompt:**\n\n```text\nYou're a content strategist helping audit developer documentation.\n\nAudit scope and objectives:\n[Paste your audit charter]\n\nQuality criteria:\n[Paste your quality criteria]\n\nI'll be sharing content inventory data and asking you to help identify:\n- Duplicates and overlapping content\n- Content gaps based on user journeys\n- Quality issues and improvement priorities\n- Structural and organizational issues\n\nI have [number] total items. I'll start with a sample to ensure you understand \nthe content domain, then share the full inventory.\n\nPlease confirm you understand the audit scope and ask any clarifying questions \nbefore we begin analysis.\n```\n\n**Why this works:**\n- Establishes AI as an expert collaborator\n- Provides full context upfront\n- Sets clear expectations\n- Invites questions (catches misunderstandings early)\n\n---\n\n### 2.2 Exploratory Analysis on Sample Content\n\nStart with a representative sample to calibrate AI's understanding.\n\n**Your Prompt:**\n\n```text\nHere's a representative sample of 10 items from the documentation:\n\n[Paste your sample content with full detail]\n\nBased on this sample:\n1. What patterns do you notice in structure and organization?\n2. What content types are represented?\n3. What potential issues stand out?\n4. What questions should guide the full audit?\n5. Are my quality criteria clear and appropriate for this content?\n\nDon't make final judgments yet\u2014I want your initial observations to refine \nmy audit approach.\n```\n\n**Expected AI Output Pattern:**\n\n```text\nSAMPLE ANALYSIS - DEVELOPER DOCUMENTATION\n\nPATTERNS OBSERVED:\n\nStructure:\n- Consistent three-part pattern: Overview \u2192 Implementation \u2192 Examples\n- Most guides 1000-1500 words\n- Reference docs significantly longer (2000+ words)\n- Tutorials include code snippets, guides more conceptual\n\nOrganization:\n- Content grouped by feature area (not user journey)\n- Mix of beginner and advanced content in same sections\n- \"Getting Started\" seems isolated from advanced content\n- No clear progression paths indicated\n\nContent Types:\n- Tutorials (20%): Step-by-step, hands-on\n- Guides (40%): How-to, task-oriented\n- Reference (30%): Technical specifications\n- Concepts (10%): Explanatory content\n\nPOTENTIAL ISSUES:\n\n1. Possible duplication: Three items mention \"webhooks\" - may overlap\n2. Inconsistent depth: Some tutorials very brief (<500 words), others detailed\n3. Missing connections: No indication of prerequisites or \"next steps\"\n4. Age variation: Dates range from 2022-2024, some may be outdated\n5. Audience clarity: Mix of beginner/advanced without clear labeling\n\nAUDIT QUESTIONS TO EXPLORE:\n\n1. Is content appropriately distributed across types (tutorial/guide/reference)?\n2. Do learning paths exist, or is content fragmented?\n3. What's the right balance of breadth vs. depth?\n4. Should webhooks content be consolidated?\n5. What criteria should trigger content updates?\n\nQUALITY CRITERIA ASSESSMENT:\n\nYour criteria are clear and measurable. Suggestions:\n- Add \"Actionability\" - Can users accomplish their goal?\n- Consider \"Discoverability\" - Can users find related content?\n- \"Currency\" might need product-version context for accuracy\n```\n\n<Info>\n  **Calibration Tip:** This exploratory step is crucial. If AI misunderstands your content domain or criteria, catch it here before analyzing hundreds of pages. Refine your criteria based on AI's questions.\n</Info>\n\n---\n\n### 2.3 Duplicate Content Detection\n\nFind exact and near-duplicates that confuse users and waste maintenance effort.\n\n**Your Prompt:**\n\n```text\nNow analyzing the full inventory for duplicate and overlapping content.\n\nFull inventory (showing: Title, URL, Category, Type, Description):\n[Paste full inventory]\n\nPlease identify:\n1. Exact or near-exact duplicates (same title, very similar content)\n2. Significant topical overlap (covering same information differently)\n3. Semantic duplication (different words, same meaning)\n\nFor each duplicate cluster:\n- List the items involved\n- Explain the likely overlap\n- Assess user impact (confusion, maintenance burden)\n- Recommend: consolidate, differentiate, or redirect\n\nFocus on the 10 highest-priority duplication issues first.\n```\n\n**Expected AI Output Example:**\n\n```text\nDUPLICATE CONTENT ANALYSIS\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nDUPLICATE CLUSTER 1: Webhook Setup (HIGH PRIORITY)\n\nItems involved:\n1. \"Getting Started with Webhooks\" (/docs/webhooks/intro)\n2. \"How to Set Up Webhooks\" (/docs/guides/webhook-setup)\n3. \"Webhook Configuration\" (/docs/api/webhooks/config)\n\nLikely overlap:\nAll three appear to cover basic webhook setup and configuration. Based on \ntitles and URLs, they likely contain:\n- What webhooks are (conceptual)\n- How to register webhook endpoints\n- How to verify webhook signatures\n- Example webhook payloads\n\nUser impact:\n- Confusion: Which is the \"right\" guide to follow?\n- Inconsistency risk: If one is updated, others may become outdated\n- Maintenance burden: Three places to update for any webhook changes\n- SEO cannibalization: Competing for same search terms\n\nRecommendation: CONSOLIDATE\n\u2192 Create single authoritative \"Webhooks Guide\" at /docs/webhooks/\n\u2192 Structure as:\n  - Introduction (what webhooks are)\n  - Setup & Configuration (how to register)\n  - Security (signature verification)\n  - Examples & Use Cases\n  - Troubleshooting\n\u2192 Redirect old URLs to new consolidated guide\n\u2192 Estimated effort: 4-6 hours\n\nPriority: HIGH\n- Core feature (webhooks are frequently used)\n- High confusion potential (three competing guides)\n- Moderate consolidation effort\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nDUPLICATE CLUSTER 2: Authentication Basics (MEDIUM PRIORITY)\n\nItems involved:\n1. \"API Authentication\" (/docs/auth)\n2. \"Authentication Guide\" (/docs/guides/authentication)\n3. \"Getting Started: Authentication\" (/docs/start/auth)\n\nLikely overlap:\nAll cover API authentication basics. Possible differences:\n- Item 1 might be reference-style (all auth methods)\n- Item 2 might be how-to (step-by-step implementation)\n- Item 3 might be beginner tutorial (first time setup)\n\nUser impact:\n- Less severe than webhooks (may serve different purposes)\n- Still creates uncertainty about where to start\n- Maintenance burden across three documents\n\nRecommendation: DIFFERENTIATE or CONSOLIDATE\nOption A (Differentiate):\n\u2192 Keep all three but clarify purpose in each title/description:\n  - \"Authentication Overview\" (reference, all methods)\n  - \"Authentication Implementation Guide\" (how-to for developers)\n  - \"First-Time Authentication\" (beginner tutorial)\n\u2192 Cross-link clearly with \"see also\" sections\n\u2192 Estimated effort: 2-3 hours\n\nOption B (Consolidate):\n\u2192 Single \"Authentication Guide\" with sections for different audiences\n\u2192 Redirect old URLs\n\u2192 Estimated effort: 4-5 hours\n\nPriority: MEDIUM\n- Critical feature but possibly serving different needs\n- Moderate confusion potential\n- Requires further investigation to choose approach\n\n[Continue for clusters 3-10...]\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nSUMMARY:\n\nTotal duplicate clusters identified: 10\n- High priority (consolidate immediately): 3 clusters\n- Medium priority (consolidate or differentiate): 5 clusters\n- Low priority (monitor, address opportunistically): 2 clusters\n\nEstimated effort for all high-priority consolidations: 12-18 hours\nExpected impact: Eliminate confusion for 3 core features, reduce maintenance \nburden by ~30% for affected content\n```\n\n<Tip>\n  **Validation Step:** AI can identify potential duplicates, but you should verify by actually reading 2-3 examples from each cluster. Sometimes similar titles cover genuinely different content.\n</Tip>\n\n---\n\n### 2.4 Gap Analysis Against User Journeys\n\nThe most meaningful gaps are those that block users from accomplishing their goals.\n\n**Your Prompt:**\n\n```text\nAssess content gaps for this user journey:\n\nUSER JOURNEY: First-Time Integration\nUser: Backend developer integrating CloudAPI for the first time\nGoal: Successfully make authenticated API calls within 60 minutes\n\nJourney stages:\n1. Discovery: Understand what CloudAPI does and if it fits needs\n   Goals: Learn capabilities, see use cases, understand pricing/limits\n   \n2. Setup: Get access and set up development environment\n   Goals: Create account, get API keys, install SDK/tools\n   \n3. Authentication: Implement authentication correctly\n   Goals: Understand auth flow, implement securely, test auth\n   \n4. First API Call: Make first successful API request\n   Goals: Choose right endpoint, construct request, handle response\n   \n5. Validation: Confirm integration works and understand next steps\n   Goals: Test thoroughly, handle errors, know where to go next\n\nCurrent inventory:\n[Paste relevant portion of inventory, or reference the full inventory]\n\nFor each journey stage:\n1. What content supports it?\n2. What critical gaps would block users?\n3. What nice-to-have content is missing?\n4. Is existing content at the right depth/format?\n\nPrioritize gaps by user impact and create a gap matrix showing current vs. \nneeded coverage.\n```\n\n**Expected AI Output Example:**\n\n```text\nCONTENT GAP ANALYSIS - First-Time Integration Journey\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nSTAGE 1: DISCOVERY\nGoal: Understand what CloudAPI does and if it fits needs\n\nCurrent Coverage:\n\u2705 \"What is CloudAPI\" overview (exists)\n\u2705 \"Key Features\" page (exists)\n\u274c Use case examples (MISSING)\n\u274c Comparison to alternatives (MISSING)\n\u274c Rate limits/pricing overview (MISSING in docs, on pricing page only)\n\nCRITICAL GAPS:\n1. Use Case Library (P0)\n   - Impact: HIGH - Users can't assess fit without real examples\n   - What's needed: 5-7 concrete use case examples with code\n   - Where: New section \"Use Cases\" in Get Started\n   - Effort: 6-8 hours\n   - Why critical: Prevents wasted time for users CloudAPI doesn't fit\n\n2. Pricing & Limits Overview (P1)\n   - Impact: MEDIUM - Users fear surprise costs\n   - What's needed: Link to pricing + summary of free tier limits\n   - Where: Callout box in \"What is CloudAPI\"\n   - Effort: 1-2 hours\n   - Why critical: Common blocker in adoption decisions\n\nNICE-TO-HAVE:\n- Comparison guide (vs. competitors): P2, Low priority\n  Users can evaluate without this, but it would help\n\nCurrent content assessment:\n- \"What is CloudAPI\" is comprehensive but doesn't address use cases\n- Missing the \"Is this right for me?\" angle\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nSTAGE 2: SETUP\nGoal: Get access and set up development environment\n\nCurrent Coverage:\n\u2705 Account creation (exists - links to signup)\n\u2705 API key generation (exists)\n\u274c SDK installation (MISSING for Python, Ruby)\n\u274c Development environment setup (MISSING)\n\u2705 Postman collection (exists)\n\nCRITICAL GAPS:\n1. SDK Installation Guides (P0)\n   - Impact: HIGH - Many users prefer SDKs over raw HTTP\n   - What's needed: Installation + basic setup for Node.js, Python, Ruby\n   - Where: New \"SDK Quickstarts\" section\n   - Effort: 4-6 hours total (1-2 hours per SDK)\n   - Why critical: Reduces time-to-first-call dramatically\n\n2. Environment Setup Guide (P1)\n   - Impact: MEDIUM - Some users struggle with dev environment\n   - What's needed: Environment variables, testing vs. production setup\n   - Where: Expand \"Getting Started\" section\n   - Effort: 2-3 hours\n   - Why critical: Prevents common early mistakes (using prod keys in dev)\n\nCurrent content assessment:\n- \"Getting API Keys\" is clear but doesn't explain key management\n- No guidance on environment setup best practices\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nSTAGE 3: AUTHENTICATION\nGoal: Implement authentication correctly\n\nCurrent Coverage:\n\u2705 OAuth 2.0 documentation (exists - very detailed)\n\u2705 API key authentication (exists)\n\u274c Authentication quick comparison (MISSING)\n\u274c Common auth errors troubleshooting (MISSING)\n\u274c Security best practices (MISSING)\n\nCRITICAL GAPS:\n1. \"Which Auth Method?\" Decision Guide (P0)\n   - Impact: HIGH - Users waste time choosing wrong auth method\n   - What's needed: Flow chart or decision tree + comparison table\n   - Where: Before detailed auth docs, in overview\n   - Effort: 2-3 hours\n   - Why critical: Prevents users from implementing OAuth when API keys sufficient\n\n2. Authentication Troubleshooting (P0)\n   - Impact: HIGH - Auth errors are top support issue\n   - What's needed: Common errors, causes, solutions\n   - Where: New \"Troubleshooting Auth\" page\n   - Effort: 3-4 hours\n   - Why critical: Reduces support tickets by 20-30%\n\nNICE-TO-HAVE:\n- Security best practices: P2, should be covered but not blocking\n\nCurrent content assessment:\n- OAuth docs are too detailed for beginners (intimidating)\n- Need progressive disclosure: simple path, then advanced options\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nSTAGE 4: FIRST API CALL\nGoal: Make first successful API request\n\nCurrent Coverage:\n\u2705 API endpoints documented (exists)\n\u2705 \"Your First API Call\" tutorial (exists)\n\u274c Response handling guide (MISSING)\n\u274c Error code reference (MISSING)\n\u274c Quick reference / cheat sheet (MISSING)\n\nCRITICAL GAPS:\n1. Error Code Reference (P0)\n   - Impact: HIGH - Users stuck when things go wrong\n   - What's needed: All HTTP errors, CloudAPI-specific codes, solutions\n   - Where: New \"Error Reference\" page\n   - Effort: 4-5 hours\n   - Why critical: Unblocks users immediately when errors occur\n\n2. API Cheat Sheet (P1)\n   - Impact: MEDIUM - Convenient but not blocking\n   - What's needed: One-page quick reference of common endpoints/patterns\n   - Where: Standalone page + PDF download\n   - Effort: 3-4 hours\n   - Why critical: Reduces time searching docs once users are productive\n\nCurrent content assessment:\n- \"Your First API Call\" is excellent (clear, comprehensive)\n- But doesn't prepare users for what happens when it fails\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nSTAGE 5: VALIDATION\nGoal: Confirm integration works and understand next steps\n\nCurrent Coverage:\n\u274c Testing strategies (MISSING)\n\u274c Integration checklist (MISSING)\n\u274c \"What's next?\" recommendations (MISSING)\n\u274c Sample applications (MISSING)\n\nCRITICAL GAPS:\n1. Integration Testing Guide (P0)\n   - Impact: HIGH - Users ship untested integrations, cause issues\n   - What's needed: How to test API integration, common pitfalls, test checklist\n   - Where: New \"Testing Your Integration\" guide\n   - Effort: 4-5 hours\n   - Why critical: Prevents production issues, reduces support burden\n\n2. \"Next Steps\" Navigation (P1)\n   - Impact: MEDIUM - Users unsure what to learn next\n   - What's needed: Curated learning paths based on use case\n   - Where: End of \"First API Call\" tutorial + standalone page\n   - Effort: 2-3 hours\n   - Why critical: Increases depth of integration, engagement\n\nNICE-TO-HAVE:\n- Sample applications: P2, helpful but users can build from docs\n\nCurrent content assessment:\n- Journey essentially \"ends\" after first call\n- No guidance on production readiness or next steps\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nGAP MATRIX SUMMARY:\n\nLegend: \u2705 Adequate | \u26a0\ufe0f Partial | \u274c Missing\n\n| Journey Stage | Coverage | Critical Gaps | Priority |\n|--------------|----------|---------------|----------|\n| Discovery    | \u26a0\ufe0f Partial | Use cases (P0), Pricing (P1) | HIGH |\n| Setup        | \u26a0\ufe0f Partial | SDK setup (P0), Env setup (P1) | HIGH |\n| Authentication | \u2705 Adequate | Auth decision (P0), Troubleshooting (P0) | CRITICAL |\n| First Call   | \u2705 Adequate | Error reference (P0), Cheat sheet (P1) | HIGH |\n| Validation   | \u274c Missing | Testing guide (P0), Next steps (P1) | CRITICAL |\n\nPRIORITY GAPS (P0 - Address Immediately):\n1. Authentication decision guide - 2-3 hours\n2. Use case library - 6-8 hours\n3. Authentication troubleshooting - 3-4 hours\n4. Error code reference - 4-5 hours\n5. SDK installation guides - 4-6 hours\n6. Integration testing guide - 4-5 hours\n\nTotal P0 effort: ~24-33 hours\nExpected impact: Reduce time-to-first-call by 40%, reduce auth support tickets by 30%\n\nSECONDARY GAPS (P1 - Address This Quarter):\n[Listed with effort estimates...]\n\nOVERALL ASSESSMENT:\nJourney coverage: 60% adequate\nMajor blocker: Authentication and validation stages need significant work\nStrengths: First API call tutorial is excellent foundation\nOpportunity: Build validation stage from scratch (currently 0% coverage)\n```\n\n<Warning>\n  **Gap Analysis Reality Check:** Not every gap needs to be filled immediately. Prioritize gaps that:\n  1. Block users from accomplishing critical goals\n  2. Cause frequent support tickets\n  3. Have high impact relative to effort\n  \n  Some \"nice-to-have\" gaps can stay unfilled indefinitely if resources are limited.\n</Warning>\n\n---\n\n### 2.5 Quality Pattern Analysis\n\nIdentify systemic quality issues across your content inventory.\n\n**Your Prompt:**\n\n```text\nAnalyze quality patterns across the inventory:\n\n[Paste inventory with quality signals: update dates, word counts, categories]\n\nQuality criteria to apply:\n[Reference earlier quality criteria]\n\nIdentify:\n1. Clusters of quality issues (e.g., certain categories consistently lower quality)\n2. Items that likely need review (based on age, brevity, or other signals)\n3. Patterns suggesting systemic issues vs. one-off problems\n4. Sections where quality is consistently high (learn from these)\n5. Correlation between quality signals (e.g., newer content more complete?)\n\nPrioritize the top 15 items for quality improvement based on:\n- User impact (traffic, importance to key journeys)\n- Severity of quality issue\n- Ease of improvement\n\nPresent as prioritized list with specific improvement recommendations.\n```\n\n**Expected Output Pattern:**\n\nThe AI will identify patterns like:\n- \"All content updated before 2023 lacks code examples\"\n- \"API Reference section consistently high quality (5\u2b50), Guides section variable (2-4\u2b50)\"\n- \"Content under 500 words almost always incomplete\"\n- \"Certain authors consistently produce higher quality\"\n\nThis helps you identify not just individual problems, but systemic issues to address.\n\n---\n\n### 2.6 Comparative Analysis Techniques\n\nCompare your content against benchmarks, standards, or competitors.\n\n**Competitive Gap Analysis Prompt:**\n\n```text\nI'm comparing our documentation to industry standards.\n\nOur content coverage:\n[Paste your inventory categories and counts]\n\nIndustry standard/competitor structure:\n[Paste benchmark structure or competitor table of contents]\n\nIdentify:\n1. Topic areas where we're missing coverage\n2. Areas where we have more comprehensive coverage\n3. Structural differences in how content is organized\n4. Recommendations for bringing our coverage in line with expectations\n\nPrioritize gaps that likely impact user success.\n```\n\n**Standards Compliance Check:**\n\n```text\nEvaluate this content inventory against the Di\u00e1taxis framework:\n\nDi\u00e1taxis requires four content types:\n- Tutorials: Learning-oriented, step-by-step\n- How-to Guides: Task-oriented, problem-solving\n- Reference: Information-oriented, technical specs\n- Explanation: Understanding-oriented, concepts\n\nOur current content:\n[Paste inventory]\n\nFor each Di\u00e1taxis category:\n1. What content we have that fits\n2. What's missing\n3. Content that's miscategorized\n4. Recommendations for restructuring\n\nFocus on the biggest structural misalignments first.\n```\n\n<Info>\n  **Framework Context:** Di\u00e1taxis is a systematic approach to technical documentation that organizes content into four quadrants. Many successful documentation sites (Django, Stripe, Divio) follow this framework. Learn more at [diataxis.fr](https://diataxis.fr)\n</Info>\n\n---\n\n### 2.7 Multi-Pass Audit Strategies\n\nFor complex audits, use a phased approach with increasingly focused prompts.\n\n**Pass 1: High-Level Structure**\n\n```text\nFirst pass review - focus on structure and organization only:\n\n[Paste inventory]\n\nAssess:\n1. Overall information architecture (logical grouping?)\n2. Navigation and hierarchy (clear paths?)\n3. Major structural gaps\n4. Sections that seem misplaced\n\nDon't evaluate individual page quality yet\u2014stay at the structural level.\n```\n\n**Pass 2: Category-Level Analysis**\n\n```text\nSecond pass - analyze the \"Getting Started\" category in detail:\n\n[Paste Getting Started inventory items]\n\nEvaluate:\n1. Completeness for user onboarding\n2. Logical sequence and progression\n3. Overlap or redundancy within this category\n4. Quality red flags (based on titles/descriptions)\n5. Missing elements compared to user journey\n\nProvide specific, actionable recommendations.\n```\n\n**Pass 3: Cross-Category Relationships**\n\n```text\nThird pass - analyze relationships between categories:\n\nCategories: [List main categories]\nRepresentative items: [Paste sample from each category]\n\nIdentify:\n1. Content that should be connected but isn't\n2. Duplicate coverage across categories\n3. Logical progression paths users would follow\n4. Navigation or wayfinding gaps between categories\n\nMap the top 5 priority cross-category improvements.\n```\n\n---",
            "hydration_source_header": "2. Prompt Strategies for Content Analysis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "quick-wins-build-momentum",
            "title": "Quick Wins Build Momentum",
            "partOf": "phased-action-planning",
            "lines": "1665-1670",
            "crossModule": false,
            "content": "**Metrics:**\n- Time-to-first-API-call: 75 min \u2192 38 min (49% improvement)\n- Developer NPS: 32 \u2192 48 (50% improvement)\n- Documentation support tickets: -35%\n- Developer satisfaction: \"Documentation\" rating 3.2 \u2192 4.4 out of 5\n\n**Process Improvements:**\n- Quarterly documentation review process established\n- Content quality standards documented\n- Cross-team collaboration on shared content\n- AI-assisted monitoring for duplicates and gaps\n\n**Lessons Learned:**\n- AI-assisted audit saved ~120 hours vs. manual approach\n- Validation was critical (10% of AI findings were incorrect)\n- Quick wins (Phase 1) built momentum for larger changes\n- Executive summary got leadership buy-in immediately\n\n<Info>\n  **Case Study Insight:** CloudTech's success came from three factors: (1) using AI for scale analysis, (2) ruthless prioritization (focused on P0 gaps only initially), and (3) measuring impact with clear metrics.\n</Info>\n\n---",
            "hydration_source_header": "Results (6 Months Post-Audit)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "executive-summary-gets-buy-in",
            "title": "Executive Summary Gets Buy-In",
            "partOf": "documentation-deliverables",
            "lines": "1670",
            "crossModule": false,
            "retrievalQuestions": [
              "How do I get leadership buy-in for content improvements?"
            ],
            "content": "Now it's your turn! Conduct a complete content audit and create an actionable improvement plan.\n\n### Project Brief\n\n**Objective:** Audit documentation for a real site and deliver a comprehensive improvement plan.\n\n**Scope:** Choose one:\n- **Option A:** Your organization's documentation (most relevant)\n- **Option B:** Open-source project docs (Python, React, Vue, etc.)\n- **Option C:** Publicly available API documentation (Stripe, Twilio, etc.)\n\n**Minimum Requirements:**\n- Analyze at least 50 pages\n- Map content to at least one user journey\n- Identify duplicates, gaps, and quality issues\n- Create prioritized action plan\n\n---\n\n### Deliverables\n\n<AccordionGroup>\n  <Accordion title=\"Deliverable 1: Content Inventory (Spreadsheet)\">\n    **Requirements:**\n    - Minimum 50 items analyzed\n    - Required fields:\n      - Title\n      - URL\n      - Category\n      - Content type\n      - Last updated date\n      - Word count\n      - Brief description\n    \n    **Optional but recommended:**\n    - Author\n    - Status\n    - Traffic data (if available)\n    - Quality signals\n    \n    **Format:** Excel or Google Sheets\n    \n    **Evaluation criteria:**\n    - Completeness of inventory\n    - Metadata quality\n    - Categorization consistency\n  </Accordion>\n  \n  <Accordion title=\"Deliverable 2: Audit Findings Report (3-5 pages)\">\n    **Required sections:**\n    \n    **1. Duplicate Content Analysis**\n    - Top 5-10 duplicate clusters\n    - Consolidation recommendations\n    - Effort estimates\n    \n    **2. Content Gap Analysis**\n    - User journey defined\n    - Gaps mapped to journey stages\n    - P0/P1/P2 prioritization\n    - Effort estimates\n    \n    **3. Quality Assessment**\n    - Top 10-15 quality issues\n    - Patterns identified\n    - Specific improvement recommendations\n    \n    **4. Structural Issues**\n    - Navigation/IA problems\n    - Inconsistencies\n    - Organizational recommendations\n    \n    **Format:** PDF or Word document\n    \n    **Evaluation criteria:**\n    - Thoroughness of analysis\n    - Evidence-based findings\n    - Actionable recommendations\n  </Accordion>\n  \n  <Accordion title=\"Deliverable 3: Prioritized Action Plan (1-2 pages)\">\n    **Required elements:**\n    \n    **Phased Roadmap:**\n    - Phase 1: Immediate (Week 1-2)\n    - Phase 2: Foundation (Month 1-2)\n    - Phase 3: Strategic (Month 3-6)\n    \n    **For each phase:**\n    - Specific deliverables\n    - Effort estimates (hours)\n    - Expected outcomes\n    - Success metrics\n    \n    **Resource Requirements:**\n    - Team composition\n    - Total hours\n    - Timeline\n    - Tools needed\n    \n    **Format:** PDF, slide deck, or roadmap tool\n    \n    **Evaluation criteria:**\n    - Realistic estimates\n    - Clear prioritization\n    - Measurable outcomes\n  </Accordion>\n  \n  <Accordion title=\"Deliverable 4: Executive Summary (1 page)\">\n    **Required content:**\n    \n    **Overview:**\n    - Audit scope\n    - Methodology\n    - Timeline\n    \n    **Key Findings (3-5 bullets):**\n    - Most critical issues\n    - Impact on users\n    \n    **Top Recommendations (3-5 items):**\n    - Specific actions\n    - Expected benefits\n    \n    **Resource Requirements:**\n    - Hours needed\n    - Timeline\n    - ROI/impact\n    \n    **Format:** PDF (single page, executive-friendly)\n    \n    **Evaluation criteria:**\n    - Clarity for non-technical audience\n    - Compelling case for action\n    - Professional presentation\n  </Accordion>\n  \n  <Accordion title=\"Deliverable 5: Sample AI Prompts (Appendix)\">\n    **Include 3-5 of your most effective prompts:**\n    \n    For each prompt:\n    - Context (what you were trying to accomplish)\n    - Full prompt text\n    - Key insights from AI response\n    - How you validated/used the output\n    \n    **Purpose:** Demonstrate AI-human collaboration\n    \n    **Evaluation criteria:**\n    - Prompt quality and specificity\n    - Effective use of AI capabilities\n    - Critical evaluation of outputs\n  </Accordion>\n  \n  <Accordion title=\"Optional: Brief Reflection (1 paragraph)\">\n    **Reflection questions:**\n    - What surprised you most?\n    - What would you do differently next time?\n    - How did AI change your audit approach?\n    - What was the biggest challenge?\n    \n    **Purpose:** Demonstrate learning and self-awareness\n  </Accordion>\n</AccordionGroup>\n\n---\n\n### Evaluation Criteria\n\nYour project will be assessed on:\n\n**1. Audit Rigor (30%)**\n- \u2713 Comprehensive inventory with rich metadata\n- \u2713 Systematic application of quality criteria\n- \u2713 Thorough gap analysis against user journey\n- \u2713 Evidence-based findings (not assumptions)\n- \u2713 Appropriate validation of AI outputs\n\n**2. AI Prompt Quality (25%)**\n- \u2713 Effective use of AI for scale analysis\n- \u2713 Clear, specific prompts with context\n- \u2713 Appropriate prompts for different tasks\n- \u2713 Critical evaluation of AI outputs\n- \u2713 Demonstration of human-AI partnership\n\n**3. Actionability (25%)**\n- \u2713 Clear prioritization (P0/P1/P2/P3)\n- \u2713 Realistic effort estimates\n- \u2713 Specific, implementable recommendations\n- \u2713 Clear success metrics\n- \u2713 Resource requirements defined\n\n**4. Documentation Quality (20%)**\n- \u2713 Clear, well-organized deliverables\n- \u2713 Appropriate format for each audience\n- \u2713 Professional presentation\n- \u2713 Reproducible methodology\n- \u2713 Executive summary compelling\n\n---\n\n### Common Pitfalls to Avoid\n\n<Warning>\n  **Avoid These Common Mistakes:**\n  \n  \u274c **Scope creep** - Don't try to audit everything. Focus on defined section.\n  \n  \u274c **Over-reliance on AI** - Always validate AI findings with spot-checks.\n  \n  \u274c **Vague recommendations** - \"Improve quality\" isn't actionable. Be specific.\n  \n  \u274c **Ignoring effort** - Recommendations must include realistic time estimates.\n  \n  \u274c **Missing user context** - Gap analysis must tie to actual user journeys, not just categories.\n  \n  \u274c **Lack of prioritization** - Everything can't be P0. Make hard priority choices.\n  \n  \u274c **Analysis paralysis** - Aim for actionable insights, not perfect analysis.\n</Warning>\n\n---\n\n### Success Indicators\n\n**You've done well if:**\n\n\u2705 You can defend every priority decision with data\n\n\u2705 Your recommendations are specific enough to assign and schedule\n\n\u2705 A stakeholder could approve resources based on your executive summary\n\n\u2705 You identified insights you wouldn't have found manually\n\n\u2705 You saved 60%+ time vs. manual audit while maintaining quality\n\n\u2705 You demonstrated appropriate skepticism of AI outputs\n\n\u2705 Your action plan includes realistic timelines and effort estimates\n\n---\n\n### Time Budget\n\n**Recommended time allocation:**\n\n- Preparation & inventory: 2-3 hours\n- AI-assisted analysis: 3-4 hours\n- Validation & refinement: 2-3 hours\n- Documentation: 2-3 hours\n- **Total: 9-13 hours**\n\n**Compare to traditional manual audit:**\n- Manual audit: 40-80 hours\n- AI-assisted: 9-13 hours\n- **Time saved: 60-80%**\n\n---",
            "hydration_source_header": "7. Self-Assessment Project",
            "hydration_method": "line_proximity"
          },
          {
            "id": "spot-check-10-percent",
            "title": "Spot-Check 10% of AI Findings",
            "partOf": "validation-is-critical",
            "lines": "800-810, 1665",
            "crossModule": false,
            "retrievalQuestions": [
              "What percentage of AI findings should I verify?"
            ],
            "content": "Identify systemic quality issues across your content inventory.\n\n**Your Prompt:**\n\n```text\nAnalyze quality patterns across the inventory:\n\n[Paste inventory with quality signals: update dates, word counts, categories]\n\nQuality criteria to apply:\n[Reference earlier quality criteria]\n\nIdentify:\n1. Clusters of quality issues (e.g., certain categories consistently lower quality)\n2. Items that likely need review (based on age, brevity, or other signals)\n3. Patterns suggesting systemic issues vs. one-off problems\n4. Sections where quality is consistently high (learn from these)\n5. Correlation between quality signals (e.g., newer content more complete?)\n\nPrioritize the top 15 items for quality improvement based on:\n- User impact (traffic, importance to key journeys)\n- Severity of quality issue\n- Ease of improvement\n\nPresent as prioritized list with specific improvement recommendations.\n```\n\n**Expected Output Pattern:**\n\nThe AI will identify patterns like:\n- \"All content updated before 2023 lacks code examples\"\n- \"API Reference section consistently high quality (5\u2b50), Guides section variable (2-4\u2b50)\"\n- \"Content under 500 words almost always incomplete\"\n- \"Certain authors consistently produce higher quality\"\n\nThis helps you identify not just individual problems, but systemic issues to address.\n\n---",
            "hydration_source_header": "2.5 Quality Pattern Analysis",
            "hydration_method": "line_proximity"
          }
        ],
        "patterns": [
          {
            "id": "content-inventory-pattern",
            "title": "Content Inventory Pattern",
            "purpose": "Structure for cataloging content",
            "lines": "128-155",
            "content": "A good content inventory is the foundation of any audit. At minimum, capture:\n\n**Essential fields:**\n- Title\n- URL\n- Category/section\n- Content type (tutorial, reference, guide, etc.)\n- Last updated date\n- Word count (approximate)\n\n**Recommended fields:**\n- Author\n- Status (published, draft, archived)\n- Primary audience\n- Related content (links to/from)\n- Tags/keywords\n\n<CodeGroup>\n\n```csv Example Inventory (CSV)\nTitle,URL,Category,Type,Last_Updated,Word_Count,Author\nGetting Started,/docs/start,Onboarding,Tutorial,2024-01-15,850,Jane\nAPI Authentication,/docs/auth,API,Guide,2023-12-20,1200,Alex\nUser Endpoints,/docs/api/users,API,Reference,2024-02-01,2100,Chris\nError Handling,/docs/errors,Guides,Explanation,2023-11-10,900,Sam\n```\n\n```text Example Inventory (Formatted)\nCONTENT INVENTORY - DEVELOPER DOCUMENTATION\n\nItem 1:\n- Title: \"Getting Started with CloudAPI\"\n- URL: /docs/getting-started\n- Category: Onboarding\n- Type: Tutorial\n- Updated: 2024-01-15\n- Words: ~850\n- Description: Step-by-step guide for first API call\n\nItem 2:\n- Title: \"API Authentication Guide\"\n- URL: /docs/authentication\n- Category: Security\n- Type: How-to Guide\n- Updated: 2023-12-20\n- Words: ~1200\n- Description: How to authenticate API requests using OAuth 2.0\n\n[Continue for all items...]\n```\n\n</CodeGroup>\n\n---",
            "hydration_source_header": "1.1 Creating Your Content Inventory",
            "hydration_method": "line_proximity"
          },
          {
            "id": "quality-criteria-pattern",
            "title": "Quality Criteria Definition Pattern",
            "purpose": "How to define measurable quality standards",
            "lines": "158-240",
            "retrievalQuestions": [
              "How do I create a content inventory?"
            ],
            "content": "AI needs clear criteria to assess content quality. Define what \"good\" looks like for your documentation.\n\n**Sample quality criteria:**\n\n<AccordionGroup>\n  <Accordion title=\"Completeness\">\n    **Indicators:**\n    - Covers topic comprehensively\n    - Includes code examples\n    - Has prerequisites listed\n    - Links to related content\n    \n    **Quality scale:**\n    - \u2b50\u2b50\u2b50\u2b50\u2b50 Complete with examples and context\n    - \u2b50\u2b50\u2b50 Covers basics but missing examples\n    - \u2b50 Incomplete or skeletal content\n  </Accordion>\n  \n  <Accordion title=\"Currency\">\n    **Indicators:**\n    - Updated within last 6 months\n    - References current product version\n    - No deprecated information\n    - Matches current UI/API\n    \n    **Quality scale:**\n    - \u2b50\u2b50\u2b50\u2b50\u2b50 Updated within 3 months\n    - \u2b50\u2b50\u2b50 3-12 months old but still accurate\n    - \u2b50 Over 12 months, likely outdated\n  </Accordion>\n  \n  <Accordion title=\"Clarity\">\n    **Indicators:**\n    - Clear, concise writing\n    - Logical structure\n    - Appropriate for target audience\n    - Good use of headings/formatting\n    \n    **Quality scale:**\n    - \u2b50\u2b50\u2b50\u2b50\u2b50 Crystal clear, well-structured\n    - \u2b50\u2b50\u2b50 Understandable but could improve\n    - \u2b50 Confusing or poorly organized\n  </Accordion>\n  \n  <Accordion title=\"Accuracy\">\n    **Indicators:**\n    - Technically correct\n    - Code examples work\n    - No conflicting information\n    - Matches product behavior\n    \n    **Quality scale:**\n    - \u2b50\u2b50\u2b50\u2b50\u2b50 Verified accurate\n    - \u2b50\u2b50\u2b50 Generally accurate, minor issues\n    - \u2b50 Contains errors or outdated info\n  </Accordion>\n</AccordionGroup>\n\n**Your AI Prompt Template:**\n\n```text\nI'm conducting a content audit and need to establish quality criteria.\n\nMy documentation covers: [Brief description]\nPrimary audience: [User type and level]\nKey user goals: [What users need to accomplish]\n\nHelp me define 5-7 quality criteria appropriate for this content and audience.\n\nFor each criterion:\n1. Name and definition\n2. What \"good\" looks like\n3. What \"poor\" looks like\n4. How to measure it (quantitative or qualitative indicators)\n5. Why it matters to users\n\nFocus on criteria that can be consistently applied across 200+ pages.\n```\n\n---",
            "hydration_source_header": "1.2 Defining Quality Criteria",
            "hydration_method": "line_proximity"
          },
          {
            "id": "audit-charter-pattern",
            "title": "Audit Charter/Scope Pattern",
            "purpose": "How to define audit scope and objectives",
            "lines": "245-295",
            "content": "Not all audits need to cover everything. Define your scope clearly.\n\n**Sample audit charter:**\n\n```text\nCONTENT AUDIT CHARTER\n\nAudit Name: Q1 2024 Developer Documentation Audit\nAudit Lead: [Your name]\nDate Range: [Start] - [End]\n\nSCOPE:\nIn scope:\n- Developer documentation (API Reference, Guides, Tutorials)\n- Approximately 280 pages\n- English language only\n\nOut of scope:\n- Marketing content\n- Blog posts\n- Support knowledge base\n- Non-English translations\n\nPRIMARY OBJECTIVES:\n1. Identify critical gaps in developer onboarding journey\n2. Find duplicate or conflicting content causing confusion\n3. Assess documentation completeness vs. competitive standards\n4. Prioritize outdated content for updates\n\nSUCCESS CRITERIA:\n- Complete inventory of all in-scope content\n- Gap analysis mapped to 3 primary user journeys\n- Prioritized list of top 20 improvements\n- Actionable recommendations with effort estimates\n\nDELIVERABLES:\n1. Content inventory spreadsheet\n2. Audit findings report (5-10 pages)\n3. Prioritized improvement plan\n4. Executive summary (1-2 pages)\n\nTIMELINE:\n- Week 1: Inventory and initial analysis\n- Week 2: Gap analysis and quality assessment\n- Week 3: Validation and recommendations\n- Week 4: Final report and presentation\n```\n\n<Warning>\n  **Scope Creep Alert:** It's tempting to audit everything once you start. Stay focused on your defined scope and objectives. You can always conduct follow-up audits for other content areas.\n</Warning>\n\n---",
            "hydration_source_header": "1.3 Creating Audit Scope and Objectives",
            "hydration_method": "line_proximity"
          },
          {
            "id": "duplicate-detection-pattern",
            "title": "Duplicate Content Detection Pattern",
            "purpose": "Finding exact and semantic duplicates",
            "lines": "390-550",
            "retrievalQuestions": [
              "How do I find duplicate content with AI?"
            ],
            "content": "Find exact and near-duplicates that confuse users and waste maintenance effort.\n\n**Your Prompt:**\n\n```text\nNow analyzing the full inventory for duplicate and overlapping content.\n\nFull inventory (showing: Title, URL, Category, Type, Description):\n[Paste full inventory]\n\nPlease identify:\n1. Exact or near-exact duplicates (same title, very similar content)\n2. Significant topical overlap (covering same information differently)\n3. Semantic duplication (different words, same meaning)\n\nFor each duplicate cluster:\n- List the items involved\n- Explain the likely overlap\n- Assess user impact (confusion, maintenance burden)\n- Recommend: consolidate, differentiate, or redirect\n\nFocus on the 10 highest-priority duplication issues first.\n```\n\n**Expected AI Output Example:**\n\n```text\nDUPLICATE CONTENT ANALYSIS\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nDUPLICATE CLUSTER 1: Webhook Setup (HIGH PRIORITY)\n\nItems involved:\n1. \"Getting Started with Webhooks\" (/docs/webhooks/intro)\n2. \"How to Set Up Webhooks\" (/docs/guides/webhook-setup)\n3. \"Webhook Configuration\" (/docs/api/webhooks/config)\n\nLikely overlap:\nAll three appear to cover basic webhook setup and configuration. Based on \ntitles and URLs, they likely contain:\n- What webhooks are (conceptual)\n- How to register webhook endpoints\n- How to verify webhook signatures\n- Example webhook payloads\n\nUser impact:\n- Confusion: Which is the \"right\" guide to follow?\n- Inconsistency risk: If one is updated, others may become outdated\n- Maintenance burden: Three places to update for any webhook changes\n- SEO cannibalization: Competing for same search terms\n\nRecommendation: CONSOLIDATE\n\u2192 Create single authoritative \"Webhooks Guide\" at /docs/webhooks/\n\u2192 Structure as:\n  - Introduction (what webhooks are)\n  - Setup & Configuration (how to register)\n  - Security (signature verification)\n  - Examples & Use Cases\n  - Troubleshooting\n\u2192 Redirect old URLs to new consolidated guide\n\u2192 Estimated effort: 4-6 hours\n\nPriority: HIGH\n- Core feature (webhooks are frequently used)\n- High confusion potential (three competing guides)\n- Moderate consolidation effort\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nDUPLICATE CLUSTER 2: Authentication Basics (MEDIUM PRIORITY)\n\nItems involved:\n1. \"API Authentication\" (/docs/auth)\n2. \"Authentication Guide\" (/docs/guides/authentication)\n3. \"Getting Started: Authentication\" (/docs/start/auth)\n\nLikely overlap:\nAll cover API authentication basics. Possible differences:\n- Item 1 might be reference-style (all auth methods)\n- Item 2 might be how-to (step-by-step implementation)\n- Item 3 might be beginner tutorial (first time setup)\n\nUser impact:\n- Less severe than webhooks (may serve different purposes)\n- Still creates uncertainty about where to start\n- Maintenance burden across three documents\n\nRecommendation: DIFFERENTIATE or CONSOLIDATE\nOption A (Differentiate):\n\u2192 Keep all three but clarify purpose in each title/description:\n  - \"Authentication Overview\" (reference, all methods)\n  - \"Authentication Implementation Guide\" (how-to for developers)\n  - \"First-Time Authentication\" (beginner tutorial)\n\u2192 Cross-link clearly with \"see also\" sections\n\u2192 Estimated effort: 2-3 hours\n\nOption B (Consolidate):\n\u2192 Single \"Authentication Guide\" with sections for different audiences\n\u2192 Redirect old URLs\n\u2192 Estimated effort: 4-5 hours\n\nPriority: MEDIUM\n- Critical feature but possibly serving different needs\n- Moderate confusion potential\n- Requires further investigation to choose approach\n\n[Continue for clusters 3-10...]\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nSUMMARY:\n\nTotal duplicate clusters identified: 10\n- High priority (consolidate immediately): 3 clusters\n- Medium priority (consolidate or differentiate): 5 clusters\n- Low priority (monitor, address opportunistically): 2 clusters\n\nEstimated effort for all high-priority consolidations: 12-18 hours\nExpected impact: Eliminate confusion for 3 core features, reduce maintenance \nburden by ~30% for affected content\n```\n\n<Tip>\n  **Validation Step:** AI can identify potential duplicates, but you should verify by actually reading 2-3 examples from each cluster. Sometimes similar titles cover genuinely different content.\n</Tip>\n\n---",
            "hydration_source_header": "2.3 Duplicate Content Detection",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "gap-analysis-pattern",
            "title": "Gap Analysis Against User Journey Pattern",
            "purpose": "Mapping content to journey stages",
            "lines": "555-790",
            "retrievalQuestions": [
              "How do I analyze content gaps?"
            ],
            "content": "The most meaningful content gaps are those that prevent users from accomplishing their goals. Let's map content systematically against user journeys.\n\n### 4.1 Mapping Content to User Journeys\n\n**First, define your primary user journeys:**\n\n```text\nUSER JOURNEY TEMPLATE\n\nJourney Name: [Descriptive name]\nUser Persona: [Who is this user?]\nStarting Point: [Where does the journey begin?]\nEnd Goal: [What does success look like?]\n\nStages:\n1. [Stage name]\n   - User goal: [What they want to accomplish]\n   - Expected content: [What would help them]\n   - Current content: [What exists now - TBD in analysis]\n   \n2. [Next stage...]\n   [Continue for 4-7 stages]\n\nSuccess Criteria:\n- [How do you know the journey is well-supported?]\n```\n\n---\n\n### 4.2 Identifying Journey Gaps\n\n**Your Prompt:**\n\n```text\nMap our content inventory to this user journey and identify gaps:\n\nJourney: [Paste your journey definition]\n\nCurrent inventory:\n[Paste inventory]\n\nFor each journey stage:\n1. What content exists that supports this stage?\n2. What's the quality/appropriateness of existing content?\n3. What critical gaps would block users?\n4. What nice-to-have content is missing?\n5. Rate overall coverage: Complete (5) / Adequate (3-4) / Partial (2) / Missing (1)\n\nCreate a gap matrix showing:\n- Journey stages (rows)\n- Coverage assessment (columns)\n- Priority gaps to address\n- Estimated effort for each gap\n\nFocus on gaps that would prevent users from advancing to the next stage.\n```\n\n---\n\n### 4.3 Prioritizing Gap Remediation\n\nNot all gaps are equal\u2014prioritize based on user impact and business value.\n\n**Gap Prioritization Framework Prompt:**\n\n```text\nPrioritize these identified content gaps:\n\n[Paste list of gaps identified]\n\nFor each gap, assess:\n1. User impact: How many users are affected? How severely?\n2. Business impact: Effect on adoption, retention, support costs\n3. Urgency: Is this blocking current users? Upcoming product launch?\n4. Effort: Content creation complexity and resource requirements\n5. Dependencies: Does this gap block other improvements?\n\nAssign priority level (P0/P1/P2/P3) and recommend sequence for addressing gaps.\n\nP0 = Blocking critical user paths, address immediately\nP1 = Significant user friction, address this quarter\nP2 = Nice to have, address this year\nP3 = Low impact, address opportunistically\n\nFor P0 and P1 gaps, provide:\n- Recommended content format (tutorial/guide/reference)\n- Estimated effort (hours)\n- Key messages to cover\n- Success metrics\n```\n\n<CardGroup cols={2}>\n  <Card title=\"High-Impact Gaps\" icon=\"fire\">\n    **Prioritize when:**\n    - Blocks critical user goals\n    - Generates support tickets\n    - Affects many users\n    - Quick to address\n    \n    Example: Missing error code reference\n  </Card>\n  \n  <Card title=\"Low-Priority Gaps\" icon=\"clock\">\n    **Defer when:**\n    - Nice-to-have only\n    - Affects few users\n    - Workarounds exist\n    - High effort required\n    \n    Example: Edge case documentation\n  </Card>\n</CardGroup>\n\n---\n\n### 4.4 Documenting Gap Analysis Findings\n\nCreate documentation that drives action.\n\n**Gap Analysis Report Structure:**\n\n```text\nCreate an executive summary of gap analysis findings:\n\nInput data:\n- User journey map: [Paste or describe]\n- Identified gaps: [Paste gap list]\n- Current content inventory: [Reference to full inventory]\n\nExecutive Summary structure:\n1. Overview: Audit scope, methodology, key findings\n2. Critical Gaps: Top 3-5 gaps blocking user success\n3. Gap Categories: Organize remaining gaps by type or theme\n4. Impact Assessment: Overall user experience impact\n5. Recommendations: Prioritized action plan with timeline\n6. Quick Wins: High-impact, low-effort improvements to start immediately\n\nKeep summary to 1-2 pages. Support with detailed appendix if needed.\n\nFormat for executive audience\u2014focus on impact and recommendations, not methodology.\n```\n\n---",
            "hydration_source_header": "4. Gap Analysis Against User Journeys",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "quality-pattern-analysis",
            "title": "Quality Pattern Analysis",
            "purpose": "Finding systemic quality issues",
            "lines": "795-865",
            "content": "Identify systemic quality issues across your content inventory.\n\n**Your Prompt:**\n\n```text\nAnalyze quality patterns across the inventory:\n\n[Paste inventory with quality signals: update dates, word counts, categories]\n\nQuality criteria to apply:\n[Reference earlier quality criteria]\n\nIdentify:\n1. Clusters of quality issues (e.g., certain categories consistently lower quality)\n2. Items that likely need review (based on age, brevity, or other signals)\n3. Patterns suggesting systemic issues vs. one-off problems\n4. Sections where quality is consistently high (learn from these)\n5. Correlation between quality signals (e.g., newer content more complete?)\n\nPrioritize the top 15 items for quality improvement based on:\n- User impact (traffic, importance to key journeys)\n- Severity of quality issue\n- Ease of improvement\n\nPresent as prioritized list with specific improvement recommendations.\n```\n\n**Expected Output Pattern:**\n\nThe AI will identify patterns like:\n- \"All content updated before 2023 lacks code examples\"\n- \"API Reference section consistently high quality (5\u2b50), Guides section variable (2-4\u2b50)\"\n- \"Content under 500 words almost always incomplete\"\n- \"Certain authors consistently produce higher quality\"\n\nThis helps you identify not just individual problems, but systemic issues to address.\n\n---",
            "hydration_source_header": "2.5 Quality Pattern Analysis",
            "hydration_method": "title_match"
          },
          {
            "id": "comparative-analysis-pattern",
            "title": "Comparative Analysis Pattern",
            "purpose": "Benchmarking against standards/competitors",
            "lines": "920-1010",
            "content": "Compare your content against benchmarks, standards, or competitors.\n\n**Competitive Gap Analysis Prompt:**\n\n```text\nI'm comparing our documentation to industry standards.\n\nOur content coverage:\n[Paste your inventory categories and counts]\n\nIndustry standard/competitor structure:\n[Paste benchmark structure or competitor table of contents]\n\nIdentify:\n1. Topic areas where we're missing coverage\n2. Areas where we have more comprehensive coverage\n3. Structural differences in how content is organized\n4. Recommendations for bringing our coverage in line with expectations\n\nPrioritize gaps that likely impact user success.\n```\n\n**Standards Compliance Check:**\n\n```text\nEvaluate this content inventory against the Di\u00e1taxis framework:\n\nDi\u00e1taxis requires four content types:\n- Tutorials: Learning-oriented, step-by-step\n- How-to Guides: Task-oriented, problem-solving\n- Reference: Information-oriented, technical specs\n- Explanation: Understanding-oriented, concepts\n\nOur current content:\n[Paste inventory]\n\nFor each Di\u00e1taxis category:\n1. What content we have that fits\n2. What's missing\n3. Content that's miscategorized\n4. Recommendations for restructuring\n\nFocus on the biggest structural misalignments first.\n```\n\n<Info>\n  **Framework Context:** Di\u00e1taxis is a systematic approach to technical documentation that organizes content into four quadrants. Many successful documentation sites (Django, Stripe, Divio) follow this framework. Learn more at [diataxis.fr](https://diataxis.fr)\n</Info>\n\n---",
            "hydration_source_header": "2.6 Comparative Analysis Techniques",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "batch-quality-scoring",
            "title": "Batch Quality Scoring Pattern",
            "purpose": "Assessing quality at scale",
            "lines": "1020-1050",
            "content": "**Your Prompt:**\n\n```text\nAssess content quality for these items using our established criteria:\n\nQuality criteria:\n1. Completeness (1-5): Covers topic comprehensively\n2. Currency (1-5): Up-to-date and accurate\n3. Clarity (1-5): Well-written and organized\n4. Actionability (1-5): Users can accomplish goals\n5. Discoverability (1-5): Linked to related content\n\nItems to assess (Title, URL, Description, Last Updated, Word Count):\n[Paste batch of 20-30 items]\n\nFor each item, provide:\n- Overall quality score (1-5)\n- Scores for each criterion\n- Key strengths\n- Top 2-3 improvement opportunities\n- Priority (High/Medium/Low) based on user impact\n\nFocus on identifying patterns across items, not perfecting individual assessments.\n```\n\n---",
            "hydration_source_header": "3.1 Batch Quality Scoring",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "outlier-identification",
            "title": "Quality Outlier Identification Pattern",
            "purpose": "Finding best and worst examples",
            "lines": "1055-1090",
            "retrievalQuestions": [
              "How do I find the best and worst content examples?"
            ],
            "content": "The most meaningful content gaps are those that prevent users from accomplishing their goals. Let's map content systematically against user journeys.\n\n### 4.1 Mapping Content to User Journeys\n\n**First, define your primary user journeys:**\n\n```text\nUSER JOURNEY TEMPLATE\n\nJourney Name: [Descriptive name]\nUser Persona: [Who is this user?]\nStarting Point: [Where does the journey begin?]\nEnd Goal: [What does success look like?]\n\nStages:\n1. [Stage name]\n   - User goal: [What they want to accomplish]\n   - Expected content: [What would help them]\n   - Current content: [What exists now - TBD in analysis]\n   \n2. [Next stage...]\n   [Continue for 4-7 stages]\n\nSuccess Criteria:\n- [How do you know the journey is well-supported?]\n```\n\n---\n\n### 4.2 Identifying Journey Gaps\n\n**Your Prompt:**\n\n```text\nMap our content inventory to this user journey and identify gaps:\n\nJourney: [Paste your journey definition]\n\nCurrent inventory:\n[Paste inventory]\n\nFor each journey stage:\n1. What content exists that supports this stage?\n2. What's the quality/appropriateness of existing content?\n3. What critical gaps would block users?\n4. What nice-to-have content is missing?\n5. Rate overall coverage: Complete (5) / Adequate (3-4) / Partial (2) / Missing (1)\n\nCreate a gap matrix showing:\n- Journey stages (rows)\n- Coverage assessment (columns)\n- Priority gaps to address\n- Estimated effort for each gap\n\nFocus on gaps that would prevent users from advancing to the next stage.\n```\n\n---\n\n### 4.3 Prioritizing Gap Remediation\n\nNot all gaps are equal\u2014prioritize based on user impact and business value.\n\n**Gap Prioritization Framework Prompt:**\n\n```text\nPrioritize these identified content gaps:\n\n[Paste list of gaps identified]\n\nFor each gap, assess:\n1. User impact: How many users are affected? How severely?\n2. Business impact: Effect on adoption, retention, support costs\n3. Urgency: Is this blocking current users? Upcoming product launch?\n4. Effort: Content creation complexity and resource requirements\n5. Dependencies: Does this gap block other improvements?\n\nAssign priority level (P0/P1/P2/P3) and recommend sequence for addressing gaps.\n\nP0 = Blocking critical user paths, address immediately\nP1 = Significant user friction, address this quarter\nP2 = Nice to have, address this year\nP3 = Low impact, address opportunistically\n\nFor P0 and P1 gaps, provide:\n- Recommended content format (tutorial/guide/reference)\n- Estimated effort (hours)\n- Key messages to cover\n- Success metrics\n```\n\n<CardGroup cols={2}>\n  <Card title=\"High-Impact Gaps\" icon=\"fire\">\n    **Prioritize when:**\n    - Blocks critical user goals\n    - Generates support tickets\n    - Affects many users\n    - Quick to address\n    \n    Example: Missing error code reference\n  </Card>\n  \n  <Card title=\"Low-Priority Gaps\" icon=\"clock\">\n    **Defer when:**\n    - Nice-to-have only\n    - Affects few users\n    - Workarounds exist\n    - High effort required\n    \n    Example: Edge case documentation\n  </Card>\n</CardGroup>\n\n---\n\n### 4.4 Documenting Gap Analysis Findings\n\nCreate documentation that drives action.\n\n**Gap Analysis Report Structure:**\n\n```text\nCreate an executive summary of gap analysis findings:\n\nInput data:\n- User journey map: [Paste or describe]\n- Identified gaps: [Paste gap list]\n- Current content inventory: [Reference to full inventory]\n\nExecutive Summary structure:\n1. Overview: Audit scope, methodology, key findings\n2. Critical Gaps: Top 3-5 gaps blocking user success\n3. Gap Categories: Organize remaining gaps by type or theme\n4. Impact Assessment: Overall user experience impact\n5. Recommendations: Prioritized action plan with timeline\n6. Quick Wins: High-impact, low-effort improvements to start immediately\n\nKeep summary to 1-2 pages. Support with detailed appendix if needed.\n\nFormat for executive audience\u2014focus on impact and recommendations, not methodology.\n```\n\n---",
            "hydration_source_header": "4. Gap Analysis Against User Journeys",
            "hydration_method": "line_proximity"
          },
          {
            "id": "staleness-analysis",
            "title": "Age and Staleness Analysis Pattern",
            "purpose": "Finding outdated content",
            "lines": "1095-1130",
            "content": "**Your Prompt:**\n\n```text\nAnalyze content age and identify stale content:\n\nInventory with update dates:\n[Paste inventory]\n\nProduct release history:\n- v1.0: January 2022\n- v2.0: July 2023 (major changes to auth)\n- v2.5: February 2024 (new API endpoints)\n\nIdentify:\n1. Content not updated since major product changes\n2. Topics likely affected by product evolution\n3. High-traffic content that's outdated (if traffic data available)\n4. Content approaching 12 months without review\n\nPrioritize updates by:\n- User impact (importance of topic)\n- Staleness severity (how outdated)\n- Update complexity (effort to refresh)\n\nCreate tiered update plan: Immediate (P0), This Quarter (P1), This Year (P2)\n```\n\n<Tip>\n  **Validation Approach:** AI can flag potentially outdated content, but you need to verify. Set up a spot-check process: for every 10 items AI flags, manually review 2-3 to confirm accuracy before committing to updates.\n</Tip>\n\n---",
            "hydration_source_header": "3.3 Age and Staleness Analysis",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "promptPatterns": [
          {
            "id": "quality-criteria-definition-prompt",
            "title": "Quality Criteria Definition Prompt",
            "taskType": "generation",
            "lines": "230-245",
            "standalone": true,
            "retrievalQuestions": [
              "Give me a prompt to define content quality criteria"
            ],
            "content": "Not all audits need to cover everything. Define your scope clearly.\n\n**Sample audit charter:**\n\n```text\nCONTENT AUDIT CHARTER\n\nAudit Name: Q1 2024 Developer Documentation Audit\nAudit Lead: [Your name]\nDate Range: [Start] - [End]\n\nSCOPE:\nIn scope:\n- Developer documentation (API Reference, Guides, Tutorials)\n- Approximately 280 pages\n- English language only\n\nOut of scope:\n- Marketing content\n- Blog posts\n- Support knowledge base\n- Non-English translations\n\nPRIMARY OBJECTIVES:\n1. Identify critical gaps in developer onboarding journey\n2. Find duplicate or conflicting content causing confusion\n3. Assess documentation completeness vs. competitive standards\n4. Prioritize outdated content for updates\n\nSUCCESS CRITERIA:\n- Complete inventory of all in-scope content\n- Gap analysis mapped to 3 primary user journeys\n- Prioritized list of top 20 improvements\n- Actionable recommendations with effort estimates\n\nDELIVERABLES:\n1. Content inventory spreadsheet\n2. Audit findings report (5-10 pages)\n3. Prioritized improvement plan\n4. Executive summary (1-2 pages)\n\nTIMELINE:\n- Week 1: Inventory and initial analysis\n- Week 2: Gap analysis and quality assessment\n- Week 3: Validation and recommendations\n- Week 4: Final report and presentation\n```\n\n<Warning>\n  **Scope Creep Alert:** It's tempting to audit everything once you start. Stay focused on your defined scope and objectives. You can always conduct follow-up audits for other content areas.\n</Warning>\n\n---",
            "hydration_source_header": "1.3 Creating Audit Scope and Objectives",
            "hydration_method": "line_proximity"
          },
          {
            "id": "audit-framework-prompt",
            "title": "Content Audit Framework Prompt",
            "taskType": "analysis",
            "lines": "310-340",
            "standalone": true,
            "content": "This foundational prompt establishes context for all your audit work.\n\n**Your Prompt:**\n\n```text\nYou're a content strategist helping audit developer documentation.\n\nAudit scope and objectives:\n[Paste your audit charter]\n\nQuality criteria:\n[Paste your quality criteria]\n\nI'll be sharing content inventory data and asking you to help identify:\n- Duplicates and overlapping content\n- Content gaps based on user journeys\n- Quality issues and improvement priorities\n- Structural and organizational issues\n\nI have [number] total items. I'll start with a sample to ensure you understand \nthe content domain, then share the full inventory.\n\nPlease confirm you understand the audit scope and ask any clarifying questions \nbefore we begin analysis.\n```\n\n**Why this works:**\n- Establishes AI as an expert collaborator\n- Provides full context upfront\n- Sets clear expectations\n- Invites questions (catches misunderstandings early)\n\n---",
            "hydration_source_header": "2.1 The Content Audit Framework Prompt",
            "hydration_method": "title_match"
          },
          {
            "id": "exploratory-sample-prompt",
            "title": "Exploratory Analysis on Sample Prompt",
            "taskType": "analysis",
            "lines": "345-375",
            "standalone": true,
            "content": "Start with a representative sample to calibrate AI's understanding.\n\n**Your Prompt:**\n\n```text\nHere's a representative sample of 10 items from the documentation:\n\n[Paste your sample content with full detail]\n\nBased on this sample:\n1. What patterns do you notice in structure and organization?\n2. What content types are represented?\n3. What potential issues stand out?\n4. What questions should guide the full audit?\n5. Are my quality criteria clear and appropriate for this content?\n\nDon't make final judgments yet\u2014I want your initial observations to refine \nmy audit approach.\n```\n\n**Expected AI Output Pattern:**\n\n```text\nSAMPLE ANALYSIS - DEVELOPER DOCUMENTATION\n\nPATTERNS OBSERVED:\n\nStructure:\n- Consistent three-part pattern: Overview \u2192 Implementation \u2192 Examples\n- Most guides 1000-1500 words\n- Reference docs significantly longer (2000+ words)\n- Tutorials include code snippets, guides more conceptual\n\nOrganization:\n- Content grouped by feature area (not user journey)\n- Mix of beginner and advanced content in same sections\n- \"Getting Started\" seems isolated from advanced content\n- No clear progression paths indicated\n\nContent Types:\n- Tutorials (20%): Step-by-step, hands-on\n- Guides (40%): How-to, task-oriented\n- Reference (30%): Technical specifications\n- Concepts (10%): Explanatory content\n\nPOTENTIAL ISSUES:\n\n1. Possible duplication: Three items mention \"webhooks\" - may overlap\n2. Inconsistent depth: Some tutorials very brief (<500 words), others detailed\n3. Missing connections: No indication of prerequisites or \"next steps\"\n4. Age variation: Dates range from 2022-2024, some may be outdated\n5. Audience clarity: Mix of beginner/advanced without clear labeling\n\nAUDIT QUESTIONS TO EXPLORE:\n\n1. Is content appropriately distributed across types (tutorial/guide/reference)?\n2. Do learning paths exist, or is content fragmented?\n3. What's the right balance of breadth vs. depth?\n4. Should webhooks content be consolidated?\n5. What criteria should trigger content updates?\n\nQUALITY CRITERIA ASSESSMENT:\n\nYour criteria are clear and measurable. Suggestions:\n- Add \"Actionability\" - Can users accomplish their goal?\n- Consider \"Discoverability\" - Can users find related content?\n- \"Currency\" might need product-version context for accuracy\n```\n\n<Info>\n  **Calibration Tip:** This exploratory step is crucial. If AI misunderstands your content domain or criteria, catch it here before analyzing hundreds of pages. Refine your criteria based on AI's questions.\n</Info>\n\n---",
            "hydration_source_header": "2.2 Exploratory Analysis on Sample Content",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "duplicate-detection-prompt",
            "title": "Duplicate Content Detection Prompt",
            "taskType": "analysis",
            "lines": "395-425",
            "standalone": true,
            "retrievalQuestions": [
              "What prompt finds duplicate content?"
            ],
            "content": "Find exact and near-duplicates that confuse users and waste maintenance effort.\n\n**Your Prompt:**\n\n```text\nNow analyzing the full inventory for duplicate and overlapping content.\n\nFull inventory (showing: Title, URL, Category, Type, Description):\n[Paste full inventory]\n\nPlease identify:\n1. Exact or near-exact duplicates (same title, very similar content)\n2. Significant topical overlap (covering same information differently)\n3. Semantic duplication (different words, same meaning)\n\nFor each duplicate cluster:\n- List the items involved\n- Explain the likely overlap\n- Assess user impact (confusion, maintenance burden)\n- Recommend: consolidate, differentiate, or redirect\n\nFocus on the 10 highest-priority duplication issues first.\n```\n\n**Expected AI Output Example:**\n\n```text\nDUPLICATE CONTENT ANALYSIS\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nDUPLICATE CLUSTER 1: Webhook Setup (HIGH PRIORITY)\n\nItems involved:\n1. \"Getting Started with Webhooks\" (/docs/webhooks/intro)\n2. \"How to Set Up Webhooks\" (/docs/guides/webhook-setup)\n3. \"Webhook Configuration\" (/docs/api/webhooks/config)\n\nLikely overlap:\nAll three appear to cover basic webhook setup and configuration. Based on \ntitles and URLs, they likely contain:\n- What webhooks are (conceptual)\n- How to register webhook endpoints\n- How to verify webhook signatures\n- Example webhook payloads\n\nUser impact:\n- Confusion: Which is the \"right\" guide to follow?\n- Inconsistency risk: If one is updated, others may become outdated\n- Maintenance burden: Three places to update for any webhook changes\n- SEO cannibalization: Competing for same search terms\n\nRecommendation: CONSOLIDATE\n\u2192 Create single authoritative \"Webhooks Guide\" at /docs/webhooks/\n\u2192 Structure as:\n  - Introduction (what webhooks are)\n  - Setup & Configuration (how to register)\n  - Security (signature verification)\n  - Examples & Use Cases\n  - Troubleshooting\n\u2192 Redirect old URLs to new consolidated guide\n\u2192 Estimated effort: 4-6 hours\n\nPriority: HIGH\n- Core feature (webhooks are frequently used)\n- High confusion potential (three competing guides)\n- Moderate consolidation effort\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nDUPLICATE CLUSTER 2: Authentication Basics (MEDIUM PRIORITY)\n\nItems involved:\n1. \"API Authentication\" (/docs/auth)\n2. \"Authentication Guide\" (/docs/guides/authentication)\n3. \"Getting Started: Authentication\" (/docs/start/auth)\n\nLikely overlap:\nAll cover API authentication basics. Possible differences:\n- Item 1 might be reference-style (all auth methods)\n- Item 2 might be how-to (step-by-step implementation)\n- Item 3 might be beginner tutorial (first time setup)\n\nUser impact:\n- Less severe than webhooks (may serve different purposes)\n- Still creates uncertainty about where to start\n- Maintenance burden across three documents\n\nRecommendation: DIFFERENTIATE or CONSOLIDATE\nOption A (Differentiate):\n\u2192 Keep all three but clarify purpose in each title/description:\n  - \"Authentication Overview\" (reference, all methods)\n  - \"Authentication Implementation Guide\" (how-to for developers)\n  - \"First-Time Authentication\" (beginner tutorial)\n\u2192 Cross-link clearly with \"see also\" sections\n\u2192 Estimated effort: 2-3 hours\n\nOption B (Consolidate):\n\u2192 Single \"Authentication Guide\" with sections for different audiences\n\u2192 Redirect old URLs\n\u2192 Estimated effort: 4-5 hours\n\nPriority: MEDIUM\n- Critical feature but possibly serving different needs\n- Moderate confusion potential\n- Requires further investigation to choose approach\n\n[Continue for clusters 3-10...]\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nSUMMARY:\n\nTotal duplicate clusters identified: 10\n- High priority (consolidate immediately): 3 clusters\n- Medium priority (consolidate or differentiate): 5 clusters\n- Low priority (monitor, address opportunistically): 2 clusters\n\nEstimated effort for all high-priority consolidations: 12-18 hours\nExpected impact: Eliminate confusion for 3 core features, reduce maintenance \nburden by ~30% for affected content\n```\n\n<Tip>\n  **Validation Step:** AI can identify potential duplicates, but you should verify by actually reading 2-3 examples from each cluster. Sometimes similar titles cover genuinely different content.\n</Tip>\n\n---",
            "hydration_source_header": "2.3 Duplicate Content Detection",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "gap-analysis-prompt",
            "title": "Gap Analysis Against User Journey Prompt",
            "taskType": "analysis",
            "lines": "560-600",
            "standalone": true,
            "retrievalQuestions": [
              "How do I prompt AI to analyze content gaps?"
            ],
            "content": "The most meaningful content gaps are those that prevent users from accomplishing their goals. Let's map content systematically against user journeys.\n\n### 4.1 Mapping Content to User Journeys\n\n**First, define your primary user journeys:**\n\n```text\nUSER JOURNEY TEMPLATE\n\nJourney Name: [Descriptive name]\nUser Persona: [Who is this user?]\nStarting Point: [Where does the journey begin?]\nEnd Goal: [What does success look like?]\n\nStages:\n1. [Stage name]\n   - User goal: [What they want to accomplish]\n   - Expected content: [What would help them]\n   - Current content: [What exists now - TBD in analysis]\n   \n2. [Next stage...]\n   [Continue for 4-7 stages]\n\nSuccess Criteria:\n- [How do you know the journey is well-supported?]\n```\n\n---\n\n### 4.2 Identifying Journey Gaps\n\n**Your Prompt:**\n\n```text\nMap our content inventory to this user journey and identify gaps:\n\nJourney: [Paste your journey definition]\n\nCurrent inventory:\n[Paste inventory]\n\nFor each journey stage:\n1. What content exists that supports this stage?\n2. What's the quality/appropriateness of existing content?\n3. What critical gaps would block users?\n4. What nice-to-have content is missing?\n5. Rate overall coverage: Complete (5) / Adequate (3-4) / Partial (2) / Missing (1)\n\nCreate a gap matrix showing:\n- Journey stages (rows)\n- Coverage assessment (columns)\n- Priority gaps to address\n- Estimated effort for each gap\n\nFocus on gaps that would prevent users from advancing to the next stage.\n```\n\n---\n\n### 4.3 Prioritizing Gap Remediation\n\nNot all gaps are equal\u2014prioritize based on user impact and business value.\n\n**Gap Prioritization Framework Prompt:**\n\n```text\nPrioritize these identified content gaps:\n\n[Paste list of gaps identified]\n\nFor each gap, assess:\n1. User impact: How many users are affected? How severely?\n2. Business impact: Effect on adoption, retention, support costs\n3. Urgency: Is this blocking current users? Upcoming product launch?\n4. Effort: Content creation complexity and resource requirements\n5. Dependencies: Does this gap block other improvements?\n\nAssign priority level (P0/P1/P2/P3) and recommend sequence for addressing gaps.\n\nP0 = Blocking critical user paths, address immediately\nP1 = Significant user friction, address this quarter\nP2 = Nice to have, address this year\nP3 = Low impact, address opportunistically\n\nFor P0 and P1 gaps, provide:\n- Recommended content format (tutorial/guide/reference)\n- Estimated effort (hours)\n- Key messages to cover\n- Success metrics\n```\n\n<CardGroup cols={2}>\n  <Card title=\"High-Impact Gaps\" icon=\"fire\">\n    **Prioritize when:**\n    - Blocks critical user goals\n    - Generates support tickets\n    - Affects many users\n    - Quick to address\n    \n    Example: Missing error code reference\n  </Card>\n  \n  <Card title=\"Low-Priority Gaps\" icon=\"clock\">\n    **Defer when:**\n    - Nice-to-have only\n    - Affects few users\n    - Workarounds exist\n    - High effort required\n    \n    Example: Edge case documentation\n  </Card>\n</CardGroup>\n\n---\n\n### 4.4 Documenting Gap Analysis Findings\n\nCreate documentation that drives action.\n\n**Gap Analysis Report Structure:**\n\n```text\nCreate an executive summary of gap analysis findings:\n\nInput data:\n- User journey map: [Paste or describe]\n- Identified gaps: [Paste gap list]\n- Current content inventory: [Reference to full inventory]\n\nExecutive Summary structure:\n1. Overview: Audit scope, methodology, key findings\n2. Critical Gaps: Top 3-5 gaps blocking user success\n3. Gap Categories: Organize remaining gaps by type or theme\n4. Impact Assessment: Overall user experience impact\n5. Recommendations: Prioritized action plan with timeline\n6. Quick Wins: High-impact, low-effort improvements to start immediately\n\nKeep summary to 1-2 pages. Support with detailed appendix if needed.\n\nFormat for executive audience\u2014focus on impact and recommendations, not methodology.\n```\n\n---",
            "hydration_source_header": "4. Gap Analysis Against User Journeys",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "quality-pattern-prompt",
            "title": "Quality Pattern Analysis Prompt",
            "taskType": "analysis",
            "lines": "800-835",
            "standalone": true,
            "content": "Identify systemic quality issues across your content inventory.\n\n**Your Prompt:**\n\n```text\nAnalyze quality patterns across the inventory:\n\n[Paste inventory with quality signals: update dates, word counts, categories]\n\nQuality criteria to apply:\n[Reference earlier quality criteria]\n\nIdentify:\n1. Clusters of quality issues (e.g., certain categories consistently lower quality)\n2. Items that likely need review (based on age, brevity, or other signals)\n3. Patterns suggesting systemic issues vs. one-off problems\n4. Sections where quality is consistently high (learn from these)\n5. Correlation between quality signals (e.g., newer content more complete?)\n\nPrioritize the top 15 items for quality improvement based on:\n- User impact (traffic, importance to key journeys)\n- Severity of quality issue\n- Ease of improvement\n\nPresent as prioritized list with specific improvement recommendations.\n```\n\n**Expected Output Pattern:**\n\nThe AI will identify patterns like:\n- \"All content updated before 2023 lacks code examples\"\n- \"API Reference section consistently high quality (5\u2b50), Guides section variable (2-4\u2b50)\"\n- \"Content under 500 words almost always incomplete\"\n- \"Certain authors consistently produce higher quality\"\n\nThis helps you identify not just individual problems, but systemic issues to address.\n\n---",
            "hydration_source_header": "2.5 Quality Pattern Analysis",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "competitive-gap-prompt",
            "title": "Competitive Gap Analysis Prompt",
            "taskType": "analysis",
            "lines": "925-945",
            "standalone": true,
            "content": "For complex audits, use a phased approach with increasingly focused prompts.\n\n**Pass 1: High-Level Structure**\n\n```text\nFirst pass review - focus on structure and organization only:\n\n[Paste inventory]\n\nAssess:\n1. Overall information architecture (logical grouping?)\n2. Navigation and hierarchy (clear paths?)\n3. Major structural gaps\n4. Sections that seem misplaced\n\nDon't evaluate individual page quality yet\u2014stay at the structural level.\n```\n\n**Pass 2: Category-Level Analysis**\n\n```text\nSecond pass - analyze the \"Getting Started\" category in detail:\n\n[Paste Getting Started inventory items]\n\nEvaluate:\n1. Completeness for user onboarding\n2. Logical sequence and progression\n3. Overlap or redundancy within this category\n4. Quality red flags (based on titles/descriptions)\n5. Missing elements compared to user journey\n\nProvide specific, actionable recommendations.\n```\n\n**Pass 3: Cross-Category Relationships**\n\n```text\nThird pass - analyze relationships between categories:\n\nCategories: [List main categories]\nRepresentative items: [Paste sample from each category]\n\nIdentify:\n1. Content that should be connected but isn't\n2. Duplicate coverage across categories\n3. Logical progression paths users would follow\n4. Navigation or wayfinding gaps between categories\n\nMap the top 5 priority cross-category improvements.\n```\n\n---",
            "hydration_source_header": "2.7 Multi-Pass Audit Strategies",
            "hydration_method": "line_proximity"
          },
          {
            "id": "diataxis-compliance-prompt",
            "title": "Di\u00e1taxis Framework Compliance Prompt",
            "taskType": "analysis",
            "lines": "950-975",
            "standalone": true,
            "content": "Assessing quality for hundreds of pages manually is impractical. Use AI to identify quality issues systematically.\n\n### 3.1 Batch Quality Scoring\n\n**Your Prompt:**\n\n```text\nAssess content quality for these items using our established criteria:\n\nQuality criteria:\n1. Completeness (1-5): Covers topic comprehensively\n2. Currency (1-5): Up-to-date and accurate\n3. Clarity (1-5): Well-written and organized\n4. Actionability (1-5): Users can accomplish goals\n5. Discoverability (1-5): Linked to related content\n\nItems to assess (Title, URL, Description, Last Updated, Word Count):\n[Paste batch of 20-30 items]\n\nFor each item, provide:\n- Overall quality score (1-5)\n- Scores for each criterion\n- Key strengths\n- Top 2-3 improvement opportunities\n- Priority (High/Medium/Low) based on user impact\n\nFocus on identifying patterns across items, not perfecting individual assessments.\n```\n\n---\n\n### 3.2 Identifying Quality Outliers\n\n**Your Prompt:**\n\n```text\nIdentify quality outliers in this inventory:\n\n[Paste full inventory with metadata]\n\nFind:\n1. Highest quality examples (5\u2b50) - what makes them excellent?\n2. Lowest quality items (1-2\u2b50) - what's wrong?\n3. Items with inconsistent quality signals (e.g., recent but brief)\n4. Sections with consistently high or low quality\n\nFor each outlier:\n- What makes it stand out?\n- Is this replicable/fixable?\n- What can we learn from high-quality examples?\n- What systemic issues do low-quality items reveal?\n\nRecommend standards/templates based on high-quality examples.\n```\n\n---\n\n### 3.3 Age and Staleness Analysis\n\n**Your Prompt:**\n\n```text\nAnalyze content age and identify stale content:\n\nInventory with update dates:\n[Paste inventory]\n\nProduct release history:\n- v1.0: January 2022\n- v2.0: July 2023 (major changes to auth)\n- v2.5: February 2024 (new API endpoints)\n\nIdentify:\n1. Content not updated since major product changes\n2. Topics likely affected by product evolution\n3. High-traffic content that's outdated (if traffic data available)\n4. Content approaching 12 months without review\n\nPrioritize updates by:\n- User impact (importance of topic)\n- Staleness severity (how outdated)\n- Update complexity (effort to refresh)\n\nCreate tiered update plan: Immediate (P0), This Quarter (P1), This Year (P2)\n```\n\n<Tip>\n  **Validation Approach:** AI can flag potentially outdated content, but you need to verify. Set up a spot-check process: for every 10 items AI flags, manually review 2-3 to confirm accuracy before committing to updates.\n</Tip>\n\n---",
            "hydration_source_header": "3. Content Quality Assessment at Scale",
            "hydration_method": "line_proximity"
          },
          {
            "id": "multi-pass-structure-prompt",
            "title": "Multi-Pass Structure Analysis Prompt",
            "taskType": "analysis",
            "lines": "875-885",
            "standalone": true,
            "content": "Compare your content against benchmarks, standards, or competitors.\n\n**Competitive Gap Analysis Prompt:**\n\n```text\nI'm comparing our documentation to industry standards.\n\nOur content coverage:\n[Paste your inventory categories and counts]\n\nIndustry standard/competitor structure:\n[Paste benchmark structure or competitor table of contents]\n\nIdentify:\n1. Topic areas where we're missing coverage\n2. Areas where we have more comprehensive coverage\n3. Structural differences in how content is organized\n4. Recommendations for bringing our coverage in line with expectations\n\nPrioritize gaps that likely impact user success.\n```\n\n**Standards Compliance Check:**\n\n```text\nEvaluate this content inventory against the Di\u00e1taxis framework:\n\nDi\u00e1taxis requires four content types:\n- Tutorials: Learning-oriented, step-by-step\n- How-to Guides: Task-oriented, problem-solving\n- Reference: Information-oriented, technical specs\n- Explanation: Understanding-oriented, concepts\n\nOur current content:\n[Paste inventory]\n\nFor each Di\u00e1taxis category:\n1. What content we have that fits\n2. What's missing\n3. Content that's miscategorized\n4. Recommendations for restructuring\n\nFocus on the biggest structural misalignments first.\n```\n\n<Info>\n  **Framework Context:** Di\u00e1taxis is a systematic approach to technical documentation that organizes content into four quadrants. Many successful documentation sites (Django, Stripe, Divio) follow this framework. Learn more at [diataxis.fr](https://diataxis.fr)\n</Info>\n\n---",
            "hydration_source_header": "2.6 Comparative Analysis Techniques",
            "hydration_method": "line_proximity"
          },
          {
            "id": "multi-pass-category-prompt",
            "title": "Multi-Pass Category Analysis Prompt",
            "taskType": "analysis",
            "lines": "890-900",
            "standalone": true,
            "content": "For complex audits, use a phased approach with increasingly focused prompts.\n\n**Pass 1: High-Level Structure**\n\n```text\nFirst pass review - focus on structure and organization only:\n\n[Paste inventory]\n\nAssess:\n1. Overall information architecture (logical grouping?)\n2. Navigation and hierarchy (clear paths?)\n3. Major structural gaps\n4. Sections that seem misplaced\n\nDon't evaluate individual page quality yet\u2014stay at the structural level.\n```\n\n**Pass 2: Category-Level Analysis**\n\n```text\nSecond pass - analyze the \"Getting Started\" category in detail:\n\n[Paste Getting Started inventory items]\n\nEvaluate:\n1. Completeness for user onboarding\n2. Logical sequence and progression\n3. Overlap or redundancy within this category\n4. Quality red flags (based on titles/descriptions)\n5. Missing elements compared to user journey\n\nProvide specific, actionable recommendations.\n```\n\n**Pass 3: Cross-Category Relationships**\n\n```text\nThird pass - analyze relationships between categories:\n\nCategories: [List main categories]\nRepresentative items: [Paste sample from each category]\n\nIdentify:\n1. Content that should be connected but isn't\n2. Duplicate coverage across categories\n3. Logical progression paths users would follow\n4. Navigation or wayfinding gaps between categories\n\nMap the top 5 priority cross-category improvements.\n```\n\n---",
            "hydration_source_header": "2.7 Multi-Pass Audit Strategies",
            "hydration_method": "line_proximity"
          },
          {
            "id": "multi-pass-relationships-prompt",
            "title": "Multi-Pass Cross-Category Prompt",
            "taskType": "analysis",
            "lines": "905-920",
            "standalone": true,
            "content": "For complex audits, use a phased approach with increasingly focused prompts.\n\n**Pass 1: High-Level Structure**\n\n```text\nFirst pass review - focus on structure and organization only:\n\n[Paste inventory]\n\nAssess:\n1. Overall information architecture (logical grouping?)\n2. Navigation and hierarchy (clear paths?)\n3. Major structural gaps\n4. Sections that seem misplaced\n\nDon't evaluate individual page quality yet\u2014stay at the structural level.\n```\n\n**Pass 2: Category-Level Analysis**\n\n```text\nSecond pass - analyze the \"Getting Started\" category in detail:\n\n[Paste Getting Started inventory items]\n\nEvaluate:\n1. Completeness for user onboarding\n2. Logical sequence and progression\n3. Overlap or redundancy within this category\n4. Quality red flags (based on titles/descriptions)\n5. Missing elements compared to user journey\n\nProvide specific, actionable recommendations.\n```\n\n**Pass 3: Cross-Category Relationships**\n\n```text\nThird pass - analyze relationships between categories:\n\nCategories: [List main categories]\nRepresentative items: [Paste sample from each category]\n\nIdentify:\n1. Content that should be connected but isn't\n2. Duplicate coverage across categories\n3. Logical progression paths users would follow\n4. Navigation or wayfinding gaps between categories\n\nMap the top 5 priority cross-category improvements.\n```\n\n---",
            "hydration_source_header": "2.7 Multi-Pass Audit Strategies",
            "hydration_method": "line_proximity"
          },
          {
            "id": "batch-quality-prompt",
            "title": "Batch Quality Scoring Prompt",
            "taskType": "analysis",
            "lines": "1025-1050",
            "standalone": true,
            "retrievalQuestions": [
              "Show me a prompt for batch quality assessment"
            ],
            "content": "**Your Prompt:**\n\n```text\nAssess content quality for these items using our established criteria:\n\nQuality criteria:\n1. Completeness (1-5): Covers topic comprehensively\n2. Currency (1-5): Up-to-date and accurate\n3. Clarity (1-5): Well-written and organized\n4. Actionability (1-5): Users can accomplish goals\n5. Discoverability (1-5): Linked to related content\n\nItems to assess (Title, URL, Description, Last Updated, Word Count):\n[Paste batch of 20-30 items]\n\nFor each item, provide:\n- Overall quality score (1-5)\n- Scores for each criterion\n- Key strengths\n- Top 2-3 improvement opportunities\n- Priority (High/Medium/Low) based on user impact\n\nFocus on identifying patterns across items, not perfecting individual assessments.\n```\n\n---",
            "hydration_source_header": "3.1 Batch Quality Scoring",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "outlier-identification-prompt",
            "title": "Quality Outlier Identification Prompt",
            "taskType": "analysis",
            "lines": "1060-1090",
            "standalone": true,
            "content": "**First, define your primary user journeys:**\n\n```text\nUSER JOURNEY TEMPLATE\n\nJourney Name: [Descriptive name]\nUser Persona: [Who is this user?]\nStarting Point: [Where does the journey begin?]\nEnd Goal: [What does success look like?]\n\nStages:\n1. [Stage name]\n   - User goal: [What they want to accomplish]\n   - Expected content: [What would help them]\n   - Current content: [What exists now - TBD in analysis]\n   \n2. [Next stage...]\n   [Continue for 4-7 stages]\n\nSuccess Criteria:\n- [How do you know the journey is well-supported?]\n```\n\n---",
            "hydration_source_header": "4.1 Mapping Content to User Journeys",
            "hydration_method": "line_proximity"
          },
          {
            "id": "staleness-analysis-prompt",
            "title": "Staleness Analysis Prompt",
            "taskType": "analysis",
            "lines": "1100-1130",
            "standalone": true,
            "retrievalQuestions": [
              "What prompt identifies outdated content?"
            ],
            "content": "**Your Prompt:**\n\n```text\nAnalyze content age and identify stale content:\n\nInventory with update dates:\n[Paste inventory]\n\nProduct release history:\n- v1.0: January 2022\n- v2.0: July 2023 (major changes to auth)\n- v2.5: February 2024 (new API endpoints)\n\nIdentify:\n1. Content not updated since major product changes\n2. Topics likely affected by product evolution\n3. High-traffic content that's outdated (if traffic data available)\n4. Content approaching 12 months without review\n\nPrioritize updates by:\n- User impact (importance of topic)\n- Staleness severity (how outdated)\n- Update complexity (effort to refresh)\n\nCreate tiered update plan: Immediate (P0), This Quarter (P1), This Year (P2)\n```\n\n<Tip>\n  **Validation Approach:** AI can flag potentially outdated content, but you need to verify. Set up a spot-check process: for every 10 items AI flags, manually review 2-3 to confirm accuracy before committing to updates.\n</Tip>\n\n---",
            "hydration_source_header": "3.3 Age and Staleness Analysis",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "gap-prioritization-prompt",
            "title": "Gap Prioritization Framework Prompt",
            "taskType": "analysis",
            "lines": "1145-1175",
            "standalone": true,
            "hydration_status": "failed"
          },
          {
            "id": "gap-report-prompt",
            "title": "Gap Analysis Report Prompt",
            "taskType": "generation",
            "lines": "1180-1200",
            "standalone": true,
            "content": "Create documentation that drives action.\n\n**Gap Analysis Report Structure:**\n\n```text\nCreate an executive summary of gap analysis findings:\n\nInput data:\n- User journey map: [Paste or describe]\n- Identified gaps: [Paste gap list]\n- Current content inventory: [Reference to full inventory]\n\nExecutive Summary structure:\n1. Overview: Audit scope, methodology, key findings\n2. Critical Gaps: Top 3-5 gaps blocking user success\n3. Gap Categories: Organize remaining gaps by type or theme\n4. Impact Assessment: Overall user experience impact\n5. Recommendations: Prioritized action plan with timeline\n6. Quick Wins: High-impact, low-effort improvements to start immediately\n\nKeep summary to 1-2 pages. Support with detailed appendix if needed.\n\nFormat for executive audience\u2014focus on impact and recommendations, not methodology.\n```\n\n---",
            "hydration_source_header": "4.4 Documenting Gap Analysis Findings",
            "hydration_method": "line_proximity"
          }
        ],
        "workflows": [
          {
            "id": "complete-audit-workflow",
            "title": "Complete Content Audit Workflow (8 steps)",
            "steps": 8,
            "uses": "all-patterns",
            "lines": "1205-1450",
            "retrievalQuestions": [
              "Walk me through a complete content audit"
            ],
            "content": "You're auditing the documentation for \"PayFlow API\"\u2014a payment processing platform. The documentation has grown organically over 3 years and users report confusion finding information.\n\n**Audit Charter:**\n- Scope: Developer documentation (100 pages)\n- Primary user: Backend developers integrating payment APIs\n- Timeline: 2 weeks\n- Deliverable: Prioritized improvement plan\n\n---\n\n<AccordionGroup>\n  <Accordion title=\"Step 1: Build Your Content Inventory (30 min)\">\n    **What You're Doing:** Create a comprehensive inventory of all content in scope.\n    \n    **Actions:**\n    1. Export or crawl your documentation site\n    2. Capture essential metadata for each page:\n       - Title\n       - URL\n       - Category/section\n       - Content type\n       - Last updated date\n       - Word count (approximate)\n       - Author (if available)\n    \n    **Tools:**\n    - Screaming Frog (web crawler)\n    - Custom scripts (if docs are in GitHub)\n    - Manual spreadsheet (for smaller sites)\n    \n    **Sample Inventory Format:**\n    ```csv\n    Title,URL,Category,Type,Updated,Words,Author\n    \"Accept Payments\",/accept,Getting Started,Tutorial,2024-01-15,1200,Sarah\n    \"Charge API\",/api/charge,API Reference,Reference,2024-02-01,2400,Alex\n    \"Error Codes\",/errors,Reference,Reference,2023-08-10,800,Chris\n    ```\n    \n    **Validation:**\n    - Do you have 100 items (as scoped)?\n    - Is metadata complete for all items?\n    - Are categories consistent?\n  </Accordion>\n  \n  <Accordion title=\"Step 2: Define Quality Criteria (20 min)\">\n    **What You're Doing:** Establish clear, measurable quality criteria.\n    \n    **Your AI Prompt:**\n    ```text\n    I'm auditing payment API documentation for backend developers.\n    \n    Help me define 5-7 quality criteria appropriate for this audience.\n    \n    For each criterion:\n    1. Name and clear definition\n    2. What \"excellent\" looks like (5\u2b50)\n    3. What \"poor\" looks like (1\u2b50)\n    4. Measurable indicators\n    5. Why it matters to developers\n    ```\n    \n    **Review AI Output:**\n    - Are criteria specific enough to apply consistently?\n    - Do they align with user needs?\n    - Can you measure them with available data?\n    \n    **Finalize Your Criteria:**\n    Document your 5-7 criteria for use throughout the audit.\n  </Accordion>\n  \n  <Accordion title=\"Step 3: Run Duplicate Analysis (45 min)\">\n    **What You're Doing:** Identify duplicate and overlapping content.\n    \n    **Your AI Prompt:**\n    ```text\n    Analyze this inventory for duplicate and overlapping content:\n    \n    [Paste your 100-item inventory]\n    \n    Identify:\n    1. Exact or near-exact duplicates\n    2. Significant topical overlap\n    3. Semantic duplication (same info, different words)\n    \n    For each duplicate cluster:\n    - Items involved\n    - Likely overlap\n    - User impact\n    - Recommendation (consolidate/differentiate/redirect)\n    \n    Focus on top 10 highest-priority duplication issues.\n    ```\n    \n    **Validation Process:**\n    1. Review AI's duplicate clusters\n    2. Spot-check 3-5 clusters by reading actual content\n    3. Confirm overlap is real (not just similar titles)\n    4. Adjust recommendations based on domain knowledge\n    \n    **Document Findings:**\n    Create a \"Duplicates to Address\" list with effort estimates.\n  </Accordion>\n  \n  <Accordion title=\"Step 4: Map User Journey (30 min)\">\n    **What You're Doing:** Define the primary user journey for gap analysis.\n    \n    **Define Journey:**\n    ```text\n    Journey: First-Time Payment Integration\n    User: Backend developer integrating PayFlow\n    Goal: Accept first payment within 90 minutes\n    \n    Stages:\n    1. Discovery: Understand PayFlow capabilities\n    2. Setup: Create account, get API keys\n    3. Authentication: Implement secure auth\n    4. First Payment: Accept first test payment\n    5. Production: Deploy to production safely\n    ```\n    \n    **Identify Expected Content:**\n    For each stage, list what content would support users:\n    - Stage 1: Overview, use cases, pricing\n    - Stage 2: Signup guide, API key generation\n    - Stage 3: Auth guide, security best practices\n    - Stage 4: Payment tutorial, testing guide\n    - Stage 5: Production checklist, go-live guide\n  </Accordion>\n  \n  <Accordion title=\"Step 5: Identify Content Gaps (60 min)\">\n    **What You're Doing:** Compare current content to journey needs.\n    \n    **Your AI Prompt:**\n    ```text\n    Map content to this user journey and identify gaps:\n    \n    Journey: [Paste your journey from Step 4]\n    \n    Current inventory: [Paste inventory]\n    \n    For each journey stage:\n    1. What content exists?\n    2. Quality of existing content?\n    3. Critical gaps that block users?\n    4. Nice-to-have missing content?\n    5. Coverage rating (1-5)\n    \n    Create gap matrix with priority gaps and effort estimates.\n    ```\n    \n    **Validation:**\n    1. Review gap analysis\n    2. Verify gaps are real (check inventory carefully)\n    3. Assess priority based on support tickets/analytics\n    4. Adjust effort estimates based on team capacity\n    \n    **Prioritize:**\n    Categorize gaps as P0/P1/P2/P3 based on impact and urgency.\n  </Accordion>\n  \n  <Accordion title=\"Step 6: Assess Content Quality (60 min)\">\n    **What You're Doing:** Evaluate quality across all content.\n    \n    **Batch Assessment (20-30 items at a time):**\n    ```text\n    Assess quality using these criteria:\n    [Paste your criteria from Step 2]\n    \n    Items: [Paste batch of 20-30 items with metadata]\n    \n    For each item:\n    - Overall quality score (1-5)\n    - Individual criterion scores\n    - Top 2-3 improvement opportunities\n    - Priority (High/Medium/Low)\n    ```\n    \n    **Run 4-5 batches to cover all 100 items**\n    \n    **Validation:**\n    - Spot-check 10% of assessments by reading actual content\n    - Look for assessment consistency across batches\n    - Identify quality patterns (certain categories lower?)\n    \n    **Create Priority List:**\n    Top 15 items for quality improvement with specific recommendations.\n  </Accordion>\n  \n  <Accordion title=\"Step 7: Synthesize Findings (45 min)\">\n    **What You're Doing:** Create executive summary and action plan.\n    \n    **Your AI Prompt:**\n    ```text\n    Create an executive summary from these audit findings:\n    \n    Duplicates: [Paste top 10 duplicate clusters]\n    Gaps: [Paste P0 and P1 gaps with effort estimates]\n    Quality: [Paste top 15 quality issues]\n    \n    Structure:\n    1. Executive Summary (3-4 bullets, key findings)\n    2. Critical Issues (top 3-5 must-fix)\n    3. Quick Wins (high-impact, low-effort)\n    4. Phased Action Plan (Immediate/Q1/Q2)\n    5. Success Metrics\n    \n    Target audience: Leadership team (non-technical)\n    Length: 1-2 pages\n    ```\n    \n    **Refine Output:**\n    1. Add specific resource requirements\n    2. Include timeline\n    3. Define success metrics\n    4. Ensure recommendations are actionable\n  </Accordion>\n  \n  <Accordion title=\"Step 8: Create Detailed Action Plan (30 min)\">\n    **What You're Doing:** Document implementation plan.\n    \n    **Action Plan Format:**\n    ```text\n    PHASE 1: IMMEDIATE (Week 1-2)\n    - Fix critical gaps blocking users\n    - Consolidate top 3 duplicate clusters\n    - Quick quality wins\n    Total effort: 20-25 hours\n    \n    PHASE 2: FOUNDATION (Month 1-2)\n    - Address P1 gaps\n    - Quality improvements for high-traffic pages\n    - Structural reorganization\n    Total effort: 40-50 hours\n    \n    PHASE 3: STRATEGIC (Month 3-6)\n    - P2 gaps and enhancements\n    - Content templates and standards\n    - Ongoing quality monitoring\n    Total effort: 60-80 hours\n    ```\n    \n    **For Each Action:**\n    - Specific deliverable\n    - Owner\n    - Effort estimate\n    - Dependencies\n    - Success criteria\n  </Accordion>\n</AccordionGroup>\n\n---",
            "hydration_source_header": "Tutorial Scenario",
            "hydration_method": "line_proximity"
          },
          {
            "id": "step-1-build-inventory",
            "title": "Step 1: Build Content Inventory",
            "uses": "content-inventory-pattern",
            "lines": "1210-1245",
            "content": "A good content inventory is the foundation of any audit. At minimum, capture:\n\n**Essential fields:**\n- Title\n- URL\n- Category/section\n- Content type (tutorial, reference, guide, etc.)\n- Last updated date\n- Word count (approximate)\n\n**Recommended fields:**\n- Author\n- Status (published, draft, archived)\n- Primary audience\n- Related content (links to/from)\n- Tags/keywords\n\n<CodeGroup>\n\n```csv Example Inventory (CSV)\nTitle,URL,Category,Type,Last_Updated,Word_Count,Author\nGetting Started,/docs/start,Onboarding,Tutorial,2024-01-15,850,Jane\nAPI Authentication,/docs/auth,API,Guide,2023-12-20,1200,Alex\nUser Endpoints,/docs/api/users,API,Reference,2024-02-01,2100,Chris\nError Handling,/docs/errors,Guides,Explanation,2023-11-10,900,Sam\n```\n\n```text Example Inventory (Formatted)\nCONTENT INVENTORY - DEVELOPER DOCUMENTATION\n\nItem 1:\n- Title: \"Getting Started with CloudAPI\"\n- URL: /docs/getting-started\n- Category: Onboarding\n- Type: Tutorial\n- Updated: 2024-01-15\n- Words: ~850\n- Description: Step-by-step guide for first API call\n\nItem 2:\n- Title: \"API Authentication Guide\"\n- URL: /docs/authentication\n- Category: Security\n- Type: How-to Guide\n- Updated: 2023-12-20\n- Words: ~1200\n- Description: How to authenticate API requests using OAuth 2.0\n\n[Continue for all items...]\n```\n\n</CodeGroup>\n\n---",
            "hydration_source_header": "1.1 Creating Your Content Inventory",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "step-2-define-criteria",
            "title": "Step 2: Define Quality Criteria",
            "uses": "quality-criteria-pattern",
            "lines": "1250-1280",
            "content": "AI needs clear criteria to assess content quality. Define what \"good\" looks like for your documentation.\n\n**Sample quality criteria:**\n\n<AccordionGroup>\n  <Accordion title=\"Completeness\">\n    **Indicators:**\n    - Covers topic comprehensively\n    - Includes code examples\n    - Has prerequisites listed\n    - Links to related content\n    \n    **Quality scale:**\n    - \u2b50\u2b50\u2b50\u2b50\u2b50 Complete with examples and context\n    - \u2b50\u2b50\u2b50 Covers basics but missing examples\n    - \u2b50 Incomplete or skeletal content\n  </Accordion>\n  \n  <Accordion title=\"Currency\">\n    **Indicators:**\n    - Updated within last 6 months\n    - References current product version\n    - No deprecated information\n    - Matches current UI/API\n    \n    **Quality scale:**\n    - \u2b50\u2b50\u2b50\u2b50\u2b50 Updated within 3 months\n    - \u2b50\u2b50\u2b50 3-12 months old but still accurate\n    - \u2b50 Over 12 months, likely outdated\n  </Accordion>\n  \n  <Accordion title=\"Clarity\">\n    **Indicators:**\n    - Clear, concise writing\n    - Logical structure\n    - Appropriate for target audience\n    - Good use of headings/formatting\n    \n    **Quality scale:**\n    - \u2b50\u2b50\u2b50\u2b50\u2b50 Crystal clear, well-structured\n    - \u2b50\u2b50\u2b50 Understandable but could improve\n    - \u2b50 Confusing or poorly organized\n  </Accordion>\n  \n  <Accordion title=\"Accuracy\">\n    **Indicators:**\n    - Technically correct\n    - Code examples work\n    - No conflicting information\n    - Matches product behavior\n    \n    **Quality scale:**\n    - \u2b50\u2b50\u2b50\u2b50\u2b50 Verified accurate\n    - \u2b50\u2b50\u2b50 Generally accurate, minor issues\n    - \u2b50 Contains errors or outdated info\n  </Accordion>\n</AccordionGroup>\n\n**Your AI Prompt Template:**\n\n```text\nI'm conducting a content audit and need to establish quality criteria.\n\nMy documentation covers: [Brief description]\nPrimary audience: [User type and level]\nKey user goals: [What users need to accomplish]\n\nHelp me define 5-7 quality criteria appropriate for this content and audience.\n\nFor each criterion:\n1. Name and definition\n2. What \"good\" looks like\n3. What \"poor\" looks like\n4. How to measure it (quantitative or qualitative indicators)\n5. Why it matters to users\n\nFocus on criteria that can be consistently applied across 200+ pages.\n```\n\n---",
            "hydration_source_header": "1.2 Defining Quality Criteria",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "step-3-duplicate-analysis",
            "title": "Step 3: Run Duplicate Analysis",
            "uses": "duplicate-detection-pattern",
            "lines": "1285-1325",
            "hydration_status": "failed"
          },
          {
            "id": "step-4-map-journey",
            "title": "Step 4: Map User Journey",
            "uses": "gap-analysis-pattern",
            "lines": "1330-1360",
            "content": "**First, define your primary user journeys:**\n\n```text\nUSER JOURNEY TEMPLATE\n\nJourney Name: [Descriptive name]\nUser Persona: [Who is this user?]\nStarting Point: [Where does the journey begin?]\nEnd Goal: [What does success look like?]\n\nStages:\n1. [Stage name]\n   - User goal: [What they want to accomplish]\n   - Expected content: [What would help them]\n   - Current content: [What exists now - TBD in analysis]\n   \n2. [Next stage...]\n   [Continue for 4-7 stages]\n\nSuccess Criteria:\n- [How do you know the journey is well-supported?]\n```\n\n---",
            "hydration_source_header": "4.1 Mapping Content to User Journeys",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "step-5-identify-gaps",
            "title": "Step 5: Identify Content Gaps",
            "uses": "gap-analysis-pattern",
            "lines": "1365-1395",
            "hydration_status": "failed"
          },
          {
            "id": "step-6-assess-quality",
            "title": "Step 6: Assess Content Quality",
            "uses": "batch-quality-scoring",
            "lines": "1400-1440",
            "hydration_status": "failed"
          },
          {
            "id": "step-7-synthesize",
            "title": "Step 7: Synthesize Findings",
            "uses": "gap-report-prompt",
            "lines": "1445-1475",
            "content": "You now have:\n\n**\u2705 Complete Content Inventory**\n- All 100 pages cataloged\n- Rich metadata captured\n- Ready for ongoing maintenance\n\n**\u2705 Duplicate Analysis**\n- Top 10 consolidation opportunities identified\n- Effort estimates and recommendations\n- User impact assessed\n\n**\u2705 Gap Analysis**\n- Mapped against primary user journey\n- P0/P1/P2 prioritization\n- Effort estimates for addressing\n\n**\u2705 Quality Assessment**\n- Systematic evaluation of all content\n- Top 15 quality improvements prioritized\n- Patterns and systemic issues identified\n\n**\u2705 Executive Summary**\n- 1-2 page overview for leadership\n- Clear recommendations and priorities\n- Resource requirements and timeline\n\n**\u2705 Detailed Action Plan**\n- Phased implementation roadmap\n- Specific, actionable items\n- Success metrics defined\n\n**Time Investment:**\n- Your time: 6-8 hours\n- Traditional manual audit: 40-60 hours\n- Time saved: ~85%\n\n---",
            "hydration_source_header": "Tutorial Complete: What You've Built",
            "hydration_method": "line_proximity"
          },
          {
            "id": "step-8-action-plan",
            "title": "Step 8: Create Detailed Action Plan",
            "uses": "phased-action-planning",
            "lines": "1480-1505",
            "content": "Let's see how a real company applied these techniques.\n\n### Background\n\n**CloudTech Solutions** is a mid-size SaaS company offering a cloud infrastructure platform. Their developer documentation has grown organically over five years across multiple product teams.\n\n**Problems:**\n- Increased support tickets about documentation\n- Lower developer satisfaction scores (NPS dropped from 45 to 32)\n- Longer time-to-first-API-call (45 minutes \u2192 75 minutes)\n\n**Audit Charter:**\n- Scope: Developer documentation (380 pages across 6 product areas)\n- Primary audience: Backend developers integrating CloudTech APIs\n- Timeline: 3 weeks\n- Budget: 80 hours (2 FTE weeks)\n\n---\n\n### Audit Execution\n\n**Week 1: Inventory and Discovery**\n\n<AccordionGroup>\n  <Accordion title=\"Content Inventory\">\n    - Crawled all documentation pages\n    - Extracted metadata (title, URL, category, last updated, word count)\n    - Categorized by product area and content type\n    - 380 items total\n    \n    **Key Findings:**\n    - 40% of content not updated in 18+ months\n    - Word count ranged from 100 to 5,000 words\n    - Inconsistent categorization across product teams\n  </Accordion>\n  \n  <Accordion title=\"Duplicate Analysis\">\n    Used AI to identify duplicate content:\n    \n    ```text\n    Prompt: \"Analyze this 380-page inventory for duplicates and overlap...\"\n    ```\n    \n    **Results:**\n    - 23 duplicate clusters identified\n    - Top 5 clusters affecting 45 pages\n    - Authentication docs duplicated 7 times across products\n    - Setup guides repeated with minor variations\n    \n    **Validation:**\n    - Manually checked top 10 clusters\n    - 8 confirmed as true duplicates\n    - 2 were similar but served different purposes\n  </Accordion>\n</AccordionGroup>\n\n**Week 2: Gap Analysis and Quality Assessment**\n\n<AccordionGroup>\n  <Accordion title=\"Journey Mapping\">\n    Defined 3 primary user journeys:\n    1. First-time integration (beginner)\n    2. Multi-service integration (intermediate)\n    3. Production optimization (advanced)\n    \n    Mapped existing content to each journey stage.\n  </Accordion>\n  \n  <Accordion title=\"Gap Analysis Results\">\n    Used AI to identify gaps:\n    \n    **Critical Gaps (P0):**\n    - Quickstart guide (estimated 60 min to first API call)\n    - Error troubleshooting guide\n    - Authentication decision tree\n    - Production readiness checklist\n    - Cross-service integration patterns\n    \n    **Total P0 effort:** 32-40 hours\n    **Expected impact:** Reduce time-to-first-call by 40%\n    \n    **Secondary Gaps (P1):**\n    - Advanced performance optimization\n    - Security best practices\n    - Migration guides between versions\n    \n    **Total P1 effort:** 24-32 hours\n  </Accordion>\n  \n  <Accordion title=\"Quality Assessment\">\n    AI-assisted quality scoring of all 380 pages:\n    \n    **Quality Distribution:**\n    - Excellent (5\u2b50): 15% (57 pages)\n    - Good (4\u2b50): 25% (95 pages)\n    - Adequate (3\u2b50): 30% (114 pages)\n    - Poor (2\u2b50): 20% (76 pages)\n    - Very Poor (1\u2b50): 10% (38 pages)\n    \n    **Patterns Identified:**\n    - Newest product area (launched 6 months ago) had consistently high quality\n    - Oldest product area (5+ years) had 50% poor-quality pages\n    - API reference pages generally high quality (4-5\u2b50)\n    - Tutorial/guide pages highly variable (1-5\u2b50)\n  </Accordion>\n</AccordionGroup>\n\n**Week 3: Recommendations and Action Planning**\n\n<AccordionGroup>\n  <Accordion title=\"Executive Summary\">\n    **Key Findings:**\n    1. 23 duplicate content clusters waste maintenance effort\n    2. Critical gaps in beginner journey (authentication, troubleshooting)\n    3. 30% of content needs quality improvement\n    4. Inconsistent structure across product teams\n    \n    **Top Recommendations:**\n    1. Create unified quickstart (covers all products)\n    2. Consolidate authentication docs into single source\n    3. Establish content quality standards\n    4. Implement quarterly audit process\n  </Accordion>\n  \n  <Accordion title=\"Phased Action Plan\">\n    **Phase 1: Critical Fixes (Month 1)**\n    - Unified quickstart guide (8 hours)\n    - Error troubleshooting guide (6 hours)\n    - Authentication consolidation (12 hours)\n    - Total: 26 hours\n    - Impact: Reduce time-to-first-call by 30%\n    \n    **Phase 2: Foundation (Months 2-3)**\n    - Address all P0 gaps (32 hours)\n    - Quality improvements for top 20 pages (16 hours)\n    - Content standards documentation (4 hours)\n    - Total: 52 hours\n    - Impact: Increase NPS by 8-10 points\n    \n    **Phase 3: Systematic Improvement (Months 4-6)**\n    - P1 gap addressing (24 hours)\n    - Remaining duplicate consolidation (20 hours)\n    - Quality improvements for next 30 pages (24 hours)\n    - Total: 68 hours\n    - Impact: Reduce support tickets by 25%\n  </Accordion>\n</AccordionGroup>\n\n---\n\n### Results (6 Months Post-Audit)\n\n**Metrics:**\n- Time-to-first-API-call: 75 min \u2192 38 min (49% improvement)\n- Developer NPS: 32 \u2192 48 (50% improvement)\n- Documentation support tickets: -35%\n- Developer satisfaction: \"Documentation\" rating 3.2 \u2192 4.4 out of 5\n\n**Process Improvements:**\n- Quarterly documentation review process established\n- Content quality standards documented\n- Cross-team collaboration on shared content\n- AI-assisted monitoring for duplicates and gaps\n\n**Lessons Learned:**\n- AI-assisted audit saved ~120 hours vs. manual approach\n- Validation was critical (10% of AI findings were incorrect)\n- Quick wins (Phase 1) built momentum for larger changes\n- Executive summary got leadership buy-in immediately\n\n<Info>\n  **Case Study Insight:** CloudTech's success came from three factors: (1) using AI for scale analysis, (2) ruthless prioritization (focused on P0 gaps only initially), and (3) measuring impact with clear metrics.\n</Info>\n\n---",
            "hydration_source_header": "6. Composite Example: Enterprise Documentation Audit",
            "hydration_method": "line_proximity"
          }
        ],
        "concepts": [
          {
            "id": "content-audit",
            "term": "Content Audit",
            "definition": "Systematic evaluation of content for quality, gaps, and redundancies",
            "lines": "25-55",
            "retrievalQuestions": [
              "What is a content audit?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "content-inventory",
            "term": "Content Inventory",
            "definition": "Catalog of all content with metadata (title, URL, type, date, etc.)",
            "lines": "128-155",
            "retrievalQuestions": [
              "What is a content inventory?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "quality-criteria",
            "term": "Quality Criteria",
            "definition": "Measurable standards for evaluating content",
            "lines": "158-220",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "audit-charter",
            "term": "Audit Charter",
            "definition": "Document defining scope, objectives, timeline, and deliverables",
            "lines": "245-295",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "duplicate-cluster",
            "term": "Duplicate Cluster",
            "definition": "Group of pages covering the same or overlapping topics",
            "lines": "430-435",
            "retrievalQuestions": [
              "What is a duplicate cluster?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "semantic-duplication",
            "term": "Semantic Duplication",
            "definition": "Same information expressed with different words",
            "lines": "400-405",
            "retrievalQuestions": [
              "What is semantic duplication?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "user-journey-mapping",
            "term": "User Journey Mapping",
            "definition": "Aligning content to stages of user goal accomplishment",
            "lines": "555-600",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "gap-matrix",
            "term": "Gap Matrix",
            "definition": "Visual representation of content coverage vs. user needs",
            "lines": "770-790",
            "retrievalQuestions": [
              "What is a gap matrix?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "quality-outlier",
            "term": "Quality Outlier",
            "definition": "Content significantly better or worse than average",
            "lines": "1055-1065",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "staleness",
            "term": "Content Staleness",
            "definition": "Outdated content that no longer reflects current product/reality",
            "lines": "1095-1100",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "phased-action-plan",
            "term": "Phased Action Plan",
            "definition": "Improvement roadmap organized by priority and timeline",
            "lines": "1480-1505",
            "hydration_status": "skipped_unknown"
          }
        ],
        "examples": [
          {
            "id": "csv-inventory-example",
            "title": "CSV Inventory Format Example",
            "demonstrates": "content-inventory-pattern",
            "lines": "138-148",
            "hydration_status": "failed"
          },
          {
            "id": "text-inventory-example",
            "title": "Text Inventory Format Example",
            "demonstrates": "content-inventory-pattern",
            "lines": "148-155",
            "content": "AI needs clear criteria to assess content quality. Define what \"good\" looks like for your documentation.\n\n**Sample quality criteria:**\n\n<AccordionGroup>\n  <Accordion title=\"Completeness\">\n    **Indicators:**\n    - Covers topic comprehensively\n    - Includes code examples\n    - Has prerequisites listed\n    - Links to related content\n    \n    **Quality scale:**\n    - \u2b50\u2b50\u2b50\u2b50\u2b50 Complete with examples and context\n    - \u2b50\u2b50\u2b50 Covers basics but missing examples\n    - \u2b50 Incomplete or skeletal content\n  </Accordion>\n  \n  <Accordion title=\"Currency\">\n    **Indicators:**\n    - Updated within last 6 months\n    - References current product version\n    - No deprecated information\n    - Matches current UI/API\n    \n    **Quality scale:**\n    - \u2b50\u2b50\u2b50\u2b50\u2b50 Updated within 3 months\n    - \u2b50\u2b50\u2b50 3-12 months old but still accurate\n    - \u2b50 Over 12 months, likely outdated\n  </Accordion>\n  \n  <Accordion title=\"Clarity\">\n    **Indicators:**\n    - Clear, concise writing\n    - Logical structure\n    - Appropriate for target audience\n    - Good use of headings/formatting\n    \n    **Quality scale:**\n    - \u2b50\u2b50\u2b50\u2b50\u2b50 Crystal clear, well-structured\n    - \u2b50\u2b50\u2b50 Understandable but could improve\n    - \u2b50 Confusing or poorly organized\n  </Accordion>\n  \n  <Accordion title=\"Accuracy\">\n    **Indicators:**\n    - Technically correct\n    - Code examples work\n    - No conflicting information\n    - Matches product behavior\n    \n    **Quality scale:**\n    - \u2b50\u2b50\u2b50\u2b50\u2b50 Verified accurate\n    - \u2b50\u2b50\u2b50 Generally accurate, minor issues\n    - \u2b50 Contains errors or outdated info\n  </Accordion>\n</AccordionGroup>\n\n**Your AI Prompt Template:**\n\n```text\nI'm conducting a content audit and need to establish quality criteria.\n\nMy documentation covers: [Brief description]\nPrimary audience: [User type and level]\nKey user goals: [What users need to accomplish]\n\nHelp me define 5-7 quality criteria appropriate for this content and audience.\n\nFor each criterion:\n1. Name and definition\n2. What \"good\" looks like\n3. What \"poor\" looks like\n4. How to measure it (quantitative or qualitative indicators)\n5. Why it matters to users\n\nFocus on criteria that can be consistently applied across 200+ pages.\n```\n\n---",
            "hydration_source_header": "1.2 Defining Quality Criteria",
            "hydration_method": "line_proximity"
          },
          {
            "id": "duplicate-cluster-example",
            "title": "Webhook Duplicate Cluster Example",
            "demonstrates": "duplicate-detection-pattern",
            "lines": "435-530",
            "retrievalQuestions": [
              "What does a duplicate cluster analysis look like?"
            ],
            "content": "Find exact and near-duplicates that confuse users and waste maintenance effort.\n\n**Your Prompt:**\n\n```text\nNow analyzing the full inventory for duplicate and overlapping content.\n\nFull inventory (showing: Title, URL, Category, Type, Description):\n[Paste full inventory]\n\nPlease identify:\n1. Exact or near-exact duplicates (same title, very similar content)\n2. Significant topical overlap (covering same information differently)\n3. Semantic duplication (different words, same meaning)\n\nFor each duplicate cluster:\n- List the items involved\n- Explain the likely overlap\n- Assess user impact (confusion, maintenance burden)\n- Recommend: consolidate, differentiate, or redirect\n\nFocus on the 10 highest-priority duplication issues first.\n```\n\n**Expected AI Output Example:**\n\n```text\nDUPLICATE CONTENT ANALYSIS\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nDUPLICATE CLUSTER 1: Webhook Setup (HIGH PRIORITY)\n\nItems involved:\n1. \"Getting Started with Webhooks\" (/docs/webhooks/intro)\n2. \"How to Set Up Webhooks\" (/docs/guides/webhook-setup)\n3. \"Webhook Configuration\" (/docs/api/webhooks/config)\n\nLikely overlap:\nAll three appear to cover basic webhook setup and configuration. Based on \ntitles and URLs, they likely contain:\n- What webhooks are (conceptual)\n- How to register webhook endpoints\n- How to verify webhook signatures\n- Example webhook payloads\n\nUser impact:\n- Confusion: Which is the \"right\" guide to follow?\n- Inconsistency risk: If one is updated, others may become outdated\n- Maintenance burden: Three places to update for any webhook changes\n- SEO cannibalization: Competing for same search terms\n\nRecommendation: CONSOLIDATE\n\u2192 Create single authoritative \"Webhooks Guide\" at /docs/webhooks/\n\u2192 Structure as:\n  - Introduction (what webhooks are)\n  - Setup & Configuration (how to register)\n  - Security (signature verification)\n  - Examples & Use Cases\n  - Troubleshooting\n\u2192 Redirect old URLs to new consolidated guide\n\u2192 Estimated effort: 4-6 hours\n\nPriority: HIGH\n- Core feature (webhooks are frequently used)\n- High confusion potential (three competing guides)\n- Moderate consolidation effort\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nDUPLICATE CLUSTER 2: Authentication Basics (MEDIUM PRIORITY)\n\nItems involved:\n1. \"API Authentication\" (/docs/auth)\n2. \"Authentication Guide\" (/docs/guides/authentication)\n3. \"Getting Started: Authentication\" (/docs/start/auth)\n\nLikely overlap:\nAll cover API authentication basics. Possible differences:\n- Item 1 might be reference-style (all auth methods)\n- Item 2 might be how-to (step-by-step implementation)\n- Item 3 might be beginner tutorial (first time setup)\n\nUser impact:\n- Less severe than webhooks (may serve different purposes)\n- Still creates uncertainty about where to start\n- Maintenance burden across three documents\n\nRecommendation: DIFFERENTIATE or CONSOLIDATE\nOption A (Differentiate):\n\u2192 Keep all three but clarify purpose in each title/description:\n  - \"Authentication Overview\" (reference, all methods)\n  - \"Authentication Implementation Guide\" (how-to for developers)\n  - \"First-Time Authentication\" (beginner tutorial)\n\u2192 Cross-link clearly with \"see also\" sections\n\u2192 Estimated effort: 2-3 hours\n\nOption B (Consolidate):\n\u2192 Single \"Authentication Guide\" with sections for different audiences\n\u2192 Redirect old URLs\n\u2192 Estimated effort: 4-5 hours\n\nPriority: MEDIUM\n- Critical feature but possibly serving different needs\n- Moderate confusion potential\n- Requires further investigation to choose approach\n\n[Continue for clusters 3-10...]\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nSUMMARY:\n\nTotal duplicate clusters identified: 10\n- High priority (consolidate immediately): 3 clusters\n- Medium priority (consolidate or differentiate): 5 clusters\n- Low priority (monitor, address opportunistically): 2 clusters\n\nEstimated effort for all high-priority consolidations: 12-18 hours\nExpected impact: Eliminate confusion for 3 core features, reduce maintenance \nburden by ~30% for affected content\n```\n\n<Tip>\n  **Validation Step:** AI can identify potential duplicates, but you should verify by actually reading 2-3 examples from each cluster. Sometimes similar titles cover genuinely different content.\n</Tip>\n\n---",
            "hydration_source_header": "2.3 Duplicate Content Detection",
            "hydration_method": "line_proximity"
          },
          {
            "id": "auth-duplicate-example",
            "title": "Authentication Duplicates Example",
            "demonstrates": "duplicate-detection-pattern",
            "lines": "530-545",
            "content": "The most meaningful gaps are those that block users from accomplishing their goals.\n\n**Your Prompt:**\n\n```text\nAssess content gaps for this user journey:\n\nUSER JOURNEY: First-Time Integration\nUser: Backend developer integrating CloudAPI for the first time\nGoal: Successfully make authenticated API calls within 60 minutes\n\nJourney stages:\n1. Discovery: Understand what CloudAPI does and if it fits needs\n   Goals: Learn capabilities, see use cases, understand pricing/limits\n   \n2. Setup: Get access and set up development environment\n   Goals: Create account, get API keys, install SDK/tools\n   \n3. Authentication: Implement authentication correctly\n   Goals: Understand auth flow, implement securely, test auth\n   \n4. First API Call: Make first successful API request\n   Goals: Choose right endpoint, construct request, handle response\n   \n5. Validation: Confirm integration works and understand next steps\n   Goals: Test thoroughly, handle errors, know where to go next\n\nCurrent inventory:\n[Paste relevant portion of inventory, or reference the full inventory]\n\nFor each journey stage:\n1. What content supports it?\n2. What critical gaps would block users?\n3. What nice-to-have content is missing?\n4. Is existing content at the right depth/format?\n\nPrioritize gaps by user impact and create a gap matrix showing current vs. \nneeded coverage.\n```\n\n**Expected AI Output Example:**\n\n```text\nCONTENT GAP ANALYSIS - First-Time Integration Journey\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nSTAGE 1: DISCOVERY\nGoal: Understand what CloudAPI does and if it fits needs\n\nCurrent Coverage:\n\u2705 \"What is CloudAPI\" overview (exists)\n\u2705 \"Key Features\" page (exists)\n\u274c Use case examples (MISSING)\n\u274c Comparison to alternatives (MISSING)\n\u274c Rate limits/pricing overview (MISSING in docs, on pricing page only)\n\nCRITICAL GAPS:\n1. Use Case Library (P0)\n   - Impact: HIGH - Users can't assess fit without real examples\n   - What's needed: 5-7 concrete use case examples with code\n   - Where: New section \"Use Cases\" in Get Started\n   - Effort: 6-8 hours\n   - Why critical: Prevents wasted time for users CloudAPI doesn't fit\n\n2. Pricing & Limits Overview (P1)\n   - Impact: MEDIUM - Users fear surprise costs\n   - What's needed: Link to pricing + summary of free tier limits\n   - Where: Callout box in \"What is CloudAPI\"\n   - Effort: 1-2 hours\n   - Why critical: Common blocker in adoption decisions\n\nNICE-TO-HAVE:\n- Comparison guide (vs. competitors): P2, Low priority\n  Users can evaluate without this, but it would help\n\nCurrent content assessment:\n- \"What is CloudAPI\" is comprehensive but doesn't address use cases\n- Missing the \"Is this right for me?\" angle\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nSTAGE 2: SETUP\nGoal: Get access and set up development environment\n\nCurrent Coverage:\n\u2705 Account creation (exists - links to signup)\n\u2705 API key generation (exists)\n\u274c SDK installation (MISSING for Python, Ruby)\n\u274c Development environment setup (MISSING)\n\u2705 Postman collection (exists)\n\nCRITICAL GAPS:\n1. SDK Installation Guides (P0)\n   - Impact: HIGH - Many users prefer SDKs over raw HTTP\n   - What's needed: Installation + basic setup for Node.js, Python, Ruby\n   - Where: New \"SDK Quickstarts\" section\n   - Effort: 4-6 hours total (1-2 hours per SDK)\n   - Why critical: Reduces time-to-first-call dramatically\n\n2. Environment Setup Guide (P1)\n   - Impact: MEDIUM - Some users struggle with dev environment\n   - What's needed: Environment variables, testing vs. production setup\n   - Where: Expand \"Getting Started\" section\n   - Effort: 2-3 hours\n   - Why critical: Prevents common early mistakes (using prod keys in dev)\n\nCurrent content assessment:\n- \"Getting API Keys\" is clear but doesn't explain key management\n- No guidance on environment setup best practices\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nSTAGE 3: AUTHENTICATION\nGoal: Implement authentication correctly\n\nCurrent Coverage:\n\u2705 OAuth 2.0 documentation (exists - very detailed)\n\u2705 API key authentication (exists)\n\u274c Authentication quick comparison (MISSING)\n\u274c Common auth errors troubleshooting (MISSING)\n\u274c Security best practices (MISSING)\n\nCRITICAL GAPS:\n1. \"Which Auth Method?\" Decision Guide (P0)\n   - Impact: HIGH - Users waste time choosing wrong auth method\n   - What's needed: Flow chart or decision tree + comparison table\n   - Where: Before detailed auth docs, in overview\n   - Effort: 2-3 hours\n   - Why critical: Prevents users from implementing OAuth when API keys sufficient\n\n2. Authentication Troubleshooting (P0)\n   - Impact: HIGH - Auth errors are top support issue\n   - What's needed: Common errors, causes, solutions\n   - Where: New \"Troubleshooting Auth\" page\n   - Effort: 3-4 hours\n   - Why critical: Reduces support tickets by 20-30%\n\nNICE-TO-HAVE:\n- Security best practices: P2, should be covered but not blocking\n\nCurrent content assessment:\n- OAuth docs are too detailed for beginners (intimidating)\n- Need progressive disclosure: simple path, then advanced options\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nSTAGE 4: FIRST API CALL\nGoal: Make first successful API request\n\nCurrent Coverage:\n\u2705 API endpoints documented (exists)\n\u2705 \"Your First API Call\" tutorial (exists)\n\u274c Response handling guide (MISSING)\n\u274c Error code reference (MISSING)\n\u274c Quick reference / cheat sheet (MISSING)\n\nCRITICAL GAPS:\n1. Error Code Reference (P0)\n   - Impact: HIGH - Users stuck when things go wrong\n   - What's needed: All HTTP errors, CloudAPI-specific codes, solutions\n   - Where: New \"Error Reference\" page\n   - Effort: 4-5 hours\n   - Why critical: Unblocks users immediately when errors occur\n\n2. API Cheat Sheet (P1)\n   - Impact: MEDIUM - Convenient but not blocking\n   - What's needed: One-page quick reference of common endpoints/patterns\n   - Where: Standalone page + PDF download\n   - Effort: 3-4 hours\n   - Why critical: Reduces time searching docs once users are productive\n\nCurrent content assessment:\n- \"Your First API Call\" is excellent (clear, comprehensive)\n- But doesn't prepare users for what happens when it fails\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nSTAGE 5: VALIDATION\nGoal: Confirm integration works and understand next steps\n\nCurrent Coverage:\n\u274c Testing strategies (MISSING)\n\u274c Integration checklist (MISSING)\n\u274c \"What's next?\" recommendations (MISSING)\n\u274c Sample applications (MISSING)\n\nCRITICAL GAPS:\n1. Integration Testing Guide (P0)\n   - Impact: HIGH - Users ship untested integrations, cause issues\n   - What's needed: How to test API integration, common pitfalls, test checklist\n   - Where: New \"Testing Your Integration\" guide\n   - Effort: 4-5 hours\n   - Why critical: Prevents production issues, reduces support burden\n\n2. \"Next Steps\" Navigation (P1)\n   - Impact: MEDIUM - Users unsure what to learn next\n   - What's needed: Curated learning paths based on use case\n   - Where: End of \"First API Call\" tutorial + standalone page\n   - Effort: 2-3 hours\n   - Why critical: Increases depth of integration, engagement\n\nNICE-TO-HAVE:\n- Sample applications: P2, helpful but users can build from docs\n\nCurrent content assessment:\n- Journey essentially \"ends\" after first call\n- No guidance on production readiness or next steps\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nGAP MATRIX SUMMARY:\n\nLegend: \u2705 Adequate | \u26a0\ufe0f Partial | \u274c Missing\n\n| Journey Stage | Coverage | Critical Gaps | Priority |\n|--------------|----------|---------------|----------|\n| Discovery    | \u26a0\ufe0f Partial | Use cases (P0), Pricing (P1) | HIGH |\n| Setup        | \u26a0\ufe0f Partial | SDK setup (P0), Env setup (P1) | HIGH |\n| Authentication | \u2705 Adequate | Auth decision (P0), Troubleshooting (P0) | CRITICAL |\n| First Call   | \u2705 Adequate | Error reference (P0), Cheat sheet (P1) | HIGH |\n| Validation   | \u274c Missing | Testing guide (P0), Next steps (P1) | CRITICAL |\n\nPRIORITY GAPS (P0 - Address Immediately):\n1. Authentication decision guide - 2-3 hours\n2. Use case library - 6-8 hours\n3. Authentication troubleshooting - 3-4 hours\n4. Error code reference - 4-5 hours\n5. SDK installation guides - 4-6 hours\n6. Integration testing guide - 4-5 hours\n\nTotal P0 effort: ~24-33 hours\nExpected impact: Reduce time-to-first-call by 40%, reduce auth support tickets by 30%\n\nSECONDARY GAPS (P1 - Address This Quarter):\n[Listed with effort estimates...]\n\nOVERALL ASSESSMENT:\nJourney coverage: 60% adequate\nMajor blocker: Authentication and validation stages need significant work\nStrengths: First API call tutorial is excellent foundation\nOpportunity: Build validation stage from scratch (currently 0% coverage)\n```\n\n<Warning>\n  **Gap Analysis Reality Check:** Not every gap needs to be filled immediately. Prioritize gaps that:\n  1. Block users from accomplishing critical goals\n  2. Cause frequent support tickets\n  3. Have high impact relative to effort\n  \n  Some \"nice-to-have\" gaps can stay unfilled indefinitely if resources are limited.\n</Warning>\n\n---",
            "hydration_source_header": "2.4 Gap Analysis Against User Journeys",
            "hydration_method": "line_proximity"
          },
          {
            "id": "gap-analysis-full-example",
            "title": "First-Time Integration Gap Analysis",
            "demonstrates": "gap-analysis-pattern",
            "lines": "600-790",
            "retrievalQuestions": [
              "Example of gap analysis output"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "exploratory-analysis-example",
            "title": "Sample Content Exploratory Analysis",
            "demonstrates": "exploratory-sample-prompt",
            "lines": "375-385",
            "hydration_status": "failed"
          },
          {
            "id": "cloudtech-case-study",
            "title": "CloudTech Solutions Full Audit",
            "demonstrates": "complete-audit-workflow",
            "lines": "1500-1675",
            "retrievalQuestions": [
              "Show me a complete audit case study"
            ],
            "content": "Let's see how a real company applied these techniques.\n\n### Background\n\n**CloudTech Solutions** is a mid-size SaaS company offering a cloud infrastructure platform. Their developer documentation has grown organically over five years across multiple product teams.\n\n**Problems:**\n- Increased support tickets about documentation\n- Lower developer satisfaction scores (NPS dropped from 45 to 32)\n- Longer time-to-first-API-call (45 minutes \u2192 75 minutes)\n\n**Audit Charter:**\n- Scope: Developer documentation (380 pages across 6 product areas)\n- Primary audience: Backend developers integrating CloudTech APIs\n- Timeline: 3 weeks\n- Budget: 80 hours (2 FTE weeks)\n\n---\n\n### Audit Execution\n\n**Week 1: Inventory and Discovery**\n\n<AccordionGroup>\n  <Accordion title=\"Content Inventory\">\n    - Crawled all documentation pages\n    - Extracted metadata (title, URL, category, last updated, word count)\n    - Categorized by product area and content type\n    - 380 items total\n    \n    **Key Findings:**\n    - 40% of content not updated in 18+ months\n    - Word count ranged from 100 to 5,000 words\n    - Inconsistent categorization across product teams\n  </Accordion>\n  \n  <Accordion title=\"Duplicate Analysis\">\n    Used AI to identify duplicate content:\n    \n    ```text\n    Prompt: \"Analyze this 380-page inventory for duplicates and overlap...\"\n    ```\n    \n    **Results:**\n    - 23 duplicate clusters identified\n    - Top 5 clusters affecting 45 pages\n    - Authentication docs duplicated 7 times across products\n    - Setup guides repeated with minor variations\n    \n    **Validation:**\n    - Manually checked top 10 clusters\n    - 8 confirmed as true duplicates\n    - 2 were similar but served different purposes\n  </Accordion>\n</AccordionGroup>\n\n**Week 2: Gap Analysis and Quality Assessment**\n\n<AccordionGroup>\n  <Accordion title=\"Journey Mapping\">\n    Defined 3 primary user journeys:\n    1. First-time integration (beginner)\n    2. Multi-service integration (intermediate)\n    3. Production optimization (advanced)\n    \n    Mapped existing content to each journey stage.\n  </Accordion>\n  \n  <Accordion title=\"Gap Analysis Results\">\n    Used AI to identify gaps:\n    \n    **Critical Gaps (P0):**\n    - Quickstart guide (estimated 60 min to first API call)\n    - Error troubleshooting guide\n    - Authentication decision tree\n    - Production readiness checklist\n    - Cross-service integration patterns\n    \n    **Total P0 effort:** 32-40 hours\n    **Expected impact:** Reduce time-to-first-call by 40%\n    \n    **Secondary Gaps (P1):**\n    - Advanced performance optimization\n    - Security best practices\n    - Migration guides between versions\n    \n    **Total P1 effort:** 24-32 hours\n  </Accordion>\n  \n  <Accordion title=\"Quality Assessment\">\n    AI-assisted quality scoring of all 380 pages:\n    \n    **Quality Distribution:**\n    - Excellent (5\u2b50): 15% (57 pages)\n    - Good (4\u2b50): 25% (95 pages)\n    - Adequate (3\u2b50): 30% (114 pages)\n    - Poor (2\u2b50): 20% (76 pages)\n    - Very Poor (1\u2b50): 10% (38 pages)\n    \n    **Patterns Identified:**\n    - Newest product area (launched 6 months ago) had consistently high quality\n    - Oldest product area (5+ years) had 50% poor-quality pages\n    - API reference pages generally high quality (4-5\u2b50)\n    - Tutorial/guide pages highly variable (1-5\u2b50)\n  </Accordion>\n</AccordionGroup>\n\n**Week 3: Recommendations and Action Planning**\n\n<AccordionGroup>\n  <Accordion title=\"Executive Summary\">\n    **Key Findings:**\n    1. 23 duplicate content clusters waste maintenance effort\n    2. Critical gaps in beginner journey (authentication, troubleshooting)\n    3. 30% of content needs quality improvement\n    4. Inconsistent structure across product teams\n    \n    **Top Recommendations:**\n    1. Create unified quickstart (covers all products)\n    2. Consolidate authentication docs into single source\n    3. Establish content quality standards\n    4. Implement quarterly audit process\n  </Accordion>\n  \n  <Accordion title=\"Phased Action Plan\">\n    **Phase 1: Critical Fixes (Month 1)**\n    - Unified quickstart guide (8 hours)\n    - Error troubleshooting guide (6 hours)\n    - Authentication consolidation (12 hours)\n    - Total: 26 hours\n    - Impact: Reduce time-to-first-call by 30%\n    \n    **Phase 2: Foundation (Months 2-3)**\n    - Address all P0 gaps (32 hours)\n    - Quality improvements for top 20 pages (16 hours)\n    - Content standards documentation (4 hours)\n    - Total: 52 hours\n    - Impact: Increase NPS by 8-10 points\n    \n    **Phase 3: Systematic Improvement (Months 4-6)**\n    - P1 gap addressing (24 hours)\n    - Remaining duplicate consolidation (20 hours)\n    - Quality improvements for next 30 pages (24 hours)\n    - Total: 68 hours\n    - Impact: Reduce support tickets by 25%\n  </Accordion>\n</AccordionGroup>\n\n---\n\n### Results (6 Months Post-Audit)\n\n**Metrics:**\n- Time-to-first-API-call: 75 min \u2192 38 min (49% improvement)\n- Developer NPS: 32 \u2192 48 (50% improvement)\n- Documentation support tickets: -35%\n- Developer satisfaction: \"Documentation\" rating 3.2 \u2192 4.4 out of 5\n\n**Process Improvements:**\n- Quarterly documentation review process established\n- Content quality standards documented\n- Cross-team collaboration on shared content\n- AI-assisted monitoring for duplicates and gaps\n\n**Lessons Learned:**\n- AI-assisted audit saved ~120 hours vs. manual approach\n- Validation was critical (10% of AI findings were incorrect)\n- Quick wins (Phase 1) built momentum for larger changes\n- Executive summary got leadership buy-in immediately\n\n<Info>\n  **Case Study Insight:** CloudTech's success came from three factors: (1) using AI for scale analysis, (2) ruthless prioritization (focused on P0 gaps only initially), and (3) measuring impact with clear metrics.\n</Info>\n\n---",
            "hydration_source_header": "6. Composite Example: Enterprise Documentation Audit",
            "hydration_method": "line_proximity"
          }
        ],
        "caseStudies": [
          {
            "id": "cloudtech-audit",
            "title": "CloudTech Solutions Enterprise Audit",
            "domain": "Cloud infrastructure",
            "scope": "380 pages, 3 weeks",
            "results": "49% faster time-to-first-call, 50% NPS improvement",
            "lines": "1500-1675",
            "retrievalQuestions": [
              "What results can I expect from an AI-assisted audit?",
              "How long does an enterprise audit take?"
            ],
            "content": "Let's see how a real company applied these techniques.\n\n### Background\n\n**CloudTech Solutions** is a mid-size SaaS company offering a cloud infrastructure platform. Their developer documentation has grown organically over five years across multiple product teams.\n\n**Problems:**\n- Increased support tickets about documentation\n- Lower developer satisfaction scores (NPS dropped from 45 to 32)\n- Longer time-to-first-API-call (45 minutes \u2192 75 minutes)\n\n**Audit Charter:**\n- Scope: Developer documentation (380 pages across 6 product areas)\n- Primary audience: Backend developers integrating CloudTech APIs\n- Timeline: 3 weeks\n- Budget: 80 hours (2 FTE weeks)\n\n---\n\n### Audit Execution\n\n**Week 1: Inventory and Discovery**\n\n<AccordionGroup>\n  <Accordion title=\"Content Inventory\">\n    - Crawled all documentation pages\n    - Extracted metadata (title, URL, category, last updated, word count)\n    - Categorized by product area and content type\n    - 380 items total\n    \n    **Key Findings:**\n    - 40% of content not updated in 18+ months\n    - Word count ranged from 100 to 5,000 words\n    - Inconsistent categorization across product teams\n  </Accordion>\n  \n  <Accordion title=\"Duplicate Analysis\">\n    Used AI to identify duplicate content:\n    \n    ```text\n    Prompt: \"Analyze this 380-page inventory for duplicates and overlap...\"\n    ```\n    \n    **Results:**\n    - 23 duplicate clusters identified\n    - Top 5 clusters affecting 45 pages\n    - Authentication docs duplicated 7 times across products\n    - Setup guides repeated with minor variations\n    \n    **Validation:**\n    - Manually checked top 10 clusters\n    - 8 confirmed as true duplicates\n    - 2 were similar but served different purposes\n  </Accordion>\n</AccordionGroup>\n\n**Week 2: Gap Analysis and Quality Assessment**\n\n<AccordionGroup>\n  <Accordion title=\"Journey Mapping\">\n    Defined 3 primary user journeys:\n    1. First-time integration (beginner)\n    2. Multi-service integration (intermediate)\n    3. Production optimization (advanced)\n    \n    Mapped existing content to each journey stage.\n  </Accordion>\n  \n  <Accordion title=\"Gap Analysis Results\">\n    Used AI to identify gaps:\n    \n    **Critical Gaps (P0):**\n    - Quickstart guide (estimated 60 min to first API call)\n    - Error troubleshooting guide\n    - Authentication decision tree\n    - Production readiness checklist\n    - Cross-service integration patterns\n    \n    **Total P0 effort:** 32-40 hours\n    **Expected impact:** Reduce time-to-first-call by 40%\n    \n    **Secondary Gaps (P1):**\n    - Advanced performance optimization\n    - Security best practices\n    - Migration guides between versions\n    \n    **Total P1 effort:** 24-32 hours\n  </Accordion>\n  \n  <Accordion title=\"Quality Assessment\">\n    AI-assisted quality scoring of all 380 pages:\n    \n    **Quality Distribution:**\n    - Excellent (5\u2b50): 15% (57 pages)\n    - Good (4\u2b50): 25% (95 pages)\n    - Adequate (3\u2b50): 30% (114 pages)\n    - Poor (2\u2b50): 20% (76 pages)\n    - Very Poor (1\u2b50): 10% (38 pages)\n    \n    **Patterns Identified:**\n    - Newest product area (launched 6 months ago) had consistently high quality\n    - Oldest product area (5+ years) had 50% poor-quality pages\n    - API reference pages generally high quality (4-5\u2b50)\n    - Tutorial/guide pages highly variable (1-5\u2b50)\n  </Accordion>\n</AccordionGroup>\n\n**Week 3: Recommendations and Action Planning**\n\n<AccordionGroup>\n  <Accordion title=\"Executive Summary\">\n    **Key Findings:**\n    1. 23 duplicate content clusters waste maintenance effort\n    2. Critical gaps in beginner journey (authentication, troubleshooting)\n    3. 30% of content needs quality improvement\n    4. Inconsistent structure across product teams\n    \n    **Top Recommendations:**\n    1. Create unified quickstart (covers all products)\n    2. Consolidate authentication docs into single source\n    3. Establish content quality standards\n    4. Implement quarterly audit process\n  </Accordion>\n  \n  <Accordion title=\"Phased Action Plan\">\n    **Phase 1: Critical Fixes (Month 1)**\n    - Unified quickstart guide (8 hours)\n    - Error troubleshooting guide (6 hours)\n    - Authentication consolidation (12 hours)\n    - Total: 26 hours\n    - Impact: Reduce time-to-first-call by 30%\n    \n    **Phase 2: Foundation (Months 2-3)**\n    - Address all P0 gaps (32 hours)\n    - Quality improvements for top 20 pages (16 hours)\n    - Content standards documentation (4 hours)\n    - Total: 52 hours\n    - Impact: Increase NPS by 8-10 points\n    \n    **Phase 3: Systematic Improvement (Months 4-6)**\n    - P1 gap addressing (24 hours)\n    - Remaining duplicate consolidation (20 hours)\n    - Quality improvements for next 30 pages (24 hours)\n    - Total: 68 hours\n    - Impact: Reduce support tickets by 25%\n  </Accordion>\n</AccordionGroup>\n\n---\n\n### Results (6 Months Post-Audit)\n\n**Metrics:**\n- Time-to-first-API-call: 75 min \u2192 38 min (49% improvement)\n- Developer NPS: 32 \u2192 48 (50% improvement)\n- Documentation support tickets: -35%\n- Developer satisfaction: \"Documentation\" rating 3.2 \u2192 4.4 out of 5\n\n**Process Improvements:**\n- Quarterly documentation review process established\n- Content quality standards documented\n- Cross-team collaboration on shared content\n- AI-assisted monitoring for duplicates and gaps\n\n**Lessons Learned:**\n- AI-assisted audit saved ~120 hours vs. manual approach\n- Validation was critical (10% of AI findings were incorrect)\n- Quick wins (Phase 1) built momentum for larger changes\n- Executive summary got leadership buy-in immediately\n\n<Info>\n  **Case Study Insight:** CloudTech's success came from three factors: (1) using AI for scale analysis, (2) ruthless prioritization (focused on P0 gaps only initially), and (3) measuring impact with clear metrics.\n</Info>\n\n---",
            "hydration_source_header": "6. Composite Example: Enterprise Documentation Audit",
            "hydration_method": "line_proximity"
          }
        ],
        "checklists": [
          {
            "id": "inventory-validation-checklist",
            "title": "Content Inventory Validation",
            "validates": "content-inventory-pattern",
            "items": 3,
            "lines": "1240-1245",
            "hydration_status": "failed"
          },
          {
            "id": "criteria-validation-checklist",
            "title": "Quality Criteria Validation",
            "validates": "quality-criteria-pattern",
            "items": 3,
            "lines": "1275-1280",
            "hydration_status": "failed"
          },
          {
            "id": "duplicate-validation-checklist",
            "title": "Duplicate Analysis Validation",
            "validates": "duplicate-detection-pattern",
            "items": 4,
            "lines": "1315-1325",
            "hydration_status": "failed"
          },
          {
            "id": "project-evaluation-criteria",
            "title": "Project Evaluation Criteria",
            "validates": "complete-audit-workflow",
            "items": 20,
            "lines": "1850-1880",
            "content": "Your project will be assessed on:\n\n**1. Audit Rigor (30%)**\n- \u2713 Comprehensive inventory with rich metadata\n- \u2713 Systematic application of quality criteria\n- \u2713 Thorough gap analysis against user journey\n- \u2713 Evidence-based findings (not assumptions)\n- \u2713 Appropriate validation of AI outputs\n\n**2. AI Prompt Quality (25%)**\n- \u2713 Effective use of AI for scale analysis\n- \u2713 Clear, specific prompts with context\n- \u2713 Appropriate prompts for different tasks\n- \u2713 Critical evaluation of AI outputs\n- \u2713 Demonstration of human-AI partnership\n\n**3. Actionability (25%)**\n- \u2713 Clear prioritization (P0/P1/P2/P3)\n- \u2713 Realistic effort estimates\n- \u2713 Specific, implementable recommendations\n- \u2713 Clear success metrics\n- \u2713 Resource requirements defined\n\n**4. Documentation Quality (20%)**\n- \u2713 Clear, well-organized deliverables\n- \u2713 Appropriate format for each audience\n- \u2713 Professional presentation\n- \u2713 Reproducible methodology\n- \u2713 Executive summary compelling\n\n---",
            "hydration_source_header": "Evaluation Criteria",
            "hydration_method": "title_match"
          },
          {
            "id": "success-indicators",
            "title": "Success Indicators Checklist",
            "validates": "complete-audit-workflow",
            "items": 7,
            "lines": "1915-1930",
            "retrievalQuestions": [
              "How do I know if my audit is successful?"
            ],
            "content": "**You've done well if:**\n\n\u2705 You can defend every priority decision with data\n\n\u2705 Your recommendations are specific enough to assign and schedule\n\n\u2705 A stakeholder could approve resources based on your executive summary\n\n\u2705 You identified insights you wouldn't have found manually\n\n\u2705 You saved 60%+ time vs. manual audit while maintaining quality\n\n\u2705 You demonstrated appropriate skepticism of AI outputs\n\n\u2705 Your action plan includes realistic timelines and effort estimates\n\n---",
            "hydration_source_header": "Success Indicators",
            "hydration_method": "title_match"
          }
        ],
        "qualityCriteria": [
          {
            "id": "completeness-criterion",
            "criterion": "Completeness",
            "scale": "1-5 stars",
            "keyIndicators": "Covers topic, includes examples, lists prerequisites, links to related",
            "lines": "165-180",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "currency-criterion",
            "criterion": "Currency",
            "scale": "1-5 stars",
            "keyIndicators": "Updated recently, current version, no deprecated info",
            "lines": "180-195",
            "retrievalQuestions": [
              "What makes content 'current' or 'stale'?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "clarity-criterion",
            "criterion": "Clarity",
            "scale": "1-5 stars",
            "keyIndicators": "Clear writing, logical structure, appropriate for audience",
            "lines": "195-210",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "accuracy-criterion",
            "criterion": "Accuracy",
            "scale": "1-5 stars",
            "keyIndicators": "Technically correct, code works, matches product behavior",
            "lines": "210-220",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "actionability-criterion",
            "criterion": "Actionability",
            "scale": "1-5 stars",
            "keyIndicators": "Users can accomplish goals",
            "lines": "implicit",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "discoverability-criterion",
            "criterion": "Discoverability",
            "scale": "1-5 stars",
            "keyIndicators": "Linked to related content",
            "lines": "implicit",
            "hydration_status": "skipped_unknown"
          }
        ],
        "priorityLevels": [
          {
            "id": "p0-priority",
            "level": "P0 (Critical)",
            "definition": "Blocking critical user paths",
            "whenToUse": "Address immediately",
            "lines": "1160-1165",
            "retrievalQuestions": [
              "What is a P0 gap?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "p1-priority",
            "level": "P1 (High)",
            "definition": "Significant user friction",
            "whenToUse": "Address this quarter",
            "lines": "1165-1170",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "p2-priority",
            "level": "P2 (Medium)",
            "definition": "Nice to have",
            "whenToUse": "Address this year",
            "lines": "1170",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "p3-priority",
            "level": "P3 (Low)",
            "definition": "Low impact",
            "whenToUse": "Address opportunistically",
            "lines": "1170",
            "retrievalQuestions": [
              "How do I prioritize content gaps?"
            ],
            "hydration_status": "skipped_unknown"
          }
        ],
        "warnings": [
          {
            "id": "scope-creep-warning",
            "title": "Scope Creep",
            "prevents": "Trying to audit everything",
            "lines": "295-305, 1885",
            "retrievalQuestions": [
              "How do I avoid scope creep in audits?"
            ],
            "content": "Now that your inventory is ready, let's use AI to analyze it systematically.\n\n### 2.1 The Content Audit Framework Prompt\n\nThis foundational prompt establishes context for all your audit work.\n\n**Your Prompt:**\n\n```text\nYou're a content strategist helping audit developer documentation.\n\nAudit scope and objectives:\n[Paste your audit charter]\n\nQuality criteria:\n[Paste your quality criteria]\n\nI'll be sharing content inventory data and asking you to help identify:\n- Duplicates and overlapping content\n- Content gaps based on user journeys\n- Quality issues and improvement priorities\n- Structural and organizational issues\n\nI have [number] total items. I'll start with a sample to ensure you understand \nthe content domain, then share the full inventory.\n\nPlease confirm you understand the audit scope and ask any clarifying questions \nbefore we begin analysis.\n```\n\n**Why this works:**\n- Establishes AI as an expert collaborator\n- Provides full context upfront\n- Sets clear expectations\n- Invites questions (catches misunderstandings early)\n\n---\n\n### 2.2 Exploratory Analysis on Sample Content\n\nStart with a representative sample to calibrate AI's understanding.\n\n**Your Prompt:**\n\n```text\nHere's a representative sample of 10 items from the documentation:\n\n[Paste your sample content with full detail]\n\nBased on this sample:\n1. What patterns do you notice in structure and organization?\n2. What content types are represented?\n3. What potential issues stand out?\n4. What questions should guide the full audit?\n5. Are my quality criteria clear and appropriate for this content?\n\nDon't make final judgments yet\u2014I want your initial observations to refine \nmy audit approach.\n```\n\n**Expected AI Output Pattern:**\n\n```text\nSAMPLE ANALYSIS - DEVELOPER DOCUMENTATION\n\nPATTERNS OBSERVED:\n\nStructure:\n- Consistent three-part pattern: Overview \u2192 Implementation \u2192 Examples\n- Most guides 1000-1500 words\n- Reference docs significantly longer (2000+ words)\n- Tutorials include code snippets, guides more conceptual\n\nOrganization:\n- Content grouped by feature area (not user journey)\n- Mix of beginner and advanced content in same sections\n- \"Getting Started\" seems isolated from advanced content\n- No clear progression paths indicated\n\nContent Types:\n- Tutorials (20%): Step-by-step, hands-on\n- Guides (40%): How-to, task-oriented\n- Reference (30%): Technical specifications\n- Concepts (10%): Explanatory content\n\nPOTENTIAL ISSUES:\n\n1. Possible duplication: Three items mention \"webhooks\" - may overlap\n2. Inconsistent depth: Some tutorials very brief (<500 words), others detailed\n3. Missing connections: No indication of prerequisites or \"next steps\"\n4. Age variation: Dates range from 2022-2024, some may be outdated\n5. Audience clarity: Mix of beginner/advanced without clear labeling\n\nAUDIT QUESTIONS TO EXPLORE:\n\n1. Is content appropriately distributed across types (tutorial/guide/reference)?\n2. Do learning paths exist, or is content fragmented?\n3. What's the right balance of breadth vs. depth?\n4. Should webhooks content be consolidated?\n5. What criteria should trigger content updates?\n\nQUALITY CRITERIA ASSESSMENT:\n\nYour criteria are clear and measurable. Suggestions:\n- Add \"Actionability\" - Can users accomplish their goal?\n- Consider \"Discoverability\" - Can users find related content?\n- \"Currency\" might need product-version context for accuracy\n```\n\n<Info>\n  **Calibration Tip:** This exploratory step is crucial. If AI misunderstands your content domain or criteria, catch it here before analyzing hundreds of pages. Refine your criteria based on AI's questions.\n</Info>\n\n---\n\n### 2.3 Duplicate Content Detection\n\nFind exact and near-duplicates that confuse users and waste maintenance effort.\n\n**Your Prompt:**\n\n```text\nNow analyzing the full inventory for duplicate and overlapping content.\n\nFull inventory (showing: Title, URL, Category, Type, Description):\n[Paste full inventory]\n\nPlease identify:\n1. Exact or near-exact duplicates (same title, very similar content)\n2. Significant topical overlap (covering same information differently)\n3. Semantic duplication (different words, same meaning)\n\nFor each duplicate cluster:\n- List the items involved\n- Explain the likely overlap\n- Assess user impact (confusion, maintenance burden)\n- Recommend: consolidate, differentiate, or redirect\n\nFocus on the 10 highest-priority duplication issues first.\n```\n\n**Expected AI Output Example:**\n\n```text\nDUPLICATE CONTENT ANALYSIS\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nDUPLICATE CLUSTER 1: Webhook Setup (HIGH PRIORITY)\n\nItems involved:\n1. \"Getting Started with Webhooks\" (/docs/webhooks/intro)\n2. \"How to Set Up Webhooks\" (/docs/guides/webhook-setup)\n3. \"Webhook Configuration\" (/docs/api/webhooks/config)\n\nLikely overlap:\nAll three appear to cover basic webhook setup and configuration. Based on \ntitles and URLs, they likely contain:\n- What webhooks are (conceptual)\n- How to register webhook endpoints\n- How to verify webhook signatures\n- Example webhook payloads\n\nUser impact:\n- Confusion: Which is the \"right\" guide to follow?\n- Inconsistency risk: If one is updated, others may become outdated\n- Maintenance burden: Three places to update for any webhook changes\n- SEO cannibalization: Competing for same search terms\n\nRecommendation: CONSOLIDATE\n\u2192 Create single authoritative \"Webhooks Guide\" at /docs/webhooks/\n\u2192 Structure as:\n  - Introduction (what webhooks are)\n  - Setup & Configuration (how to register)\n  - Security (signature verification)\n  - Examples & Use Cases\n  - Troubleshooting\n\u2192 Redirect old URLs to new consolidated guide\n\u2192 Estimated effort: 4-6 hours\n\nPriority: HIGH\n- Core feature (webhooks are frequently used)\n- High confusion potential (three competing guides)\n- Moderate consolidation effort\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nDUPLICATE CLUSTER 2: Authentication Basics (MEDIUM PRIORITY)\n\nItems involved:\n1. \"API Authentication\" (/docs/auth)\n2. \"Authentication Guide\" (/docs/guides/authentication)\n3. \"Getting Started: Authentication\" (/docs/start/auth)\n\nLikely overlap:\nAll cover API authentication basics. Possible differences:\n- Item 1 might be reference-style (all auth methods)\n- Item 2 might be how-to (step-by-step implementation)\n- Item 3 might be beginner tutorial (first time setup)\n\nUser impact:\n- Less severe than webhooks (may serve different purposes)\n- Still creates uncertainty about where to start\n- Maintenance burden across three documents\n\nRecommendation: DIFFERENTIATE or CONSOLIDATE\nOption A (Differentiate):\n\u2192 Keep all three but clarify purpose in each title/description:\n  - \"Authentication Overview\" (reference, all methods)\n  - \"Authentication Implementation Guide\" (how-to for developers)\n  - \"First-Time Authentication\" (beginner tutorial)\n\u2192 Cross-link clearly with \"see also\" sections\n\u2192 Estimated effort: 2-3 hours\n\nOption B (Consolidate):\n\u2192 Single \"Authentication Guide\" with sections for different audiences\n\u2192 Redirect old URLs\n\u2192 Estimated effort: 4-5 hours\n\nPriority: MEDIUM\n- Critical feature but possibly serving different needs\n- Moderate confusion potential\n- Requires further investigation to choose approach\n\n[Continue for clusters 3-10...]\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nSUMMARY:\n\nTotal duplicate clusters identified: 10\n- High priority (consolidate immediately): 3 clusters\n- Medium priority (consolidate or differentiate): 5 clusters\n- Low priority (monitor, address opportunistically): 2 clusters\n\nEstimated effort for all high-priority consolidations: 12-18 hours\nExpected impact: Eliminate confusion for 3 core features, reduce maintenance \nburden by ~30% for affected content\n```\n\n<Tip>\n  **Validation Step:** AI can identify potential duplicates, but you should verify by actually reading 2-3 examples from each cluster. Sometimes similar titles cover genuinely different content.\n</Tip>\n\n---\n\n### 2.4 Gap Analysis Against User Journeys\n\nThe most meaningful gaps are those that block users from accomplishing their goals.\n\n**Your Prompt:**\n\n```text\nAssess content gaps for this user journey:\n\nUSER JOURNEY: First-Time Integration\nUser: Backend developer integrating CloudAPI for the first time\nGoal: Successfully make authenticated API calls within 60 minutes\n\nJourney stages:\n1. Discovery: Understand what CloudAPI does and if it fits needs\n   Goals: Learn capabilities, see use cases, understand pricing/limits\n   \n2. Setup: Get access and set up development environment\n   Goals: Create account, get API keys, install SDK/tools\n   \n3. Authentication: Implement authentication correctly\n   Goals: Understand auth flow, implement securely, test auth\n   \n4. First API Call: Make first successful API request\n   Goals: Choose right endpoint, construct request, handle response\n   \n5. Validation: Confirm integration works and understand next steps\n   Goals: Test thoroughly, handle errors, know where to go next\n\nCurrent inventory:\n[Paste relevant portion of inventory, or reference the full inventory]\n\nFor each journey stage:\n1. What content supports it?\n2. What critical gaps would block users?\n3. What nice-to-have content is missing?\n4. Is existing content at the right depth/format?\n\nPrioritize gaps by user impact and create a gap matrix showing current vs. \nneeded coverage.\n```\n\n**Expected AI Output Example:**\n\n```text\nCONTENT GAP ANALYSIS - First-Time Integration Journey\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nSTAGE 1: DISCOVERY\nGoal: Understand what CloudAPI does and if it fits needs\n\nCurrent Coverage:\n\u2705 \"What is CloudAPI\" overview (exists)\n\u2705 \"Key Features\" page (exists)\n\u274c Use case examples (MISSING)\n\u274c Comparison to alternatives (MISSING)\n\u274c Rate limits/pricing overview (MISSING in docs, on pricing page only)\n\nCRITICAL GAPS:\n1. Use Case Library (P0)\n   - Impact: HIGH - Users can't assess fit without real examples\n   - What's needed: 5-7 concrete use case examples with code\n   - Where: New section \"Use Cases\" in Get Started\n   - Effort: 6-8 hours\n   - Why critical: Prevents wasted time for users CloudAPI doesn't fit\n\n2. Pricing & Limits Overview (P1)\n   - Impact: MEDIUM - Users fear surprise costs\n   - What's needed: Link to pricing + summary of free tier limits\n   - Where: Callout box in \"What is CloudAPI\"\n   - Effort: 1-2 hours\n   - Why critical: Common blocker in adoption decisions\n\nNICE-TO-HAVE:\n- Comparison guide (vs. competitors): P2, Low priority\n  Users can evaluate without this, but it would help\n\nCurrent content assessment:\n- \"What is CloudAPI\" is comprehensive but doesn't address use cases\n- Missing the \"Is this right for me?\" angle\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nSTAGE 2: SETUP\nGoal: Get access and set up development environment\n\nCurrent Coverage:\n\u2705 Account creation (exists - links to signup)\n\u2705 API key generation (exists)\n\u274c SDK installation (MISSING for Python, Ruby)\n\u274c Development environment setup (MISSING)\n\u2705 Postman collection (exists)\n\nCRITICAL GAPS:\n1. SDK Installation Guides (P0)\n   - Impact: HIGH - Many users prefer SDKs over raw HTTP\n   - What's needed: Installation + basic setup for Node.js, Python, Ruby\n   - Where: New \"SDK Quickstarts\" section\n   - Effort: 4-6 hours total (1-2 hours per SDK)\n   - Why critical: Reduces time-to-first-call dramatically\n\n2. Environment Setup Guide (P1)\n   - Impact: MEDIUM - Some users struggle with dev environment\n   - What's needed: Environment variables, testing vs. production setup\n   - Where: Expand \"Getting Started\" section\n   - Effort: 2-3 hours\n   - Why critical: Prevents common early mistakes (using prod keys in dev)\n\nCurrent content assessment:\n- \"Getting API Keys\" is clear but doesn't explain key management\n- No guidance on environment setup best practices\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nSTAGE 3: AUTHENTICATION\nGoal: Implement authentication correctly\n\nCurrent Coverage:\n\u2705 OAuth 2.0 documentation (exists - very detailed)\n\u2705 API key authentication (exists)\n\u274c Authentication quick comparison (MISSING)\n\u274c Common auth errors troubleshooting (MISSING)\n\u274c Security best practices (MISSING)\n\nCRITICAL GAPS:\n1. \"Which Auth Method?\" Decision Guide (P0)\n   - Impact: HIGH - Users waste time choosing wrong auth method\n   - What's needed: Flow chart or decision tree + comparison table\n   - Where: Before detailed auth docs, in overview\n   - Effort: 2-3 hours\n   - Why critical: Prevents users from implementing OAuth when API keys sufficient\n\n2. Authentication Troubleshooting (P0)\n   - Impact: HIGH - Auth errors are top support issue\n   - What's needed: Common errors, causes, solutions\n   - Where: New \"Troubleshooting Auth\" page\n   - Effort: 3-4 hours\n   - Why critical: Reduces support tickets by 20-30%\n\nNICE-TO-HAVE:\n- Security best practices: P2, should be covered but not blocking\n\nCurrent content assessment:\n- OAuth docs are too detailed for beginners (intimidating)\n- Need progressive disclosure: simple path, then advanced options\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nSTAGE 4: FIRST API CALL\nGoal: Make first successful API request\n\nCurrent Coverage:\n\u2705 API endpoints documented (exists)\n\u2705 \"Your First API Call\" tutorial (exists)\n\u274c Response handling guide (MISSING)\n\u274c Error code reference (MISSING)\n\u274c Quick reference / cheat sheet (MISSING)\n\nCRITICAL GAPS:\n1. Error Code Reference (P0)\n   - Impact: HIGH - Users stuck when things go wrong\n   - What's needed: All HTTP errors, CloudAPI-specific codes, solutions\n   - Where: New \"Error Reference\" page\n   - Effort: 4-5 hours\n   - Why critical: Unblocks users immediately when errors occur\n\n2. API Cheat Sheet (P1)\n   - Impact: MEDIUM - Convenient but not blocking\n   - What's needed: One-page quick reference of common endpoints/patterns\n   - Where: Standalone page + PDF download\n   - Effort: 3-4 hours\n   - Why critical: Reduces time searching docs once users are productive\n\nCurrent content assessment:\n- \"Your First API Call\" is excellent (clear, comprehensive)\n- But doesn't prepare users for what happens when it fails\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nSTAGE 5: VALIDATION\nGoal: Confirm integration works and understand next steps\n\nCurrent Coverage:\n\u274c Testing strategies (MISSING)\n\u274c Integration checklist (MISSING)\n\u274c \"What's next?\" recommendations (MISSING)\n\u274c Sample applications (MISSING)\n\nCRITICAL GAPS:\n1. Integration Testing Guide (P0)\n   - Impact: HIGH - Users ship untested integrations, cause issues\n   - What's needed: How to test API integration, common pitfalls, test checklist\n   - Where: New \"Testing Your Integration\" guide\n   - Effort: 4-5 hours\n   - Why critical: Prevents production issues, reduces support burden\n\n2. \"Next Steps\" Navigation (P1)\n   - Impact: MEDIUM - Users unsure what to learn next\n   - What's needed: Curated learning paths based on use case\n   - Where: End of \"First API Call\" tutorial + standalone page\n   - Effort: 2-3 hours\n   - Why critical: Increases depth of integration, engagement\n\nNICE-TO-HAVE:\n- Sample applications: P2, helpful but users can build from docs\n\nCurrent content assessment:\n- Journey essentially \"ends\" after first call\n- No guidance on production readiness or next steps\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nGAP MATRIX SUMMARY:\n\nLegend: \u2705 Adequate | \u26a0\ufe0f Partial | \u274c Missing\n\n| Journey Stage | Coverage | Critical Gaps | Priority |\n|--------------|----------|---------------|----------|\n| Discovery    | \u26a0\ufe0f Partial | Use cases (P0), Pricing (P1) | HIGH |\n| Setup        | \u26a0\ufe0f Partial | SDK setup (P0), Env setup (P1) | HIGH |\n| Authentication | \u2705 Adequate | Auth decision (P0), Troubleshooting (P0) | CRITICAL |\n| First Call   | \u2705 Adequate | Error reference (P0), Cheat sheet (P1) | HIGH |\n| Validation   | \u274c Missing | Testing guide (P0), Next steps (P1) | CRITICAL |\n\nPRIORITY GAPS (P0 - Address Immediately):\n1. Authentication decision guide - 2-3 hours\n2. Use case library - 6-8 hours\n3. Authentication troubleshooting - 3-4 hours\n4. Error code reference - 4-5 hours\n5. SDK installation guides - 4-6 hours\n6. Integration testing guide - 4-5 hours\n\nTotal P0 effort: ~24-33 hours\nExpected impact: Reduce time-to-first-call by 40%, reduce auth support tickets by 30%\n\nSECONDARY GAPS (P1 - Address This Quarter):\n[Listed with effort estimates...]\n\nOVERALL ASSESSMENT:\nJourney coverage: 60% adequate\nMajor blocker: Authentication and validation stages need significant work\nStrengths: First API call tutorial is excellent foundation\nOpportunity: Build validation stage from scratch (currently 0% coverage)\n```\n\n<Warning>\n  **Gap Analysis Reality Check:** Not every gap needs to be filled immediately. Prioritize gaps that:\n  1. Block users from accomplishing critical goals\n  2. Cause frequent support tickets\n  3. Have high impact relative to effort\n  \n  Some \"nice-to-have\" gaps can stay unfilled indefinitely if resources are limited.\n</Warning>\n\n---\n\n### 2.5 Quality Pattern Analysis\n\nIdentify systemic quality issues across your content inventory.\n\n**Your Prompt:**\n\n```text\nAnalyze quality patterns across the inventory:\n\n[Paste inventory with quality signals: update dates, word counts, categories]\n\nQuality criteria to apply:\n[Reference earlier quality criteria]\n\nIdentify:\n1. Clusters of quality issues (e.g., certain categories consistently lower quality)\n2. Items that likely need review (based on age, brevity, or other signals)\n3. Patterns suggesting systemic issues vs. one-off problems\n4. Sections where quality is consistently high (learn from these)\n5. Correlation between quality signals (e.g., newer content more complete?)\n\nPrioritize the top 15 items for quality improvement based on:\n- User impact (traffic, importance to key journeys)\n- Severity of quality issue\n- Ease of improvement\n\nPresent as prioritized list with specific improvement recommendations.\n```\n\n**Expected Output Pattern:**\n\nThe AI will identify patterns like:\n- \"All content updated before 2023 lacks code examples\"\n- \"API Reference section consistently high quality (5\u2b50), Guides section variable (2-4\u2b50)\"\n- \"Content under 500 words almost always incomplete\"\n- \"Certain authors consistently produce higher quality\"\n\nThis helps you identify not just individual problems, but systemic issues to address.\n\n---\n\n### 2.6 Comparative Analysis Techniques\n\nCompare your content against benchmarks, standards, or competitors.\n\n**Competitive Gap Analysis Prompt:**\n\n```text\nI'm comparing our documentation to industry standards.\n\nOur content coverage:\n[Paste your inventory categories and counts]\n\nIndustry standard/competitor structure:\n[Paste benchmark structure or competitor table of contents]\n\nIdentify:\n1. Topic areas where we're missing coverage\n2. Areas where we have more comprehensive coverage\n3. Structural differences in how content is organized\n4. Recommendations for bringing our coverage in line with expectations\n\nPrioritize gaps that likely impact user success.\n```\n\n**Standards Compliance Check:**\n\n```text\nEvaluate this content inventory against the Di\u00e1taxis framework:\n\nDi\u00e1taxis requires four content types:\n- Tutorials: Learning-oriented, step-by-step\n- How-to Guides: Task-oriented, problem-solving\n- Reference: Information-oriented, technical specs\n- Explanation: Understanding-oriented, concepts\n\nOur current content:\n[Paste inventory]\n\nFor each Di\u00e1taxis category:\n1. What content we have that fits\n2. What's missing\n3. Content that's miscategorized\n4. Recommendations for restructuring\n\nFocus on the biggest structural misalignments first.\n```\n\n<Info>\n  **Framework Context:** Di\u00e1taxis is a systematic approach to technical documentation that organizes content into four quadrants. Many successful documentation sites (Django, Stripe, Divio) follow this framework. Learn more at [diataxis.fr](https://diataxis.fr)\n</Info>\n\n---\n\n### 2.7 Multi-Pass Audit Strategies\n\nFor complex audits, use a phased approach with increasingly focused prompts.\n\n**Pass 1: High-Level Structure**\n\n```text\nFirst pass review - focus on structure and organization only:\n\n[Paste inventory]\n\nAssess:\n1. Overall information architecture (logical grouping?)\n2. Navigation and hierarchy (clear paths?)\n3. Major structural gaps\n4. Sections that seem misplaced\n\nDon't evaluate individual page quality yet\u2014stay at the structural level.\n```\n\n**Pass 2: Category-Level Analysis**\n\n```text\nSecond pass - analyze the \"Getting Started\" category in detail:\n\n[Paste Getting Started inventory items]\n\nEvaluate:\n1. Completeness for user onboarding\n2. Logical sequence and progression\n3. Overlap or redundancy within this category\n4. Quality red flags (based on titles/descriptions)\n5. Missing elements compared to user journey\n\nProvide specific, actionable recommendations.\n```\n\n**Pass 3: Cross-Category Relationships**\n\n```text\nThird pass - analyze relationships between categories:\n\nCategories: [List main categories]\nRepresentative items: [Paste sample from each category]\n\nIdentify:\n1. Content that should be connected but isn't\n2. Duplicate coverage across categories\n3. Logical progression paths users would follow\n4. Navigation or wayfinding gaps between categories\n\nMap the top 5 priority cross-category improvements.\n```\n\n---",
            "hydration_source_header": "2. Prompt Strategies for Content Analysis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "over-reliance-on-ai",
            "title": "Over-Reliance on AI",
            "prevents": "Skipping validation",
            "lines": "1885-1890",
            "retrievalQuestions": [
              "Why shouldn't I rely entirely on AI for audits?"
            ],
            "content": "<Warning>\n  **Avoid These Common Mistakes:**\n  \n  \u274c **Scope creep** - Don't try to audit everything. Focus on defined section.\n  \n  \u274c **Over-reliance on AI** - Always validate AI findings with spot-checks.\n  \n  \u274c **Vague recommendations** - \"Improve quality\" isn't actionable. Be specific.\n  \n  \u274c **Ignoring effort** - Recommendations must include realistic time estimates.\n  \n  \u274c **Missing user context** - Gap analysis must tie to actual user journeys, not just categories.\n  \n  \u274c **Lack of prioritization** - Everything can't be P0. Make hard priority choices.\n  \n  \u274c **Analysis paralysis** - Aim for actionable insights, not perfect analysis.\n</Warning>\n\n---",
            "hydration_source_header": "Common Pitfalls to Avoid",
            "hydration_method": "line_proximity"
          },
          {
            "id": "vague-recommendations",
            "title": "Vague Recommendations",
            "prevents": "\"Improve quality\" without specifics",
            "lines": "1890",
            "content": "<Warning>\n  **Avoid These Common Mistakes:**\n  \n  \u274c **Scope creep** - Don't try to audit everything. Focus on defined section.\n  \n  \u274c **Over-reliance on AI** - Always validate AI findings with spot-checks.\n  \n  \u274c **Vague recommendations** - \"Improve quality\" isn't actionable. Be specific.\n  \n  \u274c **Ignoring effort** - Recommendations must include realistic time estimates.\n  \n  \u274c **Missing user context** - Gap analysis must tie to actual user journeys, not just categories.\n  \n  \u274c **Lack of prioritization** - Everything can't be P0. Make hard priority choices.\n  \n  \u274c **Analysis paralysis** - Aim for actionable insights, not perfect analysis.\n</Warning>\n\n---",
            "hydration_source_header": "Common Pitfalls to Avoid",
            "hydration_method": "line_proximity"
          },
          {
            "id": "ignoring-effort",
            "title": "Ignoring Effort Estimates",
            "prevents": "Recommendations without time estimates",
            "lines": "1890-1895",
            "content": "<Warning>\n  **Avoid These Common Mistakes:**\n  \n  \u274c **Scope creep** - Don't try to audit everything. Focus on defined section.\n  \n  \u274c **Over-reliance on AI** - Always validate AI findings with spot-checks.\n  \n  \u274c **Vague recommendations** - \"Improve quality\" isn't actionable. Be specific.\n  \n  \u274c **Ignoring effort** - Recommendations must include realistic time estimates.\n  \n  \u274c **Missing user context** - Gap analysis must tie to actual user journeys, not just categories.\n  \n  \u274c **Lack of prioritization** - Everything can't be P0. Make hard priority choices.\n  \n  \u274c **Analysis paralysis** - Aim for actionable insights, not perfect analysis.\n</Warning>\n\n---",
            "hydration_source_header": "Common Pitfalls to Avoid",
            "hydration_method": "line_proximity"
          },
          {
            "id": "missing-user-context",
            "title": "Missing User Context",
            "prevents": "Gaps not tied to user journeys",
            "lines": "1895",
            "content": "**You've done well if:**\n\n\u2705 You can defend every priority decision with data\n\n\u2705 Your recommendations are specific enough to assign and schedule\n\n\u2705 A stakeholder could approve resources based on your executive summary\n\n\u2705 You identified insights you wouldn't have found manually\n\n\u2705 You saved 60%+ time vs. manual audit while maintaining quality\n\n\u2705 You demonstrated appropriate skepticism of AI outputs\n\n\u2705 Your action plan includes realistic timelines and effort estimates\n\n---",
            "hydration_source_header": "Success Indicators",
            "hydration_method": "line_proximity"
          },
          {
            "id": "lack-of-prioritization",
            "title": "Lack of Prioritization",
            "prevents": "Everything marked P0",
            "lines": "1895-1900",
            "content": "**You've done well if:**\n\n\u2705 You can defend every priority decision with data\n\n\u2705 Your recommendations are specific enough to assign and schedule\n\n\u2705 A stakeholder could approve resources based on your executive summary\n\n\u2705 You identified insights you wouldn't have found manually\n\n\u2705 You saved 60%+ time vs. manual audit while maintaining quality\n\n\u2705 You demonstrated appropriate skepticism of AI outputs\n\n\u2705 Your action plan includes realistic timelines and effort estimates\n\n---",
            "hydration_source_header": "Success Indicators",
            "hydration_method": "line_proximity"
          },
          {
            "id": "analysis-paralysis",
            "title": "Analysis Paralysis",
            "prevents": "Perfectionism over action",
            "lines": "1900",
            "content": "**You've done well if:**\n\n\u2705 You can defend every priority decision with data\n\n\u2705 Your recommendations are specific enough to assign and schedule\n\n\u2705 A stakeholder could approve resources based on your executive summary\n\n\u2705 You identified insights you wouldn't have found manually\n\n\u2705 You saved 60%+ time vs. manual audit while maintaining quality\n\n\u2705 You demonstrated appropriate skepticism of AI outputs\n\n\u2705 Your action plan includes realistic timelines and effort estimates\n\n---",
            "hydration_source_header": "Success Indicators",
            "hydration_method": "line_proximity"
          }
        ],
        "tools": [
          {
            "id": "screaming-frog",
            "tool": "Screaming Frog",
            "purpose": "Web crawler for content inventory",
            "lines": "1225",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "excel-sheets",
            "tool": "Excel/Google Sheets",
            "purpose": "Inventory management",
            "lines": "1230",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "custom-scripts",
            "tool": "Custom Scripts",
            "purpose": "Extracting docs from GitHub",
            "lines": "1225",
            "hydration_status": "skipped_unknown"
          }
        ],
        "deliverables": [
          {
            "id": "content-inventory-deliverable",
            "title": "Content Inventory Spreadsheet",
            "purpose": "Catalog all content",
            "format": "Excel/Sheets",
            "lines": "1710-1745",
            "content": "<AccordionGroup>\n  <Accordion title=\"Deliverable 1: Content Inventory (Spreadsheet)\">\n    **Requirements:**\n    - Minimum 50 items analyzed\n    - Required fields:\n      - Title\n      - URL\n      - Category\n      - Content type\n      - Last updated date\n      - Word count\n      - Brief description\n    \n    **Optional but recommended:**\n    - Author\n    - Status\n    - Traffic data (if available)\n    - Quality signals\n    \n    **Format:** Excel or Google Sheets\n    \n    **Evaluation criteria:**\n    - Completeness of inventory\n    - Metadata quality\n    - Categorization consistency\n  </Accordion>\n  \n  <Accordion title=\"Deliverable 2: Audit Findings Report (3-5 pages)\">\n    **Required sections:**\n    \n    **1. Duplicate Content Analysis**\n    - Top 5-10 duplicate clusters\n    - Consolidation recommendations\n    - Effort estimates\n    \n    **2. Content Gap Analysis**\n    - User journey defined\n    - Gaps mapped to journey stages\n    - P0/P1/P2 prioritization\n    - Effort estimates\n    \n    **3. Quality Assessment**\n    - Top 10-15 quality issues\n    - Patterns identified\n    - Specific improvement recommendations\n    \n    **4. Structural Issues**\n    - Navigation/IA problems\n    - Inconsistencies\n    - Organizational recommendations\n    \n    **Format:** PDF or Word document\n    \n    **Evaluation criteria:**\n    - Thoroughness of analysis\n    - Evidence-based findings\n    - Actionable recommendations\n  </Accordion>\n  \n  <Accordion title=\"Deliverable 3: Prioritized Action Plan (1-2 pages)\">\n    **Required elements:**\n    \n    **Phased Roadmap:**\n    - Phase 1: Immediate (Week 1-2)\n    - Phase 2: Foundation (Month 1-2)\n    - Phase 3: Strategic (Month 3-6)\n    \n    **For each phase:**\n    - Specific deliverables\n    - Effort estimates (hours)\n    - Expected outcomes\n    - Success metrics\n    \n    **Resource Requirements:**\n    - Team composition\n    - Total hours\n    - Timeline\n    - Tools needed\n    \n    **Format:** PDF, slide deck, or roadmap tool\n    \n    **Evaluation criteria:**\n    - Realistic estimates\n    - Clear prioritization\n    - Measurable outcomes\n  </Accordion>\n  \n  <Accordion title=\"Deliverable 4: Executive Summary (1 page)\">\n    **Required content:**\n    \n    **Overview:**\n    - Audit scope\n    - Methodology\n    - Timeline\n    \n    **Key Findings (3-5 bullets):**\n    - Most critical issues\n    - Impact on users\n    \n    **Top Recommendations (3-5 items):**\n    - Specific actions\n    - Expected benefits\n    \n    **Resource Requirements:**\n    - Hours needed\n    - Timeline\n    - ROI/impact\n    \n    **Format:** PDF (single page, executive-friendly)\n    \n    **Evaluation criteria:**\n    - Clarity for non-technical audience\n    - Compelling case for action\n    - Professional presentation\n  </Accordion>\n  \n  <Accordion title=\"Deliverable 5: Sample AI Prompts (Appendix)\">\n    **Include 3-5 of your most effective prompts:**\n    \n    For each prompt:\n    - Context (what you were trying to accomplish)\n    - Full prompt text\n    - Key insights from AI response\n    - How you validated/used the output\n    \n    **Purpose:** Demonstrate AI-human collaboration\n    \n    **Evaluation criteria:**\n    - Prompt quality and specificity\n    - Effective use of AI capabilities\n    - Critical evaluation of outputs\n  </Accordion>\n  \n  <Accordion title=\"Optional: Brief Reflection (1 paragraph)\">\n    **Reflection questions:**\n    - What surprised you most?\n    - What would you do differently next time?\n    - How did AI change your audit approach?\n    - What was the biggest challenge?\n    \n    **Purpose:** Demonstrate learning and self-awareness\n  </Accordion>\n</AccordionGroup>\n\n---",
            "hydration_source_header": "Deliverables",
            "hydration_method": "line_proximity"
          },
          {
            "id": "audit-findings-report",
            "title": "Audit Findings Report (3-5 pages)",
            "purpose": "Document findings",
            "format": "PDF/Word",
            "lines": "1750-1790",
            "hydration_status": "failed"
          },
          {
            "id": "action-plan-deliverable",
            "title": "Prioritized Action Plan (1-2 pages)",
            "purpose": "Implementation roadmap",
            "format": "PDF/Slides",
            "lines": "1795-1830",
            "hydration_status": "failed"
          },
          {
            "id": "executive-summary-deliverable",
            "title": "Executive Summary (1 page)",
            "purpose": "Leadership communication",
            "format": "PDF",
            "lines": "1835-1855",
            "retrievalQuestions": [
              "How do I write an executive summary for an audit?"
            ],
            "content": "Your project will be assessed on:\n\n**1. Audit Rigor (30%)**\n- \u2713 Comprehensive inventory with rich metadata\n- \u2713 Systematic application of quality criteria\n- \u2713 Thorough gap analysis against user journey\n- \u2713 Evidence-based findings (not assumptions)\n- \u2713 Appropriate validation of AI outputs\n\n**2. AI Prompt Quality (25%)**\n- \u2713 Effective use of AI for scale analysis\n- \u2713 Clear, specific prompts with context\n- \u2713 Appropriate prompts for different tasks\n- \u2713 Critical evaluation of AI outputs\n- \u2713 Demonstration of human-AI partnership\n\n**3. Actionability (25%)**\n- \u2713 Clear prioritization (P0/P1/P2/P3)\n- \u2713 Realistic effort estimates\n- \u2713 Specific, implementable recommendations\n- \u2713 Clear success metrics\n- \u2713 Resource requirements defined\n\n**4. Documentation Quality (20%)**\n- \u2713 Clear, well-organized deliverables\n- \u2713 Appropriate format for each audience\n- \u2713 Professional presentation\n- \u2713 Reproducible methodology\n- \u2713 Executive summary compelling\n\n---",
            "hydration_source_header": "Evaluation Criteria",
            "hydration_method": "line_proximity"
          },
          {
            "id": "sample-prompts-appendix",
            "title": "Sample AI Prompts Appendix",
            "purpose": "Demonstrate AI collaboration",
            "format": "Any",
            "lines": "1860-1875",
            "content": "Your project will be assessed on:\n\n**1. Audit Rigor (30%)**\n- \u2713 Comprehensive inventory with rich metadata\n- \u2713 Systematic application of quality criteria\n- \u2713 Thorough gap analysis against user journey\n- \u2713 Evidence-based findings (not assumptions)\n- \u2713 Appropriate validation of AI outputs\n\n**2. AI Prompt Quality (25%)**\n- \u2713 Effective use of AI for scale analysis\n- \u2713 Clear, specific prompts with context\n- \u2713 Appropriate prompts for different tasks\n- \u2713 Critical evaluation of AI outputs\n- \u2713 Demonstration of human-AI partnership\n\n**3. Actionability (25%)**\n- \u2713 Clear prioritization (P0/P1/P2/P3)\n- \u2713 Realistic effort estimates\n- \u2713 Specific, implementable recommendations\n- \u2713 Clear success metrics\n- \u2713 Resource requirements defined\n\n**4. Documentation Quality (20%)**\n- \u2713 Clear, well-organized deliverables\n- \u2713 Appropriate format for each audience\n- \u2713 Professional presentation\n- \u2713 Reproducible methodology\n- \u2713 Executive summary compelling\n\n---",
            "hydration_source_header": "Evaluation Criteria",
            "hydration_method": "line_proximity"
          }
        ],
        "timeMetrics": [
          {
            "id": "full-audit-comparison",
            "activity": "Full Audit (300 pages)",
            "traditionalTime": "5-8 weeks",
            "aiAssistedTime": "9-14 hours",
            "savings": "60-80%",
            "lines": "45-55, 1935-1940",
            "retrievalQuestions": [
              "How much time does an AI-assisted audit save?"
            ],
            "hydration_status": "skipped_unknown"
          }
        ],
        "phasedActionPlanning": [
          {
            "id": "phase-1-immediate",
            "phase": "Phase 1: Immediate",
            "timeline": "Week 1-2",
            "focus": "Critical fixes, P0 gaps",
            "lines": "1640-1650",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "phase-2-foundation",
            "phase": "Phase 2: Foundation",
            "timeline": "Month 1-2",
            "focus": "P0 gaps, quality improvements",
            "lines": "1650-1658",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "phase-3-strategic",
            "phase": "Phase 3: Strategic",
            "timeline": "Month 3-6",
            "focus": "P1 gaps, systematic improvement",
            "lines": "1658-1665",
            "retrievalQuestions": [
              "How do I phase a content improvement plan?"
            ],
            "hydration_status": "skipped_unknown"
          }
        ]
      }
    },
    "3-2-search-findability": {
      "file": "3-2-search-findability.mdx",
      "focus": "Optimizing search with AI assistance, generating SEO-friendly IA structures, improving content findability through synonym generation, query analysis, and faceted search design",
      "entityCount": 99,
      "entities": {
        "frameworks": [
          {
            "id": "findability-framework",
            "title": "Findability Framework",
            "type": "framework",
            "definition": "Three dimensions of findability: internal search, external SEO, navigation/browse",
            "contains": [
              "internal-search",
              "external-seo",
              "navigation-browse"
            ],
            "lines": "25-75",
            "crossModule": true,
            "retrievalQuestions": [
              "What are the dimensions of findability?",
              "How do I improve content findability?"
            ],
            "content": "<CardGroup cols={2}>\n  <Card title=\"The Reality Check\" icon=\"chart-line\">\n    **50-70%** of documentation users go straight to search, bypassing navigation entirely\n  </Card>\n  <Card title=\"The Vocabulary Gap\" icon=\"language\">\n    Users search using **their terms**, not yours - creating findability failures\n  </Card>\n</CardGroup>\n\n### The Three Dimensions of Findability\n\n<Accordion title=\"1. Internal Search - Finding Content Within Your Site\">\n  **Challenge:** Users can't find what they need even when it exists\n  \n  **Common Problems:**\n  - Search returns irrelevant results\n  - No results for common queries\n  - Poor result ranking\n  - Missing synonyms and variations\n  \n  **Impact:** Support tickets, abandoned tasks, user frustration\n</Accordion>\n\n<Accordion title=\"2. External Search (SEO) - Discovery via Search Engines\">\n  **Challenge:** Your content doesn't appear when users search Google\n  \n  **Common Problems:**\n  - Poor keyword targeting\n  - Weak metadata\n  - Competing with established sources\n  - Technical SEO issues\n  \n  **Impact:** Lost traffic, reduced visibility, missed opportunities\n</Accordion>\n\n<Accordion title=\"3. Navigation and Browse - Finding Without Knowing What to Search\">\n  **Challenge:** Users can't browse effectively when uncertain about terminology\n  \n  **Common Problems:**\n  - Unclear labels\n  - Deep hierarchies\n  - Missing cross-references\n  - Poor information scent\n  \n  **Impact:** Cognitive overload, inefficient exploration, user abandonment\n</Accordion>\n\n---",
            "hydration_source_header": "Introduction: The Findability Challenge",
            "hydration_method": "line_proximity"
          },
          {
            "id": "three-dimensions-findability",
            "title": "Three Dimensions of Findability",
            "type": "framework",
            "definition": "Internal search, external SEO, and navigation/browse as complementary pathways",
            "contains": [
              "internal-search-dimension",
              "external-seo-dimension",
              "navigation-browse-dimension"
            ],
            "lines": "35-75",
            "crossModule": false,
            "content": "<Accordion title=\"1. Internal Search - Finding Content Within Your Site\">\n  **Challenge:** Users can't find what they need even when it exists\n  \n  **Common Problems:**\n  - Search returns irrelevant results\n  - No results for common queries\n  - Poor result ranking\n  - Missing synonyms and variations\n  \n  **Impact:** Support tickets, abandoned tasks, user frustration\n</Accordion>\n\n<Accordion title=\"2. External Search (SEO) - Discovery via Search Engines\">\n  **Challenge:** Your content doesn't appear when users search Google\n  \n  **Common Problems:**\n  - Poor keyword targeting\n  - Weak metadata\n  - Competing with established sources\n  - Technical SEO issues\n  \n  **Impact:** Lost traffic, reduced visibility, missed opportunities\n</Accordion>\n\n<Accordion title=\"3. Navigation and Browse - Finding Without Knowing What to Search\">\n  **Challenge:** Users can't browse effectively when uncertain about terminology\n  \n  **Common Problems:**\n  - Unclear labels\n  - Deep hierarchies\n  - Missing cross-references\n  - Poor information scent\n  \n  **Impact:** Cognitive overload, inefficient exploration, user abandonment\n</Accordion>\n\n---",
            "hydration_source_header": "The Three Dimensions of Findability",
            "hydration_method": "title_match"
          },
          {
            "id": "search-intent-framework",
            "title": "Search Intent Classification Framework",
            "type": "framework",
            "definition": "Four types of search intent: navigational, informational, transactional, investigational",
            "contains": [
              "navigational",
              "informational",
              "transactional",
              "investigational"
            ],
            "lines": "85-135",
            "crossModule": false,
            "retrievalQuestions": [
              "What types of search intent exist?",
              "How do I optimize search in documentation?"
            ],
            "content": "<Info>\n  Search queries reveal not just **what** users want, but **why** they're searching and **where** they are in their journey.\n</Info>\n\n#### The Four Types of Search Intent\n\n<CodeGroup>\n```text Navigational Intent\nQuery: \"login page\"\nQuery: \"API docs\"\nQuery: \"pricing\"\n\nUser Goal: Find a specific page they know exists\nIA Response: Clear navigation paths, consistent naming\n```\n\n```text Informational Intent\nQuery: \"how to authenticate API\"\nQuery: \"what is rate limiting\"\nQuery: \"error code 403 meaning\"\n\nUser Goal: Learn or understand something\nIA Response: Comprehensive guides, clear explanations\n```\n\n```text Transactional Intent\nQuery: \"download SDK\"\nQuery: \"sign up free trial\"\nQuery: \"upgrade plan\"\n\nUser Goal: Complete a specific action\nIA Response: Clear CTAs, streamlined processes\n```\n\n```text Investigational Intent\nQuery: \"Django vs Flask\"\nQuery: \"best authentication method\"\nQuery: \"performance benchmarks\"\n\nUser Goal: Compare or evaluate options\nIA Response: Comparison content, decision guides\n```\n</CodeGroup>",
            "hydration_source_header": "1.1 Query Intent Classification",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "search-optimization-workflow",
            "title": "Search Optimization Workflow",
            "type": "framework",
            "definition": "Three-step workflow: analyze performance, generate recommendations, implement and measure",
            "contains": [
              "analyze-performance",
              "generate-recommendations",
              "implement-measure"
            ],
            "lines": "500-600",
            "crossModule": false,
            "content": "### Step 1: Analyze Current Search Performance\n\n<CodeGroup>\n```text Data Collection Checklist\n\u25a1 Export last 30 days of internal search queries\n\u25a1 Get Google Search Console data\n\u25a1 Collect support ticket search-related issues\n\u25a1 Review 404 error logs for search attempts\n\u25a1 Gather user feedback about findability\n\nCompile into single dataset:\n- Query text\n- Frequency/volume\n- Results returned (yes/no)\n- User satisfaction (if available)\n- Source (internal/external/support)\n```\n\n```text Analysis Prompt\nAnalyze this search performance data:\n\n[Paste your compiled search data]\n\nIdentify:\n1. Top 20 failed queries (no results)\n2. Top 20 low-satisfaction queries\n3. Patterns in failed searches\n4. Vocabulary mismatches\n5. Content gaps\n\nPrioritize improvements by:\n- Query volume \u00d7 failure rate\n- Business impact\n- Implementation effort\n\nProvide top 10 quick wins and top 5 strategic improvements.\n```\n</CodeGroup>\n\n### Step 2: Generate Optimization Recommendations\n\n<CodeGroup>\n```text Content Optimization Prompt\nBased on this search analysis:\n[Paste analysis results]\n\nGenerate specific optimization tasks:\n\nFor each problem identified, provide:\n\n1. THE FIX\n   - Specific action to take\n   - Example implementation\n   \n2. EFFORT ESTIMATE\n   - Hours required\n   - Technical complexity\n   - Dependencies\n   \n3. EXPECTED IMPACT\n   - Search improvement metrics\n   - User success metrics\n   \n4. SUCCESS MEASUREMENT\n   - How to track improvement\n   - Target metrics\n\nFormat as actionable sprint tasks.\n```\n\n```text Example Task Output\nSEARCH OPTIMIZATION SPRINT TASKS\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nTASK 1: Add Authentication Synonyms\nProblem: 47% of \"login\" searches return no results\nFix: Add synonym mapping: login \u2192 authentication\nImplementation:\n  - Update search configuration\n  - Add to Elasticsearch synonyms.txt:\n    \"login,signin,authentication,auth\"\n  - Test with top 10 login-related queries\nEffort: 2 hours\nImpact: +47% search success rate for auth queries\nMeasurement: Track \"login\" query success rate\n\nTASK 2: Create 401 Error Troubleshooting Page\nProblem: 890 searches for \"401 error\" with no good results\nFix: New page: /docs/troubleshooting/401-unauthorized\nContent outline:\n  - What 401 means\n  - Common causes (expired token, wrong credentials)\n  - How to debug (check headers, validate token)\n  - Code examples for fixing\nEffort: 4 hours\nImpact: Direct answer for 890 monthly searches\nMeasurement: Page views, search clickthrough\n\n[Continue for all tasks...]\n```\n</CodeGroup>\n\n### Step 3: Implement and Measure\n\n<Info>\n  Implementation should be iterative. Start with quick wins to show value, then tackle strategic improvements.\n</Info>\n\n<CardGroup cols={3}>\n  <Card title=\"Week 1: Quick Wins\" icon=\"rabbit\">\n    - Add synonyms\n    - Fix top 10 broken searches\n    - Update 5 page titles\n  </Card>\n  <Card title=\"Week 2-3: Foundation\" icon=\"hammer\">\n    - Implement faceted search\n    - Create missing content\n    - Optimize URL structure\n  </Card>\n  <Card title=\"Week 4+: Strategic\" icon=\"chess\">\n    - Full content audit\n    - SEO content calendar\n    - Search analytics dashboard\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Part 5: Hands-on Tutorial - Complete Search Optimization Workflow",
            "hydration_method": "title_match"
          }
        ],
        "principles": [
          {
            "id": "vocabulary-mismatch-problem",
            "title": "Vocabulary Mismatch is #1 Findability Problem",
            "partOf": "findability-framework",
            "lines": "195-200, 780-785",
            "crossModule": false,
            "retrievalQuestions": [
              "Why do users fail to find content?"
            ],
            "content": "### 2.1 The Synonym Challenge\n\n<Warning>\n  The #1 cause of search failure isn't bad algorithms\u2014it's vocabulary mismatch. Users search for \"login\" while your content uses \"authentication.\"\n</Warning>\n\n### 2.2 Comprehensive Synonym Development\n\n#### Advanced Synonym Generation Pattern\n\n<CodeGroup>\n```text Master Prompt\nYou are a terminology specialist creating comprehensive synonym sets for search optimization.\n\nPRIMARY TERM: [Your official term]\nCONTEXT: [Brief description of what this term refers to]\nAUDIENCE: [Target user types]\n\nGenerate a complete synonym set including:\n\n1. DIRECT SYNONYMS\n   - Exact equivalents\n   - Industry alternatives\n   \n2. COLLOQUIAL VARIANTS\n   - How non-experts describe this\n   - Common simplifications\n   \n3. RELATED CONCEPTS\n   - Broader terms (hypernyms)\n   - Narrower terms (hyponyms)\n   - Associated actions\n   \n4. COMMON MISSPELLINGS\n   - Typical typos\n   - Phonetic variations\n   \n5. ACRONYMS & ABBREVIATIONS\n   - Official acronyms\n   - Common shortenings\n   \n6. CONTEXTUAL VARIATIONS\n   - Regional differences\n   - Industry-specific terms\n   - Legacy terminology\n\n7. SEARCH QUERY PATTERNS\n   - Question formats\n   - Error message searches\n   - How-to phrasings\n\nProvide 30-40 variations total, tagged by type and relevance score (1-5).\n```\n\n```text Example Implementation\nPRIMARY TERM: Authentication\nCONTEXT: Process of verifying user identity for API access\nAUDIENCE: Developers, technical and non-technical\n\nSYNONYM SET:\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nDIRECT SYNONYMS (Relevance: 5/5):\n\u2022 Authorization\n\u2022 Auth\n\u2022 Identity verification\n\u2022 User verification\n\u2022 Access control\n\nCOLLOQUIAL VARIANTS (Relevance: 4/5):\n\u2022 Login\n\u2022 Sign in\n\u2022 Sign on\n\u2022 Log in\n\u2022 Signin/Signon (concatenated)\n\u2022 Password check\n\u2022 User check\n\nRELATED CONCEPTS (Relevance: 3-4/5):\nBroader:\n\u2022 Security\n\u2022 Access management\n\u2022 Identity management\n\nNarrower:\n\u2022 OAuth\n\u2022 Token auth\n\u2022 API keys\n\u2022 JWT\n\u2022 Basic auth\n\u2022 Two-factor auth\n\u2022 2FA\n\u2022 MFA\n\nAssociated Actions:\n\u2022 Authenticate\n\u2022 Authorize\n\u2022 Verify\n\u2022 Validate\n\u2022 Grant access\n\nCOMMON MISSPELLINGS (Relevance: 3/5):\n\u2022 Authentification\n\u2022 Authenication\n\u2022 Authintication\n\u2022 Authorisation (UK spelling)\n\nSEARCH QUERY PATTERNS (Relevance: 4/5):\n\u2022 \"How to login\"\n\u2022 \"Can't authenticate\"\n\u2022 \"401 error\"\n\u2022 \"Unauthorized access\"\n\u2022 \"Invalid credentials\"\n\u2022 \"Token expired\"\n\u2022 \"Permission denied\"\n```\n</CodeGroup>\n\n### 2.3 Synonym Implementation Strategy\n\n<Accordion title=\"Where to Apply Synonyms\">\n  \n  **1. Search Configuration**\n  - Add to search engine synonym dictionary\n  - Configure query expansion rules\n  - Set relevance weights\n  \n  **2. Content Optimization**\n  - Include variations in metadata\n  - Add to page descriptions naturally\n  - Create redirect rules for common variants\n  \n  **3. Navigation Labels**\n  - Test alternate labels with users\n  - Add hover text with alternatives\n  - Include in breadcrumb variations\n  \n  **4. Help Content**\n  - FAQ entries using user language\n  - Troubleshooting guides with error messages\n  - Glossary linking terms\n</Accordion>\n\n---",
            "hydration_source_header": "Part 2: Synonym Generation and Vocabulary Mapping",
            "hydration_method": "line_proximity"
          },
          {
            "id": "intent-over-keywords",
            "title": "Intent Matters More Than Keywords",
            "partOf": "search-intent-framework",
            "lines": "785-790",
            "crossModule": false,
            "retrievalQuestions": [
              "What's more important - keywords or intent?"
            ],
            "content": "<Info>\n  Implementation should be iterative. Start with quick wins to show value, then tackle strategic improvements.\n</Info>\n\n<CardGroup cols={3}>\n  <Card title=\"Week 1: Quick Wins\" icon=\"rabbit\">\n    - Add synonyms\n    - Fix top 10 broken searches\n    - Update 5 page titles\n  </Card>\n  <Card title=\"Week 2-3: Foundation\" icon=\"hammer\">\n    - Implement faceted search\n    - Create missing content\n    - Optimize URL structure\n  </Card>\n  <Card title=\"Week 4+: Strategic\" icon=\"chess\">\n    - Full content audit\n    - SEO content calendar\n    - Search analytics dashboard\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Step 3: Implement and Measure",
            "hydration_method": "line_proximity"
          },
          {
            "id": "ai-excels-at-scale-analysis",
            "title": "AI Excels at Scale Analysis",
            "partOf": "search-optimization-workflow",
            "lines": "790-795",
            "crossModule": true,
            "content": "<Info>\n  Implementation should be iterative. Start with quick wins to show value, then tackle strategic improvements.\n</Info>\n\n<CardGroup cols={3}>\n  <Card title=\"Week 1: Quick Wins\" icon=\"rabbit\">\n    - Add synonyms\n    - Fix top 10 broken searches\n    - Update 5 page titles\n  </Card>\n  <Card title=\"Week 2-3: Foundation\" icon=\"hammer\">\n    - Implement faceted search\n    - Create missing content\n    - Optimize URL structure\n  </Card>\n  <Card title=\"Week 4+: Strategic\" icon=\"chess\">\n    - Full content audit\n    - SEO content calendar\n    - Search analytics dashboard\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Step 3: Implement and Measure",
            "hydration_method": "line_proximity"
          },
          {
            "id": "seo-usability-alignment",
            "title": "SEO and Usability Aren't in Conflict",
            "partOf": "external-seo-dimension",
            "lines": "795-800",
            "crossModule": false,
            "retrievalQuestions": [
              "Do SEO and usability conflict?"
            ],
            "content": "<Tip>\n  Complete each deliverable to demonstrate mastery of search optimization techniques.\n</Tip>\n\n### Required Deliverables\n\n<Accordion title=\"1. Query Analysis Report (2-3 hours)\">\n  - [ ] 50+ analyzed queries with classification\n  - [ ] Intent and pattern analysis\n  - [ ] Vocabulary gap identification  \n  - [ ] Formatted as professional report\n  - [ ] Clear recommendations based on data\n</Accordion>\n\n<Accordion title=\"2. Content-Query Map (1-2 hours)\">\n  - [ ] Existing content inventory\n  - [ ] Query-to-content matching analysis\n  - [ ] Gap prioritization matrix\n  - [ ] Content creation roadmap\n</Accordion>\n\n<Accordion title=\"3. Synonym Dictionary (1-2 hours)\">\n  - [ ] 10-15 key terms with full synonym sets\n  - [ ] Tagged by type and relevance\n  - [ ] Implementation instructions\n  - [ ] Testing methodology\n</Accordion>\n\n<Accordion title=\"4. Search Optimization Plan (2-3 hours)\">\n  - [ ] Page title/metadata optimizations (10+ pages)\n  - [ ] Faceted search specification\n  - [ ] Before/after examples\n  - [ ] Content creation priorities\n</Accordion>\n\n<Accordion title=\"5. Implementation Roadmap (1-2 hours)\">\n  - [ ] Phased rollout plan\n  - [ ] Effort estimates\n  - [ ] Success metrics\n  - [ ] Risk mitigation strategies\n</Accordion>\n\n### Time Investment Comparison\n\n<CardGroup cols={2}>\n  <Card title=\"Traditional Approach\" icon=\"hourglass\">\n    - Manual query analysis: 8-16 hours\n    - Synonym research: 10-15 hours  \n    - Gap analysis: 6-10 hours\n    - **Total: 24-41 hours**\n  </Card>\n  <Card title=\"AI-Assisted Approach\" icon=\"rocket\">\n    - AI query analysis: 2-3 hours\n    - AI synonym generation: 1-2 hours\n    - AI gap analysis: 1-2 hours\n    - **Total: 4-7 hours**\n    - **Time Saved: 80%+**\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Tutorial Deliverables Checklist",
            "hydration_method": "line_proximity"
          },
          {
            "id": "facets-from-behavior",
            "title": "Faceted Search Requires User Behavior Data",
            "partOf": "faceted-search-design",
            "lines": "800-805",
            "crossModule": false,
            "retrievalQuestions": [
              "How do I design effective search facets?"
            ],
            "content": "<Tip>\n  Complete each deliverable to demonstrate mastery of search optimization techniques.\n</Tip>\n\n### Required Deliverables\n\n<Accordion title=\"1. Query Analysis Report (2-3 hours)\">\n  - [ ] 50+ analyzed queries with classification\n  - [ ] Intent and pattern analysis\n  - [ ] Vocabulary gap identification  \n  - [ ] Formatted as professional report\n  - [ ] Clear recommendations based on data\n</Accordion>\n\n<Accordion title=\"2. Content-Query Map (1-2 hours)\">\n  - [ ] Existing content inventory\n  - [ ] Query-to-content matching analysis\n  - [ ] Gap prioritization matrix\n  - [ ] Content creation roadmap\n</Accordion>\n\n<Accordion title=\"3. Synonym Dictionary (1-2 hours)\">\n  - [ ] 10-15 key terms with full synonym sets\n  - [ ] Tagged by type and relevance\n  - [ ] Implementation instructions\n  - [ ] Testing methodology\n</Accordion>\n\n<Accordion title=\"4. Search Optimization Plan (2-3 hours)\">\n  - [ ] Page title/metadata optimizations (10+ pages)\n  - [ ] Faceted search specification\n  - [ ] Before/after examples\n  - [ ] Content creation priorities\n</Accordion>\n\n<Accordion title=\"5. Implementation Roadmap (1-2 hours)\">\n  - [ ] Phased rollout plan\n  - [ ] Effort estimates\n  - [ ] Success metrics\n  - [ ] Risk mitigation strategies\n</Accordion>\n\n### Time Investment Comparison\n\n<CardGroup cols={2}>\n  <Card title=\"Traditional Approach\" icon=\"hourglass\">\n    - Manual query analysis: 8-16 hours\n    - Synonym research: 10-15 hours  \n    - Gap analysis: 6-10 hours\n    - **Total: 24-41 hours**\n  </Card>\n  <Card title=\"AI-Assisted Approach\" icon=\"rocket\">\n    - AI query analysis: 2-3 hours\n    - AI synonym generation: 1-2 hours\n    - AI gap analysis: 1-2 hours\n    - **Total: 4-7 hours**\n    - **Time Saved: 80%+**\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Tutorial Deliverables Checklist",
            "hydration_method": "line_proximity"
          },
          {
            "id": "users-bypass-navigation",
            "title": "50-70% of Users Bypass Navigation for Search",
            "partOf": "findability-framework",
            "lines": "25-30",
            "crossModule": false,
            "content": "<CardGroup cols={2}>\n  <Card title=\"The Reality Check\" icon=\"chart-line\">\n    **50-70%** of documentation users go straight to search, bypassing navigation entirely\n  </Card>\n  <Card title=\"The Vocabulary Gap\" icon=\"language\">\n    Users search using **their terms**, not yours - creating findability failures\n  </Card>\n</CardGroup>\n\n### The Three Dimensions of Findability\n\n<Accordion title=\"1. Internal Search - Finding Content Within Your Site\">\n  **Challenge:** Users can't find what they need even when it exists\n  \n  **Common Problems:**\n  - Search returns irrelevant results\n  - No results for common queries\n  - Poor result ranking\n  - Missing synonyms and variations\n  \n  **Impact:** Support tickets, abandoned tasks, user frustration\n</Accordion>\n\n<Accordion title=\"2. External Search (SEO) - Discovery via Search Engines\">\n  **Challenge:** Your content doesn't appear when users search Google\n  \n  **Common Problems:**\n  - Poor keyword targeting\n  - Weak metadata\n  - Competing with established sources\n  - Technical SEO issues\n  \n  **Impact:** Lost traffic, reduced visibility, missed opportunities\n</Accordion>\n\n<Accordion title=\"3. Navigation and Browse - Finding Without Knowing What to Search\">\n  **Challenge:** Users can't browse effectively when uncertain about terminology\n  \n  **Common Problems:**\n  - Unclear labels\n  - Deep hierarchies\n  - Missing cross-references\n  - Poor information scent\n  \n  **Impact:** Cognitive overload, inefficient exploration, user abandonment\n</Accordion>\n\n---",
            "hydration_source_header": "Introduction: The Findability Challenge",
            "hydration_method": "line_proximity"
          }
        ],
        "patterns": [
          {
            "id": "query-intent-classification",
            "title": "Query Intent Classification Pattern",
            "purpose": "Categorize search queries by user goal",
            "lines": "85-135",
            "content": "<Info>\n  Search queries reveal not just **what** users want, but **why** they're searching and **where** they are in their journey.\n</Info>\n\n#### The Four Types of Search Intent\n\n<CodeGroup>\n```text Navigational Intent\nQuery: \"login page\"\nQuery: \"API docs\"\nQuery: \"pricing\"\n\nUser Goal: Find a specific page they know exists\nIA Response: Clear navigation paths, consistent naming\n```\n\n```text Informational Intent\nQuery: \"how to authenticate API\"\nQuery: \"what is rate limiting\"\nQuery: \"error code 403 meaning\"\n\nUser Goal: Learn or understand something\nIA Response: Comprehensive guides, clear explanations\n```\n\n```text Transactional Intent\nQuery: \"download SDK\"\nQuery: \"sign up free trial\"\nQuery: \"upgrade plan\"\n\nUser Goal: Complete a specific action\nIA Response: Clear CTAs, streamlined processes\n```\n\n```text Investigational Intent\nQuery: \"Django vs Flask\"\nQuery: \"best authentication method\"\nQuery: \"performance benchmarks\"\n\nUser Goal: Compare or evaluate options\nIA Response: Comparison content, decision guides\n```\n</CodeGroup>",
            "hydration_source_header": "1.1 Query Intent Classification",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "synonym-generation-pattern",
            "title": "Comprehensive Synonym Development Pattern",
            "purpose": "Generate full synonym sets for terms",
            "lines": "195-290",
            "retrievalQuestions": [
              "How do I generate synonyms for search?"
            ],
            "content": "#### Advanced Synonym Generation Pattern\n\n<CodeGroup>\n```text Master Prompt\nYou are a terminology specialist creating comprehensive synonym sets for search optimization.\n\nPRIMARY TERM: [Your official term]\nCONTEXT: [Brief description of what this term refers to]\nAUDIENCE: [Target user types]\n\nGenerate a complete synonym set including:\n\n1. DIRECT SYNONYMS\n   - Exact equivalents\n   - Industry alternatives\n   \n2. COLLOQUIAL VARIANTS\n   - How non-experts describe this\n   - Common simplifications\n   \n3. RELATED CONCEPTS\n   - Broader terms (hypernyms)\n   - Narrower terms (hyponyms)\n   - Associated actions\n   \n4. COMMON MISSPELLINGS\n   - Typical typos\n   - Phonetic variations\n   \n5. ACRONYMS & ABBREVIATIONS\n   - Official acronyms\n   - Common shortenings\n   \n6. CONTEXTUAL VARIATIONS\n   - Regional differences\n   - Industry-specific terms\n   - Legacy terminology\n\n7. SEARCH QUERY PATTERNS\n   - Question formats\n   - Error message searches\n   - How-to phrasings\n\nProvide 30-40 variations total, tagged by type and relevance score (1-5).\n```\n\n```text Example Implementation\nPRIMARY TERM: Authentication\nCONTEXT: Process of verifying user identity for API access\nAUDIENCE: Developers, technical and non-technical\n\nSYNONYM SET:\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nDIRECT SYNONYMS (Relevance: 5/5):\n\u2022 Authorization\n\u2022 Auth\n\u2022 Identity verification\n\u2022 User verification\n\u2022 Access control\n\nCOLLOQUIAL VARIANTS (Relevance: 4/5):\n\u2022 Login\n\u2022 Sign in\n\u2022 Sign on\n\u2022 Log in\n\u2022 Signin/Signon (concatenated)\n\u2022 Password check\n\u2022 User check\n\nRELATED CONCEPTS (Relevance: 3-4/5):\nBroader:\n\u2022 Security\n\u2022 Access management\n\u2022 Identity management\n\nNarrower:\n\u2022 OAuth\n\u2022 Token auth\n\u2022 API keys\n\u2022 JWT\n\u2022 Basic auth\n\u2022 Two-factor auth\n\u2022 2FA\n\u2022 MFA\n\nAssociated Actions:\n\u2022 Authenticate\n\u2022 Authorize\n\u2022 Verify\n\u2022 Validate\n\u2022 Grant access\n\nCOMMON MISSPELLINGS (Relevance: 3/5):\n\u2022 Authentification\n\u2022 Authenication\n\u2022 Authintication\n\u2022 Authorisation (UK spelling)\n\nSEARCH QUERY PATTERNS (Relevance: 4/5):\n\u2022 \"How to login\"\n\u2022 \"Can't authenticate\"\n\u2022 \"401 error\"\n\u2022 \"Unauthorized access\"\n\u2022 \"Invalid credentials\"\n\u2022 \"Token expired\"\n\u2022 \"Permission denied\"\n```\n</CodeGroup>",
            "hydration_source_header": "2.2 Comprehensive Synonym Development",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "synonym-implementation-strategy",
            "title": "Synonym Implementation Strategy",
            "purpose": "Where and how to apply synonyms",
            "lines": "295-330",
            "content": "<Accordion title=\"Where to Apply Synonyms\">\n  \n  **1. Search Configuration**\n  - Add to search engine synonym dictionary\n  - Configure query expansion rules\n  - Set relevance weights\n  \n  **2. Content Optimization**\n  - Include variations in metadata\n  - Add to page descriptions naturally\n  - Create redirect rules for common variants\n  \n  **3. Navigation Labels**\n  - Test alternate labels with users\n  - Add hover text with alternatives\n  - Include in breadcrumb variations\n  \n  **4. Help Content**\n  - FAQ entries using user language\n  - Troubleshooting guides with error messages\n  - Glossary linking terms\n</Accordion>\n\n---",
            "hydration_source_header": "2.3 Synonym Implementation Strategy",
            "hydration_method": "title_match"
          },
          {
            "id": "title-optimization-pattern",
            "title": "Page Title Optimization Pattern",
            "purpose": "Improve page titles for search",
            "lines": "340-410",
            "content": "<CodeGroup>\n```text Analysis Prompt\nAnalyze and optimize these page titles for search:\n\nCURRENT TITLES:\n1. \"Authentication\" \u2192 /docs/auth\n2. \"Getting Started\" \u2192 /docs/start\n3. \"API Reference\" \u2192 /docs/api\n4. \"Errors\" \u2192 /docs/errors\n5. \"Configuration\" \u2192 /docs/config\n\nCONTEXT:\n- Technical documentation site\n- Primary users: developers\n- Common searches: [list top 10 queries]\n\nFor each title, provide:\n1. Current effectiveness score (1-10)\n2. Problems identified\n3. Optimized version(s)\n4. Metadata recommendations\n5. Expected impact\n\nConsider:\n- User vocabulary preferences\n- Search intent matching\n- Clarity and specificity\n- SEO keyword integration\n- Character limits (60 chars for display)\n```\n\n```text Optimization Output\nTITLE OPTIMIZATION ANALYSIS\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n1. \"Authentication\" \u2192 /docs/auth\n   Current Score: 6/10\n   \n   Problems:\n   \u2022 Too technical for some users\n   \u2022 Doesn't indicate it's a guide\n   \u2022 Missing common search terms\n   \n   Optimized Options:\n   A) \"Authentication & Login Guide\"\n   B) \"API Authentication - Setup & Examples\"\n   C) \"How to Authenticate API Requests\"\n   \n   Metadata:\n   Title: \"API Authentication Guide - Login & Security\"\n   Description: \"Learn how to authenticate API requests. Covers OAuth, tokens, API keys, and troubleshooting login errors.\"\n   \n   Expected Impact:\n   \u2022 +40% match rate for \"login\" searches\n   \u2022 +25% click-through from search results\n   \u2022 Better alignment with user vocabulary\n\n[Continue for all titles...]\n```\n</CodeGroup>",
            "hydration_source_header": "Title Optimization Framework",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "faceted-search-design-pattern",
            "title": "Faceted Search Design Pattern",
            "purpose": "Create user-driven search filters",
            "lines": "420-500",
            "retrievalQuestions": [
              "How do I design faceted search?"
            ],
            "content": "<Info>\n  Faceted search lets users progressively refine results. Good facets emerge from actual user behavior, not just available metadata.\n</Info>\n\n#### Facet Generation from User Behavior\n\n<CodeGroup>\n```text Facet Design Prompt\nBased on these search patterns, design a faceted search system:\n\nTOP SEARCH QUERIES (last 30 days):\n[List 50+ real queries]\n\nCONTENT TYPES AVAILABLE:\n- Guides (how-to, tutorials)\n- API Reference (endpoints, methods)\n- Code Examples\n- Troubleshooting\n- Concepts (explanations)\n- Videos\n- Release Notes\n\nUSER SEGMENTS:\n- Beginners (30%)\n- Intermediate developers (50%)\n- Advanced/Enterprise (20%)\n\nDesign facets that:\n1. Match how users actually search\n2. Provide meaningful refinement options\n3. Surface relevant content quickly\n4. Scale from 10 to 10,000 results\n\nProvide:\n- Recommended facet categories\n- Values for each facet\n- Display order and logic\n- Progressive disclosure strategy\n- Mobile considerations\n```\n\n```text Faceted Search Specification\nRECOMMENDED FACET STRUCTURE\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nPRIMARY FACETS (Always visible):\n\n1. CONTENT TYPE\n   \u25a1 Guides & Tutorials\n   \u25a1 API Reference\n   \u25a1 Code Examples\n   \u25a1 Troubleshooting\n   \u25a1 Videos\n   \n   Why: Users often know format they want\n   Display: Top of sidebar, expanded by default\n\n2. PROGRAMMING LANGUAGE\n   \u25a1 JavaScript/Node.js\n   \u25a1 Python\n   \u25a1 Java\n   \u25a1 Go\n   \u25a1 PHP\n   \u25a1 [Show more...]\n   \n   Why: Critical filter for developers\n   Display: Show top 5 + expand option\n\n3. DIFFICULTY LEVEL\n   \u25a1 Getting Started\n   \u25a1 Intermediate\n   \u25a1 Advanced\n   \n   Why: Matches user segments\n   Display: Simple 3-option toggle\n\nSECONDARY FACETS (Context-dependent):\n\n4. PRODUCT AREA (if >20 results)\n   \u25a1 Authentication\n   \u25a1 Data Management\n   \u25a1 Analytics\n   \u25a1 Integrations\n   \n5. LAST UPDATED (if searching docs)\n   \u25a1 Last 30 days\n   \u25a1 Last 6 months\n   \u25a1 Last year\n   \u25a1 Older\n\nSMART BEHAVIORS:\n\u2022 Auto-expand facets with few options\n\u2022 Hide facets with only 1 option\n\u2022 Remember user's common selections\n\u2022 Pre-select based on query intent\n```\n</CodeGroup>\n\n---",
            "hydration_source_header": "3.2 Faceted Search Design",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "keyword-research-pattern",
            "title": "Documentation Keyword Research Pattern",
            "purpose": "SEO keyword strategy for docs",
            "lines": "520-580",
            "retrievalQuestions": [
              "How do I do keyword research for documentation?"
            ],
            "content": "<CodeGroup>\n```text Keyword Analysis Prompt\nPerform keyword research for technical documentation:\n\nTOPIC: [Your main topic/product]\nCOMPETITORS: [List 3-5 competitor docs sites]\n\nResearch and provide:\n\n1. PRIMARY KEYWORDS (High volume, high competition)\n   - Search volume estimates\n   - Competition level\n   - Our likelihood to rank\n   \n2. LONG-TAIL OPPORTUNITIES (Lower volume, specific)\n   - Technical how-to queries\n   - Error message searches\n   - Integration queries\n   - Comparison searches\n   \n3. QUESTION KEYWORDS\n   - \"How to...\" queries\n   - \"What is...\" queries  \n   - \"Why does...\" queries\n   - \"When to use...\" queries\n   \n4. BRANDED VS NON-BRANDED\n   - \"[Product] authentication\"\n   - \"REST API authentication\"\n   \n5. CONTENT GAP ANALYSIS\n   - Keywords competitors rank for\n   - Keywords we could own\n   - Untapped opportunities\n\nFormat as actionable keyword map with content recommendations.\n```\n\n```text SEO Keyword Map\nTECHNICAL DOCUMENTATION KEYWORD STRATEGY\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nPRIMARY TARGETS (Focus pages):\n\n\"api authentication\" \n- Volume: 8,100/month\n- Competition: High\n- Strategy: Comprehensive guide as pillar page\n- Target URL: /docs/authentication\n\n\"rest api tutorial\"\n- Volume: 5,400/month  \n- Competition: Medium\n- Strategy: Step-by-step beginner guide\n- Target URL: /docs/getting-started\n\nLONG-TAIL OPPORTUNITIES (Quick wins):\n\n\"401 unauthorized error api\"\n- Volume: 720/month\n- Competition: Low\n- Strategy: Troubleshooting guide\n- Target URL: /docs/errors/401\n\n\"how to pass api key in header\"\n- Volume: 390/month\n- Competition: Low\n- Strategy: Code example page\n- Target URL: /docs/examples/api-key-header\n\n\"jwt vs oauth for api\"\n- Volume: 480/month\n- Competition: Low\n- Strategy: Comparison guide\n- Target URL: /docs/concepts/auth-methods\n\nQUESTION-BASED CONTENT:\n\n\"what is rate limiting in api\"\n- Create: Concept explanation page\n- Include: Definition, examples, implementation\n\n\"how to test api authentication\"\n- Create: Testing guide with tools\n- Include: Postman, curl, code examples\n\nCONTENT GAPS TO FILL:\n1. No Python authentication examples (890 searches/month)\n2. Missing WebSocket authentication guide (320 searches/month)\n3. No OAuth flow diagram (450 searches/month)\n4. Lack of authentication best practices (1,200 searches/month)\n```\n</CodeGroup>",
            "hydration_source_header": "Documentation Keyword Research Pattern",
            "hydration_method": "title_match"
          },
          {
            "id": "search-performance-analysis",
            "title": "Search Performance Analysis Pattern",
            "purpose": "Evaluate and improve search",
            "lines": "600-650",
            "content": "<Accordion title=\"URL Structure Optimization\">\n  \n  **Best Practices:**\n  ```\n  GOOD:\n  /docs/authentication/oauth/setup\n  /docs/api/endpoints/users\n  /docs/guides/getting-started\n  \n  AVOID:\n  /docs/page?id=12345\n  /d/auth/o/s\n  /documentation-authentication-oauth-setup-guide\n  ```\n  \n  **Rules:**\n  - Use descriptive, keyword-rich URLs\n  - Maintain logical hierarchy\n  - Keep URLs under 60 characters\n  - Use hyphens, not underscores\n  - Avoid parameters when possible\n</Accordion>\n\n<Accordion title=\"Schema Markup for Documentation\">\n  \n  ```json\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"TechArticle\",\n    \"headline\": \"API Authentication Guide\",\n    \"description\": \"Complete guide to API authentication using OAuth 2.0\",\n    \"keywords\": \"API, authentication, OAuth, security\",\n    \"datePublished\": \"2024-01-15\",\n    \"dateModified\": \"2024-10-21\",\n    \"author\": {\n      \"@type\": \"Organization\",\n      \"name\": \"Your Company\"\n    },\n    \"publisher\": {\n      \"@type\": \"Organization\",\n      \"name\": \"Your Company\"\n    },\n    \"mainEntityOfPage\": {\n      \"@type\": \"WebPage\",\n      \"@id\": \"https://docs.example.com/authentication\"\n    }\n  }\n  ```\n</Accordion>\n\n---",
            "hydration_source_header": "4.2 Technical SEO for Documentation",
            "hydration_method": "line_proximity"
          }
        ],
        "promptPatterns": [
          {
            "id": "query-classification-prompt",
            "title": "Basic Query Classification Prompt",
            "taskType": "analysis",
            "lines": "140-175",
            "standalone": true,
            "retrievalQuestions": [
              "Give me a prompt to classify search queries"
            ],
            "content": "<CodeGroup>\n```text Prompt Template\nYou are a search behavior analyst examining documentation search queries.\n\nAnalyze these search queries from our documentation site:\n[Paste 20-50 queries]\n\nFor each query, identify:\n1. Intent type (navigational/informational/transactional/investigational)\n2. User's likely goal\n3. Journey stage (awareness/consideration/decision/usage/troubleshooting)\n4. Vocabulary type (technical/colloquial/hybrid)\n5. Specificity level (broad/moderate/specific)\n\nThen provide:\n- Pattern summary across all queries\n- Top 5 vocabulary gaps (user terms vs our terminology)\n- Content opportunities we're missing\n- Recommendations for search optimization\n\nFormat as a structured analysis with clear sections.\n```\n\n```text Example Output\nQUERY ANALYSIS REPORT\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nINDIVIDUAL QUERY BREAKDOWN:\n\n1. \"rest api authentication\"\n   - Intent: Informational\n   - Goal: Learn how to authenticate API requests\n   - Stage: Usage/Implementation\n   - Vocabulary: Technical\n   - Specificity: Moderate\n\n2. \"login not working\"\n   - Intent: Investigational/Troubleshooting\n   - Goal: Fix authentication issue\n   - Stage: Troubleshooting\n   - Vocabulary: Colloquial\n   - Specificity: Broad (needs refinement)\n\n[Additional queries analyzed...]\n\nPATTERN SUMMARY:\n\u2022 45% informational queries (users learning)\n\u2022 30% troubleshooting queries (users stuck)\n\u2022 20% navigational (finding known pages)\n\u2022 5% transactional (downloads/signups)\n\nVOCABULARY GAPS IDENTIFIED:\n1. Users say \"login\" \u2192 We say \"authentication\"\n2. Users say \"limits\" \u2192 We say \"rate limiting\"\n3. Users say \"setup\" \u2192 We say \"initialization\"\n4. Users say \"broken\" \u2192 We say \"error state\"\n5. Users say \"dashboard\" \u2192 We say \"console\"\n\nMISSING CONTENT OPPORTUNITIES:\n\u2022 No troubleshooting guide for common auth errors\n\u2022 Missing quickstart for REST API\n\u2022 No comparison of authentication methods\n\u2022 Lack of code examples in primary languages\n```\n</CodeGroup>\n\n<Tip>\n  **Pro Tip:** Export your actual search logs from Google Search Console, internal site search, or support tickets to analyze real user queries rather than guessing.\n</Tip>\n\n---",
            "hydration_source_header": "Basic Query Classification Prompt",
            "hydration_method": "title_match"
          },
          {
            "id": "synonym-master-prompt",
            "title": "Master Synonym Generation Prompt",
            "taskType": "generation",
            "lines": "205-245",
            "standalone": true,
            "retrievalQuestions": [
              "What prompt generates comprehensive synonyms?"
            ],
            "content": "<CodeGroup>\n```text Master Prompt\nYou are a terminology specialist creating comprehensive synonym sets for search optimization.\n\nPRIMARY TERM: [Your official term]\nCONTEXT: [Brief description of what this term refers to]\nAUDIENCE: [Target user types]\n\nGenerate a complete synonym set including:\n\n1. DIRECT SYNONYMS\n   - Exact equivalents\n   - Industry alternatives\n   \n2. COLLOQUIAL VARIANTS\n   - How non-experts describe this\n   - Common simplifications\n   \n3. RELATED CONCEPTS\n   - Broader terms (hypernyms)\n   - Narrower terms (hyponyms)\n   - Associated actions\n   \n4. COMMON MISSPELLINGS\n   - Typical typos\n   - Phonetic variations\n   \n5. ACRONYMS & ABBREVIATIONS\n   - Official acronyms\n   - Common shortenings\n   \n6. CONTEXTUAL VARIATIONS\n   - Regional differences\n   - Industry-specific terms\n   - Legacy terminology\n\n7. SEARCH QUERY PATTERNS\n   - Question formats\n   - Error message searches\n   - How-to phrasings\n\nProvide 30-40 variations total, tagged by type and relevance score (1-5).\n```\n\n```text Example Implementation\nPRIMARY TERM: Authentication\nCONTEXT: Process of verifying user identity for API access\nAUDIENCE: Developers, technical and non-technical\n\nSYNONYM SET:\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nDIRECT SYNONYMS (Relevance: 5/5):\n\u2022 Authorization\n\u2022 Auth\n\u2022 Identity verification\n\u2022 User verification\n\u2022 Access control\n\nCOLLOQUIAL VARIANTS (Relevance: 4/5):\n\u2022 Login\n\u2022 Sign in\n\u2022 Sign on\n\u2022 Log in\n\u2022 Signin/Signon (concatenated)\n\u2022 Password check\n\u2022 User check\n\nRELATED CONCEPTS (Relevance: 3-4/5):\nBroader:\n\u2022 Security\n\u2022 Access management\n\u2022 Identity management\n\nNarrower:\n\u2022 OAuth\n\u2022 Token auth\n\u2022 API keys\n\u2022 JWT\n\u2022 Basic auth\n\u2022 Two-factor auth\n\u2022 2FA\n\u2022 MFA\n\nAssociated Actions:\n\u2022 Authenticate\n\u2022 Authorize\n\u2022 Verify\n\u2022 Validate\n\u2022 Grant access\n\nCOMMON MISSPELLINGS (Relevance: 3/5):\n\u2022 Authentification\n\u2022 Authenication\n\u2022 Authintication\n\u2022 Authorisation (UK spelling)\n\nSEARCH QUERY PATTERNS (Relevance: 4/5):\n\u2022 \"How to login\"\n\u2022 \"Can't authenticate\"\n\u2022 \"401 error\"\n\u2022 \"Unauthorized access\"\n\u2022 \"Invalid credentials\"\n\u2022 \"Token expired\"\n\u2022 \"Permission denied\"\n```\n</CodeGroup>",
            "hydration_source_header": "Advanced Synonym Generation Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "title-optimization-prompt",
            "title": "Title Optimization Analysis Prompt",
            "taskType": "analysis",
            "lines": "345-375",
            "standalone": true,
            "retrievalQuestions": [
              "How do I prompt AI to optimize page titles?"
            ],
            "content": "<CodeGroup>\n```text Analysis Prompt\nAnalyze and optimize these page titles for search:\n\nCURRENT TITLES:\n1. \"Authentication\" \u2192 /docs/auth\n2. \"Getting Started\" \u2192 /docs/start\n3. \"API Reference\" \u2192 /docs/api\n4. \"Errors\" \u2192 /docs/errors\n5. \"Configuration\" \u2192 /docs/config\n\nCONTEXT:\n- Technical documentation site\n- Primary users: developers\n- Common searches: [list top 10 queries]\n\nFor each title, provide:\n1. Current effectiveness score (1-10)\n2. Problems identified\n3. Optimized version(s)\n4. Metadata recommendations\n5. Expected impact\n\nConsider:\n- User vocabulary preferences\n- Search intent matching\n- Clarity and specificity\n- SEO keyword integration\n- Character limits (60 chars for display)\n```\n\n```text Optimization Output\nTITLE OPTIMIZATION ANALYSIS\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n1. \"Authentication\" \u2192 /docs/auth\n   Current Score: 6/10\n   \n   Problems:\n   \u2022 Too technical for some users\n   \u2022 Doesn't indicate it's a guide\n   \u2022 Missing common search terms\n   \n   Optimized Options:\n   A) \"Authentication & Login Guide\"\n   B) \"API Authentication - Setup & Examples\"\n   C) \"How to Authenticate API Requests\"\n   \n   Metadata:\n   Title: \"API Authentication Guide - Login & Security\"\n   Description: \"Learn how to authenticate API requests. Covers OAuth, tokens, API keys, and troubleshooting login errors.\"\n   \n   Expected Impact:\n   \u2022 +40% match rate for \"login\" searches\n   \u2022 +25% click-through from search results\n   \u2022 Better alignment with user vocabulary\n\n[Continue for all titles...]\n```\n</CodeGroup>",
            "hydration_source_header": "Title Optimization Framework",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "facet-design-prompt",
            "title": "Facet Generation from User Behavior Prompt",
            "taskType": "generation",
            "lines": "430-480",
            "standalone": true,
            "retrievalQuestions": [
              "Show me a prompt for faceted search design"
            ],
            "content": "<CodeGroup>\n```text Facet Design Prompt\nBased on these search patterns, design a faceted search system:\n\nTOP SEARCH QUERIES (last 30 days):\n[List 50+ real queries]\n\nCONTENT TYPES AVAILABLE:\n- Guides (how-to, tutorials)\n- API Reference (endpoints, methods)\n- Code Examples\n- Troubleshooting\n- Concepts (explanations)\n- Videos\n- Release Notes\n\nUSER SEGMENTS:\n- Beginners (30%)\n- Intermediate developers (50%)\n- Advanced/Enterprise (20%)\n\nDesign facets that:\n1. Match how users actually search\n2. Provide meaningful refinement options\n3. Surface relevant content quickly\n4. Scale from 10 to 10,000 results\n\nProvide:\n- Recommended facet categories\n- Values for each facet\n- Display order and logic\n- Progressive disclosure strategy\n- Mobile considerations\n```\n\n```text Faceted Search Specification\nRECOMMENDED FACET STRUCTURE\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nPRIMARY FACETS (Always visible):\n\n1. CONTENT TYPE\n   \u25a1 Guides & Tutorials\n   \u25a1 API Reference\n   \u25a1 Code Examples\n   \u25a1 Troubleshooting\n   \u25a1 Videos\n   \n   Why: Users often know format they want\n   Display: Top of sidebar, expanded by default\n\n2. PROGRAMMING LANGUAGE\n   \u25a1 JavaScript/Node.js\n   \u25a1 Python\n   \u25a1 Java\n   \u25a1 Go\n   \u25a1 PHP\n   \u25a1 [Show more...]\n   \n   Why: Critical filter for developers\n   Display: Show top 5 + expand option\n\n3. DIFFICULTY LEVEL\n   \u25a1 Getting Started\n   \u25a1 Intermediate\n   \u25a1 Advanced\n   \n   Why: Matches user segments\n   Display: Simple 3-option toggle\n\nSECONDARY FACETS (Context-dependent):\n\n4. PRODUCT AREA (if >20 results)\n   \u25a1 Authentication\n   \u25a1 Data Management\n   \u25a1 Analytics\n   \u25a1 Integrations\n   \n5. LAST UPDATED (if searching docs)\n   \u25a1 Last 30 days\n   \u25a1 Last 6 months\n   \u25a1 Last year\n   \u25a1 Older\n\nSMART BEHAVIORS:\n\u2022 Auto-expand facets with few options\n\u2022 Hide facets with only 1 option\n\u2022 Remember user's common selections\n\u2022 Pre-select based on query intent\n```\n</CodeGroup>\n\n---",
            "hydration_source_header": "Facet Generation from User Behavior",
            "hydration_method": "title_match"
          },
          {
            "id": "keyword-analysis-prompt",
            "title": "Documentation Keyword Research Prompt",
            "taskType": "analysis",
            "lines": "525-565",
            "standalone": true,
            "retrievalQuestions": [
              "What prompt does keyword research for docs?"
            ],
            "content": "<CodeGroup>\n```text Keyword Analysis Prompt\nPerform keyword research for technical documentation:\n\nTOPIC: [Your main topic/product]\nCOMPETITORS: [List 3-5 competitor docs sites]\n\nResearch and provide:\n\n1. PRIMARY KEYWORDS (High volume, high competition)\n   - Search volume estimates\n   - Competition level\n   - Our likelihood to rank\n   \n2. LONG-TAIL OPPORTUNITIES (Lower volume, specific)\n   - Technical how-to queries\n   - Error message searches\n   - Integration queries\n   - Comparison searches\n   \n3. QUESTION KEYWORDS\n   - \"How to...\" queries\n   - \"What is...\" queries  \n   - \"Why does...\" queries\n   - \"When to use...\" queries\n   \n4. BRANDED VS NON-BRANDED\n   - \"[Product] authentication\"\n   - \"REST API authentication\"\n   \n5. CONTENT GAP ANALYSIS\n   - Keywords competitors rank for\n   - Keywords we could own\n   - Untapped opportunities\n\nFormat as actionable keyword map with content recommendations.\n```\n\n```text SEO Keyword Map\nTECHNICAL DOCUMENTATION KEYWORD STRATEGY\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nPRIMARY TARGETS (Focus pages):\n\n\"api authentication\" \n- Volume: 8,100/month\n- Competition: High\n- Strategy: Comprehensive guide as pillar page\n- Target URL: /docs/authentication\n\n\"rest api tutorial\"\n- Volume: 5,400/month  \n- Competition: Medium\n- Strategy: Step-by-step beginner guide\n- Target URL: /docs/getting-started\n\nLONG-TAIL OPPORTUNITIES (Quick wins):\n\n\"401 unauthorized error api\"\n- Volume: 720/month\n- Competition: Low\n- Strategy: Troubleshooting guide\n- Target URL: /docs/errors/401\n\n\"how to pass api key in header\"\n- Volume: 390/month\n- Competition: Low\n- Strategy: Code example page\n- Target URL: /docs/examples/api-key-header\n\n\"jwt vs oauth for api\"\n- Volume: 480/month\n- Competition: Low\n- Strategy: Comparison guide\n- Target URL: /docs/concepts/auth-methods\n\nQUESTION-BASED CONTENT:\n\n\"what is rate limiting in api\"\n- Create: Concept explanation page\n- Include: Definition, examples, implementation\n\n\"how to test api authentication\"\n- Create: Testing guide with tools\n- Include: Postman, curl, code examples\n\nCONTENT GAPS TO FILL:\n1. No Python authentication examples (890 searches/month)\n2. Missing WebSocket authentication guide (320 searches/month)\n3. No OAuth flow diagram (450 searches/month)\n4. Lack of authentication best practices (1,200 searches/month)\n```\n</CodeGroup>",
            "hydration_source_header": "Documentation Keyword Research Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "search-analysis-prompt",
            "title": "Search Performance Analysis Prompt",
            "taskType": "analysis",
            "lines": "610-640",
            "standalone": true,
            "content": "<Accordion title=\"URL Structure Optimization\">\n  \n  **Best Practices:**\n  ```\n  GOOD:\n  /docs/authentication/oauth/setup\n  /docs/api/endpoints/users\n  /docs/guides/getting-started\n  \n  AVOID:\n  /docs/page?id=12345\n  /d/auth/o/s\n  /documentation-authentication-oauth-setup-guide\n  ```\n  \n  **Rules:**\n  - Use descriptive, keyword-rich URLs\n  - Maintain logical hierarchy\n  - Keep URLs under 60 characters\n  - Use hyphens, not underscores\n  - Avoid parameters when possible\n</Accordion>\n\n<Accordion title=\"Schema Markup for Documentation\">\n  \n  ```json\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"TechArticle\",\n    \"headline\": \"API Authentication Guide\",\n    \"description\": \"Complete guide to API authentication using OAuth 2.0\",\n    \"keywords\": \"API, authentication, OAuth, security\",\n    \"datePublished\": \"2024-01-15\",\n    \"dateModified\": \"2024-10-21\",\n    \"author\": {\n      \"@type\": \"Organization\",\n      \"name\": \"Your Company\"\n    },\n    \"publisher\": {\n      \"@type\": \"Organization\",\n      \"name\": \"Your Company\"\n    },\n    \"mainEntityOfPage\": {\n      \"@type\": \"WebPage\",\n      \"@id\": \"https://docs.example.com/authentication\"\n    }\n  }\n  ```\n</Accordion>\n\n---",
            "hydration_source_header": "4.2 Technical SEO for Documentation",
            "hydration_method": "line_proximity"
          },
          {
            "id": "content-optimization-prompt",
            "title": "Content Optimization Task Generation Prompt",
            "taskType": "generation",
            "lines": "650-680",
            "standalone": true,
            "content": "### Step 1: Analyze Current Search Performance\n\n<CodeGroup>\n```text Data Collection Checklist\n\u25a1 Export last 30 days of internal search queries\n\u25a1 Get Google Search Console data\n\u25a1 Collect support ticket search-related issues\n\u25a1 Review 404 error logs for search attempts\n\u25a1 Gather user feedback about findability\n\nCompile into single dataset:\n- Query text\n- Frequency/volume\n- Results returned (yes/no)\n- User satisfaction (if available)\n- Source (internal/external/support)\n```\n\n```text Analysis Prompt\nAnalyze this search performance data:\n\n[Paste your compiled search data]\n\nIdentify:\n1. Top 20 failed queries (no results)\n2. Top 20 low-satisfaction queries\n3. Patterns in failed searches\n4. Vocabulary mismatches\n5. Content gaps\n\nPrioritize improvements by:\n- Query volume \u00d7 failure rate\n- Business impact\n- Implementation effort\n\nProvide top 10 quick wins and top 5 strategic improvements.\n```\n</CodeGroup>\n\n### Step 2: Generate Optimization Recommendations\n\n<CodeGroup>\n```text Content Optimization Prompt\nBased on this search analysis:\n[Paste analysis results]\n\nGenerate specific optimization tasks:\n\nFor each problem identified, provide:\n\n1. THE FIX\n   - Specific action to take\n   - Example implementation\n   \n2. EFFORT ESTIMATE\n   - Hours required\n   - Technical complexity\n   - Dependencies\n   \n3. EXPECTED IMPACT\n   - Search improvement metrics\n   - User success metrics\n   \n4. SUCCESS MEASUREMENT\n   - How to track improvement\n   - Target metrics\n\nFormat as actionable sprint tasks.\n```\n\n```text Example Task Output\nSEARCH OPTIMIZATION SPRINT TASKS\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nTASK 1: Add Authentication Synonyms\nProblem: 47% of \"login\" searches return no results\nFix: Add synonym mapping: login \u2192 authentication\nImplementation:\n  - Update search configuration\n  - Add to Elasticsearch synonyms.txt:\n    \"login,signin,authentication,auth\"\n  - Test with top 10 login-related queries\nEffort: 2 hours\nImpact: +47% search success rate for auth queries\nMeasurement: Track \"login\" query success rate\n\nTASK 2: Create 401 Error Troubleshooting Page\nProblem: 890 searches for \"401 error\" with no good results\nFix: New page: /docs/troubleshooting/401-unauthorized\nContent outline:\n  - What 401 means\n  - Common causes (expired token, wrong credentials)\n  - How to debug (check headers, validate token)\n  - Code examples for fixing\nEffort: 4 hours\nImpact: Direct answer for 890 monthly searches\nMeasurement: Page views, search clickthrough\n\n[Continue for all tasks...]\n```\n</CodeGroup>\n\n### Step 3: Implement and Measure\n\n<Info>\n  Implementation should be iterative. Start with quick wins to show value, then tackle strategic improvements.\n</Info>\n\n<CardGroup cols={3}>\n  <Card title=\"Week 1: Quick Wins\" icon=\"rabbit\">\n    - Add synonyms\n    - Fix top 10 broken searches\n    - Update 5 page titles\n  </Card>\n  <Card title=\"Week 2-3: Foundation\" icon=\"hammer\">\n    - Implement faceted search\n    - Create missing content\n    - Optimize URL structure\n  </Card>\n  <Card title=\"Week 4+: Strategic\" icon=\"chess\">\n    - Full content audit\n    - SEO content calendar\n    - Search analytics dashboard\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Part 5: Hands-on Tutorial - Complete Search Optimization Workflow",
            "hydration_method": "line_proximity"
          }
        ],
        "concepts": [
          {
            "id": "findability",
            "term": "Findability",
            "definition": "How easily users can locate content they need",
            "lines": "25-35",
            "retrievalQuestions": [
              "What is findability?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "internal-search",
            "term": "Internal Search",
            "definition": "Finding content within your site",
            "lines": "40-50",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "external-seo",
            "term": "External Search (SEO)",
            "definition": "Discovery via search engines like Google",
            "lines": "50-60",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "navigation-browse",
            "term": "Navigation/Browse",
            "definition": "Finding without knowing what to search",
            "lines": "60-75",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "search-intent",
            "term": "Search Intent",
            "definition": "The underlying goal behind a search query",
            "lines": "85-90",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "navigational-intent",
            "term": "Navigational Intent",
            "definition": "User wants to find a specific known page",
            "lines": "95-100",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "informational-intent",
            "term": "Informational Intent",
            "definition": "User wants to learn or understand something",
            "lines": "100-110",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "transactional-intent",
            "term": "Transactional Intent",
            "definition": "User wants to complete a specific action",
            "lines": "110-120",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "investigational-intent",
            "term": "Investigational Intent",
            "definition": "User wants to compare or evaluate options",
            "lines": "120-130",
            "retrievalQuestions": [
              "What are the four types of search intent?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "vocabulary-mismatch",
            "term": "Vocabulary Mismatch",
            "definition": "Users search with different terms than content uses",
            "lines": "195-200",
            "retrievalQuestions": [
              "What is vocabulary mismatch?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "synonym-set",
            "term": "Synonym Set",
            "definition": "Collection of equivalent/related terms for a concept",
            "lines": "200-250",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "faceted-search",
            "term": "Faceted Search",
            "definition": "Progressive refinement of search results via filters",
            "lines": "420-430",
            "retrievalQuestions": [
              "What is faceted search?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "long-tail-keywords",
            "term": "Long-Tail Keywords",
            "definition": "Specific, lower-volume search queries",
            "lines": "540-545",
            "retrievalQuestions": [
              "What are long-tail keywords?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "schema-markup",
            "term": "Schema Markup",
            "definition": "Structured data for search engines",
            "lines": "590-600",
            "hydration_status": "skipped_unknown"
          }
        ],
        "searchIntentTypes": [
          {
            "id": "navigational-intent-type",
            "intentType": "Navigational",
            "exampleQueries": "\"login page\", \"API docs\", \"pricing\"",
            "iaResponse": "Clear navigation, consistent naming",
            "lines": "95-100",
            "retrievalQuestions": [
              "How do I design for navigational intent?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "informational-intent-type",
            "intentType": "Informational",
            "exampleQueries": "\"how to authenticate API\", \"what is rate limiting\"",
            "iaResponse": "Comprehensive guides, explanations",
            "lines": "100-110",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "transactional-intent-type",
            "intentType": "Transactional",
            "exampleQueries": "\"download SDK\", \"sign up free trial\"",
            "iaResponse": "Clear CTAs, streamlined processes",
            "lines": "110-120",
            "retrievalQuestions": [
              "How do I recognize transactional queries?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "investigational-intent-type",
            "intentType": "Investigational",
            "exampleQueries": "\"Django vs Flask\", \"best authentication method\"",
            "iaResponse": "Comparison content, decision guides",
            "lines": "120-130",
            "retrievalQuestions": [
              "What content serves investigational intent?"
            ],
            "hydration_status": "skipped_unknown"
          }
        ],
        "synonymCategories": [
          {
            "id": "direct-synonyms",
            "category": "Direct Synonyms",
            "description": "Exact equivalents",
            "example": "auth = authentication",
            "lines": "215-220",
            "retrievalQuestions": [
              "What types of synonyms should I capture?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "colloquial-variants",
            "category": "Colloquial Variants",
            "description": "Non-expert descriptions",
            "example": "login = authentication",
            "lines": "220-225",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "related-concepts",
            "category": "Related Concepts",
            "description": "Broader/narrower terms",
            "example": "OAuth, JWT (narrower than auth)",
            "lines": "225-230",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "common-misspellings",
            "category": "Common Misspellings",
            "description": "Typical typos",
            "example": "authentification = authentication",
            "lines": "230-235",
            "retrievalQuestions": [
              "How do I handle misspellings in search?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "acronyms-abbreviations",
            "category": "Acronyms & Abbreviations",
            "description": "Shortened forms",
            "example": "2FA = two-factor authentication",
            "lines": "235-240",
            "retrievalQuestions": [
              "Should I include acronyms in synonym sets?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "contextual-variations",
            "category": "Contextual Variations",
            "description": "Regional/industry terms",
            "example": "authorisation (UK) = authorization",
            "lines": "240-245",
            "retrievalQuestions": [
              "How do I handle regional spelling variations?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "query-patterns",
            "category": "Search Query Patterns",
            "description": "How-to, error searches",
            "example": "\"can't authenticate\" = auth help",
            "lines": "245-250",
            "hydration_status": "skipped_unknown"
          }
        ],
        "examples": [
          {
            "id": "query-analysis-output",
            "title": "Query Analysis Report Example",
            "demonstrates": "query-classification-prompt",
            "lines": "175-195",
            "content": "#### Basic Query Classification Prompt\n\n<CodeGroup>\n```text Prompt Template\nYou are a search behavior analyst examining documentation search queries.\n\nAnalyze these search queries from our documentation site:\n[Paste 20-50 queries]\n\nFor each query, identify:\n1. Intent type (navigational/informational/transactional/investigational)\n2. User's likely goal\n3. Journey stage (awareness/consideration/decision/usage/troubleshooting)\n4. Vocabulary type (technical/colloquial/hybrid)\n5. Specificity level (broad/moderate/specific)\n\nThen provide:\n- Pattern summary across all queries\n- Top 5 vocabulary gaps (user terms vs our terminology)\n- Content opportunities we're missing\n- Recommendations for search optimization\n\nFormat as a structured analysis with clear sections.\n```\n\n```text Example Output\nQUERY ANALYSIS REPORT\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nINDIVIDUAL QUERY BREAKDOWN:\n\n1. \"rest api authentication\"\n   - Intent: Informational\n   - Goal: Learn how to authenticate API requests\n   - Stage: Usage/Implementation\n   - Vocabulary: Technical\n   - Specificity: Moderate\n\n2. \"login not working\"\n   - Intent: Investigational/Troubleshooting\n   - Goal: Fix authentication issue\n   - Stage: Troubleshooting\n   - Vocabulary: Colloquial\n   - Specificity: Broad (needs refinement)\n\n[Additional queries analyzed...]\n\nPATTERN SUMMARY:\n\u2022 45% informational queries (users learning)\n\u2022 30% troubleshooting queries (users stuck)\n\u2022 20% navigational (finding known pages)\n\u2022 5% transactional (downloads/signups)\n\nVOCABULARY GAPS IDENTIFIED:\n1. Users say \"login\" \u2192 We say \"authentication\"\n2. Users say \"limits\" \u2192 We say \"rate limiting\"\n3. Users say \"setup\" \u2192 We say \"initialization\"\n4. Users say \"broken\" \u2192 We say \"error state\"\n5. Users say \"dashboard\" \u2192 We say \"console\"\n\nMISSING CONTENT OPPORTUNITIES:\n\u2022 No troubleshooting guide for common auth errors\n\u2022 Missing quickstart for REST API\n\u2022 No comparison of authentication methods\n\u2022 Lack of code examples in primary languages\n```\n</CodeGroup>\n\n<Tip>\n  **Pro Tip:** Export your actual search logs from Google Search Console, internal site search, or support tickets to analyze real user queries rather than guessing.\n</Tip>\n\n---",
            "hydration_source_header": "1.2 Query Analysis with AI",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "authentication-synonym-set",
            "title": "Authentication Synonym Set Example",
            "demonstrates": "synonym-master-prompt",
            "lines": "250-290",
            "retrievalQuestions": [
              "What does a synonym set look like?"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "title-optimization-output",
            "title": "Title Optimization Analysis Output",
            "demonstrates": "title-optimization-prompt",
            "lines": "375-410",
            "retrievalQuestions": [
              "Example of title optimization output"
            ],
            "content": "<CodeGroup>\n```text Analysis Prompt\nAnalyze and optimize these page titles for search:\n\nCURRENT TITLES:\n1. \"Authentication\" \u2192 /docs/auth\n2. \"Getting Started\" \u2192 /docs/start\n3. \"API Reference\" \u2192 /docs/api\n4. \"Errors\" \u2192 /docs/errors\n5. \"Configuration\" \u2192 /docs/config\n\nCONTEXT:\n- Technical documentation site\n- Primary users: developers\n- Common searches: [list top 10 queries]\n\nFor each title, provide:\n1. Current effectiveness score (1-10)\n2. Problems identified\n3. Optimized version(s)\n4. Metadata recommendations\n5. Expected impact\n\nConsider:\n- User vocabulary preferences\n- Search intent matching\n- Clarity and specificity\n- SEO keyword integration\n- Character limits (60 chars for display)\n```\n\n```text Optimization Output\nTITLE OPTIMIZATION ANALYSIS\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n1. \"Authentication\" \u2192 /docs/auth\n   Current Score: 6/10\n   \n   Problems:\n   \u2022 Too technical for some users\n   \u2022 Doesn't indicate it's a guide\n   \u2022 Missing common search terms\n   \n   Optimized Options:\n   A) \"Authentication & Login Guide\"\n   B) \"API Authentication - Setup & Examples\"\n   C) \"How to Authenticate API Requests\"\n   \n   Metadata:\n   Title: \"API Authentication Guide - Login & Security\"\n   Description: \"Learn how to authenticate API requests. Covers OAuth, tokens, API keys, and troubleshooting login errors.\"\n   \n   Expected Impact:\n   \u2022 +40% match rate for \"login\" searches\n   \u2022 +25% click-through from search results\n   \u2022 Better alignment with user vocabulary\n\n[Continue for all titles...]\n```\n</CodeGroup>",
            "hydration_source_header": "Title Optimization Framework",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "faceted-search-spec",
            "title": "Faceted Search Specification Example",
            "demonstrates": "facet-design-prompt",
            "lines": "480-500",
            "retrievalQuestions": [
              "Show me a faceted search specification"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "keyword-map-example",
            "title": "SEO Keyword Map Example",
            "demonstrates": "keyword-analysis-prompt",
            "lines": "565-580",
            "hydration_status": "failed"
          },
          {
            "id": "optimization-task-output",
            "title": "Search Optimization Sprint Tasks Example",
            "demonstrates": "content-optimization-prompt",
            "lines": "680-715",
            "content": "<CodeGroup>\n```text Data Collection Checklist\n\u25a1 Export last 30 days of internal search queries\n\u25a1 Get Google Search Console data\n\u25a1 Collect support ticket search-related issues\n\u25a1 Review 404 error logs for search attempts\n\u25a1 Gather user feedback about findability\n\nCompile into single dataset:\n- Query text\n- Frequency/volume\n- Results returned (yes/no)\n- User satisfaction (if available)\n- Source (internal/external/support)\n```\n\n```text Analysis Prompt\nAnalyze this search performance data:\n\n[Paste your compiled search data]\n\nIdentify:\n1. Top 20 failed queries (no results)\n2. Top 20 low-satisfaction queries\n3. Patterns in failed searches\n4. Vocabulary mismatches\n5. Content gaps\n\nPrioritize improvements by:\n- Query volume \u00d7 failure rate\n- Business impact\n- Implementation effort\n\nProvide top 10 quick wins and top 5 strategic improvements.\n```\n</CodeGroup>",
            "hydration_source_header": "Step 1: Analyze Current Search Performance",
            "hydration_method": "line_proximity"
          }
        ],
        "technicalSeoElements": [
          {
            "id": "url-structure-optimization",
            "element": "URL Structure Optimization",
            "purpose": "SEO-friendly URLs",
            "lines": "585-590",
            "retrievalQuestions": [
              "How do I structure URLs for SEO?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "schema-markup-docs",
            "element": "Schema Markup for Documentation",
            "purpose": "TechArticle structured data",
            "lines": "590-600",
            "retrievalQuestions": [
              "What schema markup for documentation?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "keyword-targeting",
            "element": "Keyword Targeting Strategy",
            "purpose": "Primary, long-tail, question keywords",
            "lines": "540-580",
            "retrievalQuestions": [
              "How do I target keywords in technical docs?"
            ],
            "hydration_status": "skipped_unknown"
          }
        ],
        "workflows": [
          {
            "id": "search-optimization-3step",
            "title": "Search Optimization Workflow (3 steps)",
            "steps": [
              "analyze",
              "generate-recommendations",
              "implement-measure"
            ],
            "lines": "600-720",
            "retrievalQuestions": [
              "What are the steps to optimize search?"
            ],
            "content": "<Accordion title=\"URL Structure Optimization\">\n  \n  **Best Practices:**\n  ```\n  GOOD:\n  /docs/authentication/oauth/setup\n  /docs/api/endpoints/users\n  /docs/guides/getting-started\n  \n  AVOID:\n  /docs/page?id=12345\n  /d/auth/o/s\n  /documentation-authentication-oauth-setup-guide\n  ```\n  \n  **Rules:**\n  - Use descriptive, keyword-rich URLs\n  - Maintain logical hierarchy\n  - Keep URLs under 60 characters\n  - Use hyphens, not underscores\n  - Avoid parameters when possible\n</Accordion>\n\n<Accordion title=\"Schema Markup for Documentation\">\n  \n  ```json\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"TechArticle\",\n    \"headline\": \"API Authentication Guide\",\n    \"description\": \"Complete guide to API authentication using OAuth 2.0\",\n    \"keywords\": \"API, authentication, OAuth, security\",\n    \"datePublished\": \"2024-01-15\",\n    \"dateModified\": \"2024-10-21\",\n    \"author\": {\n      \"@type\": \"Organization\",\n      \"name\": \"Your Company\"\n    },\n    \"publisher\": {\n      \"@type\": \"Organization\",\n      \"name\": \"Your Company\"\n    },\n    \"mainEntityOfPage\": {\n      \"@type\": \"WebPage\",\n      \"@id\": \"https://docs.example.com/authentication\"\n    }\n  }\n  ```\n</Accordion>\n\n---",
            "hydration_source_header": "4.2 Technical SEO for Documentation",
            "hydration_method": "line_proximity"
          },
          {
            "id": "step-1-analyze-performance",
            "title": "Step 1: Analyze Current Search Performance",
            "description": "Data collection, analysis",
            "lines": "605-650",
            "content": "<CodeGroup>\n```text Data Collection Checklist\n\u25a1 Export last 30 days of internal search queries\n\u25a1 Get Google Search Console data\n\u25a1 Collect support ticket search-related issues\n\u25a1 Review 404 error logs for search attempts\n\u25a1 Gather user feedback about findability\n\nCompile into single dataset:\n- Query text\n- Frequency/volume\n- Results returned (yes/no)\n- User satisfaction (if available)\n- Source (internal/external/support)\n```\n\n```text Analysis Prompt\nAnalyze this search performance data:\n\n[Paste your compiled search data]\n\nIdentify:\n1. Top 20 failed queries (no results)\n2. Top 20 low-satisfaction queries\n3. Patterns in failed searches\n4. Vocabulary mismatches\n5. Content gaps\n\nPrioritize improvements by:\n- Query volume \u00d7 failure rate\n- Business impact\n- Implementation effort\n\nProvide top 10 quick wins and top 5 strategic improvements.\n```\n</CodeGroup>",
            "hydration_source_header": "Step 1: Analyze Current Search Performance",
            "hydration_method": "title_match"
          },
          {
            "id": "step-2-generate-recommendations",
            "title": "Step 2: Generate Optimization Recommendations",
            "description": "Task generation",
            "lines": "650-715",
            "content": "<CodeGroup>\n```text Content Optimization Prompt\nBased on this search analysis:\n[Paste analysis results]\n\nGenerate specific optimization tasks:\n\nFor each problem identified, provide:\n\n1. THE FIX\n   - Specific action to take\n   - Example implementation\n   \n2. EFFORT ESTIMATE\n   - Hours required\n   - Technical complexity\n   - Dependencies\n   \n3. EXPECTED IMPACT\n   - Search improvement metrics\n   - User success metrics\n   \n4. SUCCESS MEASUREMENT\n   - How to track improvement\n   - Target metrics\n\nFormat as actionable sprint tasks.\n```\n\n```text Example Task Output\nSEARCH OPTIMIZATION SPRINT TASKS\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nTASK 1: Add Authentication Synonyms\nProblem: 47% of \"login\" searches return no results\nFix: Add synonym mapping: login \u2192 authentication\nImplementation:\n  - Update search configuration\n  - Add to Elasticsearch synonyms.txt:\n    \"login,signin,authentication,auth\"\n  - Test with top 10 login-related queries\nEffort: 2 hours\nImpact: +47% search success rate for auth queries\nMeasurement: Track \"login\" query success rate\n\nTASK 2: Create 401 Error Troubleshooting Page\nProblem: 890 searches for \"401 error\" with no good results\nFix: New page: /docs/troubleshooting/401-unauthorized\nContent outline:\n  - What 401 means\n  - Common causes (expired token, wrong credentials)\n  - How to debug (check headers, validate token)\n  - Code examples for fixing\nEffort: 4 hours\nImpact: Direct answer for 890 monthly searches\nMeasurement: Page views, search clickthrough\n\n[Continue for all tasks...]\n```\n</CodeGroup>",
            "hydration_source_header": "Step 2: Generate Optimization Recommendations",
            "hydration_method": "title_match"
          },
          {
            "id": "step-3-implement-measure",
            "title": "Step 3: Implement and Measure",
            "description": "Phased rollout",
            "lines": "715-730",
            "retrievalQuestions": [
              "How do I implement search improvements?"
            ],
            "content": "<Info>\n  Implementation should be iterative. Start with quick wins to show value, then tackle strategic improvements.\n</Info>\n\n<CardGroup cols={3}>\n  <Card title=\"Week 1: Quick Wins\" icon=\"rabbit\">\n    - Add synonyms\n    - Fix top 10 broken searches\n    - Update 5 page titles\n  </Card>\n  <Card title=\"Week 2-3: Foundation\" icon=\"hammer\">\n    - Implement faceted search\n    - Create missing content\n    - Optimize URL structure\n  </Card>\n  <Card title=\"Week 4+: Strategic\" icon=\"chess\">\n    - Full content audit\n    - SEO content calendar\n    - Search analytics dashboard\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Step 3: Implement and Measure",
            "hydration_method": "title_match"
          }
        ],
        "checklists": [
          {
            "id": "data-collection-checklist",
            "title": "Search Data Collection Checklist",
            "validates": "step-1-analyze-performance",
            "items": 6,
            "lines": "605-615",
            "retrievalQuestions": [
              "What data do I need to analyze search?"
            ],
            "content": "<Accordion title=\"URL Structure Optimization\">\n  \n  **Best Practices:**\n  ```\n  GOOD:\n  /docs/authentication/oauth/setup\n  /docs/api/endpoints/users\n  /docs/guides/getting-started\n  \n  AVOID:\n  /docs/page?id=12345\n  /d/auth/o/s\n  /documentation-authentication-oauth-setup-guide\n  ```\n  \n  **Rules:**\n  - Use descriptive, keyword-rich URLs\n  - Maintain logical hierarchy\n  - Keep URLs under 60 characters\n  - Use hyphens, not underscores\n  - Avoid parameters when possible\n</Accordion>\n\n<Accordion title=\"Schema Markup for Documentation\">\n  \n  ```json\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"TechArticle\",\n    \"headline\": \"API Authentication Guide\",\n    \"description\": \"Complete guide to API authentication using OAuth 2.0\",\n    \"keywords\": \"API, authentication, OAuth, security\",\n    \"datePublished\": \"2024-01-15\",\n    \"dateModified\": \"2024-10-21\",\n    \"author\": {\n      \"@type\": \"Organization\",\n      \"name\": \"Your Company\"\n    },\n    \"publisher\": {\n      \"@type\": \"Organization\",\n      \"name\": \"Your Company\"\n    },\n    \"mainEntityOfPage\": {\n      \"@type\": \"WebPage\",\n      \"@id\": \"https://docs.example.com/authentication\"\n    }\n  }\n  ```\n</Accordion>\n\n---",
            "hydration_source_header": "4.2 Technical SEO for Documentation",
            "hydration_method": "line_proximity"
          },
          {
            "id": "query-analysis-deliverable",
            "title": "Query Analysis Report Checklist",
            "validates": "self-assessment-project",
            "items": 5,
            "lines": "740-750",
            "hydration_status": "failed"
          },
          {
            "id": "content-query-map-checklist",
            "title": "Content-Query Map Checklist",
            "validates": "self-assessment-project",
            "items": 4,
            "lines": "750-755",
            "hydration_status": "failed"
          },
          {
            "id": "synonym-dictionary-checklist",
            "title": "Synonym Dictionary Checklist",
            "validates": "self-assessment-project",
            "items": 4,
            "lines": "755-760",
            "content": "<Info>\n  Implementation should be iterative. Start with quick wins to show value, then tackle strategic improvements.\n</Info>\n\n<CardGroup cols={3}>\n  <Card title=\"Week 1: Quick Wins\" icon=\"rabbit\">\n    - Add synonyms\n    - Fix top 10 broken searches\n    - Update 5 page titles\n  </Card>\n  <Card title=\"Week 2-3: Foundation\" icon=\"hammer\">\n    - Implement faceted search\n    - Create missing content\n    - Optimize URL structure\n  </Card>\n  <Card title=\"Week 4+: Strategic\" icon=\"chess\">\n    - Full content audit\n    - SEO content calendar\n    - Search analytics dashboard\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Step 3: Implement and Measure",
            "hydration_method": "line_proximity"
          },
          {
            "id": "optimization-plan-checklist",
            "title": "Search Optimization Plan Checklist",
            "validates": "self-assessment-project",
            "items": 4,
            "lines": "760-770",
            "content": "<Info>\n  Implementation should be iterative. Start with quick wins to show value, then tackle strategic improvements.\n</Info>\n\n<CardGroup cols={3}>\n  <Card title=\"Week 1: Quick Wins\" icon=\"rabbit\">\n    - Add synonyms\n    - Fix top 10 broken searches\n    - Update 5 page titles\n  </Card>\n  <Card title=\"Week 2-3: Foundation\" icon=\"hammer\">\n    - Implement faceted search\n    - Create missing content\n    - Optimize URL structure\n  </Card>\n  <Card title=\"Week 4+: Strategic\" icon=\"chess\">\n    - Full content audit\n    - SEO content calendar\n    - Search analytics dashboard\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Step 3: Implement and Measure",
            "hydration_method": "line_proximity"
          },
          {
            "id": "implementation-roadmap-checklist",
            "title": "Implementation Roadmap Checklist",
            "validates": "self-assessment-project",
            "items": 4,
            "lines": "770-775",
            "content": "<Info>\n  Implementation should be iterative. Start with quick wins to show value, then tackle strategic improvements.\n</Info>\n\n<CardGroup cols={3}>\n  <Card title=\"Week 1: Quick Wins\" icon=\"rabbit\">\n    - Add synonyms\n    - Fix top 10 broken searches\n    - Update 5 page titles\n  </Card>\n  <Card title=\"Week 2-3: Foundation\" icon=\"hammer\">\n    - Implement faceted search\n    - Create missing content\n    - Optimize URL structure\n  </Card>\n  <Card title=\"Week 4+: Strategic\" icon=\"chess\">\n    - Full content audit\n    - SEO content calendar\n    - Search analytics dashboard\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Step 3: Implement and Measure",
            "hydration_method": "line_proximity"
          },
          {
            "id": "success-criteria-checklist",
            "title": "Success Criteria Checklist",
            "validates": "self-assessment-project",
            "items": 8,
            "lines": "825-840",
            "retrievalQuestions": [
              "How do I validate my search improvement plan?"
            ],
            "content": "Your project demonstrates excellence if:\n\n- \u2713 Query analysis reveals non-obvious insights about user needs\n- \u2713 Synonym sets are comprehensive yet precisely relevant  \n- \u2713 Optimization recommendations are specific and prioritized by impact\n- \u2713 SEO strategy integrates naturally with user-focused improvements\n- \u2713 Implementation plan is realistic and actionable for your context\n- \u2713 Success metrics are measurable and tied to user outcomes\n- \u2713 AI was used strategically to enhance (not replace) human judgment\n- \u2713 A stakeholder could approve and execute your plan",
            "hydration_source_header": "Success Criteria Checklist",
            "hydration_method": "title_match"
          }
        ],
        "deliverables": [
          {
            "id": "query-analysis-report",
            "title": "Query Analysis Report",
            "purpose": "Analyze 50+ queries with classification",
            "timeEstimate": "2-3 hours",
            "lines": "740-750",
            "content": "#### Basic Query Classification Prompt\n\n<CodeGroup>\n```text Prompt Template\nYou are a search behavior analyst examining documentation search queries.\n\nAnalyze these search queries from our documentation site:\n[Paste 20-50 queries]\n\nFor each query, identify:\n1. Intent type (navigational/informational/transactional/investigational)\n2. User's likely goal\n3. Journey stage (awareness/consideration/decision/usage/troubleshooting)\n4. Vocabulary type (technical/colloquial/hybrid)\n5. Specificity level (broad/moderate/specific)\n\nThen provide:\n- Pattern summary across all queries\n- Top 5 vocabulary gaps (user terms vs our terminology)\n- Content opportunities we're missing\n- Recommendations for search optimization\n\nFormat as a structured analysis with clear sections.\n```\n\n```text Example Output\nQUERY ANALYSIS REPORT\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nINDIVIDUAL QUERY BREAKDOWN:\n\n1. \"rest api authentication\"\n   - Intent: Informational\n   - Goal: Learn how to authenticate API requests\n   - Stage: Usage/Implementation\n   - Vocabulary: Technical\n   - Specificity: Moderate\n\n2. \"login not working\"\n   - Intent: Investigational/Troubleshooting\n   - Goal: Fix authentication issue\n   - Stage: Troubleshooting\n   - Vocabulary: Colloquial\n   - Specificity: Broad (needs refinement)\n\n[Additional queries analyzed...]\n\nPATTERN SUMMARY:\n\u2022 45% informational queries (users learning)\n\u2022 30% troubleshooting queries (users stuck)\n\u2022 20% navigational (finding known pages)\n\u2022 5% transactional (downloads/signups)\n\nVOCABULARY GAPS IDENTIFIED:\n1. Users say \"login\" \u2192 We say \"authentication\"\n2. Users say \"limits\" \u2192 We say \"rate limiting\"\n3. Users say \"setup\" \u2192 We say \"initialization\"\n4. Users say \"broken\" \u2192 We say \"error state\"\n5. Users say \"dashboard\" \u2192 We say \"console\"\n\nMISSING CONTENT OPPORTUNITIES:\n\u2022 No troubleshooting guide for common auth errors\n\u2022 Missing quickstart for REST API\n\u2022 No comparison of authentication methods\n\u2022 Lack of code examples in primary languages\n```\n</CodeGroup>\n\n<Tip>\n  **Pro Tip:** Export your actual search logs from Google Search Console, internal site search, or support tickets to analyze real user queries rather than guessing.\n</Tip>\n\n---",
            "hydration_source_header": "1.2 Query Analysis with AI",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "content-query-map",
            "title": "Content-Query Map",
            "purpose": "Match content to queries, identify gaps",
            "timeEstimate": "1-2 hours",
            "lines": "750-755",
            "hydration_status": "failed"
          },
          {
            "id": "synonym-dictionary",
            "title": "Synonym Dictionary",
            "purpose": "10-15 key terms with full synonym sets",
            "timeEstimate": "1-2 hours",
            "lines": "755-760",
            "content": "<Info>\n  Implementation should be iterative. Start with quick wins to show value, then tackle strategic improvements.\n</Info>\n\n<CardGroup cols={3}>\n  <Card title=\"Week 1: Quick Wins\" icon=\"rabbit\">\n    - Add synonyms\n    - Fix top 10 broken searches\n    - Update 5 page titles\n  </Card>\n  <Card title=\"Week 2-3: Foundation\" icon=\"hammer\">\n    - Implement faceted search\n    - Create missing content\n    - Optimize URL structure\n  </Card>\n  <Card title=\"Week 4+: Strategic\" icon=\"chess\">\n    - Full content audit\n    - SEO content calendar\n    - Search analytics dashboard\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Step 3: Implement and Measure",
            "hydration_method": "line_proximity"
          },
          {
            "id": "search-optimization-plan",
            "title": "Search Optimization Plan",
            "purpose": "Page optimizations, faceted search design",
            "timeEstimate": "2-3 hours",
            "lines": "760-770",
            "retrievalQuestions": [
              "What's in a search optimization plan?"
            ],
            "content": "### 3.1 Page Title and Metadata Enhancement\n\n#### Title Optimization Framework\n\n<CodeGroup>\n```text Analysis Prompt\nAnalyze and optimize these page titles for search:\n\nCURRENT TITLES:\n1. \"Authentication\" \u2192 /docs/auth\n2. \"Getting Started\" \u2192 /docs/start\n3. \"API Reference\" \u2192 /docs/api\n4. \"Errors\" \u2192 /docs/errors\n5. \"Configuration\" \u2192 /docs/config\n\nCONTEXT:\n- Technical documentation site\n- Primary users: developers\n- Common searches: [list top 10 queries]\n\nFor each title, provide:\n1. Current effectiveness score (1-10)\n2. Problems identified\n3. Optimized version(s)\n4. Metadata recommendations\n5. Expected impact\n\nConsider:\n- User vocabulary preferences\n- Search intent matching\n- Clarity and specificity\n- SEO keyword integration\n- Character limits (60 chars for display)\n```\n\n```text Optimization Output\nTITLE OPTIMIZATION ANALYSIS\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n1. \"Authentication\" \u2192 /docs/auth\n   Current Score: 6/10\n   \n   Problems:\n   \u2022 Too technical for some users\n   \u2022 Doesn't indicate it's a guide\n   \u2022 Missing common search terms\n   \n   Optimized Options:\n   A) \"Authentication & Login Guide\"\n   B) \"API Authentication - Setup & Examples\"\n   C) \"How to Authenticate API Requests\"\n   \n   Metadata:\n   Title: \"API Authentication Guide - Login & Security\"\n   Description: \"Learn how to authenticate API requests. Covers OAuth, tokens, API keys, and troubleshooting login errors.\"\n   \n   Expected Impact:\n   \u2022 +40% match rate for \"login\" searches\n   \u2022 +25% click-through from search results\n   \u2022 Better alignment with user vocabulary\n\n[Continue for all titles...]\n```\n</CodeGroup>\n\n### 3.2 Faceted Search Design\n\n<Info>\n  Faceted search lets users progressively refine results. Good facets emerge from actual user behavior, not just available metadata.\n</Info>\n\n#### Facet Generation from User Behavior\n\n<CodeGroup>\n```text Facet Design Prompt\nBased on these search patterns, design a faceted search system:\n\nTOP SEARCH QUERIES (last 30 days):\n[List 50+ real queries]\n\nCONTENT TYPES AVAILABLE:\n- Guides (how-to, tutorials)\n- API Reference (endpoints, methods)\n- Code Examples\n- Troubleshooting\n- Concepts (explanations)\n- Videos\n- Release Notes\n\nUSER SEGMENTS:\n- Beginners (30%)\n- Intermediate developers (50%)\n- Advanced/Enterprise (20%)\n\nDesign facets that:\n1. Match how users actually search\n2. Provide meaningful refinement options\n3. Surface relevant content quickly\n4. Scale from 10 to 10,000 results\n\nProvide:\n- Recommended facet categories\n- Values for each facet\n- Display order and logic\n- Progressive disclosure strategy\n- Mobile considerations\n```\n\n```text Faceted Search Specification\nRECOMMENDED FACET STRUCTURE\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nPRIMARY FACETS (Always visible):\n\n1. CONTENT TYPE\n   \u25a1 Guides & Tutorials\n   \u25a1 API Reference\n   \u25a1 Code Examples\n   \u25a1 Troubleshooting\n   \u25a1 Videos\n   \n   Why: Users often know format they want\n   Display: Top of sidebar, expanded by default\n\n2. PROGRAMMING LANGUAGE\n   \u25a1 JavaScript/Node.js\n   \u25a1 Python\n   \u25a1 Java\n   \u25a1 Go\n   \u25a1 PHP\n   \u25a1 [Show more...]\n   \n   Why: Critical filter for developers\n   Display: Show top 5 + expand option\n\n3. DIFFICULTY LEVEL\n   \u25a1 Getting Started\n   \u25a1 Intermediate\n   \u25a1 Advanced\n   \n   Why: Matches user segments\n   Display: Simple 3-option toggle\n\nSECONDARY FACETS (Context-dependent):\n\n4. PRODUCT AREA (if >20 results)\n   \u25a1 Authentication\n   \u25a1 Data Management\n   \u25a1 Analytics\n   \u25a1 Integrations\n   \n5. LAST UPDATED (if searching docs)\n   \u25a1 Last 30 days\n   \u25a1 Last 6 months\n   \u25a1 Last year\n   \u25a1 Older\n\nSMART BEHAVIORS:\n\u2022 Auto-expand facets with few options\n\u2022 Hide facets with only 1 option\n\u2022 Remember user's common selections\n\u2022 Pre-select based on query intent\n```\n</CodeGroup>\n\n---",
            "hydration_source_header": "Part 3: Content-Search Optimization",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "implementation-roadmap",
            "title": "Implementation Roadmap",
            "purpose": "Phased rollout plan with metrics",
            "timeEstimate": "1-2 hours",
            "lines": "770-775",
            "content": "<Info>\n  Implementation should be iterative. Start with quick wins to show value, then tackle strategic improvements.\n</Info>\n\n<CardGroup cols={3}>\n  <Card title=\"Week 1: Quick Wins\" icon=\"rabbit\">\n    - Add synonyms\n    - Fix top 10 broken searches\n    - Update 5 page titles\n  </Card>\n  <Card title=\"Week 2-3: Foundation\" icon=\"hammer\">\n    - Implement faceted search\n    - Create missing content\n    - Optimize URL structure\n  </Card>\n  <Card title=\"Week 4+: Strategic\" icon=\"chess\">\n    - Full content audit\n    - SEO content calendar\n    - Search analytics dashboard\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Step 3: Implement and Measure",
            "hydration_method": "line_proximity"
          }
        ],
        "timeMetrics": [
          {
            "id": "query-analysis-time",
            "activity": "Manual Query Analysis",
            "traditionalTime": "8-16 hours",
            "aiAssistedTime": "2-3 hours",
            "savings": "~80%",
            "lines": "730-735",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "synonym-research-time",
            "activity": "Synonym Research",
            "traditionalTime": "10-15 hours",
            "aiAssistedTime": "1-2 hours",
            "savings": "~90%",
            "lines": "730-735",
            "retrievalQuestions": [
              "How long does synonym research take with AI?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "gap-analysis-time",
            "activity": "Gap Analysis",
            "traditionalTime": "6-10 hours",
            "aiAssistedTime": "1-2 hours",
            "savings": "~80%",
            "lines": "730-735",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "total-comparison",
            "activity": "Total Project Time",
            "traditionalTime": "24-41 hours",
            "aiAssistedTime": "4-7 hours",
            "savings": "80%+",
            "lines": "730-735",
            "retrievalQuestions": [
              "How much time does AI-assisted search optimization save?"
            ],
            "hydration_status": "skipped_unknown"
          }
        ],
        "warnings": [
          {
            "id": "generic-recommendations",
            "title": "Generic Recommendations",
            "prevents": "Vague suggestions without examples",
            "lines": "850",
            "content": "<CodeGroup>\n```text Content Optimization Prompt\nBased on this search analysis:\n[Paste analysis results]\n\nGenerate specific optimization tasks:\n\nFor each problem identified, provide:\n\n1. THE FIX\n   - Specific action to take\n   - Example implementation\n   \n2. EFFORT ESTIMATE\n   - Hours required\n   - Technical complexity\n   - Dependencies\n   \n3. EXPECTED IMPACT\n   - Search improvement metrics\n   - User success metrics\n   \n4. SUCCESS MEASUREMENT\n   - How to track improvement\n   - Target metrics\n\nFormat as actionable sprint tasks.\n```\n\n```text Example Task Output\nSEARCH OPTIMIZATION SPRINT TASKS\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nTASK 1: Add Authentication Synonyms\nProblem: 47% of \"login\" searches return no results\nFix: Add synonym mapping: login \u2192 authentication\nImplementation:\n  - Update search configuration\n  - Add to Elasticsearch synonyms.txt:\n    \"login,signin,authentication,auth\"\n  - Test with top 10 login-related queries\nEffort: 2 hours\nImpact: +47% search success rate for auth queries\nMeasurement: Track \"login\" query success rate\n\nTASK 2: Create 401 Error Troubleshooting Page\nProblem: 890 searches for \"401 error\" with no good results\nFix: New page: /docs/troubleshooting/401-unauthorized\nContent outline:\n  - What 401 means\n  - Common causes (expired token, wrong credentials)\n  - How to debug (check headers, validate token)\n  - Code examples for fixing\nEffort: 4 hours\nImpact: Direct answer for 890 monthly searches\nMeasurement: Page views, search clickthrough\n\n[Continue for all tasks...]\n```\n</CodeGroup>",
            "hydration_source_header": "Step 2: Generate Optimization Recommendations",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "ignoring-user-vocabulary",
            "title": "Ignoring User Vocabulary",
            "prevents": "Optimizing for wrong terms",
            "lines": "850",
            "content": "<CardGroup cols={2}>\n  <Card title=\"Traditional Approach\" icon=\"hourglass\">\n    - Manual query analysis: 8-16 hours\n    - Synonym research: 10-15 hours  \n    - Gap analysis: 6-10 hours\n    - **Total: 24-41 hours**\n  </Card>\n  <Card title=\"AI-Assisted Approach\" icon=\"rocket\">\n    - AI query analysis: 2-3 hours\n    - AI synonym generation: 1-2 hours\n    - AI gap analysis: 1-2 hours\n    - **Total: 4-7 hours**\n    - **Time Saved: 80%+**\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Time Investment Comparison",
            "hydration_method": "line_proximity"
          },
          {
            "id": "seo-without-substance",
            "title": "SEO Without Substance",
            "prevents": "Keyword stuffing, poor content",
            "lines": "855",
            "retrievalQuestions": [
              "How do I avoid SEO without substance?"
            ],
            "content": "<CardGroup cols={2}>\n  <Card title=\"Traditional Approach\" icon=\"hourglass\">\n    - Manual query analysis: 8-16 hours\n    - Synonym research: 10-15 hours  \n    - Gap analysis: 6-10 hours\n    - **Total: 24-41 hours**\n  </Card>\n  <Card title=\"AI-Assisted Approach\" icon=\"rocket\">\n    - AI query analysis: 2-3 hours\n    - AI synonym generation: 1-2 hours\n    - AI gap analysis: 1-2 hours\n    - **Total: 4-7 hours**\n    - **Time Saved: 80%+**\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Time Investment Comparison",
            "hydration_method": "line_proximity"
          },
          {
            "id": "unrealistic-scope",
            "title": "Unrealistic Scope",
            "prevents": "Trying to fix everything",
            "lines": "855",
            "content": "<CardGroup cols={2}>\n  <Card title=\"Traditional Approach\" icon=\"hourglass\">\n    - Manual query analysis: 8-16 hours\n    - Synonym research: 10-15 hours  \n    - Gap analysis: 6-10 hours\n    - **Total: 24-41 hours**\n  </Card>\n  <Card title=\"AI-Assisted Approach\" icon=\"rocket\">\n    - AI query analysis: 2-3 hours\n    - AI synonym generation: 1-2 hours\n    - AI gap analysis: 1-2 hours\n    - **Total: 4-7 hours**\n    - **Time Saved: 80%+**\n  </Card>\n</CardGroup>\n\n---",
            "hydration_source_header": "Time Investment Comparison",
            "hydration_method": "line_proximity"
          },
          {
            "id": "missing-validation",
            "title": "Missing Validation",
            "prevents": "Not checking AI synonym accuracy",
            "lines": "860",
            "retrievalQuestions": [
              "Why validate AI-generated synonyms?"
            ],
            "content": "### Project Brief\n\nDesign and document a complete findability improvement plan for a real documentation site, integrating both internal search optimization and external SEO strategy.\n\n<Warning>\n  This is a substantial project requiring 11-17 hours of work. Plan accordingly and work iteratively.\n</Warning>\n\n### Deliverables\n\n<Accordion title=\"1. Search Query Analysis Report (2-3 pages)\">\n  **Required Elements:**\n  - 50-100 analyzed queries (real or realistically simulated)\n  - Query classification by type, intent, journey stage\n  - Vocabulary gap analysis\n  - Pattern identification\n  - Key insights and implications\n  \n  **Excellence Criteria:**\n  - Non-obvious insights discovered\n  - Clear patterns identified\n  - Actionable recommendations\n  - Data visualization included\n</Accordion>\n\n<Accordion title=\"2. Synonym and Metadata Strategy (1-2 pages + appendix)\">\n  **Required Elements:**\n  - Comprehensive synonym sets for 10-15 terms\n  - Metadata tagging schema\n  - Maintenance guidelines\n  - Integration plan\n  \n  **Excellence Criteria:**\n  - Synonyms validated against real searches\n  - Clear implementation instructions\n  - Scalable approach documented\n</Accordion>\n\n<Accordion title=\"3. Content-Search Optimization Plan (3-4 pages)\">\n  **Internal Search:**\n  - Priority page optimizations (10+ pages)\n  - Before/after examples\n  - Faceted search design\n  - Internal linking strategy\n  \n  **SEO Strategy:**\n  - Keyword targets by content area\n  - URL structure recommendations\n  - Content gap opportunities\n  - Competitive positioning\n  \n  **Excellence Criteria:**\n  - Specific, actionable recommendations\n  - Realistic scope and priorities\n  - Clear success metrics\n</Accordion>\n\n<Accordion title=\"4. Implementation Roadmap (1-2 pages)\">\n  **Required Elements:**\n  - Three phases: Quick Wins, Foundation, Strategic\n  - Specific tasks with effort estimates\n  - Resource requirements\n  - Timeline with milestones\n  - Success metrics and tracking plan\n  \n  **Excellence Criteria:**\n  - Realistic for your organization\n  - Clear ownership and dependencies\n  - Risk mitigation included\n  - Measurable outcomes defined\n</Accordion>\n\n### Site Selection Options\n\n<CardGroup cols={3}>\n  <Card title=\"Option A: Your Organization\" icon=\"building\">\n    Use your actual documentation site for immediate applicability\n  </Card>\n  <Card title=\"Option B: Open Source Project\" icon=\"code\">\n    Analyze React, Python, Kubernetes, or similar public documentation\n  </Card>\n  <Card title=\"Option C: Competitor Analysis\" icon=\"trophy\">\n    Study and improve upon a competitor's documentation site\n  </Card>\n</CardGroup>\n\n### Evaluation Rubric\n\n<Info>\n  Your project will be evaluated on these five dimensions, each worth 20% of the total score.\n</Info>\n\n<Accordion title=\"Query Analysis Quality (20%)\">\n  - Realistic, representative query set\n  - Thorough intent and pattern analysis\n  - Clear vocabulary gap identification\n  - Actionable insights derived\n</Accordion>\n\n<Accordion title=\"Strategic Thinking (20%)\">\n  - SEO and internal search integration\n  - User impact-based prioritization\n  - Alignment with user journeys\n  - Innovative approaches\n</Accordion>\n\n<Accordion title=\"AI Utilization (20%)\">\n  - Effective prompt design\n  - Appropriate automation vs. human judgment\n  - Evidence of validation and refinement\n  - Documented methodology\n</Accordion>\n\n<Accordion title=\"Practical Actionability (20%)\">\n  - Specific, implementable recommendations\n  - Realistic effort estimates\n  - Clear ownership model\n  - Measurable success criteria\n</Accordion>\n\n<Accordion title=\"Documentation Quality (20%)\">\n  - Clear, professional presentation\n  - Appropriate depth and detail\n  - Scannable formatting\n  - Reproducible methodology\n</Accordion>\n\n### Success Criteria Checklist\n\nYour project demonstrates excellence if:\n\n- \u2713 Query analysis reveals non-obvious insights about user needs\n- \u2713 Synonym sets are comprehensive yet precisely relevant  \n- \u2713 Optimization recommendations are specific and prioritized by impact\n- \u2713 SEO strategy integrates naturally with user-focused improvements\n- \u2713 Implementation plan is realistic and actionable for your context\n- \u2713 Success metrics are measurable and tied to user outcomes\n- \u2713 AI was used strategically to enhance (not replace) human judgment\n- \u2713 A stakeholder could approve and execute your plan\n\n### Common Pitfalls to Avoid\n\n<Warning>\n  **Avoid These Common Mistakes:**\n  \n  \u274c **Generic recommendations** \u2013 \"Improve page titles\" without specific examples\n  \u274c **Ignoring user vocabulary** \u2013 Optimizing for terms users don't actually search\n  \u274c **SEO without substance** \u2013 Keyword stuffing or optimizing poor content\n  \u274c **Unrealistic scope** \u2013 Trying to fix everything instead of prioritizing\n  \u274c **Missing validation** \u2013 Not checking AI-generated synonyms for accuracy\n  \u274c **No success metrics** \u2013 Can't measure if recommendations work\n  \u274c **Effort underestimation** \u2013 Implementation plan requires unavailable resources\n</Warning>\n\n### Submission Requirements\n\n<Card title=\"Complete Submission Package\" icon=\"package\">\n  **Main Document:**\n  1. All four required deliverables\n  \n  **Appendices:**\n  - Full query list with classifications\n  - Complete synonym sets  \n  - Sample prompts used (5-10 most effective)\n  \n  **Supporting Materials:**\n  - Methodology note (1 paragraph)\n  - Reflection (2-3 paragraphs):\n    - What surprised you?\n    - What would you do differently?\n    - How did AI change your approach?\n    - What validation steps were critical?\n</Card>\n\n---",
            "hydration_source_header": "Self-Assessment Project: Comprehensive Findability Improvement Plan",
            "hydration_method": "line_proximity"
          },
          {
            "id": "no-success-metrics",
            "title": "No Success Metrics",
            "prevents": "Can't measure if improvements work",
            "lines": "860",
            "content": "### Project Brief\n\nDesign and document a complete findability improvement plan for a real documentation site, integrating both internal search optimization and external SEO strategy.\n\n<Warning>\n  This is a substantial project requiring 11-17 hours of work. Plan accordingly and work iteratively.\n</Warning>\n\n### Deliverables\n\n<Accordion title=\"1. Search Query Analysis Report (2-3 pages)\">\n  **Required Elements:**\n  - 50-100 analyzed queries (real or realistically simulated)\n  - Query classification by type, intent, journey stage\n  - Vocabulary gap analysis\n  - Pattern identification\n  - Key insights and implications\n  \n  **Excellence Criteria:**\n  - Non-obvious insights discovered\n  - Clear patterns identified\n  - Actionable recommendations\n  - Data visualization included\n</Accordion>\n\n<Accordion title=\"2. Synonym and Metadata Strategy (1-2 pages + appendix)\">\n  **Required Elements:**\n  - Comprehensive synonym sets for 10-15 terms\n  - Metadata tagging schema\n  - Maintenance guidelines\n  - Integration plan\n  \n  **Excellence Criteria:**\n  - Synonyms validated against real searches\n  - Clear implementation instructions\n  - Scalable approach documented\n</Accordion>\n\n<Accordion title=\"3. Content-Search Optimization Plan (3-4 pages)\">\n  **Internal Search:**\n  - Priority page optimizations (10+ pages)\n  - Before/after examples\n  - Faceted search design\n  - Internal linking strategy\n  \n  **SEO Strategy:**\n  - Keyword targets by content area\n  - URL structure recommendations\n  - Content gap opportunities\n  - Competitive positioning\n  \n  **Excellence Criteria:**\n  - Specific, actionable recommendations\n  - Realistic scope and priorities\n  - Clear success metrics\n</Accordion>\n\n<Accordion title=\"4. Implementation Roadmap (1-2 pages)\">\n  **Required Elements:**\n  - Three phases: Quick Wins, Foundation, Strategic\n  - Specific tasks with effort estimates\n  - Resource requirements\n  - Timeline with milestones\n  - Success metrics and tracking plan\n  \n  **Excellence Criteria:**\n  - Realistic for your organization\n  - Clear ownership and dependencies\n  - Risk mitigation included\n  - Measurable outcomes defined\n</Accordion>\n\n### Site Selection Options\n\n<CardGroup cols={3}>\n  <Card title=\"Option A: Your Organization\" icon=\"building\">\n    Use your actual documentation site for immediate applicability\n  </Card>\n  <Card title=\"Option B: Open Source Project\" icon=\"code\">\n    Analyze React, Python, Kubernetes, or similar public documentation\n  </Card>\n  <Card title=\"Option C: Competitor Analysis\" icon=\"trophy\">\n    Study and improve upon a competitor's documentation site\n  </Card>\n</CardGroup>\n\n### Evaluation Rubric\n\n<Info>\n  Your project will be evaluated on these five dimensions, each worth 20% of the total score.\n</Info>\n\n<Accordion title=\"Query Analysis Quality (20%)\">\n  - Realistic, representative query set\n  - Thorough intent and pattern analysis\n  - Clear vocabulary gap identification\n  - Actionable insights derived\n</Accordion>\n\n<Accordion title=\"Strategic Thinking (20%)\">\n  - SEO and internal search integration\n  - User impact-based prioritization\n  - Alignment with user journeys\n  - Innovative approaches\n</Accordion>\n\n<Accordion title=\"AI Utilization (20%)\">\n  - Effective prompt design\n  - Appropriate automation vs. human judgment\n  - Evidence of validation and refinement\n  - Documented methodology\n</Accordion>\n\n<Accordion title=\"Practical Actionability (20%)\">\n  - Specific, implementable recommendations\n  - Realistic effort estimates\n  - Clear ownership model\n  - Measurable success criteria\n</Accordion>\n\n<Accordion title=\"Documentation Quality (20%)\">\n  - Clear, professional presentation\n  - Appropriate depth and detail\n  - Scannable formatting\n  - Reproducible methodology\n</Accordion>\n\n### Success Criteria Checklist\n\nYour project demonstrates excellence if:\n\n- \u2713 Query analysis reveals non-obvious insights about user needs\n- \u2713 Synonym sets are comprehensive yet precisely relevant  \n- \u2713 Optimization recommendations are specific and prioritized by impact\n- \u2713 SEO strategy integrates naturally with user-focused improvements\n- \u2713 Implementation plan is realistic and actionable for your context\n- \u2713 Success metrics are measurable and tied to user outcomes\n- \u2713 AI was used strategically to enhance (not replace) human judgment\n- \u2713 A stakeholder could approve and execute your plan\n\n### Common Pitfalls to Avoid\n\n<Warning>\n  **Avoid These Common Mistakes:**\n  \n  \u274c **Generic recommendations** \u2013 \"Improve page titles\" without specific examples\n  \u274c **Ignoring user vocabulary** \u2013 Optimizing for terms users don't actually search\n  \u274c **SEO without substance** \u2013 Keyword stuffing or optimizing poor content\n  \u274c **Unrealistic scope** \u2013 Trying to fix everything instead of prioritizing\n  \u274c **Missing validation** \u2013 Not checking AI-generated synonyms for accuracy\n  \u274c **No success metrics** \u2013 Can't measure if recommendations work\n  \u274c **Effort underestimation** \u2013 Implementation plan requires unavailable resources\n</Warning>\n\n### Submission Requirements\n\n<Card title=\"Complete Submission Package\" icon=\"package\">\n  **Main Document:**\n  1. All four required deliverables\n  \n  **Appendices:**\n  - Full query list with classifications\n  - Complete synonym sets  \n  - Sample prompts used (5-10 most effective)\n  \n  **Supporting Materials:**\n  - Methodology note (1 paragraph)\n  - Reflection (2-3 paragraphs):\n    - What surprised you?\n    - What would you do differently?\n    - How did AI change your approach?\n    - What validation steps were critical?\n</Card>\n\n---",
            "hydration_source_header": "Self-Assessment Project: Comprehensive Findability Improvement Plan",
            "hydration_method": "line_proximity"
          },
          {
            "id": "effort-underestimation",
            "title": "Effort Underestimation",
            "prevents": "Plan requires unavailable resources",
            "lines": "865",
            "content": "### Project Brief\n\nDesign and document a complete findability improvement plan for a real documentation site, integrating both internal search optimization and external SEO strategy.\n\n<Warning>\n  This is a substantial project requiring 11-17 hours of work. Plan accordingly and work iteratively.\n</Warning>\n\n### Deliverables\n\n<Accordion title=\"1. Search Query Analysis Report (2-3 pages)\">\n  **Required Elements:**\n  - 50-100 analyzed queries (real or realistically simulated)\n  - Query classification by type, intent, journey stage\n  - Vocabulary gap analysis\n  - Pattern identification\n  - Key insights and implications\n  \n  **Excellence Criteria:**\n  - Non-obvious insights discovered\n  - Clear patterns identified\n  - Actionable recommendations\n  - Data visualization included\n</Accordion>\n\n<Accordion title=\"2. Synonym and Metadata Strategy (1-2 pages + appendix)\">\n  **Required Elements:**\n  - Comprehensive synonym sets for 10-15 terms\n  - Metadata tagging schema\n  - Maintenance guidelines\n  - Integration plan\n  \n  **Excellence Criteria:**\n  - Synonyms validated against real searches\n  - Clear implementation instructions\n  - Scalable approach documented\n</Accordion>\n\n<Accordion title=\"3. Content-Search Optimization Plan (3-4 pages)\">\n  **Internal Search:**\n  - Priority page optimizations (10+ pages)\n  - Before/after examples\n  - Faceted search design\n  - Internal linking strategy\n  \n  **SEO Strategy:**\n  - Keyword targets by content area\n  - URL structure recommendations\n  - Content gap opportunities\n  - Competitive positioning\n  \n  **Excellence Criteria:**\n  - Specific, actionable recommendations\n  - Realistic scope and priorities\n  - Clear success metrics\n</Accordion>\n\n<Accordion title=\"4. Implementation Roadmap (1-2 pages)\">\n  **Required Elements:**\n  - Three phases: Quick Wins, Foundation, Strategic\n  - Specific tasks with effort estimates\n  - Resource requirements\n  - Timeline with milestones\n  - Success metrics and tracking plan\n  \n  **Excellence Criteria:**\n  - Realistic for your organization\n  - Clear ownership and dependencies\n  - Risk mitigation included\n  - Measurable outcomes defined\n</Accordion>\n\n### Site Selection Options\n\n<CardGroup cols={3}>\n  <Card title=\"Option A: Your Organization\" icon=\"building\">\n    Use your actual documentation site for immediate applicability\n  </Card>\n  <Card title=\"Option B: Open Source Project\" icon=\"code\">\n    Analyze React, Python, Kubernetes, or similar public documentation\n  </Card>\n  <Card title=\"Option C: Competitor Analysis\" icon=\"trophy\">\n    Study and improve upon a competitor's documentation site\n  </Card>\n</CardGroup>\n\n### Evaluation Rubric\n\n<Info>\n  Your project will be evaluated on these five dimensions, each worth 20% of the total score.\n</Info>\n\n<Accordion title=\"Query Analysis Quality (20%)\">\n  - Realistic, representative query set\n  - Thorough intent and pattern analysis\n  - Clear vocabulary gap identification\n  - Actionable insights derived\n</Accordion>\n\n<Accordion title=\"Strategic Thinking (20%)\">\n  - SEO and internal search integration\n  - User impact-based prioritization\n  - Alignment with user journeys\n  - Innovative approaches\n</Accordion>\n\n<Accordion title=\"AI Utilization (20%)\">\n  - Effective prompt design\n  - Appropriate automation vs. human judgment\n  - Evidence of validation and refinement\n  - Documented methodology\n</Accordion>\n\n<Accordion title=\"Practical Actionability (20%)\">\n  - Specific, implementable recommendations\n  - Realistic effort estimates\n  - Clear ownership model\n  - Measurable success criteria\n</Accordion>\n\n<Accordion title=\"Documentation Quality (20%)\">\n  - Clear, professional presentation\n  - Appropriate depth and detail\n  - Scannable formatting\n  - Reproducible methodology\n</Accordion>\n\n### Success Criteria Checklist\n\nYour project demonstrates excellence if:\n\n- \u2713 Query analysis reveals non-obvious insights about user needs\n- \u2713 Synonym sets are comprehensive yet precisely relevant  \n- \u2713 Optimization recommendations are specific and prioritized by impact\n- \u2713 SEO strategy integrates naturally with user-focused improvements\n- \u2713 Implementation plan is realistic and actionable for your context\n- \u2713 Success metrics are measurable and tied to user outcomes\n- \u2713 AI was used strategically to enhance (not replace) human judgment\n- \u2713 A stakeholder could approve and execute your plan\n\n### Common Pitfalls to Avoid\n\n<Warning>\n  **Avoid These Common Mistakes:**\n  \n  \u274c **Generic recommendations** \u2013 \"Improve page titles\" without specific examples\n  \u274c **Ignoring user vocabulary** \u2013 Optimizing for terms users don't actually search\n  \u274c **SEO without substance** \u2013 Keyword stuffing or optimizing poor content\n  \u274c **Unrealistic scope** \u2013 Trying to fix everything instead of prioritizing\n  \u274c **Missing validation** \u2013 Not checking AI-generated synonyms for accuracy\n  \u274c **No success metrics** \u2013 Can't measure if recommendations work\n  \u274c **Effort underestimation** \u2013 Implementation plan requires unavailable resources\n</Warning>\n\n### Submission Requirements\n\n<Card title=\"Complete Submission Package\" icon=\"package\">\n  **Main Document:**\n  1. All four required deliverables\n  \n  **Appendices:**\n  - Full query list with classifications\n  - Complete synonym sets  \n  - Sample prompts used (5-10 most effective)\n  \n  **Supporting Materials:**\n  - Methodology note (1 paragraph)\n  - Reflection (2-3 paragraphs):\n    - What surprised you?\n    - What would you do differently?\n    - How did AI change your approach?\n    - What validation steps were critical?\n</Card>\n\n---",
            "hydration_source_header": "Self-Assessment Project: Comprehensive Findability Improvement Plan",
            "hydration_method": "line_proximity"
          }
        ],
        "facetedSearchElements": [
          {
            "id": "primary-facets",
            "element": "Primary Facets",
            "purpose": "Always visible filters",
            "lines": "485-492",
            "retrievalQuestions": [
              "What facets should I use for documentation search?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "secondary-facets",
            "element": "Secondary Facets",
            "purpose": "Context-dependent filters",
            "lines": "492-498",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "smart-facet-behaviors",
            "element": "Smart Facet Behaviors",
            "purpose": "Auto-expand, hide, remember",
            "lines": "498-505",
            "retrievalQuestions": [
              "What are smart facet behaviors?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "content-type-facet",
            "element": "Content Type Facet",
            "purpose": "Filter by guides, reference, examples",
            "lines": "485-488",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "language-facet",
            "element": "Programming Language Facet",
            "purpose": "Filter by JS, Python, Java, etc.",
            "lines": "488-490",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "difficulty-facet",
            "element": "Difficulty Level Facet",
            "purpose": "Filter by beginner, intermediate, advanced",
            "lines": "490-492",
            "retrievalQuestions": [
              "How do I prioritize search facets?"
            ],
            "hydration_status": "skipped_unknown"
          }
        ],
        "implementationPhases": [
          {
            "id": "quick-wins-phase",
            "phase": "Week 1: Quick Wins",
            "timeline": "Week 1",
            "focus": "Synonyms, fix broken searches, update titles",
            "lines": "720-722",
            "retrievalQuestions": [
              "What are quick wins for search optimization?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "foundation-phase",
            "phase": "Week 2-3: Foundation",
            "timeline": "Weeks 2-3",
            "focus": "Faceted search, missing content, URL structure",
            "lines": "722-725",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "strategic-phase",
            "phase": "Week 4+: Strategic",
            "timeline": "Week 4+",
            "focus": "Full audit, SEO calendar, analytics dashboard",
            "lines": "725-728",
            "retrievalQuestions": [
              "What's the strategic phase of search improvement?"
            ],
            "hydration_status": "skipped_unknown"
          }
        ]
      }
    },
    "3-3-user-research": {
      "file": "3-3-user-research.mdx",
      "focus": "Conducting and analyzing user research with AI assistance including card sorts, tree tests, and usability studies",
      "entityCount": 80,
      "entities": {
        "frameworks": [
          {
            "id": "user-research-framework",
            "title": "User Research for IA Framework",
            "type": "framework",
            "definition": "Framework covering card sorting, tree testing, and integration of findings into IA design",
            "contains": [
              "card-sorting",
              "tree-testing",
              "usability-studies",
              "findings-integration"
            ],
            "lines": "1-1510",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I use user research for IA?",
              "What research methods inform IA design?"
            ],
            "content": "By the end of this module, you will be able to:\n\n- Analyze card sorting results efficiently using AI-assisted pattern detection\n- Synthesize insights from user interviews and qualitative research data\n- Extract actionable IA recommendations from survey responses\n- Identify patterns across multiple research methods\n- Validate AI analysis to ensure nuanced human insights aren't lost\n- Generate evidence-based navigation and taxonomy recommendations\n\n---",
            "hydration_source_header": "Learning Objectives",
            "hydration_method": "line_proximity"
          },
          {
            "id": "card-sort-analysis-framework",
            "title": "Card Sort Analysis Framework",
            "type": "framework",
            "definition": "Systematic approach to analyzing card sort results with AI assistance",
            "contains": [
              "matrix-analysis",
              "cluster-identification",
              "outlier-detection",
              "hierarchy-generation"
            ],
            "lines": "70-420",
            "crossModule": false,
            "retrievalQuestions": [
              "How do I analyze card sort results?"
            ],
            "content": "#### Pattern 1: Initial Grouping Analysis\n\n**Use when:** You need to understand how participants grouped cards\n\n```markdown\nAnalyze these open card sort results to identify grouping patterns:\n\nCARD SORT DATA:\n[Paste data: Participant | Card | Group | Label]\n\nTotal participants: [NUMBER]\nTotal cards: [NUMBER]\n\nPlease analyze:\n\n1. **Grouping patterns:**\n   - Which cards were frequently grouped together?\n   - Which cards had conflicting placements (grouped differently by different users)?\n   - Are there strong clustering patterns? (cards that almost everyone grouped together)\n\n2. **Label patterns:**\n   - What labels did participants use for similar groups?\n   - What terminology variations exist? (e.g., \"Login\" vs. \"Sign In\" vs. \"Authentication\")\n   - Are labels consistent with group contents?\n\n3. **Group size patterns:**\n   - Average group size per participant\n   - Range of group sizes\n   - Are some participants creating many small groups vs. few large groups?\n\n4. **Outliers:**\n   - Cards that were consistently hard to place\n   - Unusual groupings that might reveal interesting insights\n   - Participants whose sorting patterns differ significantly from others\n\nOutput:\n- Summary statistics\n- Top 10 strongest card-to-card associations (cards grouped together most often)\n- Top 5 conflicting cards (cards placed in very different groups)\n- Common labeling themes\n```\n\n**Why this works:**\n- Systematic coverage of key patterns\n- Balances quantitative (frequency) with qualitative (why it matters)\n- Surfaces both consensus and disagreement\n- Flags areas needing closer examination\n\n---\n\n#### Pattern 2: Similarity Matrix Generation\n\n**Use when:** You need to quantify how similar different groupings are\n\n```markdown\nCreate a similarity matrix for these card sort groupings:\n\nCARD SORT DATA:\n[Paste your card sort results]\n\nFor each pair of cards, calculate:\n- How many participants (out of [N]) grouped them together\n- Similarity score: (times grouped together / total participants) \u00d7 100\n\nThen:\n1. Create a similarity matrix showing card-to-card relationships\n2. Identify high-confidence pairs (>70% agreement)\n3. Identify low-confidence pairs (<30% agreement)\n4. Suggest natural clusters based on similarity scores\n\nFormat the matrix as a table for easy reading. Highlight the strongest associations.\n```\n\n**Expected output format:**\n\n```\nCARD SIMILARITY MATRIX\n(Shows % of participants who grouped each pair together)\n\n               Reset PW | Change Email | API Keys | View Logs | ...\nReset PW          --    |     87%      |   13%    |    20%    | ...\nChange Email     87%    |      --      |   10%    |    15%    | ...\nAPI Keys         13%    |     10%      |    --    |    73%    | ...\nView Logs        20%    |     15%      |   73%    |     --    | ...\n\nHIGH-CONFIDENCE GROUPINGS (>70% agreement):\n- Reset Password + Change Email (87%)\n- API Keys + View Logs (73%)\n- [etc.]\n\nCONFLICTING PLACEMENTS (<30% agreement, but non-zero):\n- Reset Password + API Keys (13%) - These were grouped together sometimes but usually separated\n- [etc.]\n```\n\n---\n\n#### Pattern 3: Category Label Synthesis\n\n**Use when:** You need to synthesize category labels from participant-created labels\n\n```markdown\nSynthesize category labels from these open card sort results:\n\nPARTICIPANT LABELS FOR SIMILAR GROUPS:\n\nGroup 1 (cards: Reset Password, Change Email, Update Profile):\n- P1: \"My Account\"\n- P2: \"Account Settings\"  \n- P3: \"Personal Info\"\n- P4: \"Your Account\"\n- P5: \"Profile Settings\"\n- P6: \"Account Management\"\n[... more participants]\n\nGroup 2 (cards: API Keys, Webhooks, Developer Documentation):\n- P1: \"For Developers\"\n- P2: \"Developer Tools\"\n- P3: \"Technical\"\n- P4: \"API Stuff\"\n- P5: \"Developer Resources\"\n- P6: \"Integration\"\n[... more participants]\n\nFor each group of similar labels:\n1. Identify the common theme or concept\n2. Count frequency of each label variation\n3. Evaluate each label option:\n   - Clarity (Is it immediately understandable?)\n   - Precision (Does it accurately reflect contents?)\n   - User language (Does it match how users speak?)\n   - Differentiation (Is it distinct from other categories?)\n4. Recommend the best label with rationale\n5. Provide 2-3 alternative label options\n6. Note any concerns or ambiguities\n\nConsider:\n- Most frequent terms (what users naturally say)\n- Most clear/descriptive terms (what communicates best)\n- Parallel structure (do labels follow consistent patterns?)\n```\n\n---\n\n#### Pattern 4: Dendrogram/Cluster Analysis\n\n**Use when:** You need hierarchical clustering to inform taxonomy structure\n\n```markdown\nPerform hierarchical cluster analysis on these card sort results:\n\nCARD SORT DATA:\n[Paste data]\n\nAnalyze grouping patterns to suggest a hierarchical structure (dendrogram):\n\n1. **Identify primary clusters:**\n   - Which cards consistently appear together?\n   - What are the major natural divisions?\n\n2. **Identify subclusters within primary clusters:**\n   - Are there logical subdivisions within major groups?\n   - Do some cards have stronger associations with each other than with other group members?\n\n3. **Suggest hierarchy levels:**\n   - Based on clustering strength, recommend taxonomy depth (2-level? 3-level?)\n   - Identify which groupings are strong enough to be top-level categories\n   - Identify which groupings work better as subcategories\n\n4. **Calculate cluster strength:**\n   - For each suggested cluster, what % of participants grouped those cards together?\n   - Which clusters have strongest agreement? Weakest?\n\nOutput as:\n- Visual hierarchy (indented lists showing cluster relationships)\n- Cluster strength scores\n- Recommendations for category structure\n- Areas of uncertainty that need further validation\n```\n\n---\n\n#### Pattern 5: Conflict Resolution\n\n**Use when:** Cards were grouped very differently by different participants\n\n```markdown\nAnalyze conflicting card placements to inform IA decisions:\n\nCONFLICTING CARD: [Card name]\n\nPlacements across participants:\n- Group A: \"[Label]\" - Participants: P1, P4, P7, P12 (4 participants, 13%)\n- Group B: \"[Label]\" - Participants: P2, P5, P8, P9, P11, P15, P18 (7 participants, 23%)\n- Group C: \"[Label]\" - Participants: P3, P6, P10, P13, P14, P16, P17, P19, P20 (9 participants, 30%)\n- Standalone group: Participants: P21, P22, P23 (3 participants, 10%)\n- Mixed with multiple groups in small variations (7 participants, 23%)\n\nContext:\n- Card description: [What the card represents]\n- Related cards: [Other cards that might inform placement]\n- User tasks: [What users would use this for]\n\nAnalyze:\n1. Why might users place this card differently?\n2. What user needs or mental models do each placement represent?\n3. Is there a \"most correct\" placement, or are multiple valid?\n4. How should we resolve this conflict in our IA?\n\nOptions to consider:\n- Choose the most common placement\n- Provide multiple access points (card accessible from multiple categories)\n- Create a new category that better represents the card's purpose\n- Split the card into multiple more specific items\n- Placement based on primary use case\n\nRecommend a decision with rationale based on:\n- Plurality (most common placement)\n- User task alignment\n- Clarity and findability\n- Consistency with other IA decisions\n```\n\n---",
            "hydration_source_header": "Card Sort Analysis Prompt Patterns",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "tree-test-analysis-framework",
            "title": "Tree Test Analysis Framework",
            "type": "framework",
            "definition": "Approach for analyzing tree test results to validate IA structure",
            "contains": [
              "success-rate-analysis",
              "path-analysis",
              "failure-pattern-detection"
            ],
            "lines": "430-750",
            "crossModule": false,
            "retrievalQuestions": [
              "How do I analyze tree test results?"
            ],
            "content": "**Before prompting, prepare your data:**\n\n**Option 1: Full transcripts**\n- Include interviewer and participant speech\n- Mark speaker labels clearly\n- Note any important context (tone, pauses, confusion)\n\n**Option 2: Highlighted excerpts**\n- Pull out relevant quotes from longer interviews\n- Include enough context to understand the quote\n- Note participant ID for tracking patterns\n\n**Option 3: Structured interview notes**\n- Organized by question or theme\n- Key quotes preserved\n- Relevant context noted\n\n---",
            "hydration_source_header": "Interview Data Preparation",
            "hydration_method": "line_proximity"
          }
        ],
        "principles": [
          {
            "id": "ai-amplifies-research",
            "title": "AI Amplifies Research, Doesn't Replace Researchers",
            "partOf": "user-research-framework",
            "lines": "40-55",
            "crossModule": true,
            "content": "**What makes research synthesis challenging:**\n\nUser research generates rich, messy, qualitative data:\n- Participants use different terminology\n- Groupings reflect individual mental models\n- Context matters (why someone made a choice)\n- Outliers may be valuable edge cases or noise\n- Patterns may be subtle or conflicting\n\nTraditional analysis requires:\n- Meticulous data organization\n- Pattern recognition across hundreds of data points\n- Balancing frequency with meaningfulness\n- Distinguishing signal from noise\n- Preserving nuance while finding consensus\n\n**How AI transforms research synthesis:**\n\nAI excels at:\n- **Processing volume:** Analyzing hundreds of card sort results simultaneously\n- **Pattern detection:** Finding grouping clusters humans might miss\n- **Terminology mapping:** Recognizing that \"login\" and \"sign in\" mean the same thing\n- **Quantitative analysis:** Calculating similarity scores and agreement matrices\n- **Initial categorization:** First-pass coding of interview transcripts\n\n**The critical balance:**\n\n**AI handles:**\n- Initial data processing and organization\n- Mathematical pattern detection (clustering, similarity)\n- Frequency analysis and counting\n- First-pass coding and categorization\n- Generating hypotheses about patterns\n\n**Humans handle:**\n- Understanding context and intent behind choices\n- Evaluating whether a pattern is meaningful or spurious\n- Preserving important outlier insights\n- Making strategic decisions about conflicting patterns\n- Validating against domain knowledge and user needs\n\n**The danger:** Blind trust in AI analysis can obscure important nuances, outlier insights, or contextual subtleties that change interpretation.\n\n**The solution:** Systematic validation and strategic human oversight at key decision points.\n\n---",
            "hydration_source_header": "The Human-AI Partnership in Research Synthesis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "validate-with-tree-tests",
            "title": "Always Validate Card Sorts with Tree Tests",
            "partOf": "tree-test-analysis-framework",
            "lines": "1330-1335",
            "crossModule": false,
            "retrievalQuestions": [
              "Why validate card sorts with tree tests?"
            ],
            "content": "**Step 5: Run grouping analysis**\n\n```markdown\nAnalyze these open card sort results to identify natural groupings:\n\nCONTEXT:\n[Paste your context document from Step 4]\n\nCARD SORT DATA:\n[Paste your complete dataset]\n\nAnalyze:\n1. Cards consistently grouped together (>70% of participants)\n2. Cards with conflicting placements (wide variation)\n3. Average group count and size patterns\n4. Natural clustering patterns\n\nFor each pattern, provide:\n- Description\n- Frequency/percentage\n- Specific cards involved\n- Confidence level (high/medium/low)\n\nFlag any unusual patterns or outliers for human review.\n```\n\n**Save the output** as \"01-grouping-analysis.md\"\n\n**Step 6: Generate similarity matrix**\n\n```markdown\nCreate a card-to-card similarity matrix for these card sort results:\n\n[Paste your dataset]\n\nFor each pair of cards, calculate:\n- How many participants grouped them together\n- Percentage: (times together / total participants) \u00d7 100\n\nOutput as:\n1. Full similarity matrix (table format)\n2. High-confidence pairs (>70% agreement)\n3. Moderate pairs (40-69% agreement)\n4. Conflicting pairs (grouped together sometimes but usually not, 10-39%)\n\nIdentify natural cluster formations from similarity scores.\n```\n\n**Save the output** as \"02-similarity-matrix.md\"\n\n**Review** the matrix. Do the high-confidence pairs make sense? Any surprises?\n\n**Step 7: Synthesize category labels**\n\nFirst, group cards by natural clustering patterns identified in Steps 5-6.\n\n```markdown\nSynthesize category labels for these natural card groupings:\n\nCLUSTER 1: [List cards that were frequently grouped together]\nParticipant labels used:\n[Paste all labels participants created for similar groups]\n\nCLUSTER 2: [List cards for next cluster]\nParticipant labels used:\n[Paste labels]\n\n[Repeat for all major clusters]\n\nFor each cluster:\n1. Identify the most common label theme\n2. Count frequency of each label variation\n3. Evaluate label options:\n   - Clarity: Immediately understandable?\n   - Precision: Accurately reflects contents?\n   - User vocabulary: Matches how users speak?\n   - SEO: Matches search terms?\n   - Differentiation: Distinct from other categories?\n4. Recommend best label with rationale\n5. Provide 2 alternative options\n6. Note any concerns\n\nConsider:\n- Parallel structure across labels\n- Accessibility (screen reader friendly)\n- Character length for UI\n```\n\n**Save the output** as \"03-label-synthesis.md\"\n\n**Step 8: Generate hierarchical structure**\n\n```markdown\nBased on clustering patterns and label analysis, recommend a hierarchical navigation structure:\n\nCLUSTERING DATA:\n[Reference or paste findings from Steps 5-6]\n\nRECOMMENDED LABELS:\n[Reference or paste from Step 7]\n\nCONSTRAINTS:\n- Target: 5-8 top-level categories (Miller's Law)\n- Maximum depth: 2-3 levels\n- Balance: Try to keep categories relatively even in size\n- User mental model: Task-based or topic-based organization?\n\nRecommend:\n1. Number of top-level categories (with rationale)\n2. Complete hierarchy (category names and subcategories)\n3. Card assignments to each category\n4. Estimated page counts per category\n5. Confidence level for each grouping\n6. Alternatives considered and why rejected\n\nFormat as an indented list showing full hierarchy.\n```\n\n**Save the output** as \"04-hierarchy-recommendation.md\"\n\n---",
            "hydration_source_header": "Phase 2: Initial AI Analysis (30 minutes)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "context-over-data",
            "title": "Context Matters More Than Raw Data",
            "partOf": "user-research-framework",
            "lines": "1335-1340",
            "crossModule": false,
            "content": "**Step 5: Run grouping analysis**\n\n```markdown\nAnalyze these open card sort results to identify natural groupings:\n\nCONTEXT:\n[Paste your context document from Step 4]\n\nCARD SORT DATA:\n[Paste your complete dataset]\n\nAnalyze:\n1. Cards consistently grouped together (>70% of participants)\n2. Cards with conflicting placements (wide variation)\n3. Average group count and size patterns\n4. Natural clustering patterns\n\nFor each pattern, provide:\n- Description\n- Frequency/percentage\n- Specific cards involved\n- Confidence level (high/medium/low)\n\nFlag any unusual patterns or outliers for human review.\n```\n\n**Save the output** as \"01-grouping-analysis.md\"\n\n**Step 6: Generate similarity matrix**\n\n```markdown\nCreate a card-to-card similarity matrix for these card sort results:\n\n[Paste your dataset]\n\nFor each pair of cards, calculate:\n- How many participants grouped them together\n- Percentage: (times together / total participants) \u00d7 100\n\nOutput as:\n1. Full similarity matrix (table format)\n2. High-confidence pairs (>70% agreement)\n3. Moderate pairs (40-69% agreement)\n4. Conflicting pairs (grouped together sometimes but usually not, 10-39%)\n\nIdentify natural cluster formations from similarity scores.\n```\n\n**Save the output** as \"02-similarity-matrix.md\"\n\n**Review** the matrix. Do the high-confidence pairs make sense? Any surprises?\n\n**Step 7: Synthesize category labels**\n\nFirst, group cards by natural clustering patterns identified in Steps 5-6.\n\n```markdown\nSynthesize category labels for these natural card groupings:\n\nCLUSTER 1: [List cards that were frequently grouped together]\nParticipant labels used:\n[Paste all labels participants created for similar groups]\n\nCLUSTER 2: [List cards for next cluster]\nParticipant labels used:\n[Paste labels]\n\n[Repeat for all major clusters]\n\nFor each cluster:\n1. Identify the most common label theme\n2. Count frequency of each label variation\n3. Evaluate label options:\n   - Clarity: Immediately understandable?\n   - Precision: Accurately reflects contents?\n   - User vocabulary: Matches how users speak?\n   - SEO: Matches search terms?\n   - Differentiation: Distinct from other categories?\n4. Recommend best label with rationale\n5. Provide 2 alternative options\n6. Note any concerns\n\nConsider:\n- Parallel structure across labels\n- Accessibility (screen reader friendly)\n- Character length for UI\n```\n\n**Save the output** as \"03-label-synthesis.md\"\n\n**Step 8: Generate hierarchical structure**\n\n```markdown\nBased on clustering patterns and label analysis, recommend a hierarchical navigation structure:\n\nCLUSTERING DATA:\n[Reference or paste findings from Steps 5-6]\n\nRECOMMENDED LABELS:\n[Reference or paste from Step 7]\n\nCONSTRAINTS:\n- Target: 5-8 top-level categories (Miller's Law)\n- Maximum depth: 2-3 levels\n- Balance: Try to keep categories relatively even in size\n- User mental model: Task-based or topic-based organization?\n\nRecommend:\n1. Number of top-level categories (with rationale)\n2. Complete hierarchy (category names and subcategories)\n3. Card assignments to each category\n4. Estimated page counts per category\n5. Confidence level for each grouping\n6. Alternatives considered and why rejected\n\nFormat as an indented list showing full hierarchy.\n```\n\n**Save the output** as \"04-hierarchy-recommendation.md\"\n\n---",
            "hydration_source_header": "Phase 2: Initial AI Analysis (30 minutes)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "iterative-refinement",
            "title": "IA Design is Iterative",
            "partOf": "user-research-framework",
            "lines": "1340-1345",
            "crossModule": true,
            "hydration_status": "failed"
          },
          {
            "id": "quantitative-qualitative",
            "title": "Combine Quantitative and Qualitative Insights",
            "partOf": "user-research-framework",
            "lines": "1345-1350",
            "crossModule": false,
            "retrievalQuestions": [
              "Should I use quantitative or qualitative research?"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "expert-vs-novice-split",
            "title": "Segment Expert vs. Novice Users",
            "partOf": "card-sort-analysis-framework",
            "lines": "230-250",
            "crossModule": false,
            "retrievalQuestions": [
              "How do I handle expert vs novice differences in card sorts?"
            ],
            "content": "**Use when:** You need to synthesize category labels from participant-created labels\n\n```markdown\nSynthesize category labels from these open card sort results:\n\nPARTICIPANT LABELS FOR SIMILAR GROUPS:\n\nGroup 1 (cards: Reset Password, Change Email, Update Profile):\n- P1: \"My Account\"\n- P2: \"Account Settings\"  \n- P3: \"Personal Info\"\n- P4: \"Your Account\"\n- P5: \"Profile Settings\"\n- P6: \"Account Management\"\n[... more participants]\n\nGroup 2 (cards: API Keys, Webhooks, Developer Documentation):\n- P1: \"For Developers\"\n- P2: \"Developer Tools\"\n- P3: \"Technical\"\n- P4: \"API Stuff\"\n- P5: \"Developer Resources\"\n- P6: \"Integration\"\n[... more participants]\n\nFor each group of similar labels:\n1. Identify the common theme or concept\n2. Count frequency of each label variation\n3. Evaluate each label option:\n   - Clarity (Is it immediately understandable?)\n   - Precision (Does it accurately reflect contents?)\n   - User language (Does it match how users speak?)\n   - Differentiation (Is it distinct from other categories?)\n4. Recommend the best label with rationale\n5. Provide 2-3 alternative label options\n6. Note any concerns or ambiguities\n\nConsider:\n- Most frequent terms (what users naturally say)\n- Most clear/descriptive terms (what communicates best)\n- Parallel structure (do labels follow consistent patterns?)\n```\n\n---",
            "hydration_source_header": "Pattern 3: Category Label Synthesis",
            "hydration_method": "line_proximity"
          }
        ],
        "patterns": [
          {
            "id": "card-sort-matrix-analysis",
            "title": "Card Sort Similarity Matrix Analysis",
            "purpose": "Find natural groupings in card sort data",
            "lines": "110-180",
            "content": "**Use when:** You need to quantify how similar different groupings are\n\n```markdown\nCreate a similarity matrix for these card sort groupings:\n\nCARD SORT DATA:\n[Paste your card sort results]\n\nFor each pair of cards, calculate:\n- How many participants (out of [N]) grouped them together\n- Similarity score: (times grouped together / total participants) \u00d7 100\n\nThen:\n1. Create a similarity matrix showing card-to-card relationships\n2. Identify high-confidence pairs (>70% agreement)\n3. Identify low-confidence pairs (<30% agreement)\n4. Suggest natural clusters based on similarity scores\n\nFormat the matrix as a table for easy reading. Highlight the strongest associations.\n```\n\n**Expected output format:**\n\n```\nCARD SIMILARITY MATRIX\n(Shows % of participants who grouped each pair together)\n\n               Reset PW | Change Email | API Keys | View Logs | ...\nReset PW          --    |     87%      |   13%    |    20%    | ...\nChange Email     87%    |      --      |   10%    |    15%    | ...\nAPI Keys         13%    |     10%      |    --    |    73%    | ...\nView Logs        20%    |     15%      |   73%    |     --    | ...\n\nHIGH-CONFIDENCE GROUPINGS (>70% agreement):\n- Reset Password + Change Email (87%)\n- API Keys + View Logs (73%)\n- [etc.]\n\nCONFLICTING PLACEMENTS (<30% agreement, but non-zero):\n- Reset Password + API Keys (13%) - These were grouped together sometimes but usually separated\n- [etc.]\n```\n\n---",
            "hydration_source_header": "Pattern 2: Similarity Matrix Generation",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "cluster-identification-pattern",
            "title": "AI-Assisted Cluster Identification",
            "purpose": "Detect category patterns",
            "lines": "185-250",
            "content": "**Use when:** You need to quantify how similar different groupings are\n\n```markdown\nCreate a similarity matrix for these card sort groupings:\n\nCARD SORT DATA:\n[Paste your card sort results]\n\nFor each pair of cards, calculate:\n- How many participants (out of [N]) grouped them together\n- Similarity score: (times grouped together / total participants) \u00d7 100\n\nThen:\n1. Create a similarity matrix showing card-to-card relationships\n2. Identify high-confidence pairs (>70% agreement)\n3. Identify low-confidence pairs (<30% agreement)\n4. Suggest natural clusters based on similarity scores\n\nFormat the matrix as a table for easy reading. Highlight the strongest associations.\n```\n\n**Expected output format:**\n\n```\nCARD SIMILARITY MATRIX\n(Shows % of participants who grouped each pair together)\n\n               Reset PW | Change Email | API Keys | View Logs | ...\nReset PW          --    |     87%      |   13%    |    20%    | ...\nChange Email     87%    |      --      |   10%    |    15%    | ...\nAPI Keys         13%    |     10%      |    --    |    73%    | ...\nView Logs        20%    |     15%      |   73%    |     --    | ...\n\nHIGH-CONFIDENCE GROUPINGS (>70% agreement):\n- Reset Password + Change Email (87%)\n- API Keys + View Logs (73%)\n- [etc.]\n\nCONFLICTING PLACEMENTS (<30% agreement, but non-zero):\n- Reset Password + API Keys (13%) - These were grouped together sometimes but usually separated\n- [etc.]\n```\n\n---",
            "hydration_source_header": "Pattern 2: Similarity Matrix Generation",
            "hydration_method": "line_proximity"
          },
          {
            "id": "outlier-detection-pattern",
            "title": "Card Sort Outlier Detection",
            "purpose": "Find items users struggled to place",
            "lines": "255-320",
            "retrievalQuestions": [
              "How do I find problematic items in card sorts?"
            ],
            "content": "**Use when:** You need hierarchical clustering to inform taxonomy structure\n\n```markdown\nPerform hierarchical cluster analysis on these card sort results:\n\nCARD SORT DATA:\n[Paste data]\n\nAnalyze grouping patterns to suggest a hierarchical structure (dendrogram):\n\n1. **Identify primary clusters:**\n   - Which cards consistently appear together?\n   - What are the major natural divisions?\n\n2. **Identify subclusters within primary clusters:**\n   - Are there logical subdivisions within major groups?\n   - Do some cards have stronger associations with each other than with other group members?\n\n3. **Suggest hierarchy levels:**\n   - Based on clustering strength, recommend taxonomy depth (2-level? 3-level?)\n   - Identify which groupings are strong enough to be top-level categories\n   - Identify which groupings work better as subcategories\n\n4. **Calculate cluster strength:**\n   - For each suggested cluster, what % of participants grouped those cards together?\n   - Which clusters have strongest agreement? Weakest?\n\nOutput as:\n- Visual hierarchy (indented lists showing cluster relationships)\n- Cluster strength scores\n- Recommendations for category structure\n- Areas of uncertainty that need further validation\n```\n\n---",
            "hydration_source_header": "Pattern 4: Dendrogram/Cluster Analysis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "hierarchy-generation-pattern",
            "title": "AI-Generated Hierarchy from Card Sort",
            "purpose": "Create draft IA from sort data",
            "lines": "325-400",
            "content": "**Use when:** Cards were grouped very differently by different participants\n\n```markdown\nAnalyze conflicting card placements to inform IA decisions:\n\nCONFLICTING CARD: [Card name]\n\nPlacements across participants:\n- Group A: \"[Label]\" - Participants: P1, P4, P7, P12 (4 participants, 13%)\n- Group B: \"[Label]\" - Participants: P2, P5, P8, P9, P11, P15, P18 (7 participants, 23%)\n- Group C: \"[Label]\" - Participants: P3, P6, P10, P13, P14, P16, P17, P19, P20 (9 participants, 30%)\n- Standalone group: Participants: P21, P22, P23 (3 participants, 10%)\n- Mixed with multiple groups in small variations (7 participants, 23%)\n\nContext:\n- Card description: [What the card represents]\n- Related cards: [Other cards that might inform placement]\n- User tasks: [What users would use this for]\n\nAnalyze:\n1. Why might users place this card differently?\n2. What user needs or mental models do each placement represent?\n3. Is there a \"most correct\" placement, or are multiple valid?\n4. How should we resolve this conflict in our IA?\n\nOptions to consider:\n- Choose the most common placement\n- Provide multiple access points (card accessible from multiple categories)\n- Create a new category that better represents the card's purpose\n- Split the card into multiple more specific items\n- Placement based on primary use case\n\nRecommend a decision with rationale based on:\n- Plurality (most common placement)\n- User task alignment\n- Clarity and findability\n- Consistency with other IA decisions\n```\n\n---",
            "hydration_source_header": "Pattern 5: Conflict Resolution",
            "hydration_method": "line_proximity"
          },
          {
            "id": "tree-test-success-analysis",
            "title": "Tree Test Success Rate Analysis",
            "purpose": "Calculate and interpret success rates",
            "lines": "450-510",
            "content": "**Use when:** You need to identify recurring themes across multiple interviews\n\n```markdown\nConduct thematic analysis on these user interview transcripts:\n\nRESEARCH CONTEXT:\n- Topic: [What you were investigating]\n- Participants: [Number and type]\n- Goal: [What insights you're seeking]\n\nINTERVIEW TRANSCRIPTS:\n[Paste transcripts or key excerpts from 5-10 interviews]\n\nAnalyze for:\n\n1. **Recurring themes:**\n   - What topics, needs, or pain points appear across multiple interviews?\n   - How frequently does each theme appear?\n   - What language do users use to describe each theme?\n\n2. **Mental model patterns:**\n   - How do users conceptualize the information space?\n   - What terminology do they naturally use?\n   - How do they expect information to be organized?\n   - What connections or relationships do they mention?\n\n3. **Findability insights:**\n   - What do users say about finding information?\n   - What strategies do they mention using?\n   - Where do they get stuck or frustrated?\n   - What would make information easier to find?\n\n4. **Terminology insights:**\n   - What terms do users use consistently?\n   - What terms confuse users?\n   - Vocabulary mismatches (their terms vs. official terms)\n\nFor each theme, provide:\n- Theme name and description\n- Frequency (how many participants mentioned it)\n- Representative quotes (with participant IDs)\n- IA implications (how this should inform structure)\n\nOrganize from most to least frequently mentioned themes.\n```\n\n---",
            "hydration_source_header": "Pattern 1: Thematic Analysis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "path-analysis-pattern",
            "title": "Navigation Path Analysis",
            "purpose": "Understand user navigation patterns",
            "lines": "515-580",
            "retrievalQuestions": [
              "How do I analyze navigation paths?"
            ],
            "content": "```markdown\nAnalyze navigation behavior from survey responses:\n\nSURVEY QUESTION:\n\"When you visit our documentation, what do you do FIRST to find information?\"\n\nRESULTS (n=400):\n- Use the search box: 62% (248 responses)\n- Browse the main navigation menu: 18% (72 responses)\n- Click on \"Getting Started\": 8% (32 responses)\n- Use the table of contents/sidebar: 7% (28 responses)\n- Use Google to search: 3% (12 responses)\n- Contact support: 2% (8 responses)\n\nFOLLOW-UP QUESTION:\n\"If your first strategy doesn't work, what do you try next?\"\n\nRESULTS (n=400):\n- Try different search terms: 45% (180 responses)\n- Browse navigation menu: 28% (112 responses)\n- Google search: 15% (60 responses)\n- Contact support: 8% (32 responses)\n- Give up: 4% (16 responses)\n\nAnalyze:\n\n1. **Primary behavior patterns:**\n   - What does the dominant first-choice (search) tell us?\n   - What % rely on browse vs. search?\n\n2. **Implications:**\n   - How should we prioritize search optimization vs. navigation design?\n   - Are users searching because navigation is unclear?\n   - Or searching because it's genuinely faster?\n\n3. **Failure recovery:**\n   - What do users do when first strategy fails?\n   - High search reformulation rate suggests what?\n   - 4% giving up\u2014how critical is this?\n\n4. **Recommendations:**\n   - Investment priorities (search vs. navigation vs. content)\n   - Quick wins to reduce failed first attempts\n   - Long-term improvements\n\n5. **Research gaps:**\n   - What additional research would clarify user needs?\n   - Questions to investigate further\n```\n\n---",
            "hydration_source_header": "Pattern 3: Navigation Behavior Analysis",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "failure-pattern-detection",
            "title": "Tree Test Failure Pattern Detection",
            "purpose": "Identify systematic IA problems",
            "lines": "585-660",
            "content": "**Use when:** You need to understand how users conceptualize the information space\n\n```markdown\nMap user mental models from these interview transcripts:\n\nINTERVIEW EXCERPTS:\n[Paste relevant sections where users discuss how they think about or organize information]\n\nAnalyze:\n\n1. **Conceptual groupings:**\n   - How do users naturally categorize information?\n   - What relationships do they describe between topics?\n   - How do they expect to navigate between related items?\n\n2. **Task-based vs. topic-based thinking:**\n   - Do users think in terms of tasks (\"I want to do X\") or topics (\"I need info about Y\")?\n   - What language reveals their approach?\n\n3. **Hierarchy and relationships:**\n   - Do users describe hierarchical relationships (parent-child)?\n   - Do users describe associative relationships (these things are related)?\n   - What connections do users expect to find?\n\n4. **Entry points:**\n   - How do users describe starting their information search?\n   - What do they look for first?\n   - What pathways do they expect to follow?\n\n5. **Terminology mapping:**\n   - User term \u2192 Our term (if different)\n   - What conceptual labels do users use?\n\nOutput:\n- Narrative description of the dominant mental model(s)\n- Visual/structural representation (if patterns are clear)\n- Quotes supporting each aspect of the model\n- IA recommendations aligned with the mental model\n- Areas where mental models conflict (how to resolve)\n```\n\n---",
            "hydration_source_header": "Pattern 4: Mental Model Mapping",
            "hydration_method": "line_proximity"
          },
          {
            "id": "findings-synthesis-pattern",
            "title": "Research Findings Synthesis",
            "purpose": "Combine multiple research inputs",
            "lines": "760-850",
            "content": "```markdown\nAnalyze navigation behavior from survey responses:\n\nSURVEY QUESTION:\n\"When you visit our documentation, what do you do FIRST to find information?\"\n\nRESULTS (n=400):\n- Use the search box: 62% (248 responses)\n- Browse the main navigation menu: 18% (72 responses)\n- Click on \"Getting Started\": 8% (32 responses)\n- Use the table of contents/sidebar: 7% (28 responses)\n- Use Google to search: 3% (12 responses)\n- Contact support: 2% (8 responses)\n\nFOLLOW-UP QUESTION:\n\"If your first strategy doesn't work, what do you try next?\"\n\nRESULTS (n=400):\n- Try different search terms: 45% (180 responses)\n- Browse navigation menu: 28% (112 responses)\n- Google search: 15% (60 responses)\n- Contact support: 8% (32 responses)\n- Give up: 4% (16 responses)\n\nAnalyze:\n\n1. **Primary behavior patterns:**\n   - What does the dominant first-choice (search) tell us?\n   - What % rely on browse vs. search?\n\n2. **Implications:**\n   - How should we prioritize search optimization vs. navigation design?\n   - Are users searching because navigation is unclear?\n   - Or searching because it's genuinely faster?\n\n3. **Failure recovery:**\n   - What do users do when first strategy fails?\n   - High search reformulation rate suggests what?\n   - 4% giving up\u2014how critical is this?\n\n4. **Recommendations:**\n   - Investment priorities (search vs. navigation vs. content)\n   - Quick wins to reduce failed first attempts\n   - Long-term improvements\n\n5. **Research gaps:**\n   - What additional research would clarify user needs?\n   - Questions to investigate further\n```\n\n---",
            "hydration_source_header": "Pattern 3: Navigation Behavior Analysis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "ia-recommendations-pattern",
            "title": "IA Recommendations from Research",
            "purpose": "Convert findings to design changes",
            "lines": "855-950",
            "content": "| Category | Recommended Label | Alternatives Considered | Rationale |\n|----------|-------------------|------------------------|-----------|\n| [Name]   | [Label]          | [Alt1, Alt2]          | [Why]     |",
            "hydration_source_header": "Label Recommendations",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "promptPatterns": [
          {
            "id": "card-sort-matrix-prompt",
            "title": "Card Sort Matrix Analysis Prompt",
            "taskType": "analysis",
            "lines": "115-150",
            "standalone": true,
            "retrievalQuestions": [
              "Give me a prompt for card sort analysis"
            ],
            "content": "#### Pattern 1: Initial Grouping Analysis\n\n**Use when:** You need to understand how participants grouped cards\n\n```markdown\nAnalyze these open card sort results to identify grouping patterns:\n\nCARD SORT DATA:\n[Paste data: Participant | Card | Group | Label]\n\nTotal participants: [NUMBER]\nTotal cards: [NUMBER]\n\nPlease analyze:\n\n1. **Grouping patterns:**\n   - Which cards were frequently grouped together?\n   - Which cards had conflicting placements (grouped differently by different users)?\n   - Are there strong clustering patterns? (cards that almost everyone grouped together)\n\n2. **Label patterns:**\n   - What labels did participants use for similar groups?\n   - What terminology variations exist? (e.g., \"Login\" vs. \"Sign In\" vs. \"Authentication\")\n   - Are labels consistent with group contents?\n\n3. **Group size patterns:**\n   - Average group size per participant\n   - Range of group sizes\n   - Are some participants creating many small groups vs. few large groups?\n\n4. **Outliers:**\n   - Cards that were consistently hard to place\n   - Unusual groupings that might reveal interesting insights\n   - Participants whose sorting patterns differ significantly from others\n\nOutput:\n- Summary statistics\n- Top 10 strongest card-to-card associations (cards grouped together most often)\n- Top 5 conflicting cards (cards placed in very different groups)\n- Common labeling themes\n```\n\n**Why this works:**\n- Systematic coverage of key patterns\n- Balances quantitative (frequency) with qualitative (why it matters)\n- Surfaces both consensus and disagreement\n- Flags areas needing closer examination\n\n---\n\n#### Pattern 2: Similarity Matrix Generation\n\n**Use when:** You need to quantify how similar different groupings are\n\n```markdown\nCreate a similarity matrix for these card sort groupings:\n\nCARD SORT DATA:\n[Paste your card sort results]\n\nFor each pair of cards, calculate:\n- How many participants (out of [N]) grouped them together\n- Similarity score: (times grouped together / total participants) \u00d7 100\n\nThen:\n1. Create a similarity matrix showing card-to-card relationships\n2. Identify high-confidence pairs (>70% agreement)\n3. Identify low-confidence pairs (<30% agreement)\n4. Suggest natural clusters based on similarity scores\n\nFormat the matrix as a table for easy reading. Highlight the strongest associations.\n```\n\n**Expected output format:**\n\n```\nCARD SIMILARITY MATRIX\n(Shows % of participants who grouped each pair together)\n\n               Reset PW | Change Email | API Keys | View Logs | ...\nReset PW          --    |     87%      |   13%    |    20%    | ...\nChange Email     87%    |      --      |   10%    |    15%    | ...\nAPI Keys         13%    |     10%      |    --    |    73%    | ...\nView Logs        20%    |     15%      |   73%    |     --    | ...\n\nHIGH-CONFIDENCE GROUPINGS (>70% agreement):\n- Reset Password + Change Email (87%)\n- API Keys + View Logs (73%)\n- [etc.]\n\nCONFLICTING PLACEMENTS (<30% agreement, but non-zero):\n- Reset Password + API Keys (13%) - These were grouped together sometimes but usually separated\n- [etc.]\n```\n\n---\n\n#### Pattern 3: Category Label Synthesis\n\n**Use when:** You need to synthesize category labels from participant-created labels\n\n```markdown\nSynthesize category labels from these open card sort results:\n\nPARTICIPANT LABELS FOR SIMILAR GROUPS:\n\nGroup 1 (cards: Reset Password, Change Email, Update Profile):\n- P1: \"My Account\"\n- P2: \"Account Settings\"  \n- P3: \"Personal Info\"\n- P4: \"Your Account\"\n- P5: \"Profile Settings\"\n- P6: \"Account Management\"\n[... more participants]\n\nGroup 2 (cards: API Keys, Webhooks, Developer Documentation):\n- P1: \"For Developers\"\n- P2: \"Developer Tools\"\n- P3: \"Technical\"\n- P4: \"API Stuff\"\n- P5: \"Developer Resources\"\n- P6: \"Integration\"\n[... more participants]\n\nFor each group of similar labels:\n1. Identify the common theme or concept\n2. Count frequency of each label variation\n3. Evaluate each label option:\n   - Clarity (Is it immediately understandable?)\n   - Precision (Does it accurately reflect contents?)\n   - User language (Does it match how users speak?)\n   - Differentiation (Is it distinct from other categories?)\n4. Recommend the best label with rationale\n5. Provide 2-3 alternative label options\n6. Note any concerns or ambiguities\n\nConsider:\n- Most frequent terms (what users naturally say)\n- Most clear/descriptive terms (what communicates best)\n- Parallel structure (do labels follow consistent patterns?)\n```\n\n---\n\n#### Pattern 4: Dendrogram/Cluster Analysis\n\n**Use when:** You need hierarchical clustering to inform taxonomy structure\n\n```markdown\nPerform hierarchical cluster analysis on these card sort results:\n\nCARD SORT DATA:\n[Paste data]\n\nAnalyze grouping patterns to suggest a hierarchical structure (dendrogram):\n\n1. **Identify primary clusters:**\n   - Which cards consistently appear together?\n   - What are the major natural divisions?\n\n2. **Identify subclusters within primary clusters:**\n   - Are there logical subdivisions within major groups?\n   - Do some cards have stronger associations with each other than with other group members?\n\n3. **Suggest hierarchy levels:**\n   - Based on clustering strength, recommend taxonomy depth (2-level? 3-level?)\n   - Identify which groupings are strong enough to be top-level categories\n   - Identify which groupings work better as subcategories\n\n4. **Calculate cluster strength:**\n   - For each suggested cluster, what % of participants grouped those cards together?\n   - Which clusters have strongest agreement? Weakest?\n\nOutput as:\n- Visual hierarchy (indented lists showing cluster relationships)\n- Cluster strength scores\n- Recommendations for category structure\n- Areas of uncertainty that need further validation\n```\n\n---\n\n#### Pattern 5: Conflict Resolution\n\n**Use when:** Cards were grouped very differently by different participants\n\n```markdown\nAnalyze conflicting card placements to inform IA decisions:\n\nCONFLICTING CARD: [Card name]\n\nPlacements across participants:\n- Group A: \"[Label]\" - Participants: P1, P4, P7, P12 (4 participants, 13%)\n- Group B: \"[Label]\" - Participants: P2, P5, P8, P9, P11, P15, P18 (7 participants, 23%)\n- Group C: \"[Label]\" - Participants: P3, P6, P10, P13, P14, P16, P17, P19, P20 (9 participants, 30%)\n- Standalone group: Participants: P21, P22, P23 (3 participants, 10%)\n- Mixed with multiple groups in small variations (7 participants, 23%)\n\nContext:\n- Card description: [What the card represents]\n- Related cards: [Other cards that might inform placement]\n- User tasks: [What users would use this for]\n\nAnalyze:\n1. Why might users place this card differently?\n2. What user needs or mental models do each placement represent?\n3. Is there a \"most correct\" placement, or are multiple valid?\n4. How should we resolve this conflict in our IA?\n\nOptions to consider:\n- Choose the most common placement\n- Provide multiple access points (card accessible from multiple categories)\n- Create a new category that better represents the card's purpose\n- Split the card into multiple more specific items\n- Placement based on primary use case\n\nRecommend a decision with rationale based on:\n- Plurality (most common placement)\n- User task alignment\n- Clarity and findability\n- Consistency with other IA decisions\n```\n\n---",
            "hydration_source_header": "Card Sort Analysis Prompt Patterns",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "cluster-interpretation-prompt",
            "title": "Cluster Interpretation Prompt",
            "taskType": "analysis",
            "lines": "195-230",
            "standalone": true,
            "content": "**Use when:** You need to quantify how similar different groupings are\n\n```markdown\nCreate a similarity matrix for these card sort groupings:\n\nCARD SORT DATA:\n[Paste your card sort results]\n\nFor each pair of cards, calculate:\n- How many participants (out of [N]) grouped them together\n- Similarity score: (times grouped together / total participants) \u00d7 100\n\nThen:\n1. Create a similarity matrix showing card-to-card relationships\n2. Identify high-confidence pairs (>70% agreement)\n3. Identify low-confidence pairs (<30% agreement)\n4. Suggest natural clusters based on similarity scores\n\nFormat the matrix as a table for easy reading. Highlight the strongest associations.\n```\n\n**Expected output format:**\n\n```\nCARD SIMILARITY MATRIX\n(Shows % of participants who grouped each pair together)\n\n               Reset PW | Change Email | API Keys | View Logs | ...\nReset PW          --    |     87%      |   13%    |    20%    | ...\nChange Email     87%    |      --      |   10%    |    15%    | ...\nAPI Keys         13%    |     10%      |    --    |    73%    | ...\nView Logs        20%    |     15%      |   73%    |     --    | ...\n\nHIGH-CONFIDENCE GROUPINGS (>70% agreement):\n- Reset Password + Change Email (87%)\n- API Keys + View Logs (73%)\n- [etc.]\n\nCONFLICTING PLACEMENTS (<30% agreement, but non-zero):\n- Reset Password + API Keys (13%) - These were grouped together sometimes but usually separated\n- [etc.]\n```\n\n---",
            "hydration_source_header": "Pattern 2: Similarity Matrix Generation",
            "hydration_method": "line_proximity"
          },
          {
            "id": "expert-novice-split-prompt",
            "title": "Expert vs. Novice Analysis Prompt",
            "taskType": "analysis",
            "lines": "235-265",
            "standalone": true,
            "retrievalQuestions": [
              "Prompt for expert vs novice card sort analysis"
            ],
            "content": "**Use when:** You need to synthesize category labels from participant-created labels\n\n```markdown\nSynthesize category labels from these open card sort results:\n\nPARTICIPANT LABELS FOR SIMILAR GROUPS:\n\nGroup 1 (cards: Reset Password, Change Email, Update Profile):\n- P1: \"My Account\"\n- P2: \"Account Settings\"  \n- P3: \"Personal Info\"\n- P4: \"Your Account\"\n- P5: \"Profile Settings\"\n- P6: \"Account Management\"\n[... more participants]\n\nGroup 2 (cards: API Keys, Webhooks, Developer Documentation):\n- P1: \"For Developers\"\n- P2: \"Developer Tools\"\n- P3: \"Technical\"\n- P4: \"API Stuff\"\n- P5: \"Developer Resources\"\n- P6: \"Integration\"\n[... more participants]\n\nFor each group of similar labels:\n1. Identify the common theme or concept\n2. Count frequency of each label variation\n3. Evaluate each label option:\n   - Clarity (Is it immediately understandable?)\n   - Precision (Does it accurately reflect contents?)\n   - User language (Does it match how users speak?)\n   - Differentiation (Is it distinct from other categories?)\n4. Recommend the best label with rationale\n5. Provide 2-3 alternative label options\n6. Note any concerns or ambiguities\n\nConsider:\n- Most frequent terms (what users naturally say)\n- Most clear/descriptive terms (what communicates best)\n- Parallel structure (do labels follow consistent patterns?)\n```\n\n---",
            "hydration_source_header": "Pattern 3: Category Label Synthesis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "outlier-analysis-prompt",
            "title": "Outlier Item Analysis Prompt",
            "taskType": "analysis",
            "lines": "265-300",
            "standalone": true,
            "content": "#### Pattern 1: Terminology Preference Analysis\n\n```markdown\nAnalyze survey results on terminology preferences:\n\nSURVEY QUESTION:\n\"What would you call the section containing step-by-step instructions for common tasks?\"\n\nRESULTS (n=250 respondents):\n- \"How-To Guides\" - 38% (95 responses)\n- \"Tutorials\" - 28% (70 responses)\n- \"Instructions\" - 18% (45 responses)\n- \"Step-by-Step Guides\" - 12% (30 responses)\n- \"Walkthroughs\" - 4% (10 responses)\n\nAdditional context:\n- Target audience: Developers and technical users\n- Current site label: \"Procedural Documentation\"\n- Competitive analysis: Most competitors use \"Guides\" or \"How-To\"\n\nAnalyze:\n\n1. **Clear winner or split preference?**\n   - Is there a dominant preference (>50%)?\n   - Are top choices close enough that decision is difficult?\n\n2. **Why might users prefer each option?**\n   - What does each term signal to users?\n   - Pros/cons of each option\n\n3. **Recommendation:**\n   - Best label choice with rationale\n   - Should we use multiple labels (e.g., \"How-To Guides & Tutorials\")?\n   - Alternative approaches if preference is split\n\n4. **Implementation notes:**\n   - Should old terms be redirected?\n   - Should we use synonyms in search?\n   - Implications for content creation guidelines\n\nConsider both quantitative results (%) and qualitative factors (clarity, SEO, consistency).\n```\n\n---\n\n#### Pattern 2: Findability Issue Analysis\n\n```markdown\nAnalyze survey findability ratings to identify IA problem areas:\n\nSURVEY QUESTIONS & RESULTS (n=300):\n\nQ1: \"How easy is it to find API authentication documentation?\"\n- Very Easy: 12%\n- Easy: 28%\n- Neutral: 25%\n- Difficult: 22%\n- Very Difficult: 13%\nMean score: 2.8/5\n\nQ2: \"How easy is it to find code examples for specific features?\"\n- Very Easy: 35%\n- Easy: 42%\n- Neutral: 15%\n- Difficult: 6%\n- Very Difficult: 2%\nMean score: 4.0/5\n\nQ3: \"How easy is it to find troubleshooting information when you encounter errors?\"\n- Very Easy: 8%\n- Easy: 18%\n- Neutral: 22%\n- Difficult: 32%\n- Very Difficult: 20%\nMean score: 2.5/5\n\n[Include 5-10 questions with similar format]\n\nAnalyze:\n\n1. **Problem areas:**\n   - Which topics have lowest findability scores?\n   - What threshold indicates a problem (e.g., <3.0 mean)?\n\n2. **Success areas:**\n   - Which topics have highest findability scores?\n   - What makes these easier to find? (Can we replicate?)\n\n3. **Priority ranking:**\n   - Rank findability issues by severity\n   - Consider both mean score and % \"Difficult/Very Difficult\"\n\n4. **Root cause hypotheses:**\n   - Why might these items be hard to find?\n   - Navigation issues? Search issues? Content organization?\n\n5. **Recommendations:**\n   - Specific IA changes to improve findability\n   - Navigation restructuring\n   - Search optimization\n   - Wayfinding improvements\n\nCompare findings to qualitative research (interview themes, card sort patterns).\n```\n\n---\n\n#### Pattern 3: Navigation Behavior Analysis\n\n```markdown\nAnalyze navigation behavior from survey responses:\n\nSURVEY QUESTION:\n\"When you visit our documentation, what do you do FIRST to find information?\"\n\nRESULTS (n=400):\n- Use the search box: 62% (248 responses)\n- Browse the main navigation menu: 18% (72 responses)\n- Click on \"Getting Started\": 8% (32 responses)\n- Use the table of contents/sidebar: 7% (28 responses)\n- Use Google to search: 3% (12 responses)\n- Contact support: 2% (8 responses)\n\nFOLLOW-UP QUESTION:\n\"If your first strategy doesn't work, what do you try next?\"\n\nRESULTS (n=400):\n- Try different search terms: 45% (180 responses)\n- Browse navigation menu: 28% (112 responses)\n- Google search: 15% (60 responses)\n- Contact support: 8% (32 responses)\n- Give up: 4% (16 responses)\n\nAnalyze:\n\n1. **Primary behavior patterns:**\n   - What does the dominant first-choice (search) tell us?\n   - What % rely on browse vs. search?\n\n2. **Implications:**\n   - How should we prioritize search optimization vs. navigation design?\n   - Are users searching because navigation is unclear?\n   - Or searching because it's genuinely faster?\n\n3. **Failure recovery:**\n   - What do users do when first strategy fails?\n   - High search reformulation rate suggests what?\n   - 4% giving up\u2014how critical is this?\n\n4. **Recommendations:**\n   - Investment priorities (search vs. navigation vs. content)\n   - Quick wins to reduce failed first attempts\n   - Long-term improvements\n\n5. **Research gaps:**\n   - What additional research would clarify user needs?\n   - Questions to investigate further\n```\n\n---",
            "hydration_source_header": "Survey Analysis Prompt Patterns",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "hierarchy-generation-prompt",
            "title": "Hierarchy Generation from Card Sort Prompt",
            "taskType": "generation",
            "lines": "335-380",
            "standalone": true,
            "retrievalQuestions": [
              "What prompt creates IA from card sort data?"
            ],
            "content": "**Use when:** Cards were grouped very differently by different participants\n\n```markdown\nAnalyze conflicting card placements to inform IA decisions:\n\nCONFLICTING CARD: [Card name]\n\nPlacements across participants:\n- Group A: \"[Label]\" - Participants: P1, P4, P7, P12 (4 participants, 13%)\n- Group B: \"[Label]\" - Participants: P2, P5, P8, P9, P11, P15, P18 (7 participants, 23%)\n- Group C: \"[Label]\" - Participants: P3, P6, P10, P13, P14, P16, P17, P19, P20 (9 participants, 30%)\n- Standalone group: Participants: P21, P22, P23 (3 participants, 10%)\n- Mixed with multiple groups in small variations (7 participants, 23%)\n\nContext:\n- Card description: [What the card represents]\n- Related cards: [Other cards that might inform placement]\n- User tasks: [What users would use this for]\n\nAnalyze:\n1. Why might users place this card differently?\n2. What user needs or mental models do each placement represent?\n3. Is there a \"most correct\" placement, or are multiple valid?\n4. How should we resolve this conflict in our IA?\n\nOptions to consider:\n- Choose the most common placement\n- Provide multiple access points (card accessible from multiple categories)\n- Create a new category that better represents the card's purpose\n- Split the card into multiple more specific items\n- Placement based on primary use case\n\nRecommend a decision with rationale based on:\n- Plurality (most common placement)\n- User task alignment\n- Clarity and findability\n- Consistency with other IA decisions\n```\n\n---",
            "hydration_source_header": "Pattern 5: Conflict Resolution",
            "hydration_method": "line_proximity"
          },
          {
            "id": "tree-test-success-prompt",
            "title": "Tree Test Success Analysis Prompt",
            "taskType": "analysis",
            "lines": "460-495",
            "standalone": true,
            "content": "**Use when:** You need to identify recurring themes across multiple interviews\n\n```markdown\nConduct thematic analysis on these user interview transcripts:\n\nRESEARCH CONTEXT:\n- Topic: [What you were investigating]\n- Participants: [Number and type]\n- Goal: [What insights you're seeking]\n\nINTERVIEW TRANSCRIPTS:\n[Paste transcripts or key excerpts from 5-10 interviews]\n\nAnalyze for:\n\n1. **Recurring themes:**\n   - What topics, needs, or pain points appear across multiple interviews?\n   - How frequently does each theme appear?\n   - What language do users use to describe each theme?\n\n2. **Mental model patterns:**\n   - How do users conceptualize the information space?\n   - What terminology do they naturally use?\n   - How do they expect information to be organized?\n   - What connections or relationships do they mention?\n\n3. **Findability insights:**\n   - What do users say about finding information?\n   - What strategies do they mention using?\n   - Where do they get stuck or frustrated?\n   - What would make information easier to find?\n\n4. **Terminology insights:**\n   - What terms do users use consistently?\n   - What terms confuse users?\n   - Vocabulary mismatches (their terms vs. official terms)\n\nFor each theme, provide:\n- Theme name and description\n- Frequency (how many participants mentioned it)\n- Representative quotes (with participant IDs)\n- IA implications (how this should inform structure)\n\nOrganize from most to least frequently mentioned themes.\n```\n\n---",
            "hydration_source_header": "Pattern 1: Thematic Analysis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "path-analysis-prompt",
            "title": "Path Analysis Prompt",
            "taskType": "analysis",
            "lines": "525-560",
            "standalone": true,
            "content": "**Step 1: Initial grouping analysis**\n\n**Prompt used:**\n\n```markdown\nAnalyze these card sort results to identify natural groupings:\n\n[Pasted full dataset: 30 participants, 48 cards, all placements]\n\nFocus on:\n1. Cards that were consistently grouped together (>70% agreement)\n2. Cards with conflicting placements\n3. Average number of groups created per participant\n4. Natural cluster patterns\n```\n\n**AI findings:**\n\n**High-agreement groupings (>70%):**\n- Getting Started + Installation + First Tutorial (87% grouped together)\n- All API endpoint reference pages (83% grouped together)\n- All authentication-related how-to pages (77% grouped together)\n- Webhook setup + webhook troubleshooting (73% grouped together)\n\n**Moderate-agreement groupings (40-70%):**\n- Error handling + troubleshooting pages (62%)\n- Code examples + tutorials (58%)\n- Changelog + release notes + migration guides (52%)\n\n**Conflicting placements (less than 40% agreement):**\n- \"Best Practices Guide\" - split between tutorials (33%), how-to (27%), and a standalone \"Best Practices\" category (23%)\n- \"Rate Limiting\" - split between technical reference (40%) and how-to guides (35%)\n- \"Webhooks Overview\" - split between explanations/concepts (38%) and how-to guides (35%)\n\n**Participant grouping patterns:**\n- Average groups created: 6.2 (range: 4-9)\n- Mode: 6 groups\n- Most common structure: 5-7 top-level categories\n\n**Step 2: Label synthesis**\n\n**Prompt used:**\n\n```markdown\nSynthesize category labels for these natural groupings:\n\nGROUP 1 (Getting Started + Installation + First Tutorial):\nParticipant labels:\n- \"Basics\" (7 participants)\n- \"Getting Started\" (11 participants)\n- \"Begin Here\" (3 participants)\n- \"First Steps\" (4 participants)\n- \"Introduction\" (3 participants)\n- \"Setup\" (2 participants)\n\nGROUP 2 (API endpoint reference pages):\nParticipant labels:\n- \"API Reference\" (14 participants)\n- \"API Docs\" (8 participants)\n- \"Reference\" (4 participants)\n- \"Endpoints\" (2 participants)\n- \"Technical Reference\" (2 participants)\n\n[Continued for all major groups...]\n\nFor each, recommend the best label and provide rationale.\n```\n\n**AI recommendations:**\n\n**GROUP 1: \"Getting Started\"**\n- Rationale: Most popular label (37% of participants)\n- Clear action orientation\n- Sets user expectations appropriately\n- Industry-standard term\n- Alternative: \"Basics\" (less clear about what makes something \"basic\")\n\n**GROUP 2: \"API Reference\"**\n- Rationale: Dominant preference (47% of participants)\n- Industry standard\n- Clearly differentiates technical specs from how-to content\n- Alternative: \"API Docs\" (less specific\u2014\"docs\" could mean anything)\n\n**GROUP 3: \"Authentication & Security\"**\n- Rationale: Combines two common themes\n- 40% used \"Security\", 37% used \"Authentication\"\n- Both terms important for SEO and user search\n- Alternative: \"Security\" alone (but doesn't capture auth setup focus)\n\n**Step 3: Hierarchical clustering**\n\n**Prompt used:**\n\n```markdown\nBased on grouping patterns, recommend a hierarchical navigation structure:\n\n[Pasted clustering data with similarity scores]\n\nConsider:\n- Optimal number of top-level categories\n- Whether subcategories are needed\n- Logical hierarchy based on user mental models\n- Balance of category sizes\n```\n\n**AI recommendations:**\n\n**Proposed structure (2 levels):**\n\n```\n1. Getting Started (15 pages)\n   - Installation\n   - Configuration\n   - First API Call\n   - Quick Start Guides\n\n2. Guides & Tutorials (18 pages)\n   - Step-by-Step Tutorials\n   - How-To Guides\n   - Use Case Examples\n\n3. API Reference (22 pages)\n   - Endpoints\n   - Request/Response Formats\n   - Error Codes\n   - Data Objects\n\n4. Authentication & Security (12 pages)\n   - API Keys\n   - OAuth Setup\n   - Best Practices\n   - Troubleshooting\n\n5. Webhooks & Events (10 pages)\n   - Webhook Setup\n   - Event Types\n   - Handling Webhooks\n   - Troubleshooting\n\n6. Advanced Topics (8 pages)\n   - Rate Limiting\n   - Pagination\n   - Versioning\n   - Performance Optimization\n\n7. Resources (3 pages)\n   - Changelog\n   - Migration Guides\n   - SDKs & Libraries\n```\n\n**Rationale:**\n- 7 top-level categories (within Miller's Law range)\n- Relatively balanced distribution (3-22 pages)\n- Clear differentiation between categories\n- Matches dominant patterns from card sort\n- Separates reference from task-oriented content\n\n**Step 4: Conflict resolution**\n\nThe team identified cards with conflicting placements that needed human decision-making:\n\n**\"Best Practices Guide\" conflict:**\n- 33% placed with tutorials\n- 27% placed with how-to guides\n- 23% created standalone \"Best Practices\" category\n\n**Human decision:** \nAfter reviewing the actual content, the team realized \"Best Practices\" covered multiple topics. They split it into context-specific best practices placed within relevant sections (Authentication Best Practices, Webhook Best Practices) rather than a standalone section.\n\n**Validation:** They added search tags and cross-links so users could find all best practices content regardless of entry point.\n\n**\"Rate Limiting\" conflict:**\n- 40% placed in technical reference\n- 35% placed in how-to guides\n\n**Human decision:**\nCreated two pieces of content:\n1. \"Rate Limiting\" (technical reference) - explains how rate limiting works, limits, headers\n2. \"Handling Rate Limits\" (how-to guide) - explains how to detect and handle rate limit errors\n\n**Validation:** Cross-linked between the two, added to both API Reference and relevant How-To section.",
            "hydration_source_header": "The Analysis Process",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "failure-pattern-prompt",
            "title": "Failure Pattern Detection Prompt",
            "taskType": "analysis",
            "lines": "595-635",
            "standalone": true,
            "retrievalQuestions": [
              "Prompt for identifying tree test failure patterns"
            ],
            "content": "Surveys can provide quantitative validation of qualitative findings, especially for terminology and navigation preferences.\n\n### Survey Data Types for IA\n\n**Common IA-relevant survey questions:**\n\n**1. Terminology preference**\n\"Which term do you prefer for...?\"\n- Options: A, B, C\n- Results: % choosing each option\n\n**2. Findability ratings**\n\"How easy is it to find...?\"\n- Scale: Very Easy to Very Difficult\n- Results: Distribution across scale\n\n**3. Navigation patterns**\n\"When looking for [X], where do you go first?\"\n- Options: Search, Browse [Category A], Browse [Category B], etc.\n- Results: % choosing each option\n\n**4. Category sorting**\n\"Which category would you expect to find [Item]?\"\n- Options: Category A, B, C, D\n- Results: % choosing each category\n\n---\n\n### Survey Analysis Prompt Patterns\n\n#### Pattern 1: Terminology Preference Analysis\n\n```markdown\nAnalyze survey results on terminology preferences:\n\nSURVEY QUESTION:\n\"What would you call the section containing step-by-step instructions for common tasks?\"\n\nRESULTS (n=250 respondents):\n- \"How-To Guides\" - 38% (95 responses)\n- \"Tutorials\" - 28% (70 responses)\n- \"Instructions\" - 18% (45 responses)\n- \"Step-by-Step Guides\" - 12% (30 responses)\n- \"Walkthroughs\" - 4% (10 responses)\n\nAdditional context:\n- Target audience: Developers and technical users\n- Current site label: \"Procedural Documentation\"\n- Competitive analysis: Most competitors use \"Guides\" or \"How-To\"\n\nAnalyze:\n\n1. **Clear winner or split preference?**\n   - Is there a dominant preference (>50%)?\n   - Are top choices close enough that decision is difficult?\n\n2. **Why might users prefer each option?**\n   - What does each term signal to users?\n   - Pros/cons of each option\n\n3. **Recommendation:**\n   - Best label choice with rationale\n   - Should we use multiple labels (e.g., \"How-To Guides & Tutorials\")?\n   - Alternative approaches if preference is split\n\n4. **Implementation notes:**\n   - Should old terms be redirected?\n   - Should we use synonyms in search?\n   - Implications for content creation guidelines\n\nConsider both quantitative results (%) and qualitative factors (clarity, SEO, consistency).\n```\n\n---\n\n#### Pattern 2: Findability Issue Analysis\n\n```markdown\nAnalyze survey findability ratings to identify IA problem areas:\n\nSURVEY QUESTIONS & RESULTS (n=300):\n\nQ1: \"How easy is it to find API authentication documentation?\"\n- Very Easy: 12%\n- Easy: 28%\n- Neutral: 25%\n- Difficult: 22%\n- Very Difficult: 13%\nMean score: 2.8/5\n\nQ2: \"How easy is it to find code examples for specific features?\"\n- Very Easy: 35%\n- Easy: 42%\n- Neutral: 15%\n- Difficult: 6%\n- Very Difficult: 2%\nMean score: 4.0/5\n\nQ3: \"How easy is it to find troubleshooting information when you encounter errors?\"\n- Very Easy: 8%\n- Easy: 18%\n- Neutral: 22%\n- Difficult: 32%\n- Very Difficult: 20%\nMean score: 2.5/5\n\n[Include 5-10 questions with similar format]\n\nAnalyze:\n\n1. **Problem areas:**\n   - Which topics have lowest findability scores?\n   - What threshold indicates a problem (e.g., <3.0 mean)?\n\n2. **Success areas:**\n   - Which topics have highest findability scores?\n   - What makes these easier to find? (Can we replicate?)\n\n3. **Priority ranking:**\n   - Rank findability issues by severity\n   - Consider both mean score and % \"Difficult/Very Difficult\"\n\n4. **Root cause hypotheses:**\n   - Why might these items be hard to find?\n   - Navigation issues? Search issues? Content organization?\n\n5. **Recommendations:**\n   - Specific IA changes to improve findability\n   - Navigation restructuring\n   - Search optimization\n   - Wayfinding improvements\n\nCompare findings to qualitative research (interview themes, card sort patterns).\n```\n\n---\n\n#### Pattern 3: Navigation Behavior Analysis\n\n```markdown\nAnalyze navigation behavior from survey responses:\n\nSURVEY QUESTION:\n\"When you visit our documentation, what do you do FIRST to find information?\"\n\nRESULTS (n=400):\n- Use the search box: 62% (248 responses)\n- Browse the main navigation menu: 18% (72 responses)\n- Click on \"Getting Started\": 8% (32 responses)\n- Use the table of contents/sidebar: 7% (28 responses)\n- Use Google to search: 3% (12 responses)\n- Contact support: 2% (8 responses)\n\nFOLLOW-UP QUESTION:\n\"If your first strategy doesn't work, what do you try next?\"\n\nRESULTS (n=400):\n- Try different search terms: 45% (180 responses)\n- Browse navigation menu: 28% (112 responses)\n- Google search: 15% (60 responses)\n- Contact support: 8% (32 responses)\n- Give up: 4% (16 responses)\n\nAnalyze:\n\n1. **Primary behavior patterns:**\n   - What does the dominant first-choice (search) tell us?\n   - What % rely on browse vs. search?\n\n2. **Implications:**\n   - How should we prioritize search optimization vs. navigation design?\n   - Are users searching because navigation is unclear?\n   - Or searching because it's genuinely faster?\n\n3. **Failure recovery:**\n   - What do users do when first strategy fails?\n   - High search reformulation rate suggests what?\n   - 4% giving up\u2014how critical is this?\n\n4. **Recommendations:**\n   - Investment priorities (search vs. navigation vs. content)\n   - Quick wins to reduce failed first attempts\n   - Long-term improvements\n\n5. **Research gaps:**\n   - What additional research would clarify user needs?\n   - Questions to investigate further\n```\n\n---",
            "hydration_source_header": "Survey Data Analysis for IA Insights",
            "hydration_method": "line_proximity"
          },
          {
            "id": "findings-synthesis-prompt",
            "title": "Research Synthesis Prompt",
            "taskType": "analysis",
            "lines": "770-820",
            "standalone": true,
            "content": "#### Pattern 1: Thematic Analysis\n\n**Use when:** You need to identify recurring themes across multiple interviews\n\n```markdown\nConduct thematic analysis on these user interview transcripts:\n\nRESEARCH CONTEXT:\n- Topic: [What you were investigating]\n- Participants: [Number and type]\n- Goal: [What insights you're seeking]\n\nINTERVIEW TRANSCRIPTS:\n[Paste transcripts or key excerpts from 5-10 interviews]\n\nAnalyze for:\n\n1. **Recurring themes:**\n   - What topics, needs, or pain points appear across multiple interviews?\n   - How frequently does each theme appear?\n   - What language do users use to describe each theme?\n\n2. **Mental model patterns:**\n   - How do users conceptualize the information space?\n   - What terminology do they naturally use?\n   - How do they expect information to be organized?\n   - What connections or relationships do they mention?\n\n3. **Findability insights:**\n   - What do users say about finding information?\n   - What strategies do they mention using?\n   - Where do they get stuck or frustrated?\n   - What would make information easier to find?\n\n4. **Terminology insights:**\n   - What terms do users use consistently?\n   - What terms confuse users?\n   - Vocabulary mismatches (their terms vs. official terms)\n\nFor each theme, provide:\n- Theme name and description\n- Frequency (how many participants mentioned it)\n- Representative quotes (with participant IDs)\n- IA implications (how this should inform structure)\n\nOrganize from most to least frequently mentioned themes.\n```\n\n---\n\n#### Pattern 2: Quote Extraction and Categorization\n\n**Use when:** You need to organize quotes by topic or insight\n\n```markdown\nExtract and categorize insightful quotes from these interview transcripts:\n\nTRANSCRIPTS:\n[Paste interview transcripts]\n\nCategories to organize by:\n- Navigation/Findability\n- Terminology/Language\n- Content needs/gaps\n- Mental models\n- Pain points\n- Positive experiences\n- Feature requests\n- [Add custom categories relevant to your research]\n\nFor each category:\n1. Extract relevant quotes (keep them verbatim)\n2. Include participant ID with each quote\n3. Add brief context if needed\n4. Note any patterns (multiple participants saying similar things)\n\nFormat:\n**[CATEGORY NAME]**\n- \"Quote text here\" \u2014P3 [Context: Discussing task flows]\n- \"Another quote\" \u2014P7 [Context: When asked about current process]\n- Pattern observed: 6 of 10 participants mentioned [X]\n\nHighlight the most impactful quotes\u2014ones that strongly inform IA decisions.\n```\n\n---\n\n#### Pattern 3: Pain Point and Need Identification\n\n**Use when:** You need to extract actionable insights about user needs\n\n```markdown\nIdentify user pain points and needs from these interview transcripts:\n\nINTERVIEWS:\n[Paste transcripts or excerpts]\n\nFor each pain point or need identified:\n\n1. **Pain point/Need description:**\n   - What is the user struggling with or wanting?\n   - How do they describe it in their own words?\n\n2. **Evidence:**\n   - Which participants mentioned this? (IDs)\n   - Relevant quotes\n   - How often it came up\n\n3. **Current workarounds:**\n   - How do users currently handle this?\n   - What strategies do they mention?\n\n4. **IA implications:**\n   - How could information architecture address this?\n   - Navigation changes needed?\n   - Content structure changes?\n   - Findability improvements?\n\n5. **Priority:**\n   - High: Blocks user success, mentioned by many participants\n   - Medium: Causes friction, mentioned by several participants  \n   - Low: Nice-to-have, mentioned by few participants\n\nOrganize by priority level, with highest-priority pain points first.\n```\n\n---\n\n#### Pattern 4: Mental Model Mapping\n\n**Use when:** You need to understand how users conceptualize the information space\n\n```markdown\nMap user mental models from these interview transcripts:\n\nINTERVIEW EXCERPTS:\n[Paste relevant sections where users discuss how they think about or organize information]\n\nAnalyze:\n\n1. **Conceptual groupings:**\n   - How do users naturally categorize information?\n   - What relationships do they describe between topics?\n   - How do they expect to navigate between related items?\n\n2. **Task-based vs. topic-based thinking:**\n   - Do users think in terms of tasks (\"I want to do X\") or topics (\"I need info about Y\")?\n   - What language reveals their approach?\n\n3. **Hierarchy and relationships:**\n   - Do users describe hierarchical relationships (parent-child)?\n   - Do users describe associative relationships (these things are related)?\n   - What connections do users expect to find?\n\n4. **Entry points:**\n   - How do users describe starting their information search?\n   - What do they look for first?\n   - What pathways do they expect to follow?\n\n5. **Terminology mapping:**\n   - User term \u2192 Our term (if different)\n   - What conceptual labels do users use?\n\nOutput:\n- Narrative description of the dominant mental model(s)\n- Visual/structural representation (if patterns are clear)\n- Quotes supporting each aspect of the model\n- IA recommendations aligned with the mental model\n- Areas where mental models conflict (how to resolve)\n```\n\n---",
            "hydration_source_header": "Interview Synthesis Prompt Patterns",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "ia-recommendations-prompt",
            "title": "IA Recommendations Prompt",
            "taskType": "generation",
            "lines": "865-920",
            "standalone": true,
            "retrievalQuestions": [
              "What prompt generates IA recommendations from research?"
            ],
            "content": "| Category | Recommended Label | Alternatives Considered | Rationale |\n|----------|-------------------|------------------------|-----------|\n| [Name]   | [Label]          | [Alt1, Alt2]          | [Why]     |",
            "hydration_source_header": "Label Recommendations",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "concepts": [
          {
            "id": "card-sorting",
            "term": "Card Sorting",
            "definition": "Research method where users organize topics into categories",
            "lines": "60-75",
            "retrievalQuestions": [
              "What is card sorting?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "open-card-sort",
            "term": "Open Card Sort",
            "definition": "Users create their own category names",
            "lines": "75-80",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "closed-card-sort",
            "term": "Closed Card Sort",
            "definition": "Users place items into predefined categories",
            "lines": "80-85",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "hybrid-card-sort",
            "term": "Hybrid Card Sort",
            "definition": "Predefined categories plus user-created ones",
            "lines": "85-90",
            "retrievalQuestions": [
              "What's the difference between open and closed card sorts?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "tree-testing",
            "term": "Tree Testing",
            "definition": "Users find items in a proposed navigation structure",
            "lines": "430-445",
            "retrievalQuestions": [
              "What is tree testing?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "findability-rate",
            "term": "Findability Rate",
            "definition": "Percentage of users who successfully find target",
            "lines": "455-465",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "directness-score",
            "term": "Directness Score",
            "definition": "Percentage who found target without backtracking",
            "lines": "465-475",
            "retrievalQuestions": [
              "What is directness in tree testing?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "first-click-success",
            "term": "First Click Success",
            "definition": "Percentage whose first click was on correct path",
            "lines": "475-485",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "similarity-matrix",
            "term": "Similarity Matrix",
            "definition": "Matrix showing how often pairs of items were grouped together",
            "lines": "115-125",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "dendrogram",
            "term": "Dendrogram",
            "definition": "Hierarchical clustering visualization",
            "lines": "125-130",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "standardization-score",
            "term": "Standardization Score",
            "definition": "Agreement level on category names",
            "lines": "130-140",
            "hydration_status": "skipped_unknown"
          }
        ],
        "workflows": [
          {
            "id": "card-sort-workflow",
            "title": "Card Sort Analysis Workflow",
            "steps": 4,
            "uses": [
              "matrix-analysis",
              "cluster-identification",
              "outlier-detection",
              "hierarchy-generation"
            ],
            "lines": "110-420",
            "retrievalQuestions": [
              "What are the steps to analyze a card sort?"
            ],
            "content": "Card sorting reveals how users naturally group and label information\u2014essential for designing intuitive IA structures.\n\n### Understanding Card Sort Data\n\n**Types of card sorts:**\n\n**Open card sort:** Participants create their own groups and labels\n- More exploratory\n- Reveals natural mental models\n- Produces more varied results\n- Requires more synthesis effort\n\n**Closed card sort:** Participants sort into predefined categories\n- Tests existing IA\n- More structured data\n- Easier to analyze\n- Less exploratory\n\n**Hybrid card sort:** Some predefined categories, but participants can create new ones\n- Balances structure with discovery\n- Tests existing + explores alternatives\n\n### Card Sort Data Format\n\nTypical card sort data includes:\n\n```\nParticipant | Card | Group Created | Group Label\n------------|------|---------------|-------------\nP1          | Reset password | Account settings | \"My Account\"\nP1          | Change email | Account settings | \"My Account\"\nP1          | API keys | Developer tools | \"For Developers\"\nP2          | Reset password | Login & Security | \"Login stuff\"\nP2          | Change email | Login & Security | \"Login stuff\"\nP2          | API keys | Advanced | \"Advanced Features\"\n...\n```\n\n---\n\n### Card Sort Analysis Prompt Patterns\n\n#### Pattern 1: Initial Grouping Analysis\n\n**Use when:** You need to understand how participants grouped cards\n\n```markdown\nAnalyze these open card sort results to identify grouping patterns:\n\nCARD SORT DATA:\n[Paste data: Participant | Card | Group | Label]\n\nTotal participants: [NUMBER]\nTotal cards: [NUMBER]\n\nPlease analyze:\n\n1. **Grouping patterns:**\n   - Which cards were frequently grouped together?\n   - Which cards had conflicting placements (grouped differently by different users)?\n   - Are there strong clustering patterns? (cards that almost everyone grouped together)\n\n2. **Label patterns:**\n   - What labels did participants use for similar groups?\n   - What terminology variations exist? (e.g., \"Login\" vs. \"Sign In\" vs. \"Authentication\")\n   - Are labels consistent with group contents?\n\n3. **Group size patterns:**\n   - Average group size per participant\n   - Range of group sizes\n   - Are some participants creating many small groups vs. few large groups?\n\n4. **Outliers:**\n   - Cards that were consistently hard to place\n   - Unusual groupings that might reveal interesting insights\n   - Participants whose sorting patterns differ significantly from others\n\nOutput:\n- Summary statistics\n- Top 10 strongest card-to-card associations (cards grouped together most often)\n- Top 5 conflicting cards (cards placed in very different groups)\n- Common labeling themes\n```\n\n**Why this works:**\n- Systematic coverage of key patterns\n- Balances quantitative (frequency) with qualitative (why it matters)\n- Surfaces both consensus and disagreement\n- Flags areas needing closer examination\n\n---\n\n#### Pattern 2: Similarity Matrix Generation\n\n**Use when:** You need to quantify how similar different groupings are\n\n```markdown\nCreate a similarity matrix for these card sort groupings:\n\nCARD SORT DATA:\n[Paste your card sort results]\n\nFor each pair of cards, calculate:\n- How many participants (out of [N]) grouped them together\n- Similarity score: (times grouped together / total participants) \u00d7 100\n\nThen:\n1. Create a similarity matrix showing card-to-card relationships\n2. Identify high-confidence pairs (>70% agreement)\n3. Identify low-confidence pairs (<30% agreement)\n4. Suggest natural clusters based on similarity scores\n\nFormat the matrix as a table for easy reading. Highlight the strongest associations.\n```\n\n**Expected output format:**\n\n```\nCARD SIMILARITY MATRIX\n(Shows % of participants who grouped each pair together)\n\n               Reset PW | Change Email | API Keys | View Logs | ...\nReset PW          --    |     87%      |   13%    |    20%    | ...\nChange Email     87%    |      --      |   10%    |    15%    | ...\nAPI Keys         13%    |     10%      |    --    |    73%    | ...\nView Logs        20%    |     15%      |   73%    |     --    | ...\n\nHIGH-CONFIDENCE GROUPINGS (>70% agreement):\n- Reset Password + Change Email (87%)\n- API Keys + View Logs (73%)\n- [etc.]\n\nCONFLICTING PLACEMENTS (<30% agreement, but non-zero):\n- Reset Password + API Keys (13%) - These were grouped together sometimes but usually separated\n- [etc.]\n```\n\n---\n\n#### Pattern 3: Category Label Synthesis\n\n**Use when:** You need to synthesize category labels from participant-created labels\n\n```markdown\nSynthesize category labels from these open card sort results:\n\nPARTICIPANT LABELS FOR SIMILAR GROUPS:\n\nGroup 1 (cards: Reset Password, Change Email, Update Profile):\n- P1: \"My Account\"\n- P2: \"Account Settings\"  \n- P3: \"Personal Info\"\n- P4: \"Your Account\"\n- P5: \"Profile Settings\"\n- P6: \"Account Management\"\n[... more participants]\n\nGroup 2 (cards: API Keys, Webhooks, Developer Documentation):\n- P1: \"For Developers\"\n- P2: \"Developer Tools\"\n- P3: \"Technical\"\n- P4: \"API Stuff\"\n- P5: \"Developer Resources\"\n- P6: \"Integration\"\n[... more participants]\n\nFor each group of similar labels:\n1. Identify the common theme or concept\n2. Count frequency of each label variation\n3. Evaluate each label option:\n   - Clarity (Is it immediately understandable?)\n   - Precision (Does it accurately reflect contents?)\n   - User language (Does it match how users speak?)\n   - Differentiation (Is it distinct from other categories?)\n4. Recommend the best label with rationale\n5. Provide 2-3 alternative label options\n6. Note any concerns or ambiguities\n\nConsider:\n- Most frequent terms (what users naturally say)\n- Most clear/descriptive terms (what communicates best)\n- Parallel structure (do labels follow consistent patterns?)\n```\n\n---\n\n#### Pattern 4: Dendrogram/Cluster Analysis\n\n**Use when:** You need hierarchical clustering to inform taxonomy structure\n\n```markdown\nPerform hierarchical cluster analysis on these card sort results:\n\nCARD SORT DATA:\n[Paste data]\n\nAnalyze grouping patterns to suggest a hierarchical structure (dendrogram):\n\n1. **Identify primary clusters:**\n   - Which cards consistently appear together?\n   - What are the major natural divisions?\n\n2. **Identify subclusters within primary clusters:**\n   - Are there logical subdivisions within major groups?\n   - Do some cards have stronger associations with each other than with other group members?\n\n3. **Suggest hierarchy levels:**\n   - Based on clustering strength, recommend taxonomy depth (2-level? 3-level?)\n   - Identify which groupings are strong enough to be top-level categories\n   - Identify which groupings work better as subcategories\n\n4. **Calculate cluster strength:**\n   - For each suggested cluster, what % of participants grouped those cards together?\n   - Which clusters have strongest agreement? Weakest?\n\nOutput as:\n- Visual hierarchy (indented lists showing cluster relationships)\n- Cluster strength scores\n- Recommendations for category structure\n- Areas of uncertainty that need further validation\n```\n\n---\n\n#### Pattern 5: Conflict Resolution\n\n**Use when:** Cards were grouped very differently by different participants\n\n```markdown\nAnalyze conflicting card placements to inform IA decisions:\n\nCONFLICTING CARD: [Card name]\n\nPlacements across participants:\n- Group A: \"[Label]\" - Participants: P1, P4, P7, P12 (4 participants, 13%)\n- Group B: \"[Label]\" - Participants: P2, P5, P8, P9, P11, P15, P18 (7 participants, 23%)\n- Group C: \"[Label]\" - Participants: P3, P6, P10, P13, P14, P16, P17, P19, P20 (9 participants, 30%)\n- Standalone group: Participants: P21, P22, P23 (3 participants, 10%)\n- Mixed with multiple groups in small variations (7 participants, 23%)\n\nContext:\n- Card description: [What the card represents]\n- Related cards: [Other cards that might inform placement]\n- User tasks: [What users would use this for]\n\nAnalyze:\n1. Why might users place this card differently?\n2. What user needs or mental models do each placement represent?\n3. Is there a \"most correct\" placement, or are multiple valid?\n4. How should we resolve this conflict in our IA?\n\nOptions to consider:\n- Choose the most common placement\n- Provide multiple access points (card accessible from multiple categories)\n- Create a new category that better represents the card's purpose\n- Split the card into multiple more specific items\n- Placement based on primary use case\n\nRecommend a decision with rationale based on:\n- Plurality (most common placement)\n- User task alignment\n- Clarity and findability\n- Consistency with other IA decisions\n```\n\n---\n\n### Comprehensive Card Sort Analysis Example\n\n**Prompt for complete analysis:**\n\n```markdown\nConduct a comprehensive analysis of this open card sort study:\n\nSTUDY DETAILS:\n- Participants: 30\n- Cards: 45 (documentation pages for a cloud platform)\n- Type: Open card sort (participants created their own groups and labels)\n- Goal: Design primary navigation for developer documentation\n\nCARD SORT DATA:\n[Paste complete dataset: Participant | Card | Group | Label]\n\nProvide a comprehensive analysis including:\n\n1. **GROUPING CONSENSUS:**\n   - High-agreement groupings (>70% of participants grouped together)\n   - Moderate-agreement groupings (40-70%)\n   - Low-agreement groupings (<40%)\n   - Cards with conflicting placements\n\n2. **LABEL ANALYSIS:**\n   - Most common labels for each natural group\n   - Terminology patterns (what users call things)\n   - Recommended labels with rationale\n   - Labels to avoid (confusing, ambiguous, or unpopular)\n\n3. **SUGGESTED IA STRUCTURE:**\n   - Recommended number of top-level categories (based on natural clustering)\n   - Proposed category names\n   - Cards assigned to each category\n   - Confidence level for each grouping\n   - Subcategories if hierarchy emerges\n\n4. **INSIGHTS & ANOMALIES:**\n   - Surprising groupings that reveal mental models\n   - Cards that don't fit cleanly anywhere\n   - Patterns that suggest user needs or pain points\n   - Differences from any existing IA (if applicable)\n\n5. **RECOMMENDATIONS:**\n   - Primary navigation structure\n   - How to handle conflicted cards\n   - Areas needing further research or testing\n   - Alternative access points (search tags, cross-links)\n\n6. **VALIDATION NOTES:**\n   - Which findings have strong evidence (high agreement)?\n   - Which findings need human review (ambiguous or conflicting)?\n   - Specific data points to verify manually\n\nFormat as a structured report ready to share with stakeholders.\n```\n\n---",
            "hydration_source_header": "Card Sorting Analysis with AI",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "tree-test-workflow",
            "title": "Tree Test Analysis Workflow",
            "steps": 3,
            "uses": [
              "success-rate-analysis",
              "path-analysis",
              "failure-pattern-detection"
            ],
            "lines": "450-660",
            "retrievalQuestions": [
              "How do I analyze tree test results step by step?"
            ],
            "content": "**Use when:** You need to identify recurring themes across multiple interviews\n\n```markdown\nConduct thematic analysis on these user interview transcripts:\n\nRESEARCH CONTEXT:\n- Topic: [What you were investigating]\n- Participants: [Number and type]\n- Goal: [What insights you're seeking]\n\nINTERVIEW TRANSCRIPTS:\n[Paste transcripts or key excerpts from 5-10 interviews]\n\nAnalyze for:\n\n1. **Recurring themes:**\n   - What topics, needs, or pain points appear across multiple interviews?\n   - How frequently does each theme appear?\n   - What language do users use to describe each theme?\n\n2. **Mental model patterns:**\n   - How do users conceptualize the information space?\n   - What terminology do they naturally use?\n   - How do they expect information to be organized?\n   - What connections or relationships do they mention?\n\n3. **Findability insights:**\n   - What do users say about finding information?\n   - What strategies do they mention using?\n   - Where do they get stuck or frustrated?\n   - What would make information easier to find?\n\n4. **Terminology insights:**\n   - What terms do users use consistently?\n   - What terms confuse users?\n   - Vocabulary mismatches (their terms vs. official terms)\n\nFor each theme, provide:\n- Theme name and description\n- Frequency (how many participants mentioned it)\n- Representative quotes (with participant IDs)\n- IA implications (how this should inform structure)\n\nOrganize from most to least frequently mentioned themes.\n```\n\n---",
            "hydration_source_header": "Pattern 1: Thematic Analysis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "research-to-ia-workflow",
            "title": "Research-to-IA Design Workflow",
            "steps": 3,
            "uses": [
              "findings-synthesis",
              "ia-recommendations",
              "validation-loop"
            ],
            "lines": "760-1000",
            "retrievalQuestions": [
              "How do I turn research into IA design?"
            ],
            "content": "```markdown\nAnalyze navigation behavior from survey responses:\n\nSURVEY QUESTION:\n\"When you visit our documentation, what do you do FIRST to find information?\"\n\nRESULTS (n=400):\n- Use the search box: 62% (248 responses)\n- Browse the main navigation menu: 18% (72 responses)\n- Click on \"Getting Started\": 8% (32 responses)\n- Use the table of contents/sidebar: 7% (28 responses)\n- Use Google to search: 3% (12 responses)\n- Contact support: 2% (8 responses)\n\nFOLLOW-UP QUESTION:\n\"If your first strategy doesn't work, what do you try next?\"\n\nRESULTS (n=400):\n- Try different search terms: 45% (180 responses)\n- Browse navigation menu: 28% (112 responses)\n- Google search: 15% (60 responses)\n- Contact support: 8% (32 responses)\n- Give up: 4% (16 responses)\n\nAnalyze:\n\n1. **Primary behavior patterns:**\n   - What does the dominant first-choice (search) tell us?\n   - What % rely on browse vs. search?\n\n2. **Implications:**\n   - How should we prioritize search optimization vs. navigation design?\n   - Are users searching because navigation is unclear?\n   - Or searching because it's genuinely faster?\n\n3. **Failure recovery:**\n   - What do users do when first strategy fails?\n   - High search reformulation rate suggests what?\n   - 4% giving up\u2014how critical is this?\n\n4. **Recommendations:**\n   - Investment priorities (search vs. navigation vs. content)\n   - Quick wins to reduce failed first attempts\n   - Long-term improvements\n\n5. **Research gaps:**\n   - What additional research would clarify user needs?\n   - Questions to investigate further\n```\n\n---",
            "hydration_source_header": "Pattern 3: Navigation Behavior Analysis",
            "hydration_method": "line_proximity"
          }
        ],
        "examples": [
          {
            "id": "card-sort-matrix-output",
            "title": "Similarity Matrix Analysis Output",
            "demonstrates": "card-sort-matrix-prompt",
            "lines": "150-180",
            "content": "**Use when:** You need to understand how participants grouped cards\n\n```markdown\nAnalyze these open card sort results to identify grouping patterns:\n\nCARD SORT DATA:\n[Paste data: Participant | Card | Group | Label]\n\nTotal participants: [NUMBER]\nTotal cards: [NUMBER]\n\nPlease analyze:\n\n1. **Grouping patterns:**\n   - Which cards were frequently grouped together?\n   - Which cards had conflicting placements (grouped differently by different users)?\n   - Are there strong clustering patterns? (cards that almost everyone grouped together)\n\n2. **Label patterns:**\n   - What labels did participants use for similar groups?\n   - What terminology variations exist? (e.g., \"Login\" vs. \"Sign In\" vs. \"Authentication\")\n   - Are labels consistent with group contents?\n\n3. **Group size patterns:**\n   - Average group size per participant\n   - Range of group sizes\n   - Are some participants creating many small groups vs. few large groups?\n\n4. **Outliers:**\n   - Cards that were consistently hard to place\n   - Unusual groupings that might reveal interesting insights\n   - Participants whose sorting patterns differ significantly from others\n\nOutput:\n- Summary statistics\n- Top 10 strongest card-to-card associations (cards grouped together most often)\n- Top 5 conflicting cards (cards placed in very different groups)\n- Common labeling themes\n```\n\n**Why this works:**\n- Systematic coverage of key patterns\n- Balances quantitative (frequency) with qualitative (why it matters)\n- Surfaces both consensus and disagreement\n- Flags areas needing closer examination\n\n---",
            "hydration_source_header": "Pattern 1: Initial Grouping Analysis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "cluster-output-example",
            "title": "Cluster Identification Output",
            "demonstrates": "cluster-interpretation-prompt",
            "lines": "230-250",
            "content": "**Use when:** You need to synthesize category labels from participant-created labels\n\n```markdown\nSynthesize category labels from these open card sort results:\n\nPARTICIPANT LABELS FOR SIMILAR GROUPS:\n\nGroup 1 (cards: Reset Password, Change Email, Update Profile):\n- P1: \"My Account\"\n- P2: \"Account Settings\"  \n- P3: \"Personal Info\"\n- P4: \"Your Account\"\n- P5: \"Profile Settings\"\n- P6: \"Account Management\"\n[... more participants]\n\nGroup 2 (cards: API Keys, Webhooks, Developer Documentation):\n- P1: \"For Developers\"\n- P2: \"Developer Tools\"\n- P3: \"Technical\"\n- P4: \"API Stuff\"\n- P5: \"Developer Resources\"\n- P6: \"Integration\"\n[... more participants]\n\nFor each group of similar labels:\n1. Identify the common theme or concept\n2. Count frequency of each label variation\n3. Evaluate each label option:\n   - Clarity (Is it immediately understandable?)\n   - Precision (Does it accurately reflect contents?)\n   - User language (Does it match how users speak?)\n   - Differentiation (Is it distinct from other categories?)\n4. Recommend the best label with rationale\n5. Provide 2-3 alternative label options\n6. Note any concerns or ambiguities\n\nConsider:\n- Most frequent terms (what users naturally say)\n- Most clear/descriptive terms (what communicates best)\n- Parallel structure (do labels follow consistent patterns?)\n```\n\n---",
            "hydration_source_header": "Pattern 3: Category Label Synthesis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "expert-novice-split-output",
            "title": "Expert vs. Novice Split Analysis",
            "demonstrates": "expert-novice-split-prompt",
            "lines": "265-290",
            "content": "**Use when:** You need hierarchical clustering to inform taxonomy structure\n\n```markdown\nPerform hierarchical cluster analysis on these card sort results:\n\nCARD SORT DATA:\n[Paste data]\n\nAnalyze grouping patterns to suggest a hierarchical structure (dendrogram):\n\n1. **Identify primary clusters:**\n   - Which cards consistently appear together?\n   - What are the major natural divisions?\n\n2. **Identify subclusters within primary clusters:**\n   - Are there logical subdivisions within major groups?\n   - Do some cards have stronger associations with each other than with other group members?\n\n3. **Suggest hierarchy levels:**\n   - Based on clustering strength, recommend taxonomy depth (2-level? 3-level?)\n   - Identify which groupings are strong enough to be top-level categories\n   - Identify which groupings work better as subcategories\n\n4. **Calculate cluster strength:**\n   - For each suggested cluster, what % of participants grouped those cards together?\n   - Which clusters have strongest agreement? Weakest?\n\nOutput as:\n- Visual hierarchy (indented lists showing cluster relationships)\n- Cluster strength scores\n- Recommendations for category structure\n- Areas of uncertainty that need further validation\n```\n\n---",
            "hydration_source_header": "Pattern 4: Dendrogram/Cluster Analysis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "outlier-analysis-output",
            "title": "Outlier Item Analysis Output",
            "demonstrates": "outlier-analysis-prompt",
            "lines": "300-320",
            "content": "**Use when:** Cards were grouped very differently by different participants\n\n```markdown\nAnalyze conflicting card placements to inform IA decisions:\n\nCONFLICTING CARD: [Card name]\n\nPlacements across participants:\n- Group A: \"[Label]\" - Participants: P1, P4, P7, P12 (4 participants, 13%)\n- Group B: \"[Label]\" - Participants: P2, P5, P8, P9, P11, P15, P18 (7 participants, 23%)\n- Group C: \"[Label]\" - Participants: P3, P6, P10, P13, P14, P16, P17, P19, P20 (9 participants, 30%)\n- Standalone group: Participants: P21, P22, P23 (3 participants, 10%)\n- Mixed with multiple groups in small variations (7 participants, 23%)\n\nContext:\n- Card description: [What the card represents]\n- Related cards: [Other cards that might inform placement]\n- User tasks: [What users would use this for]\n\nAnalyze:\n1. Why might users place this card differently?\n2. What user needs or mental models do each placement represent?\n3. Is there a \"most correct\" placement, or are multiple valid?\n4. How should we resolve this conflict in our IA?\n\nOptions to consider:\n- Choose the most common placement\n- Provide multiple access points (card accessible from multiple categories)\n- Create a new category that better represents the card's purpose\n- Split the card into multiple more specific items\n- Placement based on primary use case\n\nRecommend a decision with rationale based on:\n- Plurality (most common placement)\n- User task alignment\n- Clarity and findability\n- Consistency with other IA decisions\n```\n\n---",
            "hydration_source_header": "Pattern 5: Conflict Resolution",
            "hydration_method": "line_proximity"
          },
          {
            "id": "generated-hierarchy-output",
            "title": "AI-Generated Hierarchy Example",
            "demonstrates": "hierarchy-generation-prompt",
            "lines": "380-400",
            "retrievalQuestions": [
              "Show me an AI-generated hierarchy from card sort data"
            ],
            "content": "**Prompt for complete analysis:**\n\n```markdown\nConduct a comprehensive analysis of this open card sort study:\n\nSTUDY DETAILS:\n- Participants: 30\n- Cards: 45 (documentation pages for a cloud platform)\n- Type: Open card sort (participants created their own groups and labels)\n- Goal: Design primary navigation for developer documentation\n\nCARD SORT DATA:\n[Paste complete dataset: Participant | Card | Group | Label]\n\nProvide a comprehensive analysis including:\n\n1. **GROUPING CONSENSUS:**\n   - High-agreement groupings (>70% of participants grouped together)\n   - Moderate-agreement groupings (40-70%)\n   - Low-agreement groupings (<40%)\n   - Cards with conflicting placements\n\n2. **LABEL ANALYSIS:**\n   - Most common labels for each natural group\n   - Terminology patterns (what users call things)\n   - Recommended labels with rationale\n   - Labels to avoid (confusing, ambiguous, or unpopular)\n\n3. **SUGGESTED IA STRUCTURE:**\n   - Recommended number of top-level categories (based on natural clustering)\n   - Proposed category names\n   - Cards assigned to each category\n   - Confidence level for each grouping\n   - Subcategories if hierarchy emerges\n\n4. **INSIGHTS & ANOMALIES:**\n   - Surprising groupings that reveal mental models\n   - Cards that don't fit cleanly anywhere\n   - Patterns that suggest user needs or pain points\n   - Differences from any existing IA (if applicable)\n\n5. **RECOMMENDATIONS:**\n   - Primary navigation structure\n   - How to handle conflicted cards\n   - Areas needing further research or testing\n   - Alternative access points (search tags, cross-links)\n\n6. **VALIDATION NOTES:**\n   - Which findings have strong evidence (high agreement)?\n   - Which findings need human review (ambiguous or conflicting)?\n   - Specific data points to verify manually\n\nFormat as a structured report ready to share with stakeholders.\n```\n\n---",
            "hydration_source_header": "Comprehensive Card Sort Analysis Example",
            "hydration_method": "line_proximity"
          },
          {
            "id": "tree-test-success-output",
            "title": "Tree Test Success Analysis Output",
            "demonstrates": "tree-test-success-prompt",
            "lines": "495-510",
            "content": "**Use when:** You need to organize quotes by topic or insight\n\n```markdown\nExtract and categorize insightful quotes from these interview transcripts:\n\nTRANSCRIPTS:\n[Paste interview transcripts]\n\nCategories to organize by:\n- Navigation/Findability\n- Terminology/Language\n- Content needs/gaps\n- Mental models\n- Pain points\n- Positive experiences\n- Feature requests\n- [Add custom categories relevant to your research]\n\nFor each category:\n1. Extract relevant quotes (keep them verbatim)\n2. Include participant ID with each quote\n3. Add brief context if needed\n4. Note any patterns (multiple participants saying similar things)\n\nFormat:\n**[CATEGORY NAME]**\n- \"Quote text here\" \u2014P3 [Context: Discussing task flows]\n- \"Another quote\" \u2014P7 [Context: When asked about current process]\n- Pattern observed: 6 of 10 participants mentioned [X]\n\nHighlight the most impactful quotes\u2014ones that strongly inform IA decisions.\n```\n\n---",
            "hydration_source_header": "Pattern 2: Quote Extraction and Categorization",
            "hydration_method": "line_proximity"
          },
          {
            "id": "path-analysis-output",
            "title": "Path Analysis Output",
            "demonstrates": "path-analysis-prompt",
            "lines": "560-580",
            "content": "**Use when:** You need to understand how users conceptualize the information space\n\n```markdown\nMap user mental models from these interview transcripts:\n\nINTERVIEW EXCERPTS:\n[Paste relevant sections where users discuss how they think about or organize information]\n\nAnalyze:\n\n1. **Conceptual groupings:**\n   - How do users naturally categorize information?\n   - What relationships do they describe between topics?\n   - How do they expect to navigate between related items?\n\n2. **Task-based vs. topic-based thinking:**\n   - Do users think in terms of tasks (\"I want to do X\") or topics (\"I need info about Y\")?\n   - What language reveals their approach?\n\n3. **Hierarchy and relationships:**\n   - Do users describe hierarchical relationships (parent-child)?\n   - Do users describe associative relationships (these things are related)?\n   - What connections do users expect to find?\n\n4. **Entry points:**\n   - How do users describe starting their information search?\n   - What do they look for first?\n   - What pathways do they expect to follow?\n\n5. **Terminology mapping:**\n   - User term \u2192 Our term (if different)\n   - What conceptual labels do users use?\n\nOutput:\n- Narrative description of the dominant mental model(s)\n- Visual/structural representation (if patterns are clear)\n- Quotes supporting each aspect of the model\n- IA recommendations aligned with the mental model\n- Areas where mental models conflict (how to resolve)\n```\n\n---",
            "hydration_source_header": "Pattern 4: Mental Model Mapping",
            "hydration_method": "line_proximity"
          },
          {
            "id": "failure-pattern-output",
            "title": "Failure Pattern Analysis Output",
            "demonstrates": "failure-pattern-prompt",
            "lines": "635-660",
            "content": "#### Pattern 1: Terminology Preference Analysis\n\n```markdown\nAnalyze survey results on terminology preferences:\n\nSURVEY QUESTION:\n\"What would you call the section containing step-by-step instructions for common tasks?\"\n\nRESULTS (n=250 respondents):\n- \"How-To Guides\" - 38% (95 responses)\n- \"Tutorials\" - 28% (70 responses)\n- \"Instructions\" - 18% (45 responses)\n- \"Step-by-Step Guides\" - 12% (30 responses)\n- \"Walkthroughs\" - 4% (10 responses)\n\nAdditional context:\n- Target audience: Developers and technical users\n- Current site label: \"Procedural Documentation\"\n- Competitive analysis: Most competitors use \"Guides\" or \"How-To\"\n\nAnalyze:\n\n1. **Clear winner or split preference?**\n   - Is there a dominant preference (>50%)?\n   - Are top choices close enough that decision is difficult?\n\n2. **Why might users prefer each option?**\n   - What does each term signal to users?\n   - Pros/cons of each option\n\n3. **Recommendation:**\n   - Best label choice with rationale\n   - Should we use multiple labels (e.g., \"How-To Guides & Tutorials\")?\n   - Alternative approaches if preference is split\n\n4. **Implementation notes:**\n   - Should old terms be redirected?\n   - Should we use synonyms in search?\n   - Implications for content creation guidelines\n\nConsider both quantitative results (%) and qualitative factors (clarity, SEO, consistency).\n```\n\n---\n\n#### Pattern 2: Findability Issue Analysis\n\n```markdown\nAnalyze survey findability ratings to identify IA problem areas:\n\nSURVEY QUESTIONS & RESULTS (n=300):\n\nQ1: \"How easy is it to find API authentication documentation?\"\n- Very Easy: 12%\n- Easy: 28%\n- Neutral: 25%\n- Difficult: 22%\n- Very Difficult: 13%\nMean score: 2.8/5\n\nQ2: \"How easy is it to find code examples for specific features?\"\n- Very Easy: 35%\n- Easy: 42%\n- Neutral: 15%\n- Difficult: 6%\n- Very Difficult: 2%\nMean score: 4.0/5\n\nQ3: \"How easy is it to find troubleshooting information when you encounter errors?\"\n- Very Easy: 8%\n- Easy: 18%\n- Neutral: 22%\n- Difficult: 32%\n- Very Difficult: 20%\nMean score: 2.5/5\n\n[Include 5-10 questions with similar format]\n\nAnalyze:\n\n1. **Problem areas:**\n   - Which topics have lowest findability scores?\n   - What threshold indicates a problem (e.g., <3.0 mean)?\n\n2. **Success areas:**\n   - Which topics have highest findability scores?\n   - What makes these easier to find? (Can we replicate?)\n\n3. **Priority ranking:**\n   - Rank findability issues by severity\n   - Consider both mean score and % \"Difficult/Very Difficult\"\n\n4. **Root cause hypotheses:**\n   - Why might these items be hard to find?\n   - Navigation issues? Search issues? Content organization?\n\n5. **Recommendations:**\n   - Specific IA changes to improve findability\n   - Navigation restructuring\n   - Search optimization\n   - Wayfinding improvements\n\nCompare findings to qualitative research (interview themes, card sort patterns).\n```\n\n---\n\n#### Pattern 3: Navigation Behavior Analysis\n\n```markdown\nAnalyze navigation behavior from survey responses:\n\nSURVEY QUESTION:\n\"When you visit our documentation, what do you do FIRST to find information?\"\n\nRESULTS (n=400):\n- Use the search box: 62% (248 responses)\n- Browse the main navigation menu: 18% (72 responses)\n- Click on \"Getting Started\": 8% (32 responses)\n- Use the table of contents/sidebar: 7% (28 responses)\n- Use Google to search: 3% (12 responses)\n- Contact support: 2% (8 responses)\n\nFOLLOW-UP QUESTION:\n\"If your first strategy doesn't work, what do you try next?\"\n\nRESULTS (n=400):\n- Try different search terms: 45% (180 responses)\n- Browse navigation menu: 28% (112 responses)\n- Google search: 15% (60 responses)\n- Contact support: 8% (32 responses)\n- Give up: 4% (16 responses)\n\nAnalyze:\n\n1. **Primary behavior patterns:**\n   - What does the dominant first-choice (search) tell us?\n   - What % rely on browse vs. search?\n\n2. **Implications:**\n   - How should we prioritize search optimization vs. navigation design?\n   - Are users searching because navigation is unclear?\n   - Or searching because it's genuinely faster?\n\n3. **Failure recovery:**\n   - What do users do when first strategy fails?\n   - High search reformulation rate suggests what?\n   - 4% giving up\u2014how critical is this?\n\n4. **Recommendations:**\n   - Investment priorities (search vs. navigation vs. content)\n   - Quick wins to reduce failed first attempts\n   - Long-term improvements\n\n5. **Research gaps:**\n   - What additional research would clarify user needs?\n   - Questions to investigate further\n```\n\n---",
            "hydration_source_header": "Survey Analysis Prompt Patterns",
            "hydration_method": "line_proximity"
          },
          {
            "id": "synthesis-output",
            "title": "Research Synthesis Output",
            "demonstrates": "findings-synthesis-prompt",
            "lines": "820-850",
            "content": "```markdown\nSynthesize findings across multiple research methods:\n\nRESEARCH METHODS CONDUCTED:\n1. Open card sort (30 participants)\n2. User interviews (12 participants)\n3. Findability survey (300 participants)\n4. Analytics review (3 months of data)\n\nKEY FINDINGS BY METHOD:\n\n**CARD SORT:**\n[Paste 3-5 key findings from card sort analysis]\n\n**INTERVIEWS:**\n[Paste 3-5 key themes from interview synthesis]\n\n**SURVEY:**\n[Paste 3-5 key results from survey analysis]\n\n**ANALYTICS:**\n[Paste 3-5 key behavioral patterns from analytics]\n\nConduct cross-method analysis:\n\n1. **CONVERGING EVIDENCE:**\n   - Which findings appear across multiple methods?\n   - What patterns are validated by multiple data sources?\n   - What conclusions can we draw with high confidence?\n\n2. **DIVERGING EVIDENCE:**\n   - Where do methods contradict each other?\n   - How can contradictions be explained?\n   - What additional research might resolve conflicts?\n\n3. **COMPLEMENTARY INSIGHTS:**\n   - What does each method reveal that others don't?\n   - How do findings from different methods build on each other?\n   - What complete picture emerges from all methods together?\n\n4. **CONFIDENCE LEVELS:**\n   - High confidence: Supported by 3+ methods\n   - Medium confidence: Supported by 2 methods\n   - Low confidence: Single method only, needs validation\n\n5. **ACTIONABLE RECOMMENDATIONS:**\n   - Based on converging evidence, what IA changes are clearly needed?\n   - Based on high-confidence findings, what should we prioritize?\n   - Based on diverging evidence, what needs further investigation?\n\nOutput as:\n- Summary of high-confidence insights\n- Recommended IA changes with evidence citations\n- Research gaps requiring further investigation\n- Implementation priorities\n```\n\n---",
            "hydration_source_header": "Cross-Method Analysis Pattern",
            "hydration_method": "line_proximity"
          },
          {
            "id": "ia-recommendations-output",
            "title": "IA Recommendations Output",
            "demonstrates": "ia-recommendations-prompt",
            "lines": "920-950",
            "retrievalQuestions": [
              "Example of IA recommendations from research"
            ],
            "content": "| Category | Recommended Label | Alternatives Considered | Rationale |\n|----------|-------------------|------------------------|-----------|\n| [Name]   | [Label]          | [Alt1, Alt2]          | [Why]     |",
            "hydration_source_header": "Label Recommendations",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "checklists": [
          {
            "id": "card-sort-validation-checklist",
            "title": "Card Sort Analysis Validation",
            "validates": "card-sort-analysis-framework",
            "items": 5,
            "lines": "1355-1375",
            "content": "Card sorting reveals how users naturally group and label information\u2014essential for designing intuitive IA structures.\n\n### Understanding Card Sort Data\n\n**Types of card sorts:**\n\n**Open card sort:** Participants create their own groups and labels\n- More exploratory\n- Reveals natural mental models\n- Produces more varied results\n- Requires more synthesis effort\n\n**Closed card sort:** Participants sort into predefined categories\n- Tests existing IA\n- More structured data\n- Easier to analyze\n- Less exploratory\n\n**Hybrid card sort:** Some predefined categories, but participants can create new ones\n- Balances structure with discovery\n- Tests existing + explores alternatives\n\n### Card Sort Data Format\n\nTypical card sort data includes:\n\n```\nParticipant | Card | Group Created | Group Label\n------------|------|---------------|-------------\nP1          | Reset password | Account settings | \"My Account\"\nP1          | Change email | Account settings | \"My Account\"\nP1          | API keys | Developer tools | \"For Developers\"\nP2          | Reset password | Login & Security | \"Login stuff\"\nP2          | Change email | Login & Security | \"Login stuff\"\nP2          | API keys | Advanced | \"Advanced Features\"\n...\n```\n\n---\n\n### Card Sort Analysis Prompt Patterns\n\n#### Pattern 1: Initial Grouping Analysis\n\n**Use when:** You need to understand how participants grouped cards\n\n```markdown\nAnalyze these open card sort results to identify grouping patterns:\n\nCARD SORT DATA:\n[Paste data: Participant | Card | Group | Label]\n\nTotal participants: [NUMBER]\nTotal cards: [NUMBER]\n\nPlease analyze:\n\n1. **Grouping patterns:**\n   - Which cards were frequently grouped together?\n   - Which cards had conflicting placements (grouped differently by different users)?\n   - Are there strong clustering patterns? (cards that almost everyone grouped together)\n\n2. **Label patterns:**\n   - What labels did participants use for similar groups?\n   - What terminology variations exist? (e.g., \"Login\" vs. \"Sign In\" vs. \"Authentication\")\n   - Are labels consistent with group contents?\n\n3. **Group size patterns:**\n   - Average group size per participant\n   - Range of group sizes\n   - Are some participants creating many small groups vs. few large groups?\n\n4. **Outliers:**\n   - Cards that were consistently hard to place\n   - Unusual groupings that might reveal interesting insights\n   - Participants whose sorting patterns differ significantly from others\n\nOutput:\n- Summary statistics\n- Top 10 strongest card-to-card associations (cards grouped together most often)\n- Top 5 conflicting cards (cards placed in very different groups)\n- Common labeling themes\n```\n\n**Why this works:**\n- Systematic coverage of key patterns\n- Balances quantitative (frequency) with qualitative (why it matters)\n- Surfaces both consensus and disagreement\n- Flags areas needing closer examination\n\n---\n\n#### Pattern 2: Similarity Matrix Generation\n\n**Use when:** You need to quantify how similar different groupings are\n\n```markdown\nCreate a similarity matrix for these card sort groupings:\n\nCARD SORT DATA:\n[Paste your card sort results]\n\nFor each pair of cards, calculate:\n- How many participants (out of [N]) grouped them together\n- Similarity score: (times grouped together / total participants) \u00d7 100\n\nThen:\n1. Create a similarity matrix showing card-to-card relationships\n2. Identify high-confidence pairs (>70% agreement)\n3. Identify low-confidence pairs (<30% agreement)\n4. Suggest natural clusters based on similarity scores\n\nFormat the matrix as a table for easy reading. Highlight the strongest associations.\n```\n\n**Expected output format:**\n\n```\nCARD SIMILARITY MATRIX\n(Shows % of participants who grouped each pair together)\n\n               Reset PW | Change Email | API Keys | View Logs | ...\nReset PW          --    |     87%      |   13%    |    20%    | ...\nChange Email     87%    |      --      |   10%    |    15%    | ...\nAPI Keys         13%    |     10%      |    --    |    73%    | ...\nView Logs        20%    |     15%      |   73%    |     --    | ...\n\nHIGH-CONFIDENCE GROUPINGS (>70% agreement):\n- Reset Password + Change Email (87%)\n- API Keys + View Logs (73%)\n- [etc.]\n\nCONFLICTING PLACEMENTS (<30% agreement, but non-zero):\n- Reset Password + API Keys (13%) - These were grouped together sometimes but usually separated\n- [etc.]\n```\n\n---\n\n#### Pattern 3: Category Label Synthesis\n\n**Use when:** You need to synthesize category labels from participant-created labels\n\n```markdown\nSynthesize category labels from these open card sort results:\n\nPARTICIPANT LABELS FOR SIMILAR GROUPS:\n\nGroup 1 (cards: Reset Password, Change Email, Update Profile):\n- P1: \"My Account\"\n- P2: \"Account Settings\"  \n- P3: \"Personal Info\"\n- P4: \"Your Account\"\n- P5: \"Profile Settings\"\n- P6: \"Account Management\"\n[... more participants]\n\nGroup 2 (cards: API Keys, Webhooks, Developer Documentation):\n- P1: \"For Developers\"\n- P2: \"Developer Tools\"\n- P3: \"Technical\"\n- P4: \"API Stuff\"\n- P5: \"Developer Resources\"\n- P6: \"Integration\"\n[... more participants]\n\nFor each group of similar labels:\n1. Identify the common theme or concept\n2. Count frequency of each label variation\n3. Evaluate each label option:\n   - Clarity (Is it immediately understandable?)\n   - Precision (Does it accurately reflect contents?)\n   - User language (Does it match how users speak?)\n   - Differentiation (Is it distinct from other categories?)\n4. Recommend the best label with rationale\n5. Provide 2-3 alternative label options\n6. Note any concerns or ambiguities\n\nConsider:\n- Most frequent terms (what users naturally say)\n- Most clear/descriptive terms (what communicates best)\n- Parallel structure (do labels follow consistent patterns?)\n```\n\n---\n\n#### Pattern 4: Dendrogram/Cluster Analysis\n\n**Use when:** You need hierarchical clustering to inform taxonomy structure\n\n```markdown\nPerform hierarchical cluster analysis on these card sort results:\n\nCARD SORT DATA:\n[Paste data]\n\nAnalyze grouping patterns to suggest a hierarchical structure (dendrogram):\n\n1. **Identify primary clusters:**\n   - Which cards consistently appear together?\n   - What are the major natural divisions?\n\n2. **Identify subclusters within primary clusters:**\n   - Are there logical subdivisions within major groups?\n   - Do some cards have stronger associations with each other than with other group members?\n\n3. **Suggest hierarchy levels:**\n   - Based on clustering strength, recommend taxonomy depth (2-level? 3-level?)\n   - Identify which groupings are strong enough to be top-level categories\n   - Identify which groupings work better as subcategories\n\n4. **Calculate cluster strength:**\n   - For each suggested cluster, what % of participants grouped those cards together?\n   - Which clusters have strongest agreement? Weakest?\n\nOutput as:\n- Visual hierarchy (indented lists showing cluster relationships)\n- Cluster strength scores\n- Recommendations for category structure\n- Areas of uncertainty that need further validation\n```\n\n---\n\n#### Pattern 5: Conflict Resolution\n\n**Use when:** Cards were grouped very differently by different participants\n\n```markdown\nAnalyze conflicting card placements to inform IA decisions:\n\nCONFLICTING CARD: [Card name]\n\nPlacements across participants:\n- Group A: \"[Label]\" - Participants: P1, P4, P7, P12 (4 participants, 13%)\n- Group B: \"[Label]\" - Participants: P2, P5, P8, P9, P11, P15, P18 (7 participants, 23%)\n- Group C: \"[Label]\" - Participants: P3, P6, P10, P13, P14, P16, P17, P19, P20 (9 participants, 30%)\n- Standalone group: Participants: P21, P22, P23 (3 participants, 10%)\n- Mixed with multiple groups in small variations (7 participants, 23%)\n\nContext:\n- Card description: [What the card represents]\n- Related cards: [Other cards that might inform placement]\n- User tasks: [What users would use this for]\n\nAnalyze:\n1. Why might users place this card differently?\n2. What user needs or mental models do each placement represent?\n3. Is there a \"most correct\" placement, or are multiple valid?\n4. How should we resolve this conflict in our IA?\n\nOptions to consider:\n- Choose the most common placement\n- Provide multiple access points (card accessible from multiple categories)\n- Create a new category that better represents the card's purpose\n- Split the card into multiple more specific items\n- Placement based on primary use case\n\nRecommend a decision with rationale based on:\n- Plurality (most common placement)\n- User task alignment\n- Clarity and findability\n- Consistency with other IA decisions\n```\n\n---\n\n### Comprehensive Card Sort Analysis Example\n\n**Prompt for complete analysis:**\n\n```markdown\nConduct a comprehensive analysis of this open card sort study:\n\nSTUDY DETAILS:\n- Participants: 30\n- Cards: 45 (documentation pages for a cloud platform)\n- Type: Open card sort (participants created their own groups and labels)\n- Goal: Design primary navigation for developer documentation\n\nCARD SORT DATA:\n[Paste complete dataset: Participant | Card | Group | Label]\n\nProvide a comprehensive analysis including:\n\n1. **GROUPING CONSENSUS:**\n   - High-agreement groupings (>70% of participants grouped together)\n   - Moderate-agreement groupings (40-70%)\n   - Low-agreement groupings (<40%)\n   - Cards with conflicting placements\n\n2. **LABEL ANALYSIS:**\n   - Most common labels for each natural group\n   - Terminology patterns (what users call things)\n   - Recommended labels with rationale\n   - Labels to avoid (confusing, ambiguous, or unpopular)\n\n3. **SUGGESTED IA STRUCTURE:**\n   - Recommended number of top-level categories (based on natural clustering)\n   - Proposed category names\n   - Cards assigned to each category\n   - Confidence level for each grouping\n   - Subcategories if hierarchy emerges\n\n4. **INSIGHTS & ANOMALIES:**\n   - Surprising groupings that reveal mental models\n   - Cards that don't fit cleanly anywhere\n   - Patterns that suggest user needs or pain points\n   - Differences from any existing IA (if applicable)\n\n5. **RECOMMENDATIONS:**\n   - Primary navigation structure\n   - How to handle conflicted cards\n   - Areas needing further research or testing\n   - Alternative access points (search tags, cross-links)\n\n6. **VALIDATION NOTES:**\n   - Which findings have strong evidence (high agreement)?\n   - Which findings need human review (ambiguous or conflicting)?\n   - Specific data points to verify manually\n\nFormat as a structured report ready to share with stakeholders.\n```\n\n---",
            "hydration_source_header": "Card Sorting Analysis with AI",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "tree-test-validation-checklist",
            "title": "Tree Test Analysis Validation",
            "validates": "tree-test-analysis-framework",
            "items": 5,
            "lines": "1375-1395",
            "content": "**Implementation:**\nThe team implemented the recommended 7-category structure with minor adjustments based on conflict resolution.\n\n**Validation approach:**\n- Tree testing with 20 new participants to validate findability\n- A/B test of old vs. new navigation\n- Search analytics monitoring\n\n**Results (3 months post-launch):**\n- Task success rate improved from 67% to 89%\n- Average time-to-find decreased by 35%\n- Navigation usage increased from 18% to 42% (less search dependence)\n- Bounce rate from documentation decreased by 28%\n\n**Key lessons:**\n\n1. **AI accelerated analysis dramatically:** What would have taken 2-3 days of manual analysis took 4 hours with AI assistance\n\n2. **Human validation was essential:** Conflicts required context and judgment AI couldn't provide\n\n3. **Convergent patterns were reliable:** High-agreement groupings (>70%) proved to be solid foundations\n\n4. **Divergent patterns revealed opportunities:** Conflicts often indicated content that needed splitting or restructuring\n\n---",
            "hydration_source_header": "Results & Validation",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "synthesis-validation-checklist",
            "title": "Research Synthesis Validation",
            "validates": "findings-synthesis-pattern",
            "items": 5,
            "lines": "1395-1415",
            "retrievalQuestions": [
              "How do I validate my research synthesis?"
            ],
            "content": "**Implementation:**\nThe team implemented the recommended 7-category structure with minor adjustments based on conflict resolution.\n\n**Validation approach:**\n- Tree testing with 20 new participants to validate findability\n- A/B test of old vs. new navigation\n- Search analytics monitoring\n\n**Results (3 months post-launch):**\n- Task success rate improved from 67% to 89%\n- Average time-to-find decreased by 35%\n- Navigation usage increased from 18% to 42% (less search dependence)\n- Bounce rate from documentation decreased by 28%\n\n**Key lessons:**\n\n1. **AI accelerated analysis dramatically:** What would have taken 2-3 days of manual analysis took 4 hours with AI assistance\n\n2. **Human validation was essential:** Conflicts required context and judgment AI couldn't provide\n\n3. **Convergent patterns were reliable:** High-agreement groupings (>70%) proved to be solid foundations\n\n4. **Divergent patterns revealed opportunities:** Conflicts often indicated content that needed splitting or restructuring\n\n---",
            "hydration_source_header": "Results & Validation",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "ia-recommendations-checklist",
            "title": "IA Recommendations Validation",
            "validates": "ia-recommendations-pattern",
            "items": 5,
            "lines": "1415-1435",
            "content": "| Category | Recommended Label | Alternatives Considered | Rationale |\n|----------|-------------------|------------------------|-----------|\n| [Name]   | [Label]          | [Alt1, Alt2]          | [Why]     |",
            "hydration_source_header": "Label Recommendations",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "success-criteria-checklist",
            "title": "Success Criteria Checklist",
            "validates": "user-research-framework",
            "items": 7,
            "lines": "1455-1480",
            "retrievalQuestions": [
              "How do I know if my user research was successful?"
            ],
            "content": "Your project demonstrates excellence if:\n\n\u2713 Analysis reveals non-obvious patterns and insights\n\u2713 Recommendations are directly traceable to evidence\n\u2713 Validation catches and addresses any AI errors or oversights\n\u2713 Navigation structure is clear, balanced, and user-centered\n\u2713 Conflicts are resolved with clear rationale\n\u2713 Implementation plan is realistic and actionable\n\u2713 A team could execute your recommendations with confidence\n\u2713 Success can be measured objectively",
            "hydration_source_header": "Success Criteria",
            "hydration_method": "title_match"
          }
        ],
        "warnings": [
          {
            "id": "small-sample-warning",
            "title": "Small Sample Size",
            "prevents": "Over-interpreting limited data",
            "lines": "1240",
            "content": "This hands-on tutorial walks you through analyzing real card sort data from preparation through validation.\n\n**Tutorial setup:**\n- Time: 1.5-2 hours\n- Tools: Your AI assistant, spreadsheet software\n- Data: Sample card sort dataset (provided) or your own data\n- Deliverable: Navigation recommendations with validation\n\n---\n\n### Phase 1: Data Preparation (15 minutes)\n\n**Step 1: Organize your data**\n\nEnsure your card sort data is in this format:\n\n```\nParticipant ID | Card Name | Group Number | Group Label\nP1 | Reset Password | 1 | Account Settings\nP1 | Change Email | 1 | Account Settings\nP1 | API Keys | 2 | Developer Tools\n...\n```\n\n**If your data is in a different format:**\n- Use spreadsheet software to reorganize\n- Ensure consistent column headers\n- Remove any extraneous columns\n- Verify no missing data (especially group labels)\n\n**Step 2: Create summary statistics**\n\nCalculate:\n- Total participants\n- Total cards\n- Average groups created per participant\n- Range of groups created (min-max)\n\n**Step 3: Identify any data quality issues**\n\nCheck for:\n- Participants who created way too many or too few groups (outliers)\n- Missing group labels\n- Unclear or ambiguous labels\n- Cards that weren't sorted by some participants\n\n**Step 4: Prepare context document**\n\n```\nCARD SORT STUDY OVERVIEW\n\nStudy goal: [What you're trying to learn]\nParticipants: [Number and description]\nCards: [Number and what they represent]\nType: Open/Closed/Hybrid\nDate conducted: [Date range]\nCurrent IA (if applicable): [Brief description of existing structure]\n\nData quality notes:\n- [Any issues identified]\n- [Participants excluded and why]\n- [Data cleaning performed]\n```\n\n---\n\n### Phase 2: Initial AI Analysis (30 minutes)\n\n**Step 5: Run grouping analysis**\n\n```markdown\nAnalyze these open card sort results to identify natural groupings:\n\nCONTEXT:\n[Paste your context document from Step 4]\n\nCARD SORT DATA:\n[Paste your complete dataset]\n\nAnalyze:\n1. Cards consistently grouped together (>70% of participants)\n2. Cards with conflicting placements (wide variation)\n3. Average group count and size patterns\n4. Natural clustering patterns\n\nFor each pattern, provide:\n- Description\n- Frequency/percentage\n- Specific cards involved\n- Confidence level (high/medium/low)\n\nFlag any unusual patterns or outliers for human review.\n```\n\n**Save the output** as \"01-grouping-analysis.md\"\n\n**Step 6: Generate similarity matrix**\n\n```markdown\nCreate a card-to-card similarity matrix for these card sort results:\n\n[Paste your dataset]\n\nFor each pair of cards, calculate:\n- How many participants grouped them together\n- Percentage: (times together / total participants) \u00d7 100\n\nOutput as:\n1. Full similarity matrix (table format)\n2. High-confidence pairs (>70% agreement)\n3. Moderate pairs (40-69% agreement)\n4. Conflicting pairs (grouped together sometimes but usually not, 10-39%)\n\nIdentify natural cluster formations from similarity scores.\n```\n\n**Save the output** as \"02-similarity-matrix.md\"\n\n**Review** the matrix. Do the high-confidence pairs make sense? Any surprises?\n\n**Step 7: Synthesize category labels**\n\nFirst, group cards by natural clustering patterns identified in Steps 5-6.\n\n```markdown\nSynthesize category labels for these natural card groupings:\n\nCLUSTER 1: [List cards that were frequently grouped together]\nParticipant labels used:\n[Paste all labels participants created for similar groups]\n\nCLUSTER 2: [List cards for next cluster]\nParticipant labels used:\n[Paste labels]\n\n[Repeat for all major clusters]\n\nFor each cluster:\n1. Identify the most common label theme\n2. Count frequency of each label variation\n3. Evaluate label options:\n   - Clarity: Immediately understandable?\n   - Precision: Accurately reflects contents?\n   - User vocabulary: Matches how users speak?\n   - SEO: Matches search terms?\n   - Differentiation: Distinct from other categories?\n4. Recommend best label with rationale\n5. Provide 2 alternative options\n6. Note any concerns\n\nConsider:\n- Parallel structure across labels\n- Accessibility (screen reader friendly)\n- Character length for UI\n```\n\n**Save the output** as \"03-label-synthesis.md\"\n\n**Step 8: Generate hierarchical structure**\n\n```markdown\nBased on clustering patterns and label analysis, recommend a hierarchical navigation structure:\n\nCLUSTERING DATA:\n[Reference or paste findings from Steps 5-6]\n\nRECOMMENDED LABELS:\n[Reference or paste from Step 7]\n\nCONSTRAINTS:\n- Target: 5-8 top-level categories (Miller's Law)\n- Maximum depth: 2-3 levels\n- Balance: Try to keep categories relatively even in size\n- User mental model: Task-based or topic-based organization?\n\nRecommend:\n1. Number of top-level categories (with rationale)\n2. Complete hierarchy (category names and subcategories)\n3. Card assignments to each category\n4. Estimated page counts per category\n5. Confidence level for each grouping\n6. Alternatives considered and why rejected\n\nFormat as an indented list showing full hierarchy.\n```\n\n**Save the output** as \"04-hierarchy-recommendation.md\"\n\n---\n\n### Phase 3: Conflict Resolution & Human Decision-Making (20 minutes)\n\n**Step 9: Identify conflicts requiring human judgment**\n\n```markdown\nIdentify cards with conflicting placements that require human decision:\n\nSIMILARITY MATRIX:\n[Reference Step 6 output]\n\nFlag cards where:\n- No dominant placement (no option >50%)\n- Placement spread across 3+ different groups\n- Logical conflicts (card could reasonably fit multiple places)\n\nFor each conflicting card:\n1. What were the different placements?\n2. What % chose each placement?\n3. What might explain the conflict? (multiple valid mental models? unclear card description? card represents multiple things?)\n4. What are the resolution options?\n   - Choose most common placement\n   - Provide multiple access points\n   - Split into multiple more specific cards\n   - Create new category\n5. Recommendation with rationale\n\nPresent conflicts ordered by priority (most frequent conflicts first).\n```\n\n**Step 10: Make human decisions on conflicts**\n\nFor each flagged conflict:\n\n**Review the actual card content** (what does this card represent in your real documentation?)\n\n**Consider user tasks** (how would users actually use this information?)\n\n**Make a decision:**\n- \u2713 Choose primary placement\n- \u2713 Decide if secondary access is needed (cross-links, tags, multiple nav appearances)\n- \u2713 Note any content changes needed (splitting, clarifying, restructuring)\n\n**Document your decisions:**\n\n```\nCONFLICT: [Card name]\nPLACEMENT OPTIONS: [List with percentages]\nDECISION: [What you decided and why]\nIMPLEMENTATION: [How this will be implemented in actual IA]\nVALIDATION: [How you'll test this decision]\n```\n\n**Save** as \"05-conflict-resolutions.md\"\n\n---\n\n### Phase 4: Validation (25 minutes)\n\n**Step 11: Sample validation**\n\nSelect 3 random participants (10% of 30). Manually review their complete sorts.\n\n**For each sample participant, verify:**\n\n```markdown\nPARTICIPANT: [ID]\n\nAI Findings to Verify:\n1. [Finding 1 from Step 5]\n   \u25a1 Confirmed in this participant's data\n   \u25a1 Not confirmed\n   \u25a1 Partially confirmed (note: ___________)\n\n2. [Finding 2]\n   \u25a1 Confirmed\n   \u25a1 Not confirmed\n   \u25a1 Partially confirmed (note: ___________)\n\n[Repeat for all major findings]\n\nAdditional observations from manual review:\n- [Any patterns AI missed?]\n- [Any contextual notes that inform interpretation?]\n- [Any unusual choices this participant made?]\n\nOverall assessment:\n\u25a1 AI analysis is accurate\n\u25a1 AI analysis needs minor corrections: [describe]\n\u25a1 AI analysis has significant issues: [describe]\n```\n\n**Step 12: Edge case review**\n\nReview the 3-5 most unusual sorting patterns (outliers flagged by AI or identified in manual review).\n\n**For each outlier:**\n```\nOUTLIER: [Participant ID or specific unusual grouping]\nPATTERN: [What's unusual?]\nASSESSMENT:\n\u25a1 Participant error/misunderstanding (can ignore)\n\u25a1 Valid alternative mental model (consider in IA)\n\u25a1 Important insight (definitely incorporate)\n\u25a1 Random noise (can ignore)\n\nIF IMPORTANT:\n- What does this reveal about user needs?\n- How should this inform IA decisions?\n- Action: [What you'll do with this insight]\n```\n\n**Step 13: Cross-reference validation** (if you have other research data)\n\nIf you have interview data, survey results, or analytics:\n\n```markdown\nCompare card sort findings to other research:\n\nCARD SORT FINDING 1: [Finding from AI analysis]\nSupporting evidence from other methods:\n- Interviews: [Quote or theme that supports/contradicts]\n- Survey: [Result that supports/contradicts]\n- Analytics: [Behavior that supports/contradicts]\nConfidence: High / Medium / Low\n\n[Repeat for all major findings]\n\nConvergent findings (supported by multiple methods):\n- [List findings with multiple sources of support]\n\nDivergent findings (contradictions to resolve):\n- [List contradictions with plan for resolution]\n```\n\n---\n\n### Phase 5: Final Recommendations (10 minutes)\n\n**Step 14: Compile final recommendations**\n\nCreate a structured recommendations document:\n\n```markdown",
            "hydration_source_header": "Step-by-Step Tutorial: Complete Card Sort Analysis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "confirmation-bias",
            "title": "Confirmation Bias",
            "prevents": "Looking only for supporting evidence",
            "lines": "1245",
            "retrievalQuestions": [
              "How do I avoid confirmation bias in research?"
            ],
            "content": "This hands-on tutorial walks you through analyzing real card sort data from preparation through validation.\n\n**Tutorial setup:**\n- Time: 1.5-2 hours\n- Tools: Your AI assistant, spreadsheet software\n- Data: Sample card sort dataset (provided) or your own data\n- Deliverable: Navigation recommendations with validation\n\n---\n\n### Phase 1: Data Preparation (15 minutes)\n\n**Step 1: Organize your data**\n\nEnsure your card sort data is in this format:\n\n```\nParticipant ID | Card Name | Group Number | Group Label\nP1 | Reset Password | 1 | Account Settings\nP1 | Change Email | 1 | Account Settings\nP1 | API Keys | 2 | Developer Tools\n...\n```\n\n**If your data is in a different format:**\n- Use spreadsheet software to reorganize\n- Ensure consistent column headers\n- Remove any extraneous columns\n- Verify no missing data (especially group labels)\n\n**Step 2: Create summary statistics**\n\nCalculate:\n- Total participants\n- Total cards\n- Average groups created per participant\n- Range of groups created (min-max)\n\n**Step 3: Identify any data quality issues**\n\nCheck for:\n- Participants who created way too many or too few groups (outliers)\n- Missing group labels\n- Unclear or ambiguous labels\n- Cards that weren't sorted by some participants\n\n**Step 4: Prepare context document**\n\n```\nCARD SORT STUDY OVERVIEW\n\nStudy goal: [What you're trying to learn]\nParticipants: [Number and description]\nCards: [Number and what they represent]\nType: Open/Closed/Hybrid\nDate conducted: [Date range]\nCurrent IA (if applicable): [Brief description of existing structure]\n\nData quality notes:\n- [Any issues identified]\n- [Participants excluded and why]\n- [Data cleaning performed]\n```\n\n---\n\n### Phase 2: Initial AI Analysis (30 minutes)\n\n**Step 5: Run grouping analysis**\n\n```markdown\nAnalyze these open card sort results to identify natural groupings:\n\nCONTEXT:\n[Paste your context document from Step 4]\n\nCARD SORT DATA:\n[Paste your complete dataset]\n\nAnalyze:\n1. Cards consistently grouped together (>70% of participants)\n2. Cards with conflicting placements (wide variation)\n3. Average group count and size patterns\n4. Natural clustering patterns\n\nFor each pattern, provide:\n- Description\n- Frequency/percentage\n- Specific cards involved\n- Confidence level (high/medium/low)\n\nFlag any unusual patterns or outliers for human review.\n```\n\n**Save the output** as \"01-grouping-analysis.md\"\n\n**Step 6: Generate similarity matrix**\n\n```markdown\nCreate a card-to-card similarity matrix for these card sort results:\n\n[Paste your dataset]\n\nFor each pair of cards, calculate:\n- How many participants grouped them together\n- Percentage: (times together / total participants) \u00d7 100\n\nOutput as:\n1. Full similarity matrix (table format)\n2. High-confidence pairs (>70% agreement)\n3. Moderate pairs (40-69% agreement)\n4. Conflicting pairs (grouped together sometimes but usually not, 10-39%)\n\nIdentify natural cluster formations from similarity scores.\n```\n\n**Save the output** as \"02-similarity-matrix.md\"\n\n**Review** the matrix. Do the high-confidence pairs make sense? Any surprises?\n\n**Step 7: Synthesize category labels**\n\nFirst, group cards by natural clustering patterns identified in Steps 5-6.\n\n```markdown\nSynthesize category labels for these natural card groupings:\n\nCLUSTER 1: [List cards that were frequently grouped together]\nParticipant labels used:\n[Paste all labels participants created for similar groups]\n\nCLUSTER 2: [List cards for next cluster]\nParticipant labels used:\n[Paste labels]\n\n[Repeat for all major clusters]\n\nFor each cluster:\n1. Identify the most common label theme\n2. Count frequency of each label variation\n3. Evaluate label options:\n   - Clarity: Immediately understandable?\n   - Precision: Accurately reflects contents?\n   - User vocabulary: Matches how users speak?\n   - SEO: Matches search terms?\n   - Differentiation: Distinct from other categories?\n4. Recommend best label with rationale\n5. Provide 2 alternative options\n6. Note any concerns\n\nConsider:\n- Parallel structure across labels\n- Accessibility (screen reader friendly)\n- Character length for UI\n```\n\n**Save the output** as \"03-label-synthesis.md\"\n\n**Step 8: Generate hierarchical structure**\n\n```markdown\nBased on clustering patterns and label analysis, recommend a hierarchical navigation structure:\n\nCLUSTERING DATA:\n[Reference or paste findings from Steps 5-6]\n\nRECOMMENDED LABELS:\n[Reference or paste from Step 7]\n\nCONSTRAINTS:\n- Target: 5-8 top-level categories (Miller's Law)\n- Maximum depth: 2-3 levels\n- Balance: Try to keep categories relatively even in size\n- User mental model: Task-based or topic-based organization?\n\nRecommend:\n1. Number of top-level categories (with rationale)\n2. Complete hierarchy (category names and subcategories)\n3. Card assignments to each category\n4. Estimated page counts per category\n5. Confidence level for each grouping\n6. Alternatives considered and why rejected\n\nFormat as an indented list showing full hierarchy.\n```\n\n**Save the output** as \"04-hierarchy-recommendation.md\"\n\n---\n\n### Phase 3: Conflict Resolution & Human Decision-Making (20 minutes)\n\n**Step 9: Identify conflicts requiring human judgment**\n\n```markdown\nIdentify cards with conflicting placements that require human decision:\n\nSIMILARITY MATRIX:\n[Reference Step 6 output]\n\nFlag cards where:\n- No dominant placement (no option >50%)\n- Placement spread across 3+ different groups\n- Logical conflicts (card could reasonably fit multiple places)\n\nFor each conflicting card:\n1. What were the different placements?\n2. What % chose each placement?\n3. What might explain the conflict? (multiple valid mental models? unclear card description? card represents multiple things?)\n4. What are the resolution options?\n   - Choose most common placement\n   - Provide multiple access points\n   - Split into multiple more specific cards\n   - Create new category\n5. Recommendation with rationale\n\nPresent conflicts ordered by priority (most frequent conflicts first).\n```\n\n**Step 10: Make human decisions on conflicts**\n\nFor each flagged conflict:\n\n**Review the actual card content** (what does this card represent in your real documentation?)\n\n**Consider user tasks** (how would users actually use this information?)\n\n**Make a decision:**\n- \u2713 Choose primary placement\n- \u2713 Decide if secondary access is needed (cross-links, tags, multiple nav appearances)\n- \u2713 Note any content changes needed (splitting, clarifying, restructuring)\n\n**Document your decisions:**\n\n```\nCONFLICT: [Card name]\nPLACEMENT OPTIONS: [List with percentages]\nDECISION: [What you decided and why]\nIMPLEMENTATION: [How this will be implemented in actual IA]\nVALIDATION: [How you'll test this decision]\n```\n\n**Save** as \"05-conflict-resolutions.md\"\n\n---\n\n### Phase 4: Validation (25 minutes)\n\n**Step 11: Sample validation**\n\nSelect 3 random participants (10% of 30). Manually review their complete sorts.\n\n**For each sample participant, verify:**\n\n```markdown\nPARTICIPANT: [ID]\n\nAI Findings to Verify:\n1. [Finding 1 from Step 5]\n   \u25a1 Confirmed in this participant's data\n   \u25a1 Not confirmed\n   \u25a1 Partially confirmed (note: ___________)\n\n2. [Finding 2]\n   \u25a1 Confirmed\n   \u25a1 Not confirmed\n   \u25a1 Partially confirmed (note: ___________)\n\n[Repeat for all major findings]\n\nAdditional observations from manual review:\n- [Any patterns AI missed?]\n- [Any contextual notes that inform interpretation?]\n- [Any unusual choices this participant made?]\n\nOverall assessment:\n\u25a1 AI analysis is accurate\n\u25a1 AI analysis needs minor corrections: [describe]\n\u25a1 AI analysis has significant issues: [describe]\n```\n\n**Step 12: Edge case review**\n\nReview the 3-5 most unusual sorting patterns (outliers flagged by AI or identified in manual review).\n\n**For each outlier:**\n```\nOUTLIER: [Participant ID or specific unusual grouping]\nPATTERN: [What's unusual?]\nASSESSMENT:\n\u25a1 Participant error/misunderstanding (can ignore)\n\u25a1 Valid alternative mental model (consider in IA)\n\u25a1 Important insight (definitely incorporate)\n\u25a1 Random noise (can ignore)\n\nIF IMPORTANT:\n- What does this reveal about user needs?\n- How should this inform IA decisions?\n- Action: [What you'll do with this insight]\n```\n\n**Step 13: Cross-reference validation** (if you have other research data)\n\nIf you have interview data, survey results, or analytics:\n\n```markdown\nCompare card sort findings to other research:\n\nCARD SORT FINDING 1: [Finding from AI analysis]\nSupporting evidence from other methods:\n- Interviews: [Quote or theme that supports/contradicts]\n- Survey: [Result that supports/contradicts]\n- Analytics: [Behavior that supports/contradicts]\nConfidence: High / Medium / Low\n\n[Repeat for all major findings]\n\nConvergent findings (supported by multiple methods):\n- [List findings with multiple sources of support]\n\nDivergent findings (contradictions to resolve):\n- [List contradictions with plan for resolution]\n```\n\n---\n\n### Phase 5: Final Recommendations (10 minutes)\n\n**Step 14: Compile final recommendations**\n\nCreate a structured recommendations document:\n\n```markdown",
            "hydration_source_header": "Step-by-Step Tutorial: Complete Card Sort Analysis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "over-automation",
            "title": "Over-Automating Interpretation",
            "prevents": "Trusting AI without human judgment",
            "lines": "1250",
            "content": "**Step 1: Organize your data**\n\nEnsure your card sort data is in this format:\n\n```\nParticipant ID | Card Name | Group Number | Group Label\nP1 | Reset Password | 1 | Account Settings\nP1 | Change Email | 1 | Account Settings\nP1 | API Keys | 2 | Developer Tools\n...\n```\n\n**If your data is in a different format:**\n- Use spreadsheet software to reorganize\n- Ensure consistent column headers\n- Remove any extraneous columns\n- Verify no missing data (especially group labels)\n\n**Step 2: Create summary statistics**\n\nCalculate:\n- Total participants\n- Total cards\n- Average groups created per participant\n- Range of groups created (min-max)\n\n**Step 3: Identify any data quality issues**\n\nCheck for:\n- Participants who created way too many or too few groups (outliers)\n- Missing group labels\n- Unclear or ambiguous labels\n- Cards that weren't sorted by some participants\n\n**Step 4: Prepare context document**\n\n```\nCARD SORT STUDY OVERVIEW\n\nStudy goal: [What you're trying to learn]\nParticipants: [Number and description]\nCards: [Number and what they represent]\nType: Open/Closed/Hybrid\nDate conducted: [Date range]\nCurrent IA (if applicable): [Brief description of existing structure]\n\nData quality notes:\n- [Any issues identified]\n- [Participants excluded and why]\n- [Data cleaning performed]\n```\n\n---",
            "hydration_source_header": "Phase 1: Data Preparation (15 minutes)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "ignoring-context",
            "title": "Ignoring User Context",
            "prevents": "Missing why users made choices",
            "lines": "1255",
            "content": "**Step 1: Organize your data**\n\nEnsure your card sort data is in this format:\n\n```\nParticipant ID | Card Name | Group Number | Group Label\nP1 | Reset Password | 1 | Account Settings\nP1 | Change Email | 1 | Account Settings\nP1 | API Keys | 2 | Developer Tools\n...\n```\n\n**If your data is in a different format:**\n- Use spreadsheet software to reorganize\n- Ensure consistent column headers\n- Remove any extraneous columns\n- Verify no missing data (especially group labels)\n\n**Step 2: Create summary statistics**\n\nCalculate:\n- Total participants\n- Total cards\n- Average groups created per participant\n- Range of groups created (min-max)\n\n**Step 3: Identify any data quality issues**\n\nCheck for:\n- Participants who created way too many or too few groups (outliers)\n- Missing group labels\n- Unclear or ambiguous labels\n- Cards that weren't sorted by some participants\n\n**Step 4: Prepare context document**\n\n```\nCARD SORT STUDY OVERVIEW\n\nStudy goal: [What you're trying to learn]\nParticipants: [Number and description]\nCards: [Number and what they represent]\nType: Open/Closed/Hybrid\nDate conducted: [Date range]\nCurrent IA (if applicable): [Brief description of existing structure]\n\nData quality notes:\n- [Any issues identified]\n- [Participants excluded and why]\n- [Data cleaning performed]\n```\n\n---",
            "hydration_source_header": "Phase 1: Data Preparation (15 minutes)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "analysis-paralysis",
            "title": "Analysis Paralysis",
            "prevents": "Endless analysis without action",
            "lines": "1260",
            "retrievalQuestions": [
              "How do I avoid analysis paralysis in research?"
            ],
            "content": "**Step 1: Initial grouping analysis**\n\n**Prompt used:**\n\n```markdown\nAnalyze these card sort results to identify natural groupings:\n\n[Pasted full dataset: 30 participants, 48 cards, all placements]\n\nFocus on:\n1. Cards that were consistently grouped together (>70% agreement)\n2. Cards with conflicting placements\n3. Average number of groups created per participant\n4. Natural cluster patterns\n```\n\n**AI findings:**\n\n**High-agreement groupings (>70%):**\n- Getting Started + Installation + First Tutorial (87% grouped together)\n- All API endpoint reference pages (83% grouped together)\n- All authentication-related how-to pages (77% grouped together)\n- Webhook setup + webhook troubleshooting (73% grouped together)\n\n**Moderate-agreement groupings (40-70%):**\n- Error handling + troubleshooting pages (62%)\n- Code examples + tutorials (58%)\n- Changelog + release notes + migration guides (52%)\n\n**Conflicting placements (less than 40% agreement):**\n- \"Best Practices Guide\" - split between tutorials (33%), how-to (27%), and a standalone \"Best Practices\" category (23%)\n- \"Rate Limiting\" - split between technical reference (40%) and how-to guides (35%)\n- \"Webhooks Overview\" - split between explanations/concepts (38%) and how-to guides (35%)\n\n**Participant grouping patterns:**\n- Average groups created: 6.2 (range: 4-9)\n- Mode: 6 groups\n- Most common structure: 5-7 top-level categories\n\n**Step 2: Label synthesis**\n\n**Prompt used:**\n\n```markdown\nSynthesize category labels for these natural groupings:\n\nGROUP 1 (Getting Started + Installation + First Tutorial):\nParticipant labels:\n- \"Basics\" (7 participants)\n- \"Getting Started\" (11 participants)\n- \"Begin Here\" (3 participants)\n- \"First Steps\" (4 participants)\n- \"Introduction\" (3 participants)\n- \"Setup\" (2 participants)\n\nGROUP 2 (API endpoint reference pages):\nParticipant labels:\n- \"API Reference\" (14 participants)\n- \"API Docs\" (8 participants)\n- \"Reference\" (4 participants)\n- \"Endpoints\" (2 participants)\n- \"Technical Reference\" (2 participants)\n\n[Continued for all major groups...]\n\nFor each, recommend the best label and provide rationale.\n```\n\n**AI recommendations:**\n\n**GROUP 1: \"Getting Started\"**\n- Rationale: Most popular label (37% of participants)\n- Clear action orientation\n- Sets user expectations appropriately\n- Industry-standard term\n- Alternative: \"Basics\" (less clear about what makes something \"basic\")\n\n**GROUP 2: \"API Reference\"**\n- Rationale: Dominant preference (47% of participants)\n- Industry standard\n- Clearly differentiates technical specs from how-to content\n- Alternative: \"API Docs\" (less specific\u2014\"docs\" could mean anything)\n\n**GROUP 3: \"Authentication & Security\"**\n- Rationale: Combines two common themes\n- 40% used \"Security\", 37% used \"Authentication\"\n- Both terms important for SEO and user search\n- Alternative: \"Security\" alone (but doesn't capture auth setup focus)\n\n**Step 3: Hierarchical clustering**\n\n**Prompt used:**\n\n```markdown\nBased on grouping patterns, recommend a hierarchical navigation structure:\n\n[Pasted clustering data with similarity scores]\n\nConsider:\n- Optimal number of top-level categories\n- Whether subcategories are needed\n- Logical hierarchy based on user mental models\n- Balance of category sizes\n```\n\n**AI recommendations:**\n\n**Proposed structure (2 levels):**\n\n```\n1. Getting Started (15 pages)\n   - Installation\n   - Configuration\n   - First API Call\n   - Quick Start Guides\n\n2. Guides & Tutorials (18 pages)\n   - Step-by-Step Tutorials\n   - How-To Guides\n   - Use Case Examples\n\n3. API Reference (22 pages)\n   - Endpoints\n   - Request/Response Formats\n   - Error Codes\n   - Data Objects\n\n4. Authentication & Security (12 pages)\n   - API Keys\n   - OAuth Setup\n   - Best Practices\n   - Troubleshooting\n\n5. Webhooks & Events (10 pages)\n   - Webhook Setup\n   - Event Types\n   - Handling Webhooks\n   - Troubleshooting\n\n6. Advanced Topics (8 pages)\n   - Rate Limiting\n   - Pagination\n   - Versioning\n   - Performance Optimization\n\n7. Resources (3 pages)\n   - Changelog\n   - Migration Guides\n   - SDKs & Libraries\n```\n\n**Rationale:**\n- 7 top-level categories (within Miller's Law range)\n- Relatively balanced distribution (3-22 pages)\n- Clear differentiation between categories\n- Matches dominant patterns from card sort\n- Separates reference from task-oriented content\n\n**Step 4: Conflict resolution**\n\nThe team identified cards with conflicting placements that needed human decision-making:\n\n**\"Best Practices Guide\" conflict:**\n- 33% placed with tutorials\n- 27% placed with how-to guides\n- 23% created standalone \"Best Practices\" category\n\n**Human decision:** \nAfter reviewing the actual content, the team realized \"Best Practices\" covered multiple topics. They split it into context-specific best practices placed within relevant sections (Authentication Best Practices, Webhook Best Practices) rather than a standalone section.\n\n**Validation:** They added search tags and cross-links so users could find all best practices content regardless of entry point.\n\n**\"Rate Limiting\" conflict:**\n- 40% placed in technical reference\n- 35% placed in how-to guides\n\n**Human decision:**\nCreated two pieces of content:\n1. \"Rate Limiting\" (technical reference) - explains how rate limiting works, limits, headers\n2. \"Handling Rate Limits\" (how-to guide) - explains how to detect and handle rate limit errors\n\n**Validation:** Cross-linked between the two, added to both API Reference and relevant How-To section.",
            "hydration_source_header": "The Analysis Process",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "metrics": [
          {
            "id": "tree-test-success-rate",
            "metric": "Task Success Rate",
            "goodThreshold": "80%+",
            "concernThreshold": "<60%",
            "lines": "455-465",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "directness-metric",
            "metric": "Directness",
            "goodThreshold": "70%+",
            "concernThreshold": "<50%",
            "lines": "465-475",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "first-click-metric",
            "metric": "First Click Success",
            "goodThreshold": "70%+",
            "concernThreshold": "<50%",
            "lines": "475-485",
            "retrievalQuestions": [
              "What are good tree test metrics?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "card-sort-agreement",
            "metric": "Category Agreement",
            "goodThreshold": "60%+",
            "concernThreshold": "<40%",
            "lines": "130-140",
            "hydration_status": "skipped_unknown"
          }
        ],
        "timeMetrics": [
          {
            "id": "card-sort-analysis-time",
            "activity": "Card Sort Analysis",
            "traditionalTime": "8-16 hours",
            "aiAssistedTime": "2-4 hours",
            "savings": "70%+",
            "lines": "1285-1290",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "tree-test-analysis-time",
            "activity": "Tree Test Analysis",
            "traditionalTime": "6-12 hours",
            "aiAssistedTime": "2-3 hours",
            "savings": "70%+",
            "lines": "1290-1295",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "synthesis-time",
            "activity": "Research Synthesis",
            "traditionalTime": "4-8 hours",
            "aiAssistedTime": "1-2 hours",
            "savings": "75%+",
            "lines": "1295-1300",
            "retrievalQuestions": [
              "How much time does AI-assisted research analysis save?"
            ],
            "hydration_status": "skipped_unknown"
          }
        ]
      }
    },
    "4-1-no-code-tools": {
      "file": "4-1-no-code-tools.mdx",
      "focus": "Building IA tools and automations without coding including GPT-powered assistants, prompt chains, and templates",
      "entityCount": 95,
      "entities": {
        "frameworks": [
          {
            "id": "no-code-ia-tools-framework",
            "title": "No-Code IA Tools Framework",
            "type": "framework",
            "definition": "Framework for building IA tools without programming including GPT builders, prompt chains, and automation templates",
            "contains": [
              "gpt-builders",
              "prompt-chains",
              "automation-templates",
              "workflow-tools"
            ],
            "lines": "1-1680",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I build IA tools without coding?"
            ],
            "content": "By the end of this module, you will be able to:\n\n- Convert one-off prompts into reusable IA tools without writing code\n- Create Custom GPTs or Claude Projects for repeated IA tasks\n- Design prompt chains for complex, multi-step workflows\n- Document prompts effectively for team sharing and future reuse\n- Build a personal prompt library organized by IA task type\n- Evaluate when to use no-code tools vs. scripted solutions\n\n---",
            "hydration_source_header": "Learning Objectives",
            "hydration_method": "line_proximity"
          },
          {
            "id": "tool-building-spectrum",
            "title": "Tool Building Spectrum",
            "type": "framework",
            "definition": "Four levels from simple prompts to full automations",
            "contains": [
              "saved-prompts",
              "custom-gpts",
              "prompt-chains",
              "full-automations"
            ],
            "lines": "35-75",
            "crossModule": false,
            "retrievalQuestions": [
              "What levels of no-code tools can I build?"
            ],
            "content": "There's a spectrum of tool sophistication, from simple to complex:\n\n```\nLOW COMPLEXITY                                    HIGH COMPLEXITY\n\u2502                                                              \u2502\n\u2502  One-off       Documented      Custom        Prompt      Scripted\n\u2502  Prompts       Prompts         GPTs/Projects  Chains     Tools\n\u2502  \u2193             \u2193               \u2193             \u2193           \u2193\n\u2502  Ad hoc        Templates       Reusable      Multi-step  Automated\n\u2502  use           with context    interfaces    workflows   systems\n\u2502                                                           \n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2190 This module covers everything up to here\n```\n\n**This module focuses on the \"no-code\" portion:** everything from documented prompts through prompt chains. The next module (4.2) covers scripted tools for those ready to write code.\n\n---",
            "hydration_source_header": "The Tool-Building Spectrum",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "custom-gpt-design-framework",
            "title": "Custom GPT Design Framework",
            "type": "framework",
            "definition": "How to design effective custom GPTs for IA tasks",
            "contains": [
              "system-instructions",
              "knowledge-files",
              "conversation-starters",
              "capabilities-config"
            ],
            "lines": "85-380",
            "crossModule": false,
            "content": "Not every IA task needs a tool. Use this decision framework:\n\n**Build a reusable tool when:**\n- \u2705 You'll do this task again (frequency: monthly or more)\n- \u2705 Others on your team need to do it (shareability matters)\n- \u2705 The task has a consistent structure (same inputs/outputs)\n- \u2705 Quality and consistency are important (reduce errors)\n- \u2705 Setup time is significant (>5 minutes per use)\n\n**Use one-off prompts when:**\n- \u2705 This is a unique, one-time task\n- \u2705 The task changes significantly each time\n- \u2705 You're still exploring and experimenting\n- \u2705 Setup time is minimal (less than 2 minutes)\n- \u2705 Only you will ever need this\n\n**Example scenarios:**\n\n| Task | Frequency | Tool? | Why |\n|------|-----------|-------|-----|\n| Analyze quarterly card sort results | Quarterly | **YES** | Consistent structure, shared task |\n| Generate taxonomy for new product docs | Once per product launch (3-4x/year) | **YES** | High-value task, consistent approach |\n| Fix typos in a specific page | One-time | **NO** | Unique task, minimal setup |\n| Brainstorm navigation label ideas | Ad hoc, varies greatly | **NO** | Too variable, creative exploration |\n| Audit content for Di\u00c3\u00a1taxis classification | Monthly | **YES** | Consistent criteria, repeatable process |\n| Analyze user interview transcript | Per interview (frequent) | **YES** | Same analysis approach each time |\n\n---",
            "hydration_source_header": "When to Build Tools vs. Use One-Off Prompts",
            "hydration_method": "line_proximity"
          },
          {
            "id": "prompt-chain-framework",
            "title": "Prompt Chain Framework",
            "type": "framework",
            "definition": "Multi-step prompt sequences for complex IA tasks",
            "contains": [
              "chain-design",
              "input-output-mapping",
              "validation-loops"
            ],
            "lines": "390-750",
            "crossModule": false,
            "retrievalQuestions": [
              "How do I build a prompt chain?"
            ],
            "content": "Both platforms offer ways to create specialized, reusable AI assistants. Here's how they compare:\n\n**Custom GPTs (ChatGPT Plus/Enterprise):**\n\n\u2705 **Advantages:**\n- Shareable via link (can publish publicly or to workspace)\n- Can upload reference files that persist across conversations\n- Can configure specific behaviors and constraints\n- Discoverable in GPT store (if published)\n\n\u26a0\ufe0f **Limitations:**\n- Requires ChatGPT Plus ($20/month) or Enterprise\n- Limited to GPT-4 and GPT-4 Turbo models\n- No built-in version control\n\n**Claude Projects (Claude Pro/Team):**\n\n\u2705 **Advantages:**\n- Include context documents that persist across chats\n- Shareable within teams\n- Supports custom instructions\n- Works with latest Claude models\n\n\u26a0\ufe0f **Limitations:**\n- Requires Claude Pro ($20/month) or Team plan\n- Sharing limited to team members (no public sharing)\n- Context window shared between project knowledge and conversation\n\n**Bottom line:** Both work well for IA tools. Choose based on which platform you're already using and whether you need public sharing (Custom GPTs) or team-only tools (both work).\n\n---",
            "hydration_source_header": "Platform Comparison: Custom GPTs vs. Claude Projects",
            "hydration_method": "line_proximity"
          }
        ],
        "principles": [
          {
            "id": "start-simple",
            "title": "Start Simple, Add Complexity as Needed",
            "partOf": "tool-building-spectrum",
            "lines": "1390-1395",
            "crossModule": true,
            "retrievalQuestions": [
              "Where should I start with no-code tools?"
            ],
            "content": "**Tool Type:** Prompt Chain\n\n**Purpose:** Systematically audit documentation for duplicates, gaps, and quality issues.\n\n**Chain Structure:**\n\n```\nSTAGE 1: Inventory Processing\n\u251c\u2500 Input: Raw content list\n\u251c\u2500 Process: Categorize, extract metadata\n\u2514\u2500 Output: Structured inventory\n\nSTAGE 2: Duplicate Detection\n\u251c\u2500 Input: Structured inventory\n\u251c\u2500 Process: Identify overlaps\n\u2514\u2500 Output: Duplicate clusters\n\nSTAGE 3: Gap Analysis  \n\u251c\u2500 Input: Inventory + User journey\n\u251c\u2500 Process: Map coverage, find gaps\n\u2514\u2500 Output: Prioritized gap list\n\nSTAGE 4: Quality Assessment\n\u251c\u2500 Input: Inventory + gaps\n\u251c\u2500 Process: Score quality signals\n\u2514\u2500 Output: Improvement priorities\n\nSTAGE 5: Recommendations\n\u251c\u2500 Input: All previous outputs\n\u251c\u2500 Process: Synthesize into action plan\n\u2514\u2500 Output: Prioritized roadmap\n```\n\n**Stage 1 Prompt:**\n\n```\nCONTENT AUDIT - Stage 1: Inventory Processing\n\nYou're preparing a content inventory for systematic audit.\n\nRAW CONTENT LIST:\n[User pastes list with titles, URLs, brief descriptions]\n\nPROCESS:\n1. Categorize each item by content type:\n   - Tutorial (learning-oriented)\n   - How-to Guide (task-oriented)\n   - Reference (information-oriented)\n   - Explanation (understanding-oriented)\n   - Other (specify)\n\n2. Extract metadata:\n   - Title\n   - Primary topic/feature\n   - Target audience level (beginner/intermediate/advanced)\n   - Estimated word count category (<500, 500-1500, >1500)\n\n3. Organize into structured table\n\nOUTPUT FORMAT:\nProvide results as structured markdown with:",
            "hydration_source_header": "Tool 2: Content Audit Analyzer",
            "hydration_method": "line_proximity"
          },
          {
            "id": "reusable-components",
            "title": "Build Reusable Components",
            "partOf": "prompt-chain-framework",
            "lines": "1395-1400",
            "crossModule": false,
            "content": "**Tool Type:** Prompt Chain\n\n**Purpose:** Systematically audit documentation for duplicates, gaps, and quality issues.\n\n**Chain Structure:**\n\n```\nSTAGE 1: Inventory Processing\n\u251c\u2500 Input: Raw content list\n\u251c\u2500 Process: Categorize, extract metadata\n\u2514\u2500 Output: Structured inventory\n\nSTAGE 2: Duplicate Detection\n\u251c\u2500 Input: Structured inventory\n\u251c\u2500 Process: Identify overlaps\n\u2514\u2500 Output: Duplicate clusters\n\nSTAGE 3: Gap Analysis  \n\u251c\u2500 Input: Inventory + User journey\n\u251c\u2500 Process: Map coverage, find gaps\n\u2514\u2500 Output: Prioritized gap list\n\nSTAGE 4: Quality Assessment\n\u251c\u2500 Input: Inventory + gaps\n\u251c\u2500 Process: Score quality signals\n\u2514\u2500 Output: Improvement priorities\n\nSTAGE 5: Recommendations\n\u251c\u2500 Input: All previous outputs\n\u251c\u2500 Process: Synthesize into action plan\n\u2514\u2500 Output: Prioritized roadmap\n```\n\n**Stage 1 Prompt:**\n\n```\nCONTENT AUDIT - Stage 1: Inventory Processing\n\nYou're preparing a content inventory for systematic audit.\n\nRAW CONTENT LIST:\n[User pastes list with titles, URLs, brief descriptions]\n\nPROCESS:\n1. Categorize each item by content type:\n   - Tutorial (learning-oriented)\n   - How-to Guide (task-oriented)\n   - Reference (information-oriented)\n   - Explanation (understanding-oriented)\n   - Other (specify)\n\n2. Extract metadata:\n   - Title\n   - Primary topic/feature\n   - Target audience level (beginner/intermediate/advanced)\n   - Estimated word count category (<500, 500-1500, >1500)\n\n3. Organize into structured table\n\nOUTPUT FORMAT:\nProvide results as structured markdown with:",
            "hydration_source_header": "Tool 2: Content Audit Analyzer",
            "hydration_method": "line_proximity"
          },
          {
            "id": "test-before-deploying",
            "title": "Test Thoroughly Before Deploying",
            "partOf": "no-code-ia-tools-framework",
            "lines": "1400-1405",
            "crossModule": false,
            "content": "**Tool Type:** Prompt Chain\n\n**Purpose:** Systematically audit documentation for duplicates, gaps, and quality issues.\n\n**Chain Structure:**\n\n```\nSTAGE 1: Inventory Processing\n\u251c\u2500 Input: Raw content list\n\u251c\u2500 Process: Categorize, extract metadata\n\u2514\u2500 Output: Structured inventory\n\nSTAGE 2: Duplicate Detection\n\u251c\u2500 Input: Structured inventory\n\u251c\u2500 Process: Identify overlaps\n\u2514\u2500 Output: Duplicate clusters\n\nSTAGE 3: Gap Analysis  \n\u251c\u2500 Input: Inventory + User journey\n\u251c\u2500 Process: Map coverage, find gaps\n\u2514\u2500 Output: Prioritized gap list\n\nSTAGE 4: Quality Assessment\n\u251c\u2500 Input: Inventory + gaps\n\u251c\u2500 Process: Score quality signals\n\u2514\u2500 Output: Improvement priorities\n\nSTAGE 5: Recommendations\n\u251c\u2500 Input: All previous outputs\n\u251c\u2500 Process: Synthesize into action plan\n\u2514\u2500 Output: Prioritized roadmap\n```\n\n**Stage 1 Prompt:**\n\n```\nCONTENT AUDIT - Stage 1: Inventory Processing\n\nYou're preparing a content inventory for systematic audit.\n\nRAW CONTENT LIST:\n[User pastes list with titles, URLs, brief descriptions]\n\nPROCESS:\n1. Categorize each item by content type:\n   - Tutorial (learning-oriented)\n   - How-to Guide (task-oriented)\n   - Reference (information-oriented)\n   - Explanation (understanding-oriented)\n   - Other (specify)\n\n2. Extract metadata:\n   - Title\n   - Primary topic/feature\n   - Target audience level (beginner/intermediate/advanced)\n   - Estimated word count category (<500, 500-1500, >1500)\n\n3. Organize into structured table\n\nOUTPUT FORMAT:\nProvide results as structured markdown with:",
            "hydration_source_header": "Tool 2: Content Audit Analyzer",
            "hydration_method": "line_proximity"
          },
          {
            "id": "document-everything",
            "title": "Document Your Tools",
            "partOf": "no-code-ia-tools-framework",
            "lines": "1405-1410",
            "crossModule": false,
            "retrievalQuestions": [
              "Should I document my custom GPTs?"
            ],
            "content": "Create `documentation-taxonomy-generator-README.md`:\n\n```markdown",
            "hydration_source_header": "Step 6: Document Your Tool (5 minutes)",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "human-review-required",
            "title": "Always Include Human Review Points",
            "partOf": "prompt-chain-framework",
            "lines": "1410-1415",
            "crossModule": true,
            "hydration_status": "failed"
          }
        ],
        "patterns": [
          {
            "id": "system-instruction-pattern",
            "title": "GPT System Instruction Pattern",
            "purpose": "Define GPT behavior and expertise",
            "lines": "100-170",
            "content": "Before building reusable tools, let's establish best practices for one-off prompt use.\n\n### The Anatomy of a Well-Documented One-Off Prompt\n\nEven if you're not building a reusable tool, documenting your prompts pays dividends:\n- You can find them later when you have a similar need\n- You can share them with teammates\n- You learn what works (building your prompt library over time)\n\n**Minimal documentation template:**\n\n```markdown",
            "hydration_source_header": "I. Using ChatGPT/Claude for One-Off IA Tasks (15 minutes)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "knowledge-file-pattern",
            "title": "Knowledge File Configuration Pattern",
            "purpose": "Add domain knowledge to GPTs",
            "lines": "175-240",
            "content": "[Your prompt with placeholders in BRACKETS]\n\nReplace:\n- [PLACEHOLDER_1]: Description of what goes here\n- [PLACEHOLDER_2]: Description of what goes here",
            "hydration_source_header": "Template Prompt:",
            "hydration_method": "line_proximity"
          },
          {
            "id": "conversation-starter-pattern",
            "title": "Conversation Starter Design",
            "purpose": "Guide users to common tasks",
            "lines": "245-300",
            "content": "**Cluster 1: [Suggested Category Name]** (confidence: 85%)\n- Card A (grouped here by 26/30 participants)\n- Card B (grouped here by 25/30 participants)\n- Card C (grouped here by 24/30 participants)\nParticipant labels used: \"Getting Started\" (12), \"Setup\" (8), \"Begin\" (6)\n\n[Repeat for all clusters]",
            "hydration_source_header": "High-Agreement Clusters (>70% consensus)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "chain-step-design",
            "title": "Prompt Chain Step Design",
            "purpose": "Structure individual chain steps",
            "lines": "410-480",
            "retrievalQuestions": [
              "How do I design prompt chain steps?"
            ],
            "content": "Whether using ChatGPT or Claude, effective custom IA tools share common elements:\n\n**1. Clear Identity & Purpose**\n```\nName: Card Sort Analyzer Pro\nDescription: Analyzes open and closed card sorting results to generate \nevidence-based IA recommendations, including similarity matrices, \nconsensus groupings, and suggested taxonomies.\n```\n\n**2. System Instructions (Custom Behavior)**\n```\nYou are an expert UX researcher specializing in card sort analysis. Your role is to:\n\n- Process card sort data systematically and generate similarity matrices\n- Identify high-agreement groupings (>70% consensus)\n- Flag conflicted cards that need human review\n- Suggest category structures based on participant behavior\n- Provide confidence levels for all recommendations\n- Format outputs as structured reports\n\nKey principles:\n- Always calculate and show percentage agreement\n- Never invent data or groupings not present in the input\n- Flag ambiguous patterns for human review\n- Use participant language when suggesting category names\n- Provide both statistical analysis and qualitative insights\n\nWhen you receive card sort data, first confirm:\n1. Data format (open vs. closed sort)\n2. Number of participants\n3. Number of cards\n4. Whether category names should be generated or validated\n\nThen proceed with systematic analysis.\n```\n\n**3. Reference Knowledge Base**\n\nUpload reference documents that the tool should always consider:\n\nFor a Card Sort Analyzer:\n- Card sort analysis best practices guide\n- Example similarity matrix calculations\n- Interpretation guidelines for agreement percentages\n- Common pitfalls in card sort analysis\n\nFor a Taxonomy Generator:\n- IA principles checklist\n- Di\u00c3\u00a1taxis framework documentation\n- Taxonomy evaluation criteria\n- Example high-quality taxonomies\n\n**4. Conversation Starters (Custom GPTs) / Example Prompts**\n\nProvide pre-written prompts users can click to get started:\n\n```\n- \"Analyze my open card sort with 30 participants\"\n- \"Generate similarity matrix from this data: [paste]\"\n- \"Compare my closed card sort results to my hypothesis\"\n- \"Identify conflicted cards requiring review\"\n```\n\n**5. Capabilities Configuration**\n\n- **Web browsing:** Enable for research tasks (e.g., competitive analysis)\n- **Code interpreter:** Enable for data analysis tasks (similarity matrices, statistics)\n- **DALL-E:** Usually not needed for IA tools\n- **File uploads:** Enable for uploading card sort data, content inventories, transcripts\n\n---",
            "hydration_source_header": "Anatomy of an Effective Custom GPT/Project",
            "hydration_method": "line_proximity"
          },
          {
            "id": "chain-validation-pattern",
            "title": "Chain Validation Pattern",
            "purpose": "Add quality checks between steps",
            "lines": "485-550",
            "content": "**Tutorial: Build a \"Taxonomy Quality Checker\" Custom GPT**\n\n**Step 1: Access Custom GPT creation**\n- ChatGPT: Click your profile \u2192 \"My GPTs\" \u2192 \"Create a GPT\"\n- Claude: Create new project \u2192 Add custom instructions\n\n**Step 2: Define basic information**\n\n*Name:* Taxonomy Quality Checker\n\n*Description:* Evaluates taxonomy structures against IA best practices, identifying issues with depth, balance, granularity, mutual exclusivity, and labeling. Provides scored assessment and actionable improvement recommendations.\n\n**Step 3: Write system instructions**\n\n```\nYou are a senior information architect specializing in taxonomy evaluation.\n\nYour role is to assess taxonomy structures systematically against five core criteria:\n1. Depth (appropriate hierarchy levels for content volume)\n2. Balance (even distribution, no category >40% of content)\n3. Granularity (parallel level of specificity across categories)\n4. Mutual Exclusivity (clear boundaries, minimal overlap)\n5. Labeling (clear, consistent, user-friendly)\n\nWORKFLOW:\n\nWhen a user shares a taxonomy, first ask clarifying questions if needed:\n- Content volume (how many items total?)\n- Content domain (software docs, website, knowledge base?)\n- Primary user audience\n- Existing pain points (if known)\n\nThen evaluate systematically:\n\n1. DEPTH CHECK\n   - Count hierarchy levels\n   - Assess if depth matches content volume\n   - Identify overly deep or shallow areas\n   - Score: 1-5 (5 = ideal depth)\n\n2. BALANCE CHECK\n   - Calculate % distribution across top-level categories\n   - Identify unbalanced categories (>40% or <5%)\n   - Check for consistent balance at each level\n   - Score: 1-5 (5 = well-balanced)\n\n3. GRANULARITY CHECK\n   - Assess parallel specificity across categories\n   - Identify mismatched abstraction levels\n   - Check subcategory consistency\n   - Score: 1-5 (5 = consistent granularity)\n\n4. MUTUAL EXCLUSIVITY CHECK\n   - Identify overlapping categories\n   - Find ambiguous boundaries\n   - Note content that fits multiple places\n   - Score: 1-5 (5 = clear boundaries)\n\n5. LABELING CHECK\n   - Evaluate clarity and scannability\n   - Check consistency (parallel construction)\n   - Assess user-friendliness\n   - Identify jargon or ambiguous terms\n   - Score: 1-5 (5 = excellent labels)\n\nFINAL OUTPUT:\n\nProvide:\n- Overall taxonomy health score (average of 5 criteria)\n- Score breakdown with reasoning for each criterion\n- Top 3-5 highest-priority improvements\n- Specific recommendations for each issue\n- Quick wins (easy improvements with high impact)\n\nAlways base recommendations on the specific taxonomy provided\u2014avoid generic advice.\n```\n\n**Step 4: Add reference knowledge**\n\nUpload documents:\n- `taxonomy-evaluation-checklist.md` (the 5-check system from Module 2.1)\n- `taxonomy-best-practices.md`\n- `example-good-taxonomy.txt` (well-structured example)\n- `example-problematic-taxonomy.txt` (example with issues annotated)\n\n**Step 5: Configure capabilities**\n\n- \u2705 Code Interpreter: ON (for calculating percentages, distributions)\n- \u274c Web Browsing: OFF (not needed for this tool)\n- \u274c DALL-E: OFF (not needed)\n\n**Step 6: Create conversation starters**\n\n```\n1. \"Evaluate my documentation taxonomy (paste below)\"\n2. \"Check if my taxonomy is too deep\"\n3. \"Assess category balance across my IA\"\n4. \"Review my navigation label clarity\"\n```\n\n**Step 7: Test thoroughly**\n\nBefore sharing, test with:\n- \u2705 Well-structured taxonomy (should score high)\n- \u2705 Taxonomy with known issues (should catch them)\n- \u2705 Edge cases (very small taxonomy, very large, unusual structure)\n- \u2705 Incomplete input (should ask clarifying questions)\n\n**Step 8: Refine based on testing**\n\nCommon refinements after testing:\n- Add more specific examples to instructions\n- Clarify what to do with edge cases\n- Adjust scoring guidelines\n- Add validation checks\n\n**Step 9: Save and share**\n\n- **Private:** Only you can access\n- **Team:** Anyone in your workspace/project can access\n- **Public:** (Custom GPTs only) Publish to GPT store\n\n---",
            "hydration_source_header": "Step-by-Step: Creating a Custom GPT",
            "hydration_method": "line_proximity"
          },
          {
            "id": "template-design-pattern",
            "title": "Template Design Pattern",
            "purpose": "Create reusable prompt templates",
            "lines": "760-850",
            "hydration_status": "failed"
          },
          {
            "id": "automation-workflow-pattern",
            "title": "Automation Workflow Pattern",
            "purpose": "Connect prompts to triggers",
            "lines": "860-950",
            "retrievalQuestions": [
              "How do I automate IA tasks?"
            ],
            "hydration_status": "failed"
          }
        ],
        "promptPatterns": [
          {
            "id": "gpt-system-prompt",
            "title": "IA Assistant System Prompt",
            "taskType": "configuration",
            "lines": "110-155",
            "standalone": true,
            "retrievalQuestions": [
              "Give me a system prompt for an IA assistant GPT"
            ],
            "content": "Even if you're not building a reusable tool, documenting your prompts pays dividends:\n- You can find them later when you have a similar need\n- You can share them with teammates\n- You learn what works (building your prompt library over time)\n\n**Minimal documentation template:**\n\n```markdown",
            "hydration_source_header": "The Anatomy of a Well-Documented One-Off Prompt",
            "hydration_method": "line_proximity"
          },
          {
            "id": "taxonomy-helper-prompt",
            "title": "Taxonomy Helper GPT System Prompt",
            "taskType": "configuration",
            "lines": "170-210",
            "standalone": true,
            "content": "[Your prompt with placeholders in BRACKETS]\n\nReplace:\n- [PLACEHOLDER_1]: Description of what goes here\n- [PLACEHOLDER_2]: Description of what goes here",
            "hydration_source_header": "Template Prompt:",
            "hydration_method": "line_proximity"
          },
          {
            "id": "content-audit-gpt-prompt",
            "title": "Content Audit Helper GPT Prompt",
            "taskType": "configuration",
            "lines": "215-255",
            "standalone": true,
            "retrievalQuestions": [
              "System prompt for content audit GPT"
            ],
            "content": "```text\n[R - ROLE]\nYou're a UX researcher specializing in card sort analysis and information architecture research synthesis.\n\n[I - INSTRUCTIONS]\nAnalyze the open card sort data below and generate a comprehensive report.\n\nCreate:\n1. Similarity matrix showing how often each pair of cards was grouped together (calculate co-occurrence percentages)\n2. High-agreement clusters (cards grouped together by >70% of participants)\n3. List of conflicted cards (no clear grouping pattern, <50% agreement)\n4. Suggested category names based on participant language\n\n[C - CONTEXT]\nCARD SORT DATA:\n- [NUMBER] participants sorted [NUMBER] cards into their own categories\n- Open sort: participants created their own category names\n\nPARTICIPANT DATA:\n[Paste card sort results in this format:]\nParticipant ID, Card Name, Category Assigned\n\nExample:\nP01, \"Authentication Overview\", \"Getting Started\"\nP01, \"OAuth 2.0 Flow\", \"Security\"\nP02, \"Authentication Overview\", \"Security Basics\"\n...\n\n[E - EXPECTED FORMAT]\nStructure your report as follows:",
            "hydration_source_header": "Template Prompt:",
            "hydration_method": "line_proximity"
          },
          {
            "id": "navigation-designer-prompt",
            "title": "Navigation Designer GPT Prompt",
            "taskType": "configuration",
            "lines": "260-300",
            "standalone": true,
            "content": "- Confidence scores based on participant agreement percentages\n- Category names prioritize participant language over researcher interpretation\n```",
            "hydration_source_header": "Notes",
            "hydration_method": "line_proximity"
          },
          {
            "id": "chain-step-1-extract",
            "title": "Chain Step 1: Content Extraction",
            "taskType": "extraction",
            "lines": "425-450",
            "standalone": false,
            "content": "Whether using ChatGPT or Claude, effective custom IA tools share common elements:\n\n**1. Clear Identity & Purpose**\n```\nName: Card Sort Analyzer Pro\nDescription: Analyzes open and closed card sorting results to generate \nevidence-based IA recommendations, including similarity matrices, \nconsensus groupings, and suggested taxonomies.\n```\n\n**2. System Instructions (Custom Behavior)**\n```\nYou are an expert UX researcher specializing in card sort analysis. Your role is to:\n\n- Process card sort data systematically and generate similarity matrices\n- Identify high-agreement groupings (>70% consensus)\n- Flag conflicted cards that need human review\n- Suggest category structures based on participant behavior\n- Provide confidence levels for all recommendations\n- Format outputs as structured reports\n\nKey principles:\n- Always calculate and show percentage agreement\n- Never invent data or groupings not present in the input\n- Flag ambiguous patterns for human review\n- Use participant language when suggesting category names\n- Provide both statistical analysis and qualitative insights\n\nWhen you receive card sort data, first confirm:\n1. Data format (open vs. closed sort)\n2. Number of participants\n3. Number of cards\n4. Whether category names should be generated or validated\n\nThen proceed with systematic analysis.\n```\n\n**3. Reference Knowledge Base**\n\nUpload reference documents that the tool should always consider:\n\nFor a Card Sort Analyzer:\n- Card sort analysis best practices guide\n- Example similarity matrix calculations\n- Interpretation guidelines for agreement percentages\n- Common pitfalls in card sort analysis\n\nFor a Taxonomy Generator:\n- IA principles checklist\n- Di\u00c3\u00a1taxis framework documentation\n- Taxonomy evaluation criteria\n- Example high-quality taxonomies\n\n**4. Conversation Starters (Custom GPTs) / Example Prompts**\n\nProvide pre-written prompts users can click to get started:\n\n```\n- \"Analyze my open card sort with 30 participants\"\n- \"Generate similarity matrix from this data: [paste]\"\n- \"Compare my closed card sort results to my hypothesis\"\n- \"Identify conflicted cards requiring review\"\n```\n\n**5. Capabilities Configuration**\n\n- **Web browsing:** Enable for research tasks (e.g., competitive analysis)\n- **Code interpreter:** Enable for data analysis tasks (similarity matrices, statistics)\n- **DALL-E:** Usually not needed for IA tools\n- **File uploads:** Enable for uploading card sort data, content inventories, transcripts\n\n---",
            "hydration_source_header": "Anatomy of an Effective Custom GPT/Project",
            "hydration_method": "line_proximity"
          },
          {
            "id": "chain-step-2-analyze",
            "title": "Chain Step 2: Pattern Analysis",
            "taskType": "analysis",
            "lines": "455-480",
            "standalone": false,
            "hydration_status": "failed"
          },
          {
            "id": "chain-step-3-recommend",
            "title": "Chain Step 3: Recommendations",
            "taskType": "generation",
            "lines": "485-510",
            "standalone": false,
            "content": "**Tutorial: Build a \"Taxonomy Quality Checker\" Custom GPT**\n\n**Step 1: Access Custom GPT creation**\n- ChatGPT: Click your profile \u2192 \"My GPTs\" \u2192 \"Create a GPT\"\n- Claude: Create new project \u2192 Add custom instructions\n\n**Step 2: Define basic information**\n\n*Name:* Taxonomy Quality Checker\n\n*Description:* Evaluates taxonomy structures against IA best practices, identifying issues with depth, balance, granularity, mutual exclusivity, and labeling. Provides scored assessment and actionable improvement recommendations.\n\n**Step 3: Write system instructions**\n\n```\nYou are a senior information architect specializing in taxonomy evaluation.\n\nYour role is to assess taxonomy structures systematically against five core criteria:\n1. Depth (appropriate hierarchy levels for content volume)\n2. Balance (even distribution, no category >40% of content)\n3. Granularity (parallel level of specificity across categories)\n4. Mutual Exclusivity (clear boundaries, minimal overlap)\n5. Labeling (clear, consistent, user-friendly)\n\nWORKFLOW:\n\nWhen a user shares a taxonomy, first ask clarifying questions if needed:\n- Content volume (how many items total?)\n- Content domain (software docs, website, knowledge base?)\n- Primary user audience\n- Existing pain points (if known)\n\nThen evaluate systematically:\n\n1. DEPTH CHECK\n   - Count hierarchy levels\n   - Assess if depth matches content volume\n   - Identify overly deep or shallow areas\n   - Score: 1-5 (5 = ideal depth)\n\n2. BALANCE CHECK\n   - Calculate % distribution across top-level categories\n   - Identify unbalanced categories (>40% or <5%)\n   - Check for consistent balance at each level\n   - Score: 1-5 (5 = well-balanced)\n\n3. GRANULARITY CHECK\n   - Assess parallel specificity across categories\n   - Identify mismatched abstraction levels\n   - Check subcategory consistency\n   - Score: 1-5 (5 = consistent granularity)\n\n4. MUTUAL EXCLUSIVITY CHECK\n   - Identify overlapping categories\n   - Find ambiguous boundaries\n   - Note content that fits multiple places\n   - Score: 1-5 (5 = clear boundaries)\n\n5. LABELING CHECK\n   - Evaluate clarity and scannability\n   - Check consistency (parallel construction)\n   - Assess user-friendliness\n   - Identify jargon or ambiguous terms\n   - Score: 1-5 (5 = excellent labels)\n\nFINAL OUTPUT:\n\nProvide:\n- Overall taxonomy health score (average of 5 criteria)\n- Score breakdown with reasoning for each criterion\n- Top 3-5 highest-priority improvements\n- Specific recommendations for each issue\n- Quick wins (easy improvements with high impact)\n\nAlways base recommendations on the specific taxonomy provided\u2014avoid generic advice.\n```\n\n**Step 4: Add reference knowledge**\n\nUpload documents:\n- `taxonomy-evaluation-checklist.md` (the 5-check system from Module 2.1)\n- `taxonomy-best-practices.md`\n- `example-good-taxonomy.txt` (well-structured example)\n- `example-problematic-taxonomy.txt` (example with issues annotated)\n\n**Step 5: Configure capabilities**\n\n- \u2705 Code Interpreter: ON (for calculating percentages, distributions)\n- \u274c Web Browsing: OFF (not needed for this tool)\n- \u274c DALL-E: OFF (not needed)\n\n**Step 6: Create conversation starters**\n\n```\n1. \"Evaluate my documentation taxonomy (paste below)\"\n2. \"Check if my taxonomy is too deep\"\n3. \"Assess category balance across my IA\"\n4. \"Review my navigation label clarity\"\n```\n\n**Step 7: Test thoroughly**\n\nBefore sharing, test with:\n- \u2705 Well-structured taxonomy (should score high)\n- \u2705 Taxonomy with known issues (should catch them)\n- \u2705 Edge cases (very small taxonomy, very large, unusual structure)\n- \u2705 Incomplete input (should ask clarifying questions)\n\n**Step 8: Refine based on testing**\n\nCommon refinements after testing:\n- Add more specific examples to instructions\n- Clarify what to do with edge cases\n- Adjust scoring guidelines\n- Add validation checks\n\n**Step 9: Save and share**\n\n- **Private:** Only you can access\n- **Team:** Anyone in your workspace/project can access\n- **Public:** (Custom GPTs only) Publish to GPT store\n\n---",
            "hydration_source_header": "Step-by-Step: Creating a Custom GPT",
            "hydration_method": "line_proximity"
          },
          {
            "id": "chain-step-4-validate",
            "title": "Chain Step 4: Validation",
            "taskType": "validation",
            "lines": "515-540",
            "standalone": false,
            "retrievalQuestions": [
              "Show me a complete prompt chain for IA work"
            ],
            "content": "Check the validation results:\n- Depth: appropriate?\n- Balance: any category >40%?\n- Granularity: parallel levels?\n- Labels: clear and scannable?",
            "hydration_source_header": "Step 4: Validate",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "concepts": [
          {
            "id": "custom-gpt",
            "term": "Custom GPT",
            "definition": "Configured ChatGPT instance with specific instructions and knowledge",
            "lines": "85-100",
            "retrievalQuestions": [
              "What is a custom GPT?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "system-instructions",
            "term": "System Instructions",
            "definition": "Persistent instructions that define GPT behavior",
            "lines": "105-115",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "knowledge-files",
            "term": "Knowledge Files",
            "definition": "Documents uploaded to provide domain context",
            "lines": "175-185",
            "retrievalQuestions": [
              "What are GPT knowledge files?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "conversation-starters",
            "term": "Conversation Starters",
            "definition": "Suggested prompts to begin interactions",
            "lines": "245-255",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "prompt-chain",
            "term": "Prompt Chain",
            "definition": "Sequence of prompts where output of one feeds next",
            "lines": "390-405",
            "retrievalQuestions": [
              "What is a prompt chain?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "chain-step",
            "term": "Chain Step",
            "definition": "Individual prompt in a chain sequence",
            "lines": "410-420",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "validation-loop",
            "term": "Validation Loop",
            "definition": "Quality check between chain steps",
            "lines": "485-500",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "prompt-template",
            "term": "Prompt Template",
            "definition": "Reusable prompt with placeholders",
            "lines": "760-775",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "automation-trigger",
            "term": "Automation Trigger",
            "definition": "Event that starts an automated workflow",
            "lines": "860-875",
            "retrievalQuestions": [
              "What triggers can start IA automations?"
            ],
            "hydration_status": "skipped_unknown"
          }
        ],
        "toolSpecifications": [
          {
            "id": "taxonomy-helper-gpt",
            "title": "Taxonomy Helper GPT",
            "purpose": "Assist with taxonomy development",
            "features": [
              "term suggestions",
              "hierarchy review",
              "definition generation"
            ],
            "lines": "170-250",
            "retrievalQuestions": [
              "How do I build a taxonomy helper GPT?"
            ],
            "content": "[Your prompt with placeholders in BRACKETS]\n\nReplace:\n- [PLACEHOLDER_1]: Description of what goes here\n- [PLACEHOLDER_2]: Description of what goes here",
            "hydration_source_header": "Template Prompt:",
            "hydration_method": "line_proximity"
          },
          {
            "id": "content-audit-gpt",
            "title": "Content Audit Helper GPT",
            "purpose": "Assist with content audits",
            "features": [
              "quality assessment",
              "gap identification",
              "recommendations"
            ],
            "lines": "255-340",
            "content": "**Tool Type:** Prompt Chain\n\n**Purpose:** Systematically audit documentation for duplicates, gaps, and quality issues.\n\n**Chain Structure:**\n\n```\nSTAGE 1: Inventory Processing\n\u251c\u2500 Input: Raw content list\n\u251c\u2500 Process: Categorize, extract metadata\n\u2514\u2500 Output: Structured inventory\n\nSTAGE 2: Duplicate Detection\n\u251c\u2500 Input: Structured inventory\n\u251c\u2500 Process: Identify overlaps\n\u2514\u2500 Output: Duplicate clusters\n\nSTAGE 3: Gap Analysis  \n\u251c\u2500 Input: Inventory + User journey\n\u251c\u2500 Process: Map coverage, find gaps\n\u2514\u2500 Output: Prioritized gap list\n\nSTAGE 4: Quality Assessment\n\u251c\u2500 Input: Inventory + gaps\n\u251c\u2500 Process: Score quality signals\n\u2514\u2500 Output: Improvement priorities\n\nSTAGE 5: Recommendations\n\u251c\u2500 Input: All previous outputs\n\u251c\u2500 Process: Synthesize into action plan\n\u2514\u2500 Output: Prioritized roadmap\n```\n\n**Stage 1 Prompt:**\n\n```\nCONTENT AUDIT - Stage 1: Inventory Processing\n\nYou're preparing a content inventory for systematic audit.\n\nRAW CONTENT LIST:\n[User pastes list with titles, URLs, brief descriptions]\n\nPROCESS:\n1. Categorize each item by content type:\n   - Tutorial (learning-oriented)\n   - How-to Guide (task-oriented)\n   - Reference (information-oriented)\n   - Explanation (understanding-oriented)\n   - Other (specify)\n\n2. Extract metadata:\n   - Title\n   - Primary topic/feature\n   - Target audience level (beginner/intermediate/advanced)\n   - Estimated word count category (<500, 500-1500, >1500)\n\n3. Organize into structured table\n\nOUTPUT FORMAT:\nProvide results as structured markdown with:",
            "hydration_source_header": "Tool 2: Content Audit Analyzer",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "navigation-designer-gpt",
            "title": "Navigation Designer GPT",
            "purpose": "Help design navigation",
            "features": [
              "label suggestions",
              "structure analysis",
              "mobile patterns"
            ],
            "lines": "345-420",
            "retrievalQuestions": [
              "What GPT helps with navigation design?"
            ],
            "content": "Even without formal tools, an organized library of prompts is incredibly valuable.\n\n**Organizational structure:**\n\n```\nmy-ia-prompts/\n\u251c\u2500\u2500 taxonomy-generation/\n\u2502   \u251c\u2500\u2500 hierarchical-taxonomy-template.md\n\u2502   \u251c\u2500\u2500 faceted-classification-template.md\n\u2502   \u2514\u2500\u2500 diataxis-documentation-taxonomy.md\n\u251c\u2500\u2500 content-modeling/\n\u2502   \u251c\u2500\u2500 content-type-identification.md\n\u2502   \u251c\u2500\u2500 metadata-schema-generation.md\n\u2502   \u2514\u2500\u2500 relationship-mapping.md\n\u251c\u2500\u2500 navigation-design/\n\u2502   \u251c\u2500\u2500 label-variation-generator.md\n\u2502   \u251c\u2500\u2500 information-scent-evaluator.md\n\u2502   \u2514\u2500\u2500 menu-depth-analyzer.md\n\u251c\u2500\u2500 content-audit/\n\u2502   \u251c\u2500\u2500 duplicate-detector.md\n\u2502   \u251c\u2500\u2500 gap-analysis-template.md\n\u2502   \u2514\u2500\u2500 quality-assessment.md\n\u251c\u2500\u2500 research-synthesis/\n\u2502   \u251c\u2500\u2500 card-sort-analyzer.md\n\u2502   \u251c\u2500\u2500 interview-transcript-themes.md\n\u2502   \u2514\u2500\u2500 survey-data-synthesis.md\n\u2514\u2500\u2500 findability/\n    \u251c\u2500\u2500 synonym-generator.md\n    \u251c\u2500\u2500 search-query-analyzer.md\n    \u2514\u2500\u2500 seo-optimization-prompt.md\n```\n\n**Each file contains:**\n- Template prompt with placeholders\n- When to use it\n- What inputs are needed\n- Sample usage\n- Refinement notes\n\n**Maintenance tips:**\n- \u2705 Date each template when you update it\n- \u2705 Note what changes you made and why\n- \u2705 Keep a \"greatest hits\" folder with your most effective prompts\n- \u2705 Review quarterly and retire prompts that no longer work well\n- \u2705 Share with teammates via GitHub, Notion, or shared drives\n\n---",
            "hydration_source_header": "Building Your One-Off Prompt Library",
            "hydration_method": "line_proximity"
          },
          {
            "id": "ia-documentation-gpt",
            "title": "IA Documentation GPT",
            "purpose": "Generate IA documentation",
            "features": [
              "ADR generation",
              "diagram creation",
              "specification writing"
            ],
            "lines": "425-500",
            "content": "- [ ] Are examples still relevant?\n- [ ] Do instructions need clarification?\n- [ ] Are troubleshooting guides complete?",
            "hydration_source_header": "Documentation Review",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "chainTemplates": [
          {
            "id": "content-audit-chain",
            "title": "Content Audit Chain (4 steps)",
            "purpose": "Full content audit workflow",
            "steps": [
              "inventory-extraction",
              "quality-analysis",
              "gap-identification",
              "recommendations"
            ],
            "lines": "555-680",
            "retrievalQuestions": [
              "Give me a content audit prompt chain"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "taxonomy-development-chain",
            "title": "Taxonomy Development Chain (3 steps)",
            "purpose": "Develop taxonomy from content",
            "steps": [
              "term-extraction",
              "grouping",
              "hierarchy-generation"
            ],
            "lines": "685-780",
            "retrievalQuestions": [
              "Show me a taxonomy development chain"
            ],
            "content": "**Use chaining when:**\n- \u2705 The task has natural stages (analysis \u2192 synthesis \u2192 validation)\n- \u2705 Each stage requires different thinking or criteria\n- \u2705 Intermediate outputs need human review or decision points\n- \u2705 A single prompt would be too complex or hit context limits\n- \u2705 You want checkpoints to course-correct if needed\n\n**Use a single complex prompt when:**\n- \u2705 The task is straightforward with one clear output\n- \u2705 All steps can happen automatically without review\n- \u2705 Context from earlier steps isn't needed later\n- \u2705 Speed is more important than control\n\n---",
            "hydration_source_header": "When to Use Prompt Chaining",
            "hydration_method": "line_proximity"
          },
          {
            "id": "navigation-optimization-chain",
            "title": "Navigation Optimization Chain (4 steps)",
            "purpose": "Improve navigation structure",
            "steps": [
              "current-analysis",
              "label-evaluation",
              "restructuring",
              "validation"
            ],
            "lines": "785-900",
            "content": "Let's build a complete prompt chain for analyzing card sort results.\n\n**PROMPT 1: Data Validation & Preparation**\n\n```text\n[R - ROLE]\nYou're a data analyst preparing card sort research data for statistical analysis.\n\n[I - INSTRUCTIONS]\nValidate and transform the raw card sort data below.\n\nVALIDATE these aspects:\n1. Data format (confirm open vs. closed sort)\n2. Completeness (verify all participants and cards are accounted for)\n3. Data integrity (check for obvious errors, duplicates, or formatting issues)\n4. Confirm participant count and card count\n\nTRANSFORM the data:\n- Convert to standardized format: Participant ID | Card Name | Category Assigned\n- Remove any invalid entries\n- Standardize formatting (consistent quotes, delimiters, capitalization)\n\nFLAG any issues requiring human attention before analysis.\n\n[C - CONTEXT]\nRAW DATA:\n[User pastes card sort export from tool - may be CSV, JSON, or other format]\n\nExpected data structure:\n- Each row represents one card sort assignment\n- Should include: participant identifier, card name, assigned category\n- May have additional columns (timestamps, demographics) - preserve but note\n\n[E - EXPECTED OUTPUT]\nProvide:\n1. **Validation Report**\n   - Data format detected: [Open/Closed sort]\n   - Total participants: [number]\n   - Total cards: [number]\n   - Issues found: [list any problems]\n\n2. **Standardized Data**\n   ```\n   P01 | Authentication Overview | Getting Started\n   P01 | OAuth 2.0 Flow | Security\n   P02 | Authentication Overview | Security Basics\n   ...\n   ```\n\n3. **Flags for Human Review** (if any)\n   - [List any anomalies, missing data, or ambiguities]\n\nStatus: [READY FOR ANALYSIS / REQUIRES HUMAN REVIEW]\n```\n\n**Human checkpoint:** Review flagged issues, confirm data is correct.\n\n---\n\n**PROMPT 2: Similarity Matrix Generation**\n\n```text\n[R - ROLE]\nYou're a UX researcher calculating card sort similarity metrics to identify grouping patterns.\n\n[I - INSTRUCTIONS]\nCalculate card co-occurrence patterns from the validated card sort data.\n\nCALCULATE for each pair of cards:\n1. How many participants grouped them together (same category)\n2. Co-occurrence percentage (count \u00f7 total participants \u00d7 100)\n3. Classify agreement level:\n   - High consensus: >70% agreement\n   - Moderate consensus: 50-70% agreement\n   - Low consensus: <50% agreement\n\nGENERATE:\n- Complete similarity matrix showing all pairwise relationships\n- Ranked list of card pairs by agreement percentage\n- Statistical summary of the distribution\n\n[C - CONTEXT]\nVALIDATED DATA FROM PROMPT 1:\n[Paste standardized output from Prompt 1]\n\nCalculation method:\n- For cards A and B, count how many participants put them in the same category\n- Divide by total number of participants\n- Express as percentage\n\n[E - EXPECTED OUTPUT]\nProvide:\n\n1. **Similarity Matrix (Excerpt)**\n   ```\n   Card Pair                                    Co-occurrence    Agreement %\n   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   Authentication Overview + OAuth 2.0          26/30           87%\n   Rate Limits + API Status                     24/30           80%\n   Getting Started + Quickstart                 23/30           77%\n   ...\n   (Show top 15-20 pairs)\n   ```\n\n2. **High Consensus Pairs (>70% agreement)**\n   - List all card pairs with strong grouping consensus\n   - [Total count of high-consensus pairs]\n\n3. **Conflicted Pairs (<40% agreement)**\n   - List card pairs with no clear grouping pattern\n   - These indicate cards may fit multiple categories or be ambiguous\n\n4. **Summary Statistics**\n   - Median agreement: [percentage]\n   - Mean agreement: [percentage]\n   - Distribution: [X% high consensus, Y% moderate, Z% low]\n   - Most agreed pair: [cards] at [percentage]\n   - Least agreed pair: [cards] at [percentage]\n```\n\n**Human checkpoint:** Scan for unexpected patterns or clear errors.\n\n---\n\n**PROMPT 3: Cluster Identification**\n\n```text\n[R - ROLE]\nYou're a UX researcher applying clustering analysis to identify natural content groupings from card sort data.\n\n[I - INSTRUCTIONS]\nIdentify natural card clusters based on co-occurrence patterns from the similarity matrix.\n\nIDENTIFY clusters using this process:\n1. Start with highest-agreement card pairs (>70%)\n2. Expand each pair to include closely related cards\n3. Stop expanding when agreement drops below 60%\n4. For each resulting cluster:\n   - List all cards included\n   - Calculate average internal agreement percentage\n   - Assign confidence level (High >75%, Medium 60-75%, Low <60%)\n\nANALYZE special cases:\n- Singleton cards: cards that don't fit any cluster\n- Overlapping clusters: cards that could belong to multiple groups\n- Fragmented clusters: groupings with internal disagreement\n\n[C - CONTEXT]\nSIMILARITY DATA FROM PROMPT 2:\n[Paste similarity matrix and statistics from Prompt 2]\n\nClustering approach:\n- Use hierarchical clustering logic\n- Prioritize high-consensus relationships\n- Natural clusters should have >60% internal agreement\n- Typical result: 5-10 clusters for 40-60 cards\n\n[E - EXPECTED OUTPUT]\nProvide:\n\n**IDENTIFIED CLUSTERS**\n\n**Cluster 1: [Descriptive name based on content]**\n- Confidence: High (82% avg internal agreement)\n- Cards (6 total):\n  * Authentication Overview (grouped with cluster 85% of time)\n  * OAuth 2.0 Flow (grouped with cluster 83% of time)\n  * API Keys Guide (grouped with cluster 80% of time)\n  * Security Best Practices (grouped with cluster 79% of time)\n  * Token Management (grouped with cluster 82% of time)\n  * Session Handling (grouped with cluster 84% of time)\n\n[Repeat for all clusters]\n\n**SINGLETON CARDS** (don't fit any cluster):\n- [Card name]: Grouped inconsistently across categories\n- [Card name]: Split evenly between 3+ potential clusters\n\n**OVERLAPPING CARDS** (fit multiple clusters):\n- [Card name]: 65% in Cluster A, 55% in Cluster B (ambiguous placement)\n\n**SUMMARY**\n- Total clusters identified: [number]\n- Cards successfully clustered: [number/total]\n- Singleton cards needing review: [number]\n- Average cluster confidence: [percentage]\n```\n\n**Human checkpoint:** Do clusters make intuitive sense? Any surprising groupings?\n\n---\n\n**PROMPT 4: Category Naming**\n\n```text\n[R - ROLE]\nYou're a UX writer and information architect creating category labels based on user mental models from card sort data.\n\n[I - INSTRUCTIONS]\nGenerate category name options for each cluster, prioritizing participant language.\n\nFor each cluster, ANALYZE:\n1. What category names participants most frequently used for these cards\n2. Conceptual themes connecting cards in the cluster\n3. Parallel structure with other category names\n\nPROPOSE 3 naming options per cluster that:\n- Reflect participant vocabulary (not researcher jargon)\n- Clearly convey cluster contents\n- Use parallel grammatical structure\n- Are scannable (under 30 characters)\n- Have strong information scent\n\nFor each name option, PROVIDE:\n- Rationale (why this name fits the cluster)\n- Pros and cons\n- Card fit assessment (which cards align best/worst with this name)\n\n[C - CONTEXT]\nIDENTIFIED CLUSTERS FROM PROMPT 3:\n[Paste cluster analysis from Prompt 3]\n\nPARTICIPANT CATEGORY NAMES:\n[Paste: Original category names participants used for cards in each cluster]\n\nExample format:\nCluster 1 cards - participant names used:\n- \"Authentication Overview\" \u2192 \"Getting Started\" (12 participants), \"Security\" (8), \"Setup\" (6)\n- \"OAuth 2.0 Flow\" \u2192 \"Security\" (15 participants), \"Authentication\" (10), \"Setup\" (5)\n...\n\n[E - EXPECTED OUTPUT]\nFormat as follows:\n\n**CLUSTER 1: [Current descriptive name]**\n\n**Option 1: \"Authentication & Security\"**\n- Rationale: Combines two most common participant labels (\"Authentication\" + \"Security\")\n- Pros: Comprehensive, clear scope, aligns with 23/30 participants' language\n- Cons: Slightly long (24 chars), combines two concepts\n- Card fit: All 6 cards align strongly with this name\n\n**Option 2: \"Security Basics\"**\n- Rationale: Second most common participant label (used by 18/30)\n- Pros: Concise (14 chars), friendly tone (\"Basics\"), beginner-focused\n- Cons: \"Basics\" might imply advanced security is elsewhere\n- Card fit: \"Security Best Practices\" less aligned (suggests advanced content)\n\n**Option 3: \"Get Started with Security\"**\n- Rationale: Merges journey stage with topic\n- Pros: Action-oriented, clear for beginners\n- Cons: Long (27 chars), mixes navigation styles\n- Card fit: Strong for authentication cards, weaker for general security\n\n**Recommendation:** Option 1 (\"Authentication & Security\")\n- Best reflects participant mental models\n- Accommodates all cluster cards without forcing fit\n- Clear information scent for target content\n\n[Repeat for all clusters]\n\n**CROSS-CLUSTER VALIDATION:**\n- All proposed names use parallel structure: [Yes/No, explain]\n- Information scent rating (average): [1-5]\n- Names cover all cards without overlaps: [Yes/No, list gaps]\n```\n\n**Human checkpoint:** Select preferred category names, adjust as needed.\n\n---\n\n**PROMPT 5: Taxonomy Structure Recommendation**\n\n```text\n[R - ROLE]\nYou're an information architect synthesizing card sort findings into a final taxonomy recommendation ready for implementation.\n\n[I - INSTRUCTIONS]\nCreate a complete taxonomy structure based on finalized clusters and category names.\n\nSYNTHESIZE:\n1. Organize all cards under their assigned categories\n2. Calculate content distribution percentages\n3. Assess balance (no category should exceed 40% of content)\n4. Identify any gaps or singleton cards needing placement decisions\n5. Provide implementation-ready structure\n\nVALIDATE against IA best practices:\n- Depth: appropriate for content volume\n- Balance: even distribution across categories\n- Mutual exclusivity: minimal overlap between categories\n- Labeling: clear, parallel structure\n\nDOCUMENT rationale for structure decisions\n\n[C - CONTEXT]\nFINALIZED CLUSTERS WITH SELECTED NAMES FROM PROMPT 4:\n[Paste: Selected category names and their associated cards]\n\nORIGINAL CARD DESCRIPTIONS:\n[Paste: List of all cards with brief descriptions of their content]\n\nTotal cards: [number]\nExpected categories: 5-10\n\n[E - EXPECTED OUTPUT]\nProvide complete taxonomy recommendation:\n\n**RECOMMENDED TAXONOMY STRUCTURE**\n\n```\nAPI Documentation (48 cards total)\n\u2502\n\u251c\u2500\u2500 Authentication & Security (8 cards, 17%)\n\u2502   \u251c\u2500\u2500 Authentication Overview\n\u2502   \u251c\u2500\u2500 OAuth 2.0 Flow\n\u2502   \u251c\u2500\u2500 API Keys Guide\n\u2502   \u251c\u2500\u2500 Security Best Practices\n\u2502   \u251c\u2500\u2500 Token Management\n\u2502   \u251c\u2500\u2500 Session Handling\n\u2502   \u251c\u2500\u2500 Two-Factor Authentication\n\u2502   \u2514\u2500\u2500 Security Audit Log\n\u2502\n\u251c\u2500\u2500 Getting Started (10 cards, 21%)\n\u2502   \u251c\u2500\u2500 Quickstart Guide\n\u2502   \u251c\u2500\u2500 Installation\n\u2502   \u251c\u2500\u2500 Configuration\n\u2502   \u251c\u2500\u2500 First API Call\n\u2502   \u2514\u2500\u2500 [remaining cards...]\n\u2502\n\u251c\u2500\u2500 API Reference (15 cards, 31%)\n\u2502   \u251c\u2500\u2500 Users Endpoint\n\u2502   \u251c\u2500\u2500 Products Endpoint\n\u2502   \u2514\u2500\u2500 [remaining cards...]\n\u2502\n\u2514\u2500\u2500 [remaining categories...]\n```\n\n**RATIONALE FOR STRUCTURE:**\n\n**Top-Level Organization:**\n- Organized by user journey stage + technical depth\n- \"Getting Started\" first (beginner entry point)\n- \"API Reference\" central (most-used by developers)\n- Reflects participant grouping behavior (85%+ alignment)\n\n**Balance Assessment:**\n- Largest category: API Reference at 31% \u2713 (under 40% threshold)\n- Smallest category: [name] at 12% \u2713 (sufficient content)\n- Distribution: [list percentages] \u2713 (well-balanced)\n\n**Depth Decision:**\n- Flat 2-level structure appropriate for 48 cards\n- Deeper nesting unnecessary and would increase navigation cost\n- Matches 78% of participant mental models\n\n**CONFIDENCE LEVELS:**\n- High confidence (8 categories): [list] - strong participant consensus (>75%)\n- Medium confidence (1 category): [name] - moderate consensus (65%)\n- Low confidence cards requiring review: [number]\n\n**SINGLETON CARD PLACEMENT:**\n- [Card name]: Assigned to [category] based on [rationale]\n- [Card name]: Could fit [category A] or [category B] - recommend cross-linking\n\n**ALTERNATIVE STRUCTURES CONSIDERED:**\n\n**Alternative 1: By Content Type**\n- Tutorials / Reference / Guides / Examples\n- Rejected: Doesn't match participant behavior (only 35% organized this way)\n\n**Alternative 2: By Feature Area**\n- Users / Products / Orders / Webhooks\n- Rejected: Too product-centric, doesn't support task-based navigation\n\n**IMPLEMENTATION NOTES:**\n- Consider adding \"Popular Topics\" landing page highlighting most-accessed cards\n- Cross-link [card X] in both [category A] and [category B]\n- Search tags for ambiguous content: [list]\n\n**NEXT STEPS:**\n1. Review with stakeholders\n2. Validate with tree testing (target: 85% task success)\n3. Implement navigation structure\n4. Monitor analytics for adjustment needs\n```\n\n**Human checkpoint:** Review against IA principles, validate makes sense for users.\n\n---\n\n**PROMPT 6: Conflict Resolution Report**\n\n```\nCONTEXT: Recommended taxonomy has been reviewed.\n\nTAXONOMY:\n[Paste: Recommended structure from Prompt 5]\n\nLOW-CONSENSUS CARDS:\n[Paste: Cards with <40% agreement from earlier analysis]\n\nFor each conflicted card:\n1. Where did participants place it most often? (top 3 locations)\n2. Why might it be ambiguous? (multiple valid interpretations?)\n3. Recommendations:\n   - Primary placement (with rationale)\n   - Alternative access points (cross-links, search tags)\n   - Content clarification needed (to reduce ambiguity)\n   - Consider splitting into multiple pieces\n\nOUTPUT: Conflict resolution guide with specific recommendations.\n```\n\n**Human checkpoint:** Make final decisions on conflicted content placement.\n\n---",
            "hydration_source_header": "Practical Example: Card Sort Analysis Chain",
            "hydration_method": "line_proximity"
          }
        ],
        "examples": [
          {
            "id": "taxonomy-gpt-example",
            "title": "Complete Taxonomy Helper GPT",
            "demonstrates": "taxonomy-helper-gpt",
            "lines": "250-340",
            "content": "- **Card X**: No clear pattern (split across 5+ categories, max 40% agreement)\n- **Card Y**: Ambiguous placement (55% in Category A, 30% in Category B)",
            "hydration_source_header": "Conflicted Cards (Require Human Review)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "chain-example-full",
            "title": "Full Content Audit Chain Example",
            "demonstrates": "content-audit-chain",
            "lines": "620-680",
            "retrievalQuestions": [
              "Show me a complete prompt chain example"
            ],
            "content": "**Tool Type:** Prompt Chain\n\n**Purpose:** Systematically audit documentation for duplicates, gaps, and quality issues.\n\n**Chain Structure:**\n\n```\nSTAGE 1: Inventory Processing\n\u251c\u2500 Input: Raw content list\n\u251c\u2500 Process: Categorize, extract metadata\n\u2514\u2500 Output: Structured inventory\n\nSTAGE 2: Duplicate Detection\n\u251c\u2500 Input: Structured inventory\n\u251c\u2500 Process: Identify overlaps\n\u2514\u2500 Output: Duplicate clusters\n\nSTAGE 3: Gap Analysis  \n\u251c\u2500 Input: Inventory + User journey\n\u251c\u2500 Process: Map coverage, find gaps\n\u2514\u2500 Output: Prioritized gap list\n\nSTAGE 4: Quality Assessment\n\u251c\u2500 Input: Inventory + gaps\n\u251c\u2500 Process: Score quality signals\n\u2514\u2500 Output: Improvement priorities\n\nSTAGE 5: Recommendations\n\u251c\u2500 Input: All previous outputs\n\u251c\u2500 Process: Synthesize into action plan\n\u2514\u2500 Output: Prioritized roadmap\n```\n\n**Stage 1 Prompt:**\n\n```\nCONTENT AUDIT - Stage 1: Inventory Processing\n\nYou're preparing a content inventory for systematic audit.\n\nRAW CONTENT LIST:\n[User pastes list with titles, URLs, brief descriptions]\n\nPROCESS:\n1. Categorize each item by content type:\n   - Tutorial (learning-oriented)\n   - How-to Guide (task-oriented)\n   - Reference (information-oriented)\n   - Explanation (understanding-oriented)\n   - Other (specify)\n\n2. Extract metadata:\n   - Title\n   - Primary topic/feature\n   - Target audience level (beginner/intermediate/advanced)\n   - Estimated word count category (<500, 500-1500, >1500)\n\n3. Organize into structured table\n\nOUTPUT FORMAT:\nProvide results as structured markdown with:",
            "hydration_source_header": "Tool 2: Content Audit Analyzer",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "template-library-example",
            "title": "IA Template Library Example",
            "demonstrates": "template-design-pattern",
            "lines": "850-920",
            "content": "A collection of reusable prompts and tools for information architecture work.\n\n## Categories\n\n- **[Taxonomy](/taxonomy/)**: Tools for generating and validating taxonomies\n- **[Content Modeling](/content-modeling/)**: Content type and schema design\n- **[Navigation](/navigation/)**: Navigation structure and label optimization\n- **[Audit](/audit/)**: Content audit and gap analysis tools\n- **[Research](/research-synthesis/)**: Card sort, interview, and survey analysis\n- **[Findability](/findability/)**: Search optimization and SEO tools\n\n## Quick Links\n\n**Most Popular:**\n- [Taxonomy Generator](/taxonomy/hierarchical-generator.md)\n- [Card Sort Analyzer](/research-synthesis/card-sort-analyzer.md)\n- [Content Gap Analyzer](/audit/gap-analyzer.md)\n\n**Getting Started:**\n- [How to Use This Library](/quick-start.md)\n- [Tool Documentation Template](/templates/tool-documentation-template.md)\n- [Contributing Guidelines](/CONTRIBUTING.md)\n\n## Contributing\n\nFound a bug? Have a better prompt? See [CONTRIBUTING.md](CONTRIBUTING.md).\n\n## License\n\n[Choose appropriate license for your organization]\n```\n\n---\n\n### Maintenance & Evolution\n\n**Quarterly review process:**\n\n```markdown\n## Prompt Library Review Checklist\n\n**Review Date:** [Date]\n**Reviewer:** [Name]\n\nFor each tool category:\n\n### Usage Review\n- [ ] Which tools were used most?\n- [ ] Which haven't been used in 6+ months?\n- [ ] Are there requests for tools we don't have?\n\n### Quality Review\n- [ ] Do prompts still work well with latest LLM versions?\n- [ ] Have any prompts become less effective?\n- [ ] Are there new capabilities we should leverage?\n\n### Documentation Review\n- [ ] Are examples still relevant?\n- [ ] Do instructions need clarification?\n- [ ] Are troubleshooting guides complete?\n\n### Deprecation Decisions\n- [ ] Tools to archive (no longer effective)\n- [ ] Tools to merge (too similar)\n- [ ] Tools to split (trying to do too much)\n\n### New Development\n- [ ] Gaps to fill\n- [ ] Improvements to prioritize\n- [ ] Beta tools ready to promote\n\n### Actions\n1. [Specific action with owner and date]\n2. [...]\n```\n\n---\n\n## VI. Hands-on Tutorial: Build a Reusable Taxonomy Generator (25 minutes)\n\nLet's build a complete, documented taxonomy generator tool from scratch.\n\n### Tutorial Overview\n\n**What You'll Build:**\nA Custom GPT (or Claude Project) that generates task-based taxonomies for software documentation.\n\n**Time Required:** 25-30 minutes\n\n**You'll Learn:**\n- How to structure system instructions\n- What reference documents to include\n- How to test thoroughly\n- How to document for reuse\n\n---\n\n### Step 1: Plan Your Tool (5 minutes)\n\n**Answer these questions before building:**\n\n1. **What specific problem does this solve?**\n   - Generates 2-3 level taxonomies for software docs in 10 minutes vs. 2-3 hours manually\n\n2. **Who will use it?**\n   - Information architects\n   - Technical writers setting up new doc sites\n   - Product managers planning documentation\n\n3. **What makes a \"good\" output?**\n   - Balanced (no category >40%)\n   - 5-7 top-level categories\n   - Task-based organization\n   - Di\u00c3\u00a1taxis-aligned\n   - Clear, action-oriented labels\n\n4. **What inputs are required?**\n   - Content domain description\n   - Approximate page count\n   - Target audience\n   - Optional: content inventory\n\n5. **What's out of scope?**\n   - Won't handle non-documentation taxonomies\n   - Won't design faceted classification\n   - Won't create deep (4+ level) hierarchies\n\n---\n\n### Step 2: Write System Instructions (10 minutes)\n\n**Create the core prompt that defines your tool's behavior:**\n\n```\nTAXONOMY GENERATOR FOR SOFTWARE DOCUMENTATION\n==============================================\n\nYou are an expert information architect specializing in software documentation taxonomy design.\n\nPURPOSE:\nGenerate task-based, user-centered taxonomies for developer documentation that:\n- Follow Di\u00c3\u00a1taxis framework principles\n- Organize by user tasks rather than features (when possible)\n- Balance across 5-7 top-level categories\n- Support both browsing and search\n- Scale appropriately for content volume\n\nWORKFLOW:\n\n1. REQUIREMENTS GATHERING\nWhen a user requests a taxonomy, ask (if not provided):\n\nRequired:\n- Content domain (API docs? CLI tool? SDK? Framework?)\n- Approximate page/article count\n- Primary audience (junior devs? Senior? DevOps? Frontend?)\n\nOptional but helpful:\n- Current pain points with existing structure\n- Must-have top-level categories (organizational constraints)\n- Content inventory (if available)\n- Product/feature list\n\n2. CONTENT ANALYSIS\nIf user provides content inventory or feature list:\n- Identify natural task-based groupings\n- Note content type patterns (lots of tutorials? Heavy reference?)\n- Spot potential organizational principles\n\nIf no inventory provided:\n- Use typical patterns for this documentation type\n- Ask about product's core capabilities\n\n3. TAXONOMY GENERATION\n\nCreate 2-3 level hierarchy:\n\nLevel 1 (Top-level): 5-7 categories\n- Organize by USER TASKS when possible (not features)\n- Examples: \"Get Started\", \"Build Core Features\", \"Secure Your App\", \"Deploy & Monitor\"\n- Use action-oriented labels\n- Ensure good balance (no single category >40% of content)\n\nLevel 2 (Sub-categories): Feature or task specifics\n- Break down top-level into specific areas\n- Maintain parallel granularity\n- Each L1 category should have 2-6 subcategories\n\nLevel 3 (Content types): Di\u00c3\u00a1taxis organization\n- Tutorial (learning through doing)\n- How-to Guide (task-focused solutions)\n- Reference (technical specifications)\n- Explanation (conceptual understanding)\n\n4. VALIDATION\n\nCheck against IA principles:\n\n**Depth Check:**\n- 2-3 levels appropriate for content volume?\n- No unnecessary nesting?\n\n**Balance Check:**\n- Calculate % distribution across L1 categories\n- Flag if any category >40% or <5%\n- Explain imbalances if unavoidable\n\n**Granularity Check:**\n- Are top-level categories at parallel level of specificity?\n- Any mixing of high-level and low-level?\n\n**Mutual Exclusivity:**\n- Clear boundaries between categories?\n- Flag potential overlaps\n- Suggest how to handle ambiguous content\n\n**Labeling Check:**\n- Clear, scannable labels?\n- Action-oriented where appropriate?\n- Consistent style (all gerunds? All imperatives?)\n- Under 30 characters each?\n\n5. OUTPUT FORMAT\n\nProvide:\n\nA. VISUAL TAXONOMY TREE\n```\n\u00e2\"\u0153\u00e2\"\u20ac\u00e2\"\u20ac Get Started (12 pages, 20%)\n\u00e2\"\u201a   \u00e2\"\u0153\u00e2\"\u20ac\u00e2\"\u20ac Quick Start\n\u00e2\"\u201a   \u00e2\"\u201a   \u00e2\"\u0153\u00e2\"\u20ac\u00e2\"\u20ac Installation (Tutorial)\n\u00e2\"\u201a   \u00e2\"\u201a   \u00e2\"\"\u00e2\"\u20ac\u00e2\"\u20ac First API Call (Tutorial)\n\u00e2\"\u201a   \u00e2\"\"\u00e2\"\u20ac\u00e2\"\u20ac Core Concepts\n\u00e2\"\u201a       \u00e2\"\u0153\u00e2\"\u20ac\u00e2\"\u20ac Architecture Overview (Explanation)\n\u00e2\"\u201a       \u00e2\"\"\u00e2\"\u20ac\u00e2\"\u20ac Authentication Basics (Explanation)\n[...]\n```\n\nB. RATIONALE\n- Why this organizational approach?\n- Key trade-offs made\n- Alternative approaches considered\n\nC. VALIDATION RESULTS\n- Depth: [Assessment]\n- Balance: [% breakdown]\n- Granularity: [Assessment]\n- Mutual Exclusivity: [Issues if any]\n- Labeling: [Assessment]\n- Overall Score: X/5\n\nD. CONTENT DISTRIBUTION\n- By level 1 category (counts and %)\n- By Di\u00c3\u00a1taxis type (counts and %)\n- By target audience if specified\n\nE. IMPLEMENTATION NOTES\n- Suggested \"Get Started\" path for new users\n- Critical cross-linking opportunities\n- Search tags to implement\n- Areas needing most content initially\n\nF. ALTERNATIVES TO CONSIDER\n- What if organized by [different principle]?\n- Pros/cons of alternative approaches\n\n6. REFINEMENT\n\nIf user wants changes:\n- Ask what's not working\n- Understand the constraint or concern\n- Regenerate addressing specific feedback\n- Explain what changed and why\n\nKEY PRINCIPLES:\n\n\u2705 DO:\n- Organize by user tasks when possible (not feature list)\n- Balance browse and search paths\n- Support progressive disclosure (simple \u2192 complex)\n- Use consistent, clear labels\n- Provide rationale for decisions\n- Flag uncertainty and ask for human judgment\n\n\u274c DON'T:\n- Mirror product feature structure blindly\n- Create overly deep hierarchies (4+ levels)\n- Use jargon in top-level categories\n- Make unbalanced taxonomies without justification\n- Ignore Di\u00c3\u00a1taxis principles for documentation\n- Forget about content types (Tutorial/How-to/Reference/Explanation)\n\nEDGE CASES:\n\n- **Very small content sets (<30 pages):** Recommend flatter structure (2 levels max)\n- **Very large content sets (>200 pages):** May need 4 levels, but justify carefully\n- **Mixed audiences:** May need parallel taxonomies or clear audience segmentation\n- **Highly technical products:** Balance technical precision with accessibility\n- **Rapidly evolving products:** Design for change (extensible categories)\n\nRemember: Taxonomies serve users, not organizations. Always center user tasks and mental models, even when it conflicts with internal product structure.\n```\n\n---\n\n### Step 3: Prepare Reference Documents (5 minutes)\n\nCreate or gather these reference files to upload:\n\n**File 1: diataxis-quick-reference.md**\n```markdown",
            "hydration_source_header": "IA Prompt Library",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "zapier-automation-example",
            "title": "Zapier Automation Example",
            "demonstrates": "automation-workflow-pattern",
            "lines": "980-1050",
            "retrievalQuestions": [
              "How do I automate IA with Zapier?"
            ],
            "hydration_status": "failed"
          }
        ],
        "workflows": [
          {
            "id": "gpt-creation-workflow",
            "title": "Custom GPT Creation Workflow",
            "steps": [
              "define-purpose",
              "write-instructions",
              "add-knowledge",
              "configure-starters",
              "test-iterate"
            ],
            "lines": "1060-1180",
            "retrievalQuestions": [
              "What are the steps to create a custom GPT?"
            ],
            "hydration_status": "failed"
          },
          {
            "id": "chain-development-workflow",
            "title": "Prompt Chain Development Workflow",
            "steps": [
              "map-task",
              "design-steps",
              "connect-outputs",
              "add-validation",
              "test-refine"
            ],
            "lines": "1185-1300",
            "retrievalQuestions": [
              "How do I develop a prompt chain?"
            ],
            "hydration_status": "failed"
          }
        ],
        "checklists": [
          {
            "id": "gpt-design-checklist",
            "title": "Custom GPT Design Checklist",
            "validates": "custom-gpt-design-framework",
            "items": 8,
            "lines": "1430-1460",
            "retrievalQuestions": [
              "What should I check when building a custom GPT?"
            ],
            "content": "- Total items: [count]\n- Content type distribution (table)\n- Audience level breakdown\n- Length category breakdown",
            "hydration_source_header": "Summary Statistics",
            "hydration_method": "line_proximity"
          },
          {
            "id": "chain-validation-checklist",
            "title": "Prompt Chain Validation Checklist",
            "validates": "prompt-chain-framework",
            "items": 7,
            "lines": "1465-1495",
            "content": "**Review Date:** [Date]\n**Reviewer:** [Name]\n\nFor each tool category:\n\n### Usage Review\n- [ ] Which tools were used most?\n- [ ] Which haven't been used in 6+ months?\n- [ ] Are there requests for tools we don't have?\n\n### Quality Review\n- [ ] Do prompts still work well with latest LLM versions?\n- [ ] Have any prompts become less effective?\n- [ ] Are there new capabilities we should leverage?\n\n### Documentation Review\n- [ ] Are examples still relevant?\n- [ ] Do instructions need clarification?\n- [ ] Are troubleshooting guides complete?\n\n### Deprecation Decisions\n- [ ] Tools to archive (no longer effective)\n- [ ] Tools to merge (too similar)\n- [ ] Tools to split (trying to do too much)\n\n### New Development\n- [ ] Gaps to fill\n- [ ] Improvements to prioritize\n- [ ] Beta tools ready to promote\n\n### Actions\n1. [Specific action with owner and date]\n2. [...]\n```\n\n---",
            "hydration_source_header": "Prompt Library Review Checklist",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "template-quality-checklist",
            "title": "Template Quality Checklist",
            "validates": "template-design-pattern",
            "items": 6,
            "lines": "1500-1525",
            "hydration_status": "failed"
          },
          {
            "id": "success-criteria-checklist",
            "title": "Success Criteria Checklist",
            "validates": "no-code-ia-tools-framework",
            "items": 8,
            "lines": "1550-1585",
            "retrievalQuestions": [
              "How do I know if my no-code tool is successful?"
            ],
            "hydration_status": "failed"
          }
        ],
        "warnings": [
          {
            "id": "over-engineering",
            "title": "Over-Engineering Tools",
            "prevents": "Building complex when simple works",
            "lines": "1310",
            "content": "**Tool Type:** Custom GPT / Claude Project\n\n**Purpose:** Generate task-based taxonomies for software documentation following Di\u00c3\u00a1taxis principles.\n\n**System Instructions:**\n\n```\nYou are a senior information architect specializing in software documentation taxonomy design.\n\nYour expertise is creating task-based, user-centered taxonomies that follow the Di\u00c3\u00a1taxis framework (Tutorial, How-to, Reference, Explanation).\n\nWORKFLOW:\n\n1. GATHER REQUIREMENTS\nAsk the user:\n- Content domain (what kind of documentation?)\n- Content volume (approximate page count)\n- Primary user audience (developers? Which level?)\n- Existing pain points (if known)\n- Organizational constraints (if any)\n\n2. ANALYZE CONTENT SCOPE\nIf user provides content inventory:\n- Identify natural groupings by feature/task\n- Note content type distribution\n- Spot potential organizational principles\n\n3. GENERATE TAXONOMY\nCreate 2-3 level hierarchy:\n- Top level: 5-7 categories (user tasks or features)\n- Second level: Specific subtasks or components\n- Third level: Content types (Tutorial/How-to/Reference/Explanation)\n\nEnsure:\n- Balanced distribution (no category >40%)\n- Parallel granularity\n- Clear, action-oriented labels\n- Task-based organization when possible\n\n4. VALIDATE\nApply the 5-check validation system from Module 2.1:\n- **Completeness:** All necessary categories covered, no obvious gaps\n- **Consistency:** Parallel structure, consistent granularity across branches\n- **Balance:** No category exceeds 35-40% of content, evenly distributed\n- **Clarity:** Clear, unambiguous labels users will understand\n- **Scalability:** Structure can accommodate 50% growth without reorganization\n\nAlso check:\n- Depth appropriate for content volume\n- Clear boundaries between categories\n\n5. PROVIDE\n- Visual taxonomy tree\n- Content count estimates per category\n- Rationale for organizational choices\n- Di\u00c3\u00a1taxis type distribution\n- Implementation notes\n\nAlways explain your reasoning and provide alternatives when choices are subjective.\n```\n\n**Reference Documents:**\n- `diataxis-framework.md`\n- `taxonomy-best-practices.md`\n- `task-based-organization-guide.md`\n\n**Conversation Starters:**\n- \"Generate taxonomy for API documentation with 80 pages\"\n- \"Create documentation structure for CLI tool\"\n- \"Organize 150 pages of developer guides\"\n\n---",
            "hydration_source_header": "Tool 1: Taxonomy Generator",
            "hydration_method": "line_proximity"
          },
          {
            "id": "no-testing",
            "title": "Skipping Testing",
            "prevents": "Deploying untested tools",
            "lines": "1315",
            "content": "**Tool Type:** Custom GPT / Claude Project\n\n**Purpose:** Generate task-based taxonomies for software documentation following Di\u00c3\u00a1taxis principles.\n\n**System Instructions:**\n\n```\nYou are a senior information architect specializing in software documentation taxonomy design.\n\nYour expertise is creating task-based, user-centered taxonomies that follow the Di\u00c3\u00a1taxis framework (Tutorial, How-to, Reference, Explanation).\n\nWORKFLOW:\n\n1. GATHER REQUIREMENTS\nAsk the user:\n- Content domain (what kind of documentation?)\n- Content volume (approximate page count)\n- Primary user audience (developers? Which level?)\n- Existing pain points (if known)\n- Organizational constraints (if any)\n\n2. ANALYZE CONTENT SCOPE\nIf user provides content inventory:\n- Identify natural groupings by feature/task\n- Note content type distribution\n- Spot potential organizational principles\n\n3. GENERATE TAXONOMY\nCreate 2-3 level hierarchy:\n- Top level: 5-7 categories (user tasks or features)\n- Second level: Specific subtasks or components\n- Third level: Content types (Tutorial/How-to/Reference/Explanation)\n\nEnsure:\n- Balanced distribution (no category >40%)\n- Parallel granularity\n- Clear, action-oriented labels\n- Task-based organization when possible\n\n4. VALIDATE\nApply the 5-check validation system from Module 2.1:\n- **Completeness:** All necessary categories covered, no obvious gaps\n- **Consistency:** Parallel structure, consistent granularity across branches\n- **Balance:** No category exceeds 35-40% of content, evenly distributed\n- **Clarity:** Clear, unambiguous labels users will understand\n- **Scalability:** Structure can accommodate 50% growth without reorganization\n\nAlso check:\n- Depth appropriate for content volume\n- Clear boundaries between categories\n\n5. PROVIDE\n- Visual taxonomy tree\n- Content count estimates per category\n- Rationale for organizational choices\n- Di\u00c3\u00a1taxis type distribution\n- Implementation notes\n\nAlways explain your reasoning and provide alternatives when choices are subjective.\n```\n\n**Reference Documents:**\n- `diataxis-framework.md`\n- `taxonomy-best-practices.md`\n- `task-based-organization-guide.md`\n\n**Conversation Starters:**\n- \"Generate taxonomy for API documentation with 80 pages\"\n- \"Create documentation structure for CLI tool\"\n- \"Organize 150 pages of developer guides\"\n\n---",
            "hydration_source_header": "Tool 1: Taxonomy Generator",
            "hydration_method": "line_proximity"
          },
          {
            "id": "poor-documentation",
            "title": "Poor Documentation",
            "prevents": "Unmaintainable tools",
            "lines": "1320",
            "retrievalQuestions": [
              "What mistakes should I avoid with no-code tools?"
            ],
            "content": "- [ ] Are examples still relevant?\n- [ ] Do instructions need clarification?\n- [ ] Are troubleshooting guides complete?",
            "hydration_source_header": "Documentation Review",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "no-human-review",
            "title": "No Human Review Points",
            "prevents": "Fully automated decisions",
            "lines": "1325",
            "content": "**Tool Type:** Custom GPT / Claude Project\n\n**Purpose:** Generate task-based taxonomies for software documentation following Di\u00c3\u00a1taxis principles.\n\n**System Instructions:**\n\n```\nYou are a senior information architect specializing in software documentation taxonomy design.\n\nYour expertise is creating task-based, user-centered taxonomies that follow the Di\u00c3\u00a1taxis framework (Tutorial, How-to, Reference, Explanation).\n\nWORKFLOW:\n\n1. GATHER REQUIREMENTS\nAsk the user:\n- Content domain (what kind of documentation?)\n- Content volume (approximate page count)\n- Primary user audience (developers? Which level?)\n- Existing pain points (if known)\n- Organizational constraints (if any)\n\n2. ANALYZE CONTENT SCOPE\nIf user provides content inventory:\n- Identify natural groupings by feature/task\n- Note content type distribution\n- Spot potential organizational principles\n\n3. GENERATE TAXONOMY\nCreate 2-3 level hierarchy:\n- Top level: 5-7 categories (user tasks or features)\n- Second level: Specific subtasks or components\n- Third level: Content types (Tutorial/How-to/Reference/Explanation)\n\nEnsure:\n- Balanced distribution (no category >40%)\n- Parallel granularity\n- Clear, action-oriented labels\n- Task-based organization when possible\n\n4. VALIDATE\nApply the 5-check validation system from Module 2.1:\n- **Completeness:** All necessary categories covered, no obvious gaps\n- **Consistency:** Parallel structure, consistent granularity across branches\n- **Balance:** No category exceeds 35-40% of content, evenly distributed\n- **Clarity:** Clear, unambiguous labels users will understand\n- **Scalability:** Structure can accommodate 50% growth without reorganization\n\nAlso check:\n- Depth appropriate for content volume\n- Clear boundaries between categories\n\n5. PROVIDE\n- Visual taxonomy tree\n- Content count estimates per category\n- Rationale for organizational choices\n- Di\u00c3\u00a1taxis type distribution\n- Implementation notes\n\nAlways explain your reasoning and provide alternatives when choices are subjective.\n```\n\n**Reference Documents:**\n- `diataxis-framework.md`\n- `taxonomy-best-practices.md`\n- `task-based-organization-guide.md`\n\n**Conversation Starters:**\n- \"Generate taxonomy for API documentation with 80 pages\"\n- \"Create documentation structure for CLI tool\"\n- \"Organize 150 pages of developer guides\"\n\n---",
            "hydration_source_header": "Tool 1: Taxonomy Generator",
            "hydration_method": "line_proximity"
          },
          {
            "id": "ignoring-edge-cases",
            "title": "Ignoring Edge Cases",
            "prevents": "Tools that fail on unusual inputs",
            "lines": "1330",
            "content": "**Tool Type:** Custom GPT / Claude Project\n\n**Purpose:** Generate task-based taxonomies for software documentation following Di\u00c3\u00a1taxis principles.\n\n**System Instructions:**\n\n```\nYou are a senior information architect specializing in software documentation taxonomy design.\n\nYour expertise is creating task-based, user-centered taxonomies that follow the Di\u00c3\u00a1taxis framework (Tutorial, How-to, Reference, Explanation).\n\nWORKFLOW:\n\n1. GATHER REQUIREMENTS\nAsk the user:\n- Content domain (what kind of documentation?)\n- Content volume (approximate page count)\n- Primary user audience (developers? Which level?)\n- Existing pain points (if known)\n- Organizational constraints (if any)\n\n2. ANALYZE CONTENT SCOPE\nIf user provides content inventory:\n- Identify natural groupings by feature/task\n- Note content type distribution\n- Spot potential organizational principles\n\n3. GENERATE TAXONOMY\nCreate 2-3 level hierarchy:\n- Top level: 5-7 categories (user tasks or features)\n- Second level: Specific subtasks or components\n- Third level: Content types (Tutorial/How-to/Reference/Explanation)\n\nEnsure:\n- Balanced distribution (no category >40%)\n- Parallel granularity\n- Clear, action-oriented labels\n- Task-based organization when possible\n\n4. VALIDATE\nApply the 5-check validation system from Module 2.1:\n- **Completeness:** All necessary categories covered, no obvious gaps\n- **Consistency:** Parallel structure, consistent granularity across branches\n- **Balance:** No category exceeds 35-40% of content, evenly distributed\n- **Clarity:** Clear, unambiguous labels users will understand\n- **Scalability:** Structure can accommodate 50% growth without reorganization\n\nAlso check:\n- Depth appropriate for content volume\n- Clear boundaries between categories\n\n5. PROVIDE\n- Visual taxonomy tree\n- Content count estimates per category\n- Rationale for organizational choices\n- Di\u00c3\u00a1taxis type distribution\n- Implementation notes\n\nAlways explain your reasoning and provide alternatives when choices are subjective.\n```\n\n**Reference Documents:**\n- `diataxis-framework.md`\n- `taxonomy-best-practices.md`\n- `task-based-organization-guide.md`\n\n**Conversation Starters:**\n- \"Generate taxonomy for API documentation with 80 pages\"\n- \"Create documentation structure for CLI tool\"\n- \"Organize 150 pages of developer guides\"\n\n---",
            "hydration_source_header": "Tool 1: Taxonomy Generator",
            "hydration_method": "line_proximity"
          },
          {
            "id": "scope-creep-tools",
            "title": "Scope Creep",
            "prevents": "Tools that try to do everything",
            "lines": "1335",
            "hydration_status": "failed"
          }
        ],
        "platforms": [
          {
            "id": "chatgpt-custom-gpts",
            "platform": "ChatGPT Custom GPTs",
            "capabilities": "System instructions, knowledge files, conversation starters, actions",
            "lines": "85-100",
            "retrievalQuestions": [
              "What can ChatGPT custom GPTs do?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "claude-projects",
            "platform": "Claude Projects",
            "capabilities": "Custom instructions, knowledge, conversation context",
            "lines": "implicit",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "zapier",
            "platform": "Zapier",
            "capabilities": "Automation triggers, AI actions, integrations",
            "lines": "970-1000",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "make-integromat",
            "platform": "Make (Integromat)",
            "capabilities": "Visual workflows, AI modules",
            "lines": "1000-1020",
            "retrievalQuestions": [
              "What platforms support no-code IA automation?"
            ],
            "hydration_status": "skipped_unknown"
          }
        ],
        "timeMetrics": [
          {
            "id": "gpt-creation-time",
            "activity": "Custom GPT Creation",
            "time": "1-2 hours",
            "lines": "1590",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "chain-development-time",
            "activity": "Prompt Chain Development",
            "time": "2-4 hours",
            "lines": "1595",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "template-library-time",
            "activity": "Template Library Creation",
            "time": "3-5 hours",
            "lines": "1600",
            "retrievalQuestions": [
              "How long does it take to build IA tools?"
            ],
            "hydration_status": "skipped_unknown"
          }
        ]
      }
    },
    "4-2-ia-notation": {
      "file": "4-2-ia-notation.mdx",
      "focus": "Creating IA documentation including diagrams, notation systems, and Architecture Decision Records (ADRs)",
      "entityCount": 130,
      "entities": {
        "frameworks": [
          {
            "id": "ia-notation-framework",
            "title": "IA Notation & Documentation Framework",
            "type": "framework",
            "definition": "Comprehensive framework for documenting IA decisions, creating diagrams, and using notation systems",
            "contains": [
              "diagram-types",
              "notation-systems",
              "adr-framework",
              "documentation-patterns"
            ],
            "lines": "1-2190",
            "crossModule": true,
            "retrievalQuestions": [
              "How do I document IA decisions?",
              "What notation systems exist for IA?"
            ],
            "content": "You've done the hard work: analyzing content, designing taxonomies, mapping user journeys, creating metadata schemas. You've built tools to make the process repeatable. Now comes a critical step that's often rushed or skipped: **documenting your information architecture.**\n\n**The documentation problem:**\n\nWithout proper IA documentation:\n- \u274c Stakeholders can't review or approve your work\n- \u274c Developers don't know what to build\n- \u274c Writers don't understand the structure\n- \u274c Future you forgets why decisions were made\n- \u274c New team members can't understand the system\n- \u274c Changes get made without considering the original design\n\n**The opportunity:**\n\nWell-documented IA:\n- \u2705 Communicates design decisions clearly\n- \u2705 Gets stakeholder buy-in faster\n- \u2705 Guides implementation accurately\n- \u2705 Serves as training material\n- \u2705 Creates institutional knowledge\n- \u2705 Enables collaborative refinement\n- \u2705 Survives team transitions\n\n**The AI advantage:**\n\nTraditionally, creating IA documentation was tedious:\n- Hand-drawing diagrams that need constant updates\n- Fighting with diagramming tools\n- Maintaining consistency across documents\n- Recreating visualizations when structures change\n\nAI transforms this by:\n- Generating diagrams from text descriptions\n- Converting between formats (text \u2192 Mermaid \u2192 SVG)\n- Maintaining consistent notation\n- Updating visualizations quickly when IA changes\n- Creating multiple views of the same structure\n\n---\n\n### The IA Documentation Stack\n\nModern IA documentation uses a **Docs-as-Code** approach:\n\n```\nTEXT-BASED SOURCE FILES (version controlled)\n           \u2193\n    MARKDOWN + MERMAID\n           \u2193\n    RENDERED DIAGRAMS\n           \u2193\n    PUBLISHED DOCUMENTATION\n```\n\n**Why Docs-as-Code?**\n\n**Traditional approach (Visio, Lucidchart, etc.):**\n- \u274c Binary files, can't diff changes\n- \u274c Hard to collaborate (file locking)\n- \u274c Version control is manual\n- \u274c Requires specialized software\n- \u274c Diagrams separate from documentation\n\n**Docs-as-Code approach (Markdown + Mermaid):**\n- \u2705 Plain text, easy to diff\n- \u2705 Multiple people can edit simultaneously\n- \u2705 Git tracks every change\n- \u2705 Any text editor works\n- \u2705 Diagrams live with documentation\n- \u2705 Automated rendering in CI/CD\n\n---",
            "hydration_source_header": "Introduction: Why IA Documentation Matters",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "adr-framework",
            "title": "Architecture Decision Record (ADR) Framework",
            "type": "framework",
            "definition": "Structured approach to documenting IA decisions with context, options, and rationale",
            "contains": [
              "adr-structure",
              "adr-templates",
              "adr-workflows"
            ],
            "lines": "785-1200",
            "crossModule": false,
            "retrievalQuestions": [
              "What is an ADR?",
              "How do I write IA decision records?"
            ],
            "content": "Reorganize documentation using task-based architecture where top-level categories represent user goals (\"Authenticate & Authorize\", \"Store & Manage Files\") rather than internal services.",
            "hydration_source_header": "Decision",
            "hydration_method": "title_match"
          },
          {
            "id": "diagram-system-framework",
            "title": "IA Diagram System Framework",
            "type": "framework",
            "definition": "Framework for choosing and creating appropriate IA diagrams",
            "contains": [
              "diagram-types",
              "when-to-use",
              "creation-patterns"
            ],
            "lines": "55-780",
            "crossModule": false,
            "retrievalQuestions": [
              "What IA diagrams should I create?"
            ],
            "content": "Modern IA documentation uses a **Docs-as-Code** approach:\n\n```\nTEXT-BASED SOURCE FILES (version controlled)\n           \u2193\n    MARKDOWN + MERMAID\n           \u2193\n    RENDERED DIAGRAMS\n           \u2193\n    PUBLISHED DOCUMENTATION\n```\n\n**Why Docs-as-Code?**\n\n**Traditional approach (Visio, Lucidchart, etc.):**\n- \u274c Binary files, can't diff changes\n- \u274c Hard to collaborate (file locking)\n- \u274c Version control is manual\n- \u274c Requires specialized software\n- \u274c Diagrams separate from documentation\n\n**Docs-as-Code approach (Markdown + Mermaid):**\n- \u2705 Plain text, easy to diff\n- \u2705 Multiple people can edit simultaneously\n- \u2705 Git tracks every change\n- \u2705 Any text editor works\n- \u2705 Diagrams live with documentation\n- \u2705 Automated rendering in CI/CD\n\n---",
            "hydration_source_header": "The IA Documentation Stack",
            "hydration_method": "line_proximity"
          }
        ],
        "principles": [
          {
            "id": "right-diagram-right-audience",
            "title": "Right Diagram for Right Audience",
            "partOf": "diagram-system-framework",
            "lines": "1900-1905",
            "crossModule": false,
            "retrievalQuestions": [
              "How do I choose the right IA diagram?"
            ],
            "content": "IA documentation should be version controlled just like code.\n\n### Git Workflow for IA Documentation\n\n**Repository structure:**\n\n```\nia-documentation/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 diagrams/\n\u2502   \u251c\u2500\u2500 sitemap.md (with Mermaid)\n\u2502   \u251c\u2500\u2500 content-model.md\n\u2502   \u251c\u2500\u2500 user-flows.md\n\u2502   \u2514\u2500\u2500 taxonomy.md\n\u251c\u2500\u2500 specifications/\n\u2502   \u251c\u2500\u2500 navigation-spec.md\n\u2502   \u251c\u2500\u2500 metadata-schema.md\n\u2502   \u2514\u2500\u2500 content-types.md\n\u251c\u2500\u2500 decisions/\n\u2502   \u251c\u2500\u2500 001-task-based-organization.md\n\u2502   \u251c\u2500\u2500 002-diataxis-integration.md\n\u2502   \u2514\u2500\u2500 003-three-level-hierarchy.md\n\u2514\u2500\u2500 archive/\n    \u2514\u2500\u2500 v1-initial/\n```\n\n**Commit message conventions:**\n\n```\nfeat(sitemap): Add webhooks section\nfix(taxonomy): Correct balance in Core Resources category\ndocs(flows): Update authentication user flow\nrefactor(model): Simplify content type relationships\n```\n\n---\n\n### Architectural Decision Records (ADRs)\n\n**ADR** (Architectural Decision Record) is a document that captures an important architectural decision along with its context and consequences.\n\nDocument major IA decisions using ADR format:\n\n**Template:**\n\n```markdown",
            "hydration_source_header": "VII. Version Control for IA Artifacts (5 minutes)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "decisions-over-diagrams",
            "title": "Document Decisions, Not Just Structures",
            "partOf": "adr-framework",
            "lines": "1905-1910",
            "crossModule": false,
            "content": "Reorganize documentation using task-based architecture where top-level categories represent user goals (\"Authenticate & Authorize\", \"Store & Manage Files\") rather than internal services.",
            "hydration_source_header": "Decision",
            "hydration_method": "title_match"
          },
          {
            "id": "maintainable-notation",
            "title": "Use Maintainable Notation (Text-Based)",
            "partOf": "ia-notation-framework",
            "lines": "1910-1915",
            "crossModule": false,
            "retrievalQuestions": [
              "Why use text-based diagrams?"
            ],
            "content": "**Repository structure:**\n\n```\nia-documentation/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 diagrams/\n\u2502   \u251c\u2500\u2500 sitemap.md (with Mermaid)\n\u2502   \u251c\u2500\u2500 content-model.md\n\u2502   \u251c\u2500\u2500 user-flows.md\n\u2502   \u2514\u2500\u2500 taxonomy.md\n\u251c\u2500\u2500 specifications/\n\u2502   \u251c\u2500\u2500 navigation-spec.md\n\u2502   \u251c\u2500\u2500 metadata-schema.md\n\u2502   \u2514\u2500\u2500 content-types.md\n\u251c\u2500\u2500 decisions/\n\u2502   \u251c\u2500\u2500 001-task-based-organization.md\n\u2502   \u251c\u2500\u2500 002-diataxis-integration.md\n\u2502   \u2514\u2500\u2500 003-three-level-hierarchy.md\n\u2514\u2500\u2500 archive/\n    \u2514\u2500\u2500 v1-initial/\n```\n\n**Commit message conventions:**\n\n```\nfeat(sitemap): Add webhooks section\nfix(taxonomy): Correct balance in Core Resources category\ndocs(flows): Update authentication user flow\nrefactor(model): Simplify content type relationships\n```\n\n---",
            "hydration_source_header": "Git Workflow for IA Documentation",
            "hydration_method": "line_proximity"
          },
          {
            "id": "living-documentation",
            "title": "Documentation Should Be Living",
            "partOf": "ia-notation-framework",
            "lines": "1915-1920",
            "crossModule": true,
            "content": "**Repository structure:**\n\n```\nia-documentation/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 diagrams/\n\u2502   \u251c\u2500\u2500 sitemap.md (with Mermaid)\n\u2502   \u251c\u2500\u2500 content-model.md\n\u2502   \u251c\u2500\u2500 user-flows.md\n\u2502   \u2514\u2500\u2500 taxonomy.md\n\u251c\u2500\u2500 specifications/\n\u2502   \u251c\u2500\u2500 navigation-spec.md\n\u2502   \u251c\u2500\u2500 metadata-schema.md\n\u2502   \u2514\u2500\u2500 content-types.md\n\u251c\u2500\u2500 decisions/\n\u2502   \u251c\u2500\u2500 001-task-based-organization.md\n\u2502   \u251c\u2500\u2500 002-diataxis-integration.md\n\u2502   \u2514\u2500\u2500 003-three-level-hierarchy.md\n\u2514\u2500\u2500 archive/\n    \u2514\u2500\u2500 v1-initial/\n```\n\n**Commit message conventions:**\n\n```\nfeat(sitemap): Add webhooks section\nfix(taxonomy): Correct balance in Core Resources category\ndocs(flows): Update authentication user flow\nrefactor(model): Simplify content type relationships\n```\n\n---",
            "hydration_source_header": "Git Workflow for IA Documentation",
            "hydration_method": "line_proximity"
          },
          {
            "id": "layer-complexity",
            "title": "Layer Complexity (Overview \u2192 Detail)",
            "partOf": "diagram-system-framework",
            "lines": "1920-1925",
            "crossModule": false,
            "content": "**Repository structure:**\n\n```\nia-documentation/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 diagrams/\n\u2502   \u251c\u2500\u2500 sitemap.md (with Mermaid)\n\u2502   \u251c\u2500\u2500 content-model.md\n\u2502   \u251c\u2500\u2500 user-flows.md\n\u2502   \u2514\u2500\u2500 taxonomy.md\n\u251c\u2500\u2500 specifications/\n\u2502   \u251c\u2500\u2500 navigation-spec.md\n\u2502   \u251c\u2500\u2500 metadata-schema.md\n\u2502   \u2514\u2500\u2500 content-types.md\n\u251c\u2500\u2500 decisions/\n\u2502   \u251c\u2500\u2500 001-task-based-organization.md\n\u2502   \u251c\u2500\u2500 002-diataxis-integration.md\n\u2502   \u2514\u2500\u2500 003-three-level-hierarchy.md\n\u2514\u2500\u2500 archive/\n    \u2514\u2500\u2500 v1-initial/\n```\n\n**Commit message conventions:**\n\n```\nfeat(sitemap): Add webhooks section\nfix(taxonomy): Correct balance in Core Resources category\ndocs(flows): Update authentication user flow\nrefactor(model): Simplify content type relationships\n```\n\n---",
            "hydration_source_header": "Git Workflow for IA Documentation",
            "hydration_method": "line_proximity"
          }
        ],
        "diagramTypes": [
          {
            "id": "site-map-diagram",
            "title": "Site Map / Navigation Diagram",
            "purpose": "Show page hierarchy and navigation",
            "whenToUse": "Stakeholder communication, development handoff",
            "lines": "70-140",
            "retrievalQuestions": [
              "When do I use a site map diagram?"
            ],
            "content": "[Detailed sidebar spec with expansion behavior]\n\n---",
            "hydration_source_header": "Sidebar Navigation Logic",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "taxonomy-diagram",
            "title": "Taxonomy Visualization",
            "purpose": "Show classification hierarchy",
            "whenToUse": "Taxonomy development, vocabulary governance",
            "lines": "145-220",
            "content": "Taxonomies can be visualized in multiple ways depending on complexity and purpose.\n\n### Simple Taxonomy Diagram Prompt\n\n**For hierarchical taxonomies:**\n\n```text\nVisualize this taxonomy as a Mermaid flowchart:\n\nTAXONOMY:\n[Paste your taxonomy structure]\n\nRequirements:\n- Use flowchart TD (top-down) layout\n- Show all levels of hierarchy (maximum 4 levels deep to prevent diagram complexity)\n- Include item counts at each node\n- Use colors to distinguish levels\n- Add a legend explaining the structure\n\nOutput valid Mermaid syntax.\n```\n\n**Example Output:**\n\n```mermaid\nflowchart TD\n    Root[Documentation Taxonomy<br/>150 pages]\n    \n    Root --> L1A[Get Started<br/>25 pages]\n    Root --> L1B[Build Features<br/>60 pages]\n    Root --> L1C[Deploy & Monitor<br/>35 pages]\n    Root --> L1D[Reference<br/>30 pages]\n    \n    L1A --> L2A1[Installation<br/>8 pages]\n    L1A --> L2A2[Quickstart<br/>12 pages]\n    L1A --> L2A3[Core Concepts<br/>5 pages]\n    \n    L1B --> L2B1[Authentication<br/>15 pages]\n    L1B --> L2B2[Data Management<br/>25 pages]\n    L1B --> L2B3[APIs<br/>20 pages]\n    \n    L1C --> L2C1[Configuration<br/>10 pages]\n    L1C --> L2C2[Deployment<br/>15 pages]\n    L1C --> L2C3[Monitoring<br/>10 pages]\n    \n    L1D --> L2D1[API Endpoints<br/>20 pages]\n    L1D --> L2D2[CLI Commands<br/>10 pages]\n    \n    L2A1 --> L3A1A[Linux]\n    L2A1 --> L3A1B[macOS]\n    L2A1 --> L3A1C[Windows]\n    \n    L2B2 --> L3B2A[Create Records]\n    L2B2 --> L3B2B[Update Records]\n    L2B2 --> L3B2C[Delete Records]\n    \n    classDef level1 fill:#e3f2fd,stroke:#1976d2,stroke-width:3px\n    classDef level2 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n    classDef level3 fill:#fff3e0,stroke:#f57c00,stroke-width:1px\n    \n    class L1A,L1B,L1C,L1D level1\n    class L2A1,L2A2,L2A3,L2B1,L2B2,L2B3,L2C1,L2C2,L2C3,L2D1,L2D2 level2\n    class L3A1A,L3A1B,L3A1C,L3B2A,L3B2B,L3B2C level3\n```\n\n---\n\n### Faceted Taxonomy Diagrams\n\nFor faceted classification systems, show multiple dimensions:\n\n**Faceted taxonomy prompt:**\n\n```\nCreate a diagram showing this faceted taxonomy:\n\nFACETS:\n[List each facet and its values]\n\nShow:\n- Each facet as a separate dimension\n- Values within each facet\n- How facets can be combined\n- Example combinations\n\nUse Mermaid mindmap or flowchart syntax.\n```\n\n**Example: Documentation Faceted Classification**\n\n**Your Prompt:**\n\n```\nCreate a diagram showing a faceted taxonomy for documentation.\n\nFacets:\n1. Content Type: Tutorial, How-to, Reference, Explanation\n2. Difficulty: Beginner, Intermediate, Advanced\n3. Product Area: Authentication, Storage, Search, Analytics\n4. Format: Text, Video, Interactive\n\nShow how these facets can be combined.\n```\n\n**AI Output:**\n\n```mermaid\nmindmap\n  root((Documentation<br/>Taxonomy))\n    Content Type\n      Tutorial\n      How-to Guide\n      Reference\n      Explanation\n    Difficulty\n      Beginner\n      Intermediate\n      Advanced\n    Product Area\n      Authentication\n      Storage\n      Search\n      Analytics\n    Format\n      Text Article\n      Video\n      Interactive Demo\n      Code Sample\n      \n```\n\n**With example combinations:**\n\n```\nEXAMPLE FACET COMBINATIONS:\n\n1. Tutorial + Beginner + Authentication + Video\n   = \"Video tutorial: Your first OAuth login (beginner)\"\n\n2. How-to + Intermediate + Storage + Text\n   = \"How to optimize file uploads (intermediate)\"\n\n3. Reference + Advanced + Analytics + Code Sample\n   = \"Analytics API reference with code samples (advanced)\"\n\n4. Explanation + Beginner + Search + Text\n   = \"How search indexing works (beginner explanation)\"\n\nFACET RULES:\n- Content Type: Required (exactly one)\n- Difficulty: Required (exactly one)\n- Product Area: Required (one or more)\n- Format: Optional (one or more)\n\nTOTAL COMBINATIONS: 4 \u00d7 3 \u00d7 4 \u00d7 4 = 192 possible combinations\n```\n\n---",
            "hydration_source_header": "IV. Taxonomy Visualizations (10 minutes)",
            "hydration_method": "title_match"
          },
          {
            "id": "content-model-diagram",
            "title": "Content Model Diagram",
            "purpose": "Show content types and relationships",
            "whenToUse": "CMS planning, content strategy",
            "lines": "225-310",
            "retrievalQuestions": [
              "How do I diagram a content model?"
            ],
            "content": "Content models show how content types relate to each other. These are essential for CMS planning and structured content systems.\n\n### Choosing Diagram Type: erDiagram vs classDiagram\n\nMermaid offers two diagram types for content models. Choose based on what you're modeling:\n\n**Use erDiagram when:**\n- \u2713 Modeling data relationships (database schema, CMS structure)\n- \u2713 Showing cardinality is important (one-to-many, many-to-many)\n- \u2713 Simple entity connections without inheritance\n- \u2713 Example: \"Show how BlogPost relates to Author, Category, and Tag\"\n\n**Use classDiagram when:**\n- \u2713 Modeling object-oriented systems with inheritance\n- \u2713 Content types inherit from base types (Tutorial \u2192 BaseContent)\n- \u2713 Need to show attributes AND methods/behaviors\n- \u2713 Example: \"Show how Tutorial, HowToGuide inherit from BaseContent\"\n\n<Tip>\n**Quick Decision:** Use **erDiagram** for data relationships (simpler syntax, clear cardinality). Use **classDiagram** when you need inheritance hierarchies or methods.\n</Tip>\n\n### Content Model Prompt Pattern\n\n**Basic content model diagram:**\n\n```text\nCreate a content model diagram in Mermaid syntax for [content domain].\n\nContent types:\n[List content types with brief descriptions]\n\nRelationships:\n[Describe key relationships, or let AI infer them]\n\nRequirements:\n- Use Mermaid entity-relationship diagram (erDiagram) syntax\n- Limit to 5-7 main entities to maintain diagram readability\n- Show cardinality (the relationship multiplicity: one-to-one, one-to-many, many-to-many)\n- Include key attributes for each content type\n- Use proper relationship labels\n\nOutput valid Mermaid syntax ready for rendering.\n```\n\n**Example: Blog Content Model**\n\n**Your Prompt:**\n\n```\nCreate a content model diagram in Mermaid syntax for a technical blog.\n\nContent types:\n1. BlogPost - Main article content\n2. Author - Person who writes posts\n3. Category - Topic classification\n4. Tag - Keyword metadata\n5. Series - Related posts grouped together\n6. Comment - Reader feedback\n\nRelationships to show:\n- Authors write BlogPosts (one author per post, authors can write many posts)\n- BlogPosts belong to one Category, Categories contain many posts\n- BlogPosts have many Tags, Tags can be on many posts\n- BlogPosts can belong to one Series (optional), Series contain many posts\n- BlogPosts have many Comments, Comments belong to one post\n\nInclude key attributes for each type.\n```\n\n**AI Output:**\n\n```mermaid\nerDiagram\n    Author ||--o{ BlogPost : writes\n    BlogPost }o--|| Category : \"belongs to\"\n    BlogPost }o--o{ Tag : \"tagged with\"\n    BlogPost }o--o| Series : \"part of\"\n    BlogPost ||--o{ Comment : receives\n    \n    Author {\n        string authorId PK\n        string name\n        string email\n        string bio\n        string avatarUrl\n        date joinedDate\n        array socialLinks\n    }\n    \n    BlogPost {\n        string postId PK\n        string authorId FK\n        string categoryId FK\n        string seriesId FK\n        string title\n        string slug\n        text content\n        string excerpt\n        array tags\n        date publishedDate\n        date updatedDate\n        string status\n        int readingTime\n        string featuredImage\n    }\n    \n    Category {\n        string categoryId PK\n        string name\n        string slug\n        string description\n        int postCount\n    }\n    \n    Tag {\n        string tagId PK\n        string name\n        string slug\n        int usageCount\n    }\n    \n    Series {\n        string seriesId PK\n        string title\n        string description\n        int postCount\n        array postOrder\n    }\n    \n    Comment {\n        string commentId PK\n        string postId FK\n        string authorName\n        string authorEmail\n        text content\n        date postedDate\n        string status\n    }\n```\n\n---\n\n### Adding Metadata Schemas to Content Models\n\nFor documentation projects, showing metadata alongside content types is crucial.\n\n**Metadata-enriched model prompt:**\n\n```\nCreate a detailed content model showing metadata schemas for documentation.\n\nContent types:\n[List types]\n\nFor each content type, show:\n- Required fields\n- Optional fields\n- Field data types\n- Validation rules (if relevant)\n- Example values\n\nUse Mermaid class diagram syntax to show inheritance and composition.\n```\n\n**Example: Documentation Content Model**\n\n**Your Prompt:**\n\n```\nCreate a detailed content model for API documentation showing metadata schemas.\n\nContent types:\n1. BaseContent (inherited by all others)\n2. Tutorial (step-by-step learning)\n3. HowToGuide (task-oriented)\n4. Reference (technical specs)\n5. Explanation (conceptual)\n\nShow required vs optional fields, data types, and inheritance.\n```\n\n**AI Output:**\n\n```mermaid\nclassDiagram\n    class BaseContent {\n        <<abstract>>\n        +string id\n        +string title\n        +string slug\n        +text description\n        +string author\n        +date createdDate\n        +date updatedDate\n        +string status\n        +array tags\n        +int readingTime\n        +string[] relatedContent\n        validate()\n        publish()\n    }\n    \n    class Tutorial {\n        +int estimatedTime\n        +string[] prerequisites\n        +string[] learningObjectives\n        +array steps\n        +string[] codeExamples\n        +string difficulty\n        +bool includesVideo\n        validateSteps()\n    }\n    \n    class HowToGuide {\n        +string problem\n        +string solution\n        +string[] prerequisites\n        +array steps\n        +string[] alternatives\n        +string[] troubleshooting\n        +string timeToComplete\n        validateProblemSolution()\n    }\n    \n    class Reference {\n        +string endpoint\n        +string httpMethod\n        +object parameters\n        +object responseSchema\n        +string[] errorCodes\n        +string apiVersion\n        +bool deprecated\n        +string deprecationDate\n        validateSchema()\n    }\n    \n    class Explanation {\n        +string concept\n        +string[] keyPoints\n        +array sections\n        +string[] furtherReading\n        +string[] relatedConcepts\n        +bool includesDiagram\n        validateConcept()\n    }\n    \n    BaseContent <|-- Tutorial\n    BaseContent <|-- HowToGuide\n    BaseContent <|-- Reference\n    BaseContent <|-- Explanation\n    \n    Tutorial --> BaseContent : relatedContent\n    HowToGuide --> BaseContent : relatedContent\n    Reference --> BaseContent : relatedContent\n    Explanation --> BaseContent : relatedContent\n```\n\n---\n\n### Relationship Types and Notation\n\nUnderstanding relationship notation helps communicate content model clearly:\n\n```\nRELATIONSHIP CARDINALITY IN MERMAID:\n\n||--||   One-to-one\n||--o{   One-to-many\n}o--o{   Many-to-many\n||--o|   One-to-zero-or-one (optional)\n}o--||   Many-to-one\n\nEXAMPLES:\n\nAuthor ||--o{ BlogPost    \n\"One author writes zero or many blog posts\"\n\nBlogPost }o--|| Category\n\"Many blog posts belong to one category\"\n\nBlogPost }o--o{ Tag\n\"Many posts have many tags, many tags on many posts\"\n\nBlogPost }o--o| Series\n\"Many posts optionally belong to one series\"\n```\n\n<Warning>\n**Knowledge Check:** Verify your content modeling skills:\n\n1. When should you use erDiagram vs classDiagram? (erDiagram for data relationships, classDiagram for inheritance)\n2. What constraint keeps content model diagrams readable? (Limit to 5-7 main entities)\n3. What does cardinality notation ||--o{} mean? (One-to-many relationship)\n\n<details>\n<summary>Check Your Answers</summary>\n\n1. **Diagram choice:** Use **erDiagram** for database/CMS data relationships with clear cardinality. Use **classDiagram** when modeling inheritance hierarchies (e.g., BaseContent \u2192 Tutorial)\n2. **Entity limit:** Keep to **5-7 main entities** to prevent diagram complexity and maintain readability\n3. **Cardinality:** `||--o{` means **one-to-many** (one entity relates to zero or more of another)\n\nYou should now be able to create content model diagrams with proper relationships.\n</details>\n</Warning>\n\n### Quick Practice Exercise (7 minutes)\n\n**Your Turn:** Create a simple content model for a blog.\n\n**Scenario:** A technical blog needs a content model with:\n- BlogPost (the main content)\n- Author (person who writes)\n- Category (topic classification - max 1 per post)\n- Tag (keywords - multiple per post)\n\n**Task:**\n1. Write a prompt to generate an erDiagram\n2. Include cardinality relationships\n3. Add 3-4 key attributes for BlogPost\n4. Test in Mermaid Live Editor\n\n<details>\n<summary>Sample Solution</summary>\n\n**Prompt:**\n```text\nCreate a content model diagram in Mermaid erDiagram syntax for a technical blog.\n\nContent types:\n1. BlogPost - Main article\n2. Author - Writer\n3. Category - Topic (one per post)\n4. Tag - Keywords (many per post)\n\nRelationships:\n- One Author writes many BlogPosts\n- One BlogPost belongs to one Category\n- BlogPosts have many Tags (many-to-many)\n\nInclude key attributes for BlogPost: title, slug, publishedDate, status\nUse proper cardinality notation.\n\nOutput valid Mermaid syntax.\n```\n\n**Expected Output:**\n```mermaid\nerDiagram\n    Author ||--o{ BlogPost : writes\n    BlogPost }o--|| Category : \"belongs to\"\n    BlogPost }o--o{ Tag : \"tagged with\"\n\n    Author {\n        string authorId PK\n        string name\n        string email\n    }\n\n    BlogPost {\n        string postId PK\n        string authorId FK\n        string categoryId FK\n        string title\n        string slug\n        date publishedDate\n        string status\n    }\n\n    Category {\n        string categoryId PK\n        string name\n    }\n\n    Tag {\n        string tagId PK\n        string name\n    }\n```\n\n**Self-check:**\n- [ ] Diagram renders in Mermaid Live Editor\n- [ ] Cardinality notation is correct (||--o{} for one-to-many)\n- [ ] All entities have at least 2-3 attributes\n- [ ] Primary/Foreign keys identified\n</details>\n\n---",
            "hydration_source_header": "III. Content Model Diagrams in Mermaid (15 minutes)",
            "hydration_method": "title_match"
          },
          {
            "id": "user-flow-diagram",
            "title": "User Flow Diagram",
            "purpose": "Show user paths through content",
            "whenToUse": "UX design, journey mapping",
            "lines": "315-400",
            "content": "**Basic user flow:**\n\n```text\nCreate a user flow diagram showing how users [accomplish specific goal].\n\nStarting point: [Where user begins]\nGoal: [What user wants to accomplish]\nKey decision points: [Major choices user makes]\nPossible paths: [Different routes to success]\nFailure points: [Where users might get stuck]\n\nUse Mermaid flowchart with:\n- Diamond shapes {} for decision points (e.g., \"Has API key?\")\n- Rectangle shapes [] for action steps (e.g., \"Read authentication guide\")\n- Different colors for successful vs. error paths\n- Specify error handling paths explicitly\n- Annotations for pain points\n\nOutput valid Mermaid syntax.\n```\n\n**Example: API Documentation User Flow**\n\n**Your Prompt:**\n\n```\nCreate a user flow diagram for a developer using API documentation to integrate authentication.\n\nStarting point: Documentation homepage\nGoal: Successfully implement OAuth 2.0 authentication\nKey decision points:\n- New to APIs vs. experienced\n- OAuth vs. API keys\n- Language/framework choice\n\nShow both successful and error paths.\n```\n\n**AI Output:**\n\n```mermaid\nflowchart TD\n    Start([Developer arrives at<br/>docs homepage])\n    Start --> Q1{New to our API?}\n    \n    Q1 -->|Yes| GetStarted[Get Started Guide]\n    Q1 -->|No| GoToAuth[Navigate to Authentication]\n    \n    GetStarted --> LearnBasics[Learn API Basics]\n    LearnBasics --> Q2{Ready for auth?}\n    Q2 -->|Yes| GoToAuth\n    Q2 -->|No| Confused1[\ud83d\ude15 Still confused]\n    \n    GoToAuth --> AuthOverview[Authentication Overview]\n    AuthOverview --> Q3{Which method?}\n    \n    Q3 -->|OAuth 2.0| OAuthGuide[OAuth 2.0 Guide]\n    Q3 -->|API Keys| APIKeyGuide[API Keys Guide]\n    Q3 -->|Not sure| Confused2[\ud83d\ude15 Which should I use?]\n    \n    OAuthGuide --> Q4{Has OAuth<br/>experience?}\n    Q4 -->|Yes| QuickStart[OAuth Quickstart]\n    Q4 -->|No| Tutorial[OAuth Tutorial]\n    \n    Tutorial --> CodeExample[Copy code example]\n    QuickStart --> CodeExample\n    \n    CodeExample --> Q5{Choose language}\n    Q5 -->|Python| PythonSDK[Python SDK Guide]\n    Q5 -->|JavaScript| JSSDK[JavaScript SDK Guide]\n    Q5 -->|Other| OtherSDK[Other Languages]\n    \n    PythonSDK --> Implement[Implement in app]\n    JSSDK --> Implement\n    OtherSDK --> Implement\n    \n    Implement --> Q6{Working?}\n    Q6 -->|Yes| Success([\u2705 Successfully authenticated])\n    Q6 -->|No| Troubleshoot[Troubleshooting Guide]\n    \n    Troubleshoot --> Q7{Found solution?}\n    Q7 -->|Yes| Implement\n    Q7 -->|No| Support[Contact Support]\n    \n    APIKeyGuide --> APIQuickStart[API Key Setup]\n    APIQuickStart --> CodeExample\n    \n    Confused1 -.->|Needs help| GetStarted\n    Confused2 -.->|Needs guidance| CompareAuth[Compare Auth Methods]\n    CompareAuth --> Q3\n    \n    classDef successPath fill:#c8e6c9,stroke:#2e7d32\n    classDef errorPath fill:#ffccbc,stroke:#d84315\n    classDef decisionPath fill:#fff9c4,stroke:#f57f17\n    classDef painPoint fill:#ffcdd2,stroke:#c62828\n    \n    class Success successPath\n    class Confused1,Confused2,Troubleshoot,Support errorPath\n    class Q1,Q2,Q3,Q4,Q5,Q6,Q7 decisionPath\n    class Confused1,Confused2 painPoint\n```\n\n**Flow analysis annotation:**\n\n```\nUSER FLOW ANALYSIS:\n\nSUCCESS PATHS:\n1. Experienced \u2192 Auth Overview \u2192 OAuth Guide \u2192 Quickstart \u2192 Implement\n   Estimated time: 10-15 minutes\n   \n2. New \u2192 Get Started \u2192 Learn Basics \u2192 Auth Guide \u2192 Tutorial \u2192 Implement\n   Estimated time: 30-45 minutes\n\nPAIN POINTS IDENTIFIED:\n\u26a0\ufe0f Confusion Point 1: New users unsure if they're ready for auth\n   Solution: Add \"Prerequisites\" checklist in Get Started\n\n\u26a0\ufe0f Confusion Point 2: Users don't know which auth method to choose\n   Solution: Add comparison table or decision tree in Auth Overview\n\n\u26a0\ufe0f Drop-off risk: Between code example and implementation\n   Solution: Add \"Test your authentication\" interactive validator\n\nMETRICS TO TRACK:\n- % taking successful path without troubleshooting\n- Average time from Start to Success\n- Most common exit points (abandonment)\n- % needing support after troubleshooting\n```\n\n---",
            "hydration_source_header": "User Flow Diagram Prompt Pattern",
            "hydration_method": "title_match"
          },
          {
            "id": "faceted-navigation-diagram",
            "title": "Faceted Navigation Diagram",
            "purpose": "Show filter/facet relationships",
            "whenToUse": "Search design, filter planning",
            "lines": "405-480",
            "content": "For faceted classification systems, show multiple dimensions:\n\n**Faceted taxonomy prompt:**\n\n```\nCreate a diagram showing this faceted taxonomy:\n\nFACETS:\n[List each facet and its values]\n\nShow:\n- Each facet as a separate dimension\n- Values within each facet\n- How facets can be combined\n- Example combinations\n\nUse Mermaid mindmap or flowchart syntax.\n```\n\n**Example: Documentation Faceted Classification**\n\n**Your Prompt:**\n\n```\nCreate a diagram showing a faceted taxonomy for documentation.\n\nFacets:\n1. Content Type: Tutorial, How-to, Reference, Explanation\n2. Difficulty: Beginner, Intermediate, Advanced\n3. Product Area: Authentication, Storage, Search, Analytics\n4. Format: Text, Video, Interactive\n\nShow how these facets can be combined.\n```\n\n**AI Output:**\n\n```mermaid\nmindmap\n  root((Documentation<br/>Taxonomy))\n    Content Type\n      Tutorial\n      How-to Guide\n      Reference\n      Explanation\n    Difficulty\n      Beginner\n      Intermediate\n      Advanced\n    Product Area\n      Authentication\n      Storage\n      Search\n      Analytics\n    Format\n      Text Article\n      Video\n      Interactive Demo\n      Code Sample\n      \n```\n\n**With example combinations:**\n\n```\nEXAMPLE FACET COMBINATIONS:\n\n1. Tutorial + Beginner + Authentication + Video\n   = \"Video tutorial: Your first OAuth login (beginner)\"\n\n2. How-to + Intermediate + Storage + Text\n   = \"How to optimize file uploads (intermediate)\"\n\n3. Reference + Advanced + Analytics + Code Sample\n   = \"Analytics API reference with code samples (advanced)\"\n\n4. Explanation + Beginner + Search + Text\n   = \"How search indexing works (beginner explanation)\"\n\nFACET RULES:\n- Content Type: Required (exactly one)\n- Difficulty: Required (exactly one)\n- Product Area: Required (one or more)\n- Format: Optional (one or more)\n\nTOTAL COMBINATIONS: 4 \u00d7 3 \u00d7 4 \u00d7 4 = 192 possible combinations\n```\n\n---",
            "hydration_source_header": "Faceted Taxonomy Diagrams",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "cross-reference-diagram",
            "title": "Cross-Reference Diagram",
            "purpose": "Show content interconnections",
            "whenToUse": "Link strategy, content relationships",
            "lines": "485-560",
            "hydration_status": "failed"
          },
          {
            "id": "metadata-schema-diagram",
            "title": "Metadata Schema Diagram",
            "purpose": "Show metadata fields and relationships",
            "whenToUse": "CMS configuration, content governance",
            "lines": "565-640",
            "content": "[Detailed schema for each content type]\n\n---",
            "hydration_source_header": "Metadata Schema",
            "hydration_method": "title_match"
          },
          {
            "id": "ia-component-diagram",
            "title": "IA Component Diagram",
            "purpose": "Show IA system components",
            "whenToUse": "Technical documentation, system design",
            "lines": "645-720",
            "retrievalQuestions": [
              "What diagrams document IA systems?"
            ],
            "hydration_status": "failed"
          }
        ],
        "notationSystems": [
          {
            "id": "mermaid-notation",
            "title": "Mermaid.js Notation",
            "format": "Text-based, renders in many tools",
            "bestFor": "Site maps, flowcharts, hierarchies",
            "lines": "725-780",
            "retrievalQuestions": [
              "How do I use Mermaid for IA diagrams?"
            ],
            "content": "**Your Turn:** Generate a simple sitemap using AI.\n\n**Scenario:** You're documenting a basic recipe website with:\n- 15 recipes (appetizers, mains, desserts)\n- 5 cooking technique guides\n- About page\n\n**Task:**\n1. Write a prompt to generate an ASCII sitemap\n2. Generate it with AI\n3. Convert to Mermaid format\n4. Test in Mermaid Live Editor\n\n<details>\n<summary>Sample Solution</summary>\n\n**Prompt:**\n```text\nGenerate a sitemap for a recipe website with 20 pages.\n\nStructure:\n- 3 recipe categories (5 recipes each)\n- 1 cooking techniques section (5 pages)\n- 1 about page\n\nFormat as ASCII tree using \u251c\u2500\u2500, \u2514\u2500\u2500, and \u2502 characters.\nInclude page counts in parentheses.\n```\n\n**Expected Output:**\n```text\nHome\n\u251c\u2500\u2500 Recipes (15 pages, 75%)\n\u2502   \u251c\u2500\u2500 Appetizers (5 pages)\n\u2502   \u251c\u2500\u2500 Main Courses (5 pages)\n\u2502   \u2514\u2500\u2500 Desserts (5 pages)\n\u251c\u2500\u2500 Techniques (5 pages, 25%)\n\u2514\u2500\u2500 About\n```\n\n**Mermaid Conversion:**\n```mermaid\nflowchart TD\n    Home[Home]\n    Home --> Recipes[Recipes<br/>15 pages]\n    Home --> Techniques[Techniques<br/>5 pages]\n    Home --> About[About]\n\n    Recipes --> Appetizers[Appetizers]\n    Recipes --> Mains[Main Courses]\n    Recipes --> Desserts[Desserts]\n```\n\n**Validation:** Paste into [Mermaid Live Editor](https://mermaid.live/) - should render without errors.\n</details>\n\n---",
            "hydration_source_header": "Quick Practice Exercise (5 minutes)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "plantUML",
            "title": "PlantUML Notation",
            "format": "Text-based, UML-style diagrams",
            "bestFor": "Complex systems, ERDs",
            "lines": "implicit",
            "hydration_status": "failed"
          },
          {
            "id": "graphviz",
            "title": "Graphviz/DOT Notation",
            "format": "Text-based, network graphs",
            "bestFor": "Relationship networks",
            "lines": "implicit",
            "hydration_status": "failed"
          },
          {
            "id": "custom-ia-notation",
            "title": "Custom IA Notation Standards",
            "format": "Team-specific symbols and conventions",
            "bestFor": "Consistent team documentation",
            "lines": "1415-1500",
            "retrievalQuestions": [
              "Should I create custom IA notation?"
            ],
            "hydration_status": "failed"
          }
        ],
        "patterns": [
          {
            "id": "site-map-creation-pattern",
            "title": "Site Map Creation Pattern",
            "purpose": "Generate site maps from content",
            "lines": "80-130",
            "content": "**Basic sitemap generation with RICE framework:**\n\n```text\n[R - ROLE]\nYou are an information architect creating hierarchical sitemap structures for documentation sites.\n\n[I - INSTRUCTIONS]\nGenerate a sitemap diagram for [description of site/content].\n\nStructure requirements:\n- [Describe hierarchy levels, e.g., \"3 levels deep maximum\"]\n- [Number of items at each level, e.g., \"5-7 top-level sections\"]\n- [Any special requirements, e.g., \"Include Di\u00e1taxis content types\"]\n\nContent areas to include:\n[List main content areas or features]\n\n[C - CONTEXT]\n- Total pages: [number]\n- Target audience: [user types]\n- Organizational principle: [task-based/topic-based/role-based]\n\n[E - EXAMPLE FORMAT]\nOutput as ASCII tree structure:\n- Use \u251c\u2500\u2500, \u2514\u2500\u2500, and \u2502 characters\n- Include page counts in parentheses\n- Show percentage distribution for top-level categories\n- Flag any areas marked for future development with [Planned]\n\nExample format:\nHome\n\u251c\u2500\u2500 Category 1 (25 pages, 35%)\n\u2502   \u251c\u2500\u2500 Subcategory 1.1\n\u2502   \u2502   \u251c\u2500\u2500 Page 1\n\u2502   \u2502   \u2514\u2500\u2500 Page 2\n\u2502   \u2514\u2500\u2500 Subcategory 1.2\n\u2514\u2500\u2500 Category 2 (18 pages, 25%)\n    \u2514\u2500\u2500 Subcategory 2.1\n\nInclude balance analysis showing percentage distribution.\n```\n\n<Tip>\n**RICE Reminder:** This prompt follows the RICE framework from Module 1.3: **R**ole (IA specialist), **I**nstructions (structured requirements), **C**ontext (audience and principles), **E**xamples (format specification).\n</Tip>\n\n**Example: REST API Documentation Sitemap**\n\n**Your Prompt:**\n\n```\nGenerate a sitemap diagram for REST API documentation.\n\nStructure:\n- 3 levels deep maximum\n- 6 top-level sections\n- Include Di\u00c3\u00a1taxis content types where relevant\n\nContent areas:\n- Getting started and authentication\n- Core API resources (Users, Files, Webhooks)\n- SDKs and tools\n- Best practices and guides\n- Complete API reference\n- Troubleshooting\n\nTotal pages: 85\n\nFormat as ASCII tree with page counts and percentages.\n```\n\n**AI Output:**\n\n```\nAPI Documentation (85 pages)\n\u2502\n\u251c\u2500\u2500 Get Started (12 pages, 14%)\n\u2502   \u251c\u2500\u2500 Quickstart [Tutorial]\n\u2502   \u251c\u2500\u2500 Authentication Setup [Tutorial]\n\u2502   \u251c\u2500\u2500 Your First API Call [Tutorial]\n\u2502   \u2514\u2500\u2500 Core Concepts [Explanation]\n\u2502\n\u251c\u2500\u2500 Authentication & Security (10 pages, 12%)\n\u2502   \u251c\u2500\u2500 Authentication Methods [Explanation]\n\u2502   \u251c\u2500\u2500 OAuth 2.0 Flow [How-to]\n\u2502   \u251c\u2500\u2500 API Keys [How-to]\n\u2502   \u251c\u2500\u2500 Token Management [How-to]\n\u2502   \u2514\u2500\u2500 Security Best Practices [Reference]\n\u2502\n\u251c\u2500\u2500 Core Resources (30 pages, 35%)\n\u2502   \u251c\u2500\u2500 Users\n\u2502   \u2502   \u251c\u2500\u2500 User Object [Reference]\n\u2502   \u2502   \u251c\u2500\u2500 Create User [How-to]\n\u2502   \u2502   \u251c\u2500\u2500 List Users [How-to]\n\u2502   \u2502   \u2514\u2500\u2500 Update User [How-to]\n\u2502   \u251c\u2500\u2500 Files\n\u2502   \u2502   \u251c\u2500\u2500 File Object [Reference]\n\u2502   \u2502   \u251c\u2500\u2500 Upload Files [Tutorial]\n\u2502   \u2502   \u251c\u2500\u2500 Download Files [How-to]\n\u2502   \u2502   \u2514\u2500\u2500 File Metadata [Reference]\n\u2502   \u2514\u2500\u2500 Webhooks\n\u2502       \u251c\u2500\u2500 Webhook Events [Reference]\n\u2502       \u251c\u2500\u2500 Setup Webhooks [Tutorial]\n\u2502       \u2514\u2500\u2500 Verify Signatures [How-to]\n\u2502\n\u251c\u2500\u2500 SDKs & Tools (8 pages, 9%)\n\u2502   \u251c\u2500\u2500 Official SDKs\n\u2502   \u2502   \u251c\u2500\u2500 Python SDK [Reference]\n\u2502   \u2502   \u251c\u2500\u2500 JavaScript SDK [Reference]\n\u2502   \u2502   \u2514\u2500\u2500 Ruby SDK [Reference]\n\u2502   \u2514\u2500\u2500 CLI Tool [How-to]\n\u2502\n\u251c\u2500\u2500 API Reference (18 pages, 21%)\n\u2502   \u251c\u2500\u2500 All Endpoints [Reference]\n\u2502   \u251c\u2500\u2500 Error Codes [Reference]\n\u2502   \u251c\u2500\u2500 Rate Limits [Reference]\n\u2502   \u2514\u2500\u2500 Versioning [Explanation]\n\u2502\n\u2514\u2500\u2500 Troubleshooting (7 pages, 8%)\n    \u251c\u2500\u2500 Common Errors [How-to]\n    \u251c\u2500\u2500 Debug Mode [How-to]\n    \u2514\u2500\u2500 Support Resources [Reference]\n\nBALANCE ANALYSIS:\n\u2713 Core Resources at 35% (acceptable, main focus)\n\u2713 No category exceeds 40%\n\u2713 Good distribution of Di\u00c3\u00a1taxis types\n\u2713 Clear progressive disclosure (Get Started \u2192 Core \u2192 Advanced)\n```\n\n---",
            "hydration_source_header": "Text-to-Sitemap Prompt Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "taxonomy-visualization-pattern",
            "title": "Taxonomy Visualization Pattern",
            "purpose": "Create taxonomy diagrams",
            "lines": "155-210",
            "content": "Taxonomies can be visualized in multiple ways depending on complexity and purpose.\n\n### Simple Taxonomy Diagram Prompt\n\n**For hierarchical taxonomies:**\n\n```text\nVisualize this taxonomy as a Mermaid flowchart:\n\nTAXONOMY:\n[Paste your taxonomy structure]\n\nRequirements:\n- Use flowchart TD (top-down) layout\n- Show all levels of hierarchy (maximum 4 levels deep to prevent diagram complexity)\n- Include item counts at each node\n- Use colors to distinguish levels\n- Add a legend explaining the structure\n\nOutput valid Mermaid syntax.\n```\n\n**Example Output:**\n\n```mermaid\nflowchart TD\n    Root[Documentation Taxonomy<br/>150 pages]\n    \n    Root --> L1A[Get Started<br/>25 pages]\n    Root --> L1B[Build Features<br/>60 pages]\n    Root --> L1C[Deploy & Monitor<br/>35 pages]\n    Root --> L1D[Reference<br/>30 pages]\n    \n    L1A --> L2A1[Installation<br/>8 pages]\n    L1A --> L2A2[Quickstart<br/>12 pages]\n    L1A --> L2A3[Core Concepts<br/>5 pages]\n    \n    L1B --> L2B1[Authentication<br/>15 pages]\n    L1B --> L2B2[Data Management<br/>25 pages]\n    L1B --> L2B3[APIs<br/>20 pages]\n    \n    L1C --> L2C1[Configuration<br/>10 pages]\n    L1C --> L2C2[Deployment<br/>15 pages]\n    L1C --> L2C3[Monitoring<br/>10 pages]\n    \n    L1D --> L2D1[API Endpoints<br/>20 pages]\n    L1D --> L2D2[CLI Commands<br/>10 pages]\n    \n    L2A1 --> L3A1A[Linux]\n    L2A1 --> L3A1B[macOS]\n    L2A1 --> L3A1C[Windows]\n    \n    L2B2 --> L3B2A[Create Records]\n    L2B2 --> L3B2B[Update Records]\n    L2B2 --> L3B2C[Delete Records]\n    \n    classDef level1 fill:#e3f2fd,stroke:#1976d2,stroke-width:3px\n    classDef level2 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n    classDef level3 fill:#fff3e0,stroke:#f57c00,stroke-width:1px\n    \n    class L1A,L1B,L1C,L1D level1\n    class L2A1,L2A2,L2A3,L2B1,L2B2,L2B3,L2C1,L2C2,L2C3,L2D1,L2D2 level2\n    class L3A1A,L3A1B,L3A1C,L3B2A,L3B2B,L3B2C level3\n```\n\n---\n\n### Faceted Taxonomy Diagrams\n\nFor faceted classification systems, show multiple dimensions:\n\n**Faceted taxonomy prompt:**\n\n```\nCreate a diagram showing this faceted taxonomy:\n\nFACETS:\n[List each facet and its values]\n\nShow:\n- Each facet as a separate dimension\n- Values within each facet\n- How facets can be combined\n- Example combinations\n\nUse Mermaid mindmap or flowchart syntax.\n```\n\n**Example: Documentation Faceted Classification**\n\n**Your Prompt:**\n\n```\nCreate a diagram showing a faceted taxonomy for documentation.\n\nFacets:\n1. Content Type: Tutorial, How-to, Reference, Explanation\n2. Difficulty: Beginner, Intermediate, Advanced\n3. Product Area: Authentication, Storage, Search, Analytics\n4. Format: Text, Video, Interactive\n\nShow how these facets can be combined.\n```\n\n**AI Output:**\n\n```mermaid\nmindmap\n  root((Documentation<br/>Taxonomy))\n    Content Type\n      Tutorial\n      How-to Guide\n      Reference\n      Explanation\n    Difficulty\n      Beginner\n      Intermediate\n      Advanced\n    Product Area\n      Authentication\n      Storage\n      Search\n      Analytics\n    Format\n      Text Article\n      Video\n      Interactive Demo\n      Code Sample\n      \n```\n\n**With example combinations:**\n\n```\nEXAMPLE FACET COMBINATIONS:\n\n1. Tutorial + Beginner + Authentication + Video\n   = \"Video tutorial: Your first OAuth login (beginner)\"\n\n2. How-to + Intermediate + Storage + Text\n   = \"How to optimize file uploads (intermediate)\"\n\n3. Reference + Advanced + Analytics + Code Sample\n   = \"Analytics API reference with code samples (advanced)\"\n\n4. Explanation + Beginner + Search + Text\n   = \"How search indexing works (beginner explanation)\"\n\nFACET RULES:\n- Content Type: Required (exactly one)\n- Difficulty: Required (exactly one)\n- Product Area: Required (one or more)\n- Format: Optional (one or more)\n\nTOTAL COMBINATIONS: 4 \u00d7 3 \u00d7 4 \u00d7 4 = 192 possible combinations\n```\n\n---",
            "hydration_source_header": "IV. Taxonomy Visualizations (10 minutes)",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "content-model-creation-pattern",
            "title": "Content Model Diagram Pattern",
            "purpose": "Document content types and relationships",
            "lines": "235-300",
            "retrievalQuestions": [
              "How do I create a content model diagram?"
            ],
            "content": "**Basic content model diagram:**\n\n```text\nCreate a content model diagram in Mermaid syntax for [content domain].\n\nContent types:\n[List content types with brief descriptions]\n\nRelationships:\n[Describe key relationships, or let AI infer them]\n\nRequirements:\n- Use Mermaid entity-relationship diagram (erDiagram) syntax\n- Limit to 5-7 main entities to maintain diagram readability\n- Show cardinality (the relationship multiplicity: one-to-one, one-to-many, many-to-many)\n- Include key attributes for each content type\n- Use proper relationship labels\n\nOutput valid Mermaid syntax ready for rendering.\n```\n\n**Example: Blog Content Model**\n\n**Your Prompt:**\n\n```\nCreate a content model diagram in Mermaid syntax for a technical blog.\n\nContent types:\n1. BlogPost - Main article content\n2. Author - Person who writes posts\n3. Category - Topic classification\n4. Tag - Keyword metadata\n5. Series - Related posts grouped together\n6. Comment - Reader feedback\n\nRelationships to show:\n- Authors write BlogPosts (one author per post, authors can write many posts)\n- BlogPosts belong to one Category, Categories contain many posts\n- BlogPosts have many Tags, Tags can be on many posts\n- BlogPosts can belong to one Series (optional), Series contain many posts\n- BlogPosts have many Comments, Comments belong to one post\n\nInclude key attributes for each type.\n```\n\n**AI Output:**\n\n```mermaid\nerDiagram\n    Author ||--o{ BlogPost : writes\n    BlogPost }o--|| Category : \"belongs to\"\n    BlogPost }o--o{ Tag : \"tagged with\"\n    BlogPost }o--o| Series : \"part of\"\n    BlogPost ||--o{ Comment : receives\n    \n    Author {\n        string authorId PK\n        string name\n        string email\n        string bio\n        string avatarUrl\n        date joinedDate\n        array socialLinks\n    }\n    \n    BlogPost {\n        string postId PK\n        string authorId FK\n        string categoryId FK\n        string seriesId FK\n        string title\n        string slug\n        text content\n        string excerpt\n        array tags\n        date publishedDate\n        date updatedDate\n        string status\n        int readingTime\n        string featuredImage\n    }\n    \n    Category {\n        string categoryId PK\n        string name\n        string slug\n        string description\n        int postCount\n    }\n    \n    Tag {\n        string tagId PK\n        string name\n        string slug\n        int usageCount\n    }\n    \n    Series {\n        string seriesId PK\n        string title\n        string description\n        int postCount\n        array postOrder\n    }\n    \n    Comment {\n        string commentId PK\n        string postId FK\n        string authorName\n        string authorEmail\n        text content\n        date postedDate\n        string status\n    }\n```\n\n---",
            "hydration_source_header": "Content Model Prompt Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "user-flow-creation-pattern",
            "title": "User Flow Creation Pattern",
            "purpose": "Map user journeys through IA",
            "lines": "325-390",
            "content": "**Basic user flow:**\n\n```text\nCreate a user flow diagram showing how users [accomplish specific goal].\n\nStarting point: [Where user begins]\nGoal: [What user wants to accomplish]\nKey decision points: [Major choices user makes]\nPossible paths: [Different routes to success]\nFailure points: [Where users might get stuck]\n\nUse Mermaid flowchart with:\n- Diamond shapes {} for decision points (e.g., \"Has API key?\")\n- Rectangle shapes [] for action steps (e.g., \"Read authentication guide\")\n- Different colors for successful vs. error paths\n- Specify error handling paths explicitly\n- Annotations for pain points\n\nOutput valid Mermaid syntax.\n```\n\n**Example: API Documentation User Flow**\n\n**Your Prompt:**\n\n```\nCreate a user flow diagram for a developer using API documentation to integrate authentication.\n\nStarting point: Documentation homepage\nGoal: Successfully implement OAuth 2.0 authentication\nKey decision points:\n- New to APIs vs. experienced\n- OAuth vs. API keys\n- Language/framework choice\n\nShow both successful and error paths.\n```\n\n**AI Output:**\n\n```mermaid\nflowchart TD\n    Start([Developer arrives at<br/>docs homepage])\n    Start --> Q1{New to our API?}\n    \n    Q1 -->|Yes| GetStarted[Get Started Guide]\n    Q1 -->|No| GoToAuth[Navigate to Authentication]\n    \n    GetStarted --> LearnBasics[Learn API Basics]\n    LearnBasics --> Q2{Ready for auth?}\n    Q2 -->|Yes| GoToAuth\n    Q2 -->|No| Confused1[\ud83d\ude15 Still confused]\n    \n    GoToAuth --> AuthOverview[Authentication Overview]\n    AuthOverview --> Q3{Which method?}\n    \n    Q3 -->|OAuth 2.0| OAuthGuide[OAuth 2.0 Guide]\n    Q3 -->|API Keys| APIKeyGuide[API Keys Guide]\n    Q3 -->|Not sure| Confused2[\ud83d\ude15 Which should I use?]\n    \n    OAuthGuide --> Q4{Has OAuth<br/>experience?}\n    Q4 -->|Yes| QuickStart[OAuth Quickstart]\n    Q4 -->|No| Tutorial[OAuth Tutorial]\n    \n    Tutorial --> CodeExample[Copy code example]\n    QuickStart --> CodeExample\n    \n    CodeExample --> Q5{Choose language}\n    Q5 -->|Python| PythonSDK[Python SDK Guide]\n    Q5 -->|JavaScript| JSSDK[JavaScript SDK Guide]\n    Q5 -->|Other| OtherSDK[Other Languages]\n    \n    PythonSDK --> Implement[Implement in app]\n    JSSDK --> Implement\n    OtherSDK --> Implement\n    \n    Implement --> Q6{Working?}\n    Q6 -->|Yes| Success([\u2705 Successfully authenticated])\n    Q6 -->|No| Troubleshoot[Troubleshooting Guide]\n    \n    Troubleshoot --> Q7{Found solution?}\n    Q7 -->|Yes| Implement\n    Q7 -->|No| Support[Contact Support]\n    \n    APIKeyGuide --> APIQuickStart[API Key Setup]\n    APIQuickStart --> CodeExample\n    \n    Confused1 -.->|Needs help| GetStarted\n    Confused2 -.->|Needs guidance| CompareAuth[Compare Auth Methods]\n    CompareAuth --> Q3\n    \n    classDef successPath fill:#c8e6c9,stroke:#2e7d32\n    classDef errorPath fill:#ffccbc,stroke:#d84315\n    classDef decisionPath fill:#fff9c4,stroke:#f57f17\n    classDef painPoint fill:#ffcdd2,stroke:#c62828\n    \n    class Success successPath\n    class Confused1,Confused2,Troubleshoot,Support errorPath\n    class Q1,Q2,Q3,Q4,Q5,Q6,Q7 decisionPath\n    class Confused1,Confused2 painPoint\n```\n\n**Flow analysis annotation:**\n\n```\nUSER FLOW ANALYSIS:\n\nSUCCESS PATHS:\n1. Experienced \u2192 Auth Overview \u2192 OAuth Guide \u2192 Quickstart \u2192 Implement\n   Estimated time: 10-15 minutes\n   \n2. New \u2192 Get Started \u2192 Learn Basics \u2192 Auth Guide \u2192 Tutorial \u2192 Implement\n   Estimated time: 30-45 minutes\n\nPAIN POINTS IDENTIFIED:\n\u26a0\ufe0f Confusion Point 1: New users unsure if they're ready for auth\n   Solution: Add \"Prerequisites\" checklist in Get Started\n\n\u26a0\ufe0f Confusion Point 2: Users don't know which auth method to choose\n   Solution: Add comparison table or decision tree in Auth Overview\n\n\u26a0\ufe0f Drop-off risk: Between code example and implementation\n   Solution: Add \"Test your authentication\" interactive validator\n\nMETRICS TO TRACK:\n- % taking successful path without troubleshooting\n- Average time from Start to Success\n- Most common exit points (abandonment)\n- % needing support after troubleshooting\n```\n\n---",
            "hydration_source_header": "User Flow Diagram Prompt Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "adr-creation-pattern",
            "title": "ADR Creation Pattern",
            "purpose": "Document IA decisions",
            "lines": "800-900",
            "content": "**Basic content model diagram:**\n\n```text\nCreate a content model diagram in Mermaid syntax for [content domain].\n\nContent types:\n[List content types with brief descriptions]\n\nRelationships:\n[Describe key relationships, or let AI infer them]\n\nRequirements:\n- Use Mermaid entity-relationship diagram (erDiagram) syntax\n- Limit to 5-7 main entities to maintain diagram readability\n- Show cardinality (the relationship multiplicity: one-to-one, one-to-many, many-to-many)\n- Include key attributes for each content type\n- Use proper relationship labels\n\nOutput valid Mermaid syntax ready for rendering.\n```\n\n**Example: Blog Content Model**\n\n**Your Prompt:**\n\n```\nCreate a content model diagram in Mermaid syntax for a technical blog.\n\nContent types:\n1. BlogPost - Main article content\n2. Author - Person who writes posts\n3. Category - Topic classification\n4. Tag - Keyword metadata\n5. Series - Related posts grouped together\n6. Comment - Reader feedback\n\nRelationships to show:\n- Authors write BlogPosts (one author per post, authors can write many posts)\n- BlogPosts belong to one Category, Categories contain many posts\n- BlogPosts have many Tags, Tags can be on many posts\n- BlogPosts can belong to one Series (optional), Series contain many posts\n- BlogPosts have many Comments, Comments belong to one post\n\nInclude key attributes for each type.\n```\n\n**AI Output:**\n\n```mermaid\nerDiagram\n    Author ||--o{ BlogPost : writes\n    BlogPost }o--|| Category : \"belongs to\"\n    BlogPost }o--o{ Tag : \"tagged with\"\n    BlogPost }o--o| Series : \"part of\"\n    BlogPost ||--o{ Comment : receives\n    \n    Author {\n        string authorId PK\n        string name\n        string email\n        string bio\n        string avatarUrl\n        date joinedDate\n        array socialLinks\n    }\n    \n    BlogPost {\n        string postId PK\n        string authorId FK\n        string categoryId FK\n        string seriesId FK\n        string title\n        string slug\n        text content\n        string excerpt\n        array tags\n        date publishedDate\n        date updatedDate\n        string status\n        int readingTime\n        string featuredImage\n    }\n    \n    Category {\n        string categoryId PK\n        string name\n        string slug\n        string description\n        int postCount\n    }\n    \n    Tag {\n        string tagId PK\n        string name\n        string slug\n        int usageCount\n    }\n    \n    Series {\n        string seriesId PK\n        string title\n        string description\n        int postCount\n        array postOrder\n    }\n    \n    Comment {\n        string commentId PK\n        string postId FK\n        string authorName\n        string authorEmail\n        text content\n        date postedDate\n        string status\n    }\n```\n\n---",
            "hydration_source_header": "Content Model Prompt Pattern",
            "hydration_method": "line_proximity"
          },
          {
            "id": "adr-template-pattern",
            "title": "ADR Template Pattern",
            "purpose": "Standard ADR structure",
            "lines": "905-1000",
            "content": "For documentation projects, showing metadata alongside content types is crucial.\n\n**Metadata-enriched model prompt:**\n\n```\nCreate a detailed content model showing metadata schemas for documentation.\n\nContent types:\n[List types]\n\nFor each content type, show:\n- Required fields\n- Optional fields\n- Field data types\n- Validation rules (if relevant)\n- Example values\n\nUse Mermaid class diagram syntax to show inheritance and composition.\n```\n\n**Example: Documentation Content Model**\n\n**Your Prompt:**\n\n```\nCreate a detailed content model for API documentation showing metadata schemas.\n\nContent types:\n1. BaseContent (inherited by all others)\n2. Tutorial (step-by-step learning)\n3. HowToGuide (task-oriented)\n4. Reference (technical specs)\n5. Explanation (conceptual)\n\nShow required vs optional fields, data types, and inheritance.\n```\n\n**AI Output:**\n\n```mermaid\nclassDiagram\n    class BaseContent {\n        <<abstract>>\n        +string id\n        +string title\n        +string slug\n        +text description\n        +string author\n        +date createdDate\n        +date updatedDate\n        +string status\n        +array tags\n        +int readingTime\n        +string[] relatedContent\n        validate()\n        publish()\n    }\n    \n    class Tutorial {\n        +int estimatedTime\n        +string[] prerequisites\n        +string[] learningObjectives\n        +array steps\n        +string[] codeExamples\n        +string difficulty\n        +bool includesVideo\n        validateSteps()\n    }\n    \n    class HowToGuide {\n        +string problem\n        +string solution\n        +string[] prerequisites\n        +array steps\n        +string[] alternatives\n        +string[] troubleshooting\n        +string timeToComplete\n        validateProblemSolution()\n    }\n    \n    class Reference {\n        +string endpoint\n        +string httpMethod\n        +object parameters\n        +object responseSchema\n        +string[] errorCodes\n        +string apiVersion\n        +bool deprecated\n        +string deprecationDate\n        validateSchema()\n    }\n    \n    class Explanation {\n        +string concept\n        +string[] keyPoints\n        +array sections\n        +string[] furtherReading\n        +string[] relatedConcepts\n        +bool includesDiagram\n        validateConcept()\n    }\n    \n    BaseContent <|-- Tutorial\n    BaseContent <|-- HowToGuide\n    BaseContent <|-- Reference\n    BaseContent <|-- Explanation\n    \n    Tutorial --> BaseContent : relatedContent\n    HowToGuide --> BaseContent : relatedContent\n    Reference --> BaseContent : relatedContent\n    Explanation --> BaseContent : relatedContent\n```\n\n---",
            "hydration_source_header": "Adding Metadata Schemas to Content Models",
            "hydration_method": "line_proximity"
          },
          {
            "id": "mermaid-site-map-pattern",
            "title": "Mermaid Site Map Pattern",
            "purpose": "Text-based site map creation",
            "lines": "1505-1580",
            "retrievalQuestions": [
              "Show me a Mermaid site map example"
            ],
            "content": "Professional IA work requires a complete documentation package, not just individual diagrams.\n\n### The Complete Documentation Set\n\n**Essential deliverables:**\n\n1. **IA Overview Document**\n   - Executive summary\n   - Key decisions and rationale\n   - Success metrics\n\n2. **Sitemap Diagram**\n   - Full hierarchical structure\n   - Page counts and distribution\n   - Implementation status\n\n3. **Content Model**\n   - Content types and relationships\n   - Metadata schemas\n   - Validation rules\n\n4. **Navigation Specification**\n   - Top navigation\n   - Sidebar/secondary navigation\n   - Breadcrumbs\n   - Footer navigation\n\n5. **Taxonomy Documentation**\n   - Classification system\n   - Tagging schema\n   - Governance rules\n\n6. **User Flows**\n   - Primary user journeys\n   - Decision points\n   - Pain points and solutions\n\n7. **Implementation Guide**\n   - Technical requirements\n   - CMS configuration\n   - Content migration plan\n   - Rollout phases\n\n---\n\n### The 5-Prompt Chain Strategy\n\n<Warning>\n**Best Practice:** Don't generate complete IA package in one prompt! Break into 5-prompt chain where each output becomes context for next.\n</Warning>\n\n**Quick overview:**\n1. Prompt 1: Executive Summary (1 page)\n2. Prompt 2: IA Overview (2-3 pages)\n3. Prompt 3: Visual Diagrams (validate in Mermaid Live)\n4. Prompt 4: Navigation Spec (1-2 pages)\n5. Prompt 5: Implementation Guide (1 page)\n\nThen assemble all outputs.\n\n### Legacy: Single Prompt Approach (Not Recommended)\n\n```\nGenerate a complete IA documentation package for [project name].\n\nPROJECT CONTEXT:\n[Brief description]\n\nINCLUDE:\n\n1. Executive Summary (1 page)\n   - Project goals\n   - Key decisions made\n   - Expected impact\n   - Success metrics\n\n2. IA Overview (2-3 pages)\n   - Organizational principle (task-based, feature-based, etc.)\n   - Hierarchy structure and rationale\n   - Balance and distribution analysis\n   - Content type strategy\n   - Design trade-offs\n\n3. Visual Diagrams\n   - Sitemap (Mermaid format)\n   - Content model (Mermaid format)\n   - Primary user flow (Mermaid format)\n\n4. Navigation Specification (1-2 pages)\n   - Top navigation items with descriptions\n   - Sidebar structure and logic\n   - Breadcrumb pattern\n   - Cross-linking strategy\n\n5. Implementation Notes (1 page)\n   - Technical requirements\n   - CMS/platform considerations\n   - Rollout phases\n   - Success metrics to track\n\nFormat as a markdown document with embedded Mermaid diagrams.\nOrganize with clear headers and table of contents.\n```\n\n**Example usage:**\n\n**Your Prompt:**\n\n```\nGenerate a complete IA documentation package for a new API documentation site.\n\nProject: CloudStore API Documentation\nGoal: Redesign documentation for 85 pages of API docs\nAudience: Backend developers (junior to senior)\nCurrent problem: Documentation is organized by internal services, confusing users\nApproach: Task-based organization with Di\u00c3\u00a1taxis framework\n\nInclude all standard sections.\n```\n\n**AI Output Structure:**\n\n```markdown",
            "hydration_source_header": "VI. Complete IA Documentation Package (10 minutes)",
            "hydration_method": "line_proximity"
          }
        ],
        "promptPatterns": [
          {
            "id": "site-map-prompt",
            "title": "Site Map Generation Prompt",
            "taskType": "generation",
            "lines": "90-120",
            "standalone": true,
            "retrievalQuestions": [
              "Give me a prompt to generate a site map"
            ],
            "content": "Before generating diagrams, understand the notation conventions that make IA documentation clear and professional.\n\n### Core IA Diagram Types\n\n**1. Sitemap / Hierarchy Diagrams**\n- **Purpose:** Show structural relationships and navigation paths\n- **Best for:** Website structure, navigation menus, content organization\n- **Notation:** Tree structure with parent-child relationships\n\n**2. Content Model Diagrams**\n- **Purpose:** Show content types and their relationships\n- **Best for:** CMS planning, structured content systems, metadata design\n- **Notation:** Entity-relationship style with typed connections\n\n**3. Taxonomy Diagrams**\n- **Purpose:** Show classification systems and facets\n- **Best for:** Categorization schemes, filtering systems, metadata hierarchies\n- **Notation:** Tree or network structure with classification logic\n\n**4. User Flow Diagrams**\n- **Purpose:** Show how users move through information space\n- **Best for:** Journey mapping, findability analysis, navigation testing\n- **Notation:** Flowchart with decision points and paths\n\n**5. Wireflow Diagrams**\n- **Purpose:** Combine page layouts with flow\n- **Best for:** Detailed interaction design, showing IA in context\n- **Notation:** Wireframes connected by flow arrows\n\n---\n\n### Decision Guide: Choosing the Right Diagram Type\n\nNot sure which diagram to use? Follow this decision flow:\n\n<AccordionGroup>\n<Accordion title=\"Start Here: What are you trying to communicate?\">\n\n**Question 1: What's your primary goal?**\n\n**A. \"Show what content exists and how it's organized\"**\n\u2192 Use **Sitemap/Hierarchy Diagram**\n- Best for: Stakeholder presentations, developer handoff, content planning\n- Example: \"Show all 85 pages in our docs and their structure\"\n\n**B. \"Show how different content types relate to each other\"**\n\u2192 Use **Content Model Diagram**\n- Best for: CMS planning, database design, metadata strategy\n- Example: \"Explain how BlogPosts, Authors, and Tags connect\"\n\n**C. \"Show how we classify and categorize things\"**\n\u2192 Use **Taxonomy Diagram**\n- Best for: Filtering systems, tag hierarchies, navigation facets\n- Example: \"Illustrate our product categorization with 3 facets\"\n\n**D. \"Show how users navigate to accomplish a goal\"**\n\u2192 Use **User Flow Diagram**\n- Best for: Journey mapping, identifying friction points, testing navigation\n- Example: \"Map the path from homepage to first successful API call\"\n\n**E. \"Show the full picture with page layouts\"**\n\u2192 Use **Wireflow Diagram**\n- Best for: Detailed interaction design, prototype documentation\n- Example: \"Combine navigation + page structure for checkout flow\"\n\n</Accordion>\n\n<Accordion title=\"Audience Considerations\">\n\n**Who will use this diagram?**\n\n**Executive Stakeholders:**\n- Keep it simple: **Sitemap** (high-level structure only)\n- Avoid: Detailed content models, technical notation\n\n**Developers/Engineers:**\n- Technical detail welcome: **Content Model** with full attributes\n- Include: Implementation notes, CMS mappings, data types\n\n**Design Team:**\n- Visual emphasis: **User Flow** with decision points\n- Include: Screen states, interaction patterns\n\n**Content Team:**\n- Practical organization: **Sitemap** or **Taxonomy**\n- Include: Content type labels, page counts, workflow notes\n\n**Mixed Audience:**\n- Start simple: **Sitemap** for overview\n- Layer detail: Add content model and flows as appendices\n\n</Accordion>\n\n  <Accordion title=\"When to Use Multiple Diagrams\">\n\n**Comprehensive Documentation Package:**\n\nUse 3-4 complementary diagrams:\n\n1. **Sitemap** \u2192 Shows overall structure\n2. **Content Model** \u2192 Shows data relationships\n3. **User Flow** \u2192 Shows 1-2 primary journeys\n4. (Optional) **Taxonomy** \u2192 Shows classification logic\n\n**Example: API Documentation Package**\n\n```\n\u251c\u2500\u2500 1-sitemap.md (85 pages, 6 top-level sections)\n\u251c\u2500\u2500 2-content-model.md (Tutorial, Guide, Reference relationships)\n\u251c\u2500\u2500 3-user-flow-onboarding.md (New user \u2192 First API call)\n\u2514\u2500\u2500 4-user-flow-troubleshooting.md (Error \u2192 Solution path)\n```\n\n**When One Diagram Isn't Enough:**\n\n- Complex site (>50 pages) \u2192 Break sitemap into sections\n- Multiple user types \u2192 Create flow per persona\n- Evolving IA \u2192 Show current vs. proposed side-by-side\n\n</Accordion>\n\n<Accordion title=\"Common Mistakes to Avoid\">\n\n\u274c **Wrong:** Using sitemap when you need to show relationships\n- **Problem:** Sitemaps only show hierarchy, not cross-links or connections\n- **Fix:** Use content model with relationship lines\n\n\u274c **Wrong:** Using content model when you need to show user paths\n- **Problem:** Content models are static, not sequential\n- **Fix:** Use user flow diagram with decision points\n\n\u274c **Wrong:** Creating one massive diagram for everything\n- **Problem:** Overwhelms viewers, hard to maintain\n- **Fix:** Break into focused diagrams, each with single purpose\n\n\u274c **Wrong:** Choosing diagram type before understanding goal\n- **Problem:** Diagram doesn't answer the actual question\n- **Fix:** Start with \"What decision will this diagram inform?\"\n\n\u2705 **Right:** Match diagram type to communication goal\n\n</Accordion>\n\n<Accordion title=\"Quick Reference Table\">\n\n| Diagram Type | Primary Use | Key Question It Answers | Complexity Level |\n|--------------|-------------|------------------------|------------------|\n| **Sitemap** | Structure overview | \"What pages exist and where?\" | Simple |\n| **Content Model** | Data relationships | \"How do content types connect?\" | Medium |\n| **Taxonomy** | Classification | \"How do we categorize things?\" | Medium |\n| **User Flow** | Navigation paths | \"How do users accomplish goals?\" | Medium-Complex |\n| **Wireflow** | Detailed interaction | \"What does user see at each step?\" | Complex |\n\n**Complexity Guide:**\n- **Simple:** Can explain in under 5 minutes, few elements\n- **Medium:** Takes 10-15 minutes to explain, moderate detail\n- **Complex:** Requires 20+ minutes, many elements, best for technical audiences\n\n</Accordion>\n\n</AccordionGroup>\n\n---\n\n### Standard Notation Elements\n\n**Hierarchy Notation:**\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  STANDARD HIERARCHY NOTATION        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502\n\u2502  \u2502 Root \u2502  \u2190 Top level              \u2502\n\u2502  \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518                           \u2502\n\u2502     \u2502                               \u2502\n\u2502     \u251c\u2500\u2500 Category 1 \u2190 Second level   \u2502\n\u2502     \u2502   \u251c\u2500\u2500 Subcategory 1.1         \u2502\n\u2502     \u2502   \u2514\u2500\u2500 Subcategory 1.2         \u2502\n\u2502     \u2502                               \u2502\n\u2502     \u2514\u2500\u2500 Category 2                  \u2502\n\u2502         \u251c\u2500\u2500 Subcategory 2.1         \u2502\n\u2502         \u2514\u2500\u2500 Subcategory 2.2         \u2502\n\u2502                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n**Relationship Notation:**\n\n```\nContent Type A \u2500\u2500\u2192 Content Type B    (one-to-one)\nContent Type A \u2500\u2500\u2192 Content Type B    (one-to-many, use label)\n               \u2500\u2500\u2192 Content Type C\n\nContent Type A \u2190\u2500\u2500\u2192 Content Type B   (bidirectional)\n\nContent Type A \u00b7\u00b7\u00b7\u00b7\u2192 Content Type B  (optional relationship)\n\nContent Type A \u2550\u2550\u2192 Content Type B    (required relationship)\n```\n\n**Status Indicators:**\n\n```\n[Implemented]     \u2190 Live in production\n[In Progress]     \u2190 Currently being built\n[Planned]         \u2190 Approved, not started\n[Proposed]        \u2190 Under consideration\n[Deprecated]      \u2190 Being phased out\n```\n\n**Content Type Labels:**\n\n```\n\ud83d\udcc4 [Tutorial]      \u2190 Learning-oriented\n\ud83d\udd27 [How-to]        \u2190 Task-oriented  \n\ud83d\udcda [Reference]     \u2190 Information-oriented\n\ud83d\udca1 [Explanation]   \u2190 Understanding-oriented\n```\n\n**Annotations:**\n\n```\nCategory Name (45 pages, 30%)  \u2190 Include page counts and percentages\nCategory Name*                 \u2190 Asterisk for notes\nCategory Name [P0]             \u2190 Priority indicators\nCategory Name \u26a0\ufe0f                \u2190 Warning/issue flags\n```\n\n---\n\n### IA Notation Best Practices\n\n**DO:**\n- \u2705 Use consistent symbols throughout a document set\n- \u2705 Include a legend/key for notation\n- \u2705 Label all relationships clearly\n- \u2705 Show quantitative information (counts, percentages)\n- \u2705 Indicate implementation status\n- \u2705 Date all diagrams\n- \u2705 Version diagrams when they change\n\n**DON'T:**\n- \u274c Mix notation styles within same document\n- \u274c Use color as the only differentiator (accessibility)\n- \u274c Create diagrams without context or explanation\n- \u274c Make diagrams so complex they're unreadable\n- \u274c Forget to update diagrams when IA changes\n\n<Warning>\n**Knowledge Check:** Before proceeding, verify your understanding:\n\n1. What are the 4 main types of IA diagrams? (Sitemaps, Content Models, Taxonomy Visualizations, User Flows)\n2. What's the main benefit of Docs-as-Code approach? (Version control, collaboration, automation)\n3. What format does this module teach for IA diagrams? (Mermaid syntax for markdown files)\n\n<details>\n<summary>Check Your Answers</summary>\n\n1. **4 main types:** Sitemaps (structure), Content Models (relationships), Taxonomy Visualizations (classification), User Flows (navigation paths)\n2. **Docs-as-Code benefits:** Version control with Git, plain text collaboration, CI/CD automation, single source of truth\n3. **Format:** Mermaid syntax embedded in markdown, renderable in docs platforms and GitHub\n\nIf you got these right, you're ready to proceed. If not, review Section I before continuing.\n</details>\n</Warning>\n\n---",
            "hydration_source_header": "I. Standard IA Notation Fundamentals (10 minutes)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "taxonomy-viz-prompt",
            "title": "Taxonomy Visualization Prompt",
            "taskType": "generation",
            "lines": "165-200",
            "standalone": true,
            "content": "Taxonomies can be visualized in multiple ways depending on complexity and purpose.\n\n### Simple Taxonomy Diagram Prompt\n\n**For hierarchical taxonomies:**\n\n```text\nVisualize this taxonomy as a Mermaid flowchart:\n\nTAXONOMY:\n[Paste your taxonomy structure]\n\nRequirements:\n- Use flowchart TD (top-down) layout\n- Show all levels of hierarchy (maximum 4 levels deep to prevent diagram complexity)\n- Include item counts at each node\n- Use colors to distinguish levels\n- Add a legend explaining the structure\n\nOutput valid Mermaid syntax.\n```\n\n**Example Output:**\n\n```mermaid\nflowchart TD\n    Root[Documentation Taxonomy<br/>150 pages]\n    \n    Root --> L1A[Get Started<br/>25 pages]\n    Root --> L1B[Build Features<br/>60 pages]\n    Root --> L1C[Deploy & Monitor<br/>35 pages]\n    Root --> L1D[Reference<br/>30 pages]\n    \n    L1A --> L2A1[Installation<br/>8 pages]\n    L1A --> L2A2[Quickstart<br/>12 pages]\n    L1A --> L2A3[Core Concepts<br/>5 pages]\n    \n    L1B --> L2B1[Authentication<br/>15 pages]\n    L1B --> L2B2[Data Management<br/>25 pages]\n    L1B --> L2B3[APIs<br/>20 pages]\n    \n    L1C --> L2C1[Configuration<br/>10 pages]\n    L1C --> L2C2[Deployment<br/>15 pages]\n    L1C --> L2C3[Monitoring<br/>10 pages]\n    \n    L1D --> L2D1[API Endpoints<br/>20 pages]\n    L1D --> L2D2[CLI Commands<br/>10 pages]\n    \n    L2A1 --> L3A1A[Linux]\n    L2A1 --> L3A1B[macOS]\n    L2A1 --> L3A1C[Windows]\n    \n    L2B2 --> L3B2A[Create Records]\n    L2B2 --> L3B2B[Update Records]\n    L2B2 --> L3B2C[Delete Records]\n    \n    classDef level1 fill:#e3f2fd,stroke:#1976d2,stroke-width:3px\n    classDef level2 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n    classDef level3 fill:#fff3e0,stroke:#f57c00,stroke-width:1px\n    \n    class L1A,L1B,L1C,L1D level1\n    class L2A1,L2A2,L2A3,L2B1,L2B2,L2B3,L2C1,L2C2,L2C3,L2D1,L2D2 level2\n    class L3A1A,L3A1B,L3A1C,L3B2A,L3B2B,L3B2C level3\n```\n\n---\n\n### Faceted Taxonomy Diagrams\n\nFor faceted classification systems, show multiple dimensions:\n\n**Faceted taxonomy prompt:**\n\n```\nCreate a diagram showing this faceted taxonomy:\n\nFACETS:\n[List each facet and its values]\n\nShow:\n- Each facet as a separate dimension\n- Values within each facet\n- How facets can be combined\n- Example combinations\n\nUse Mermaid mindmap or flowchart syntax.\n```\n\n**Example: Documentation Faceted Classification**\n\n**Your Prompt:**\n\n```\nCreate a diagram showing a faceted taxonomy for documentation.\n\nFacets:\n1. Content Type: Tutorial, How-to, Reference, Explanation\n2. Difficulty: Beginner, Intermediate, Advanced\n3. Product Area: Authentication, Storage, Search, Analytics\n4. Format: Text, Video, Interactive\n\nShow how these facets can be combined.\n```\n\n**AI Output:**\n\n```mermaid\nmindmap\n  root((Documentation<br/>Taxonomy))\n    Content Type\n      Tutorial\n      How-to Guide\n      Reference\n      Explanation\n    Difficulty\n      Beginner\n      Intermediate\n      Advanced\n    Product Area\n      Authentication\n      Storage\n      Search\n      Analytics\n    Format\n      Text Article\n      Video\n      Interactive Demo\n      Code Sample\n      \n```\n\n**With example combinations:**\n\n```\nEXAMPLE FACET COMBINATIONS:\n\n1. Tutorial + Beginner + Authentication + Video\n   = \"Video tutorial: Your first OAuth login (beginner)\"\n\n2. How-to + Intermediate + Storage + Text\n   = \"How to optimize file uploads (intermediate)\"\n\n3. Reference + Advanced + Analytics + Code Sample\n   = \"Analytics API reference with code samples (advanced)\"\n\n4. Explanation + Beginner + Search + Text\n   = \"How search indexing works (beginner explanation)\"\n\nFACET RULES:\n- Content Type: Required (exactly one)\n- Difficulty: Required (exactly one)\n- Product Area: Required (one or more)\n- Format: Optional (one or more)\n\nTOTAL COMBINATIONS: 4 \u00d7 3 \u00d7 4 \u00d7 4 = 192 possible combinations\n```\n\n---",
            "hydration_source_header": "IV. Taxonomy Visualizations (10 minutes)",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "content-model-prompt",
            "title": "Content Model Diagram Prompt",
            "taskType": "generation",
            "lines": "245-290",
            "standalone": true,
            "retrievalQuestions": [
              "What prompt creates content model diagrams?"
            ],
            "content": "**Basic content model diagram:**\n\n```text\nCreate a content model diagram in Mermaid syntax for [content domain].\n\nContent types:\n[List content types with brief descriptions]\n\nRelationships:\n[Describe key relationships, or let AI infer them]\n\nRequirements:\n- Use Mermaid entity-relationship diagram (erDiagram) syntax\n- Limit to 5-7 main entities to maintain diagram readability\n- Show cardinality (the relationship multiplicity: one-to-one, one-to-many, many-to-many)\n- Include key attributes for each content type\n- Use proper relationship labels\n\nOutput valid Mermaid syntax ready for rendering.\n```\n\n**Example: Blog Content Model**\n\n**Your Prompt:**\n\n```\nCreate a content model diagram in Mermaid syntax for a technical blog.\n\nContent types:\n1. BlogPost - Main article content\n2. Author - Person who writes posts\n3. Category - Topic classification\n4. Tag - Keyword metadata\n5. Series - Related posts grouped together\n6. Comment - Reader feedback\n\nRelationships to show:\n- Authors write BlogPosts (one author per post, authors can write many posts)\n- BlogPosts belong to one Category, Categories contain many posts\n- BlogPosts have many Tags, Tags can be on many posts\n- BlogPosts can belong to one Series (optional), Series contain many posts\n- BlogPosts have many Comments, Comments belong to one post\n\nInclude key attributes for each type.\n```\n\n**AI Output:**\n\n```mermaid\nerDiagram\n    Author ||--o{ BlogPost : writes\n    BlogPost }o--|| Category : \"belongs to\"\n    BlogPost }o--o{ Tag : \"tagged with\"\n    BlogPost }o--o| Series : \"part of\"\n    BlogPost ||--o{ Comment : receives\n    \n    Author {\n        string authorId PK\n        string name\n        string email\n        string bio\n        string avatarUrl\n        date joinedDate\n        array socialLinks\n    }\n    \n    BlogPost {\n        string postId PK\n        string authorId FK\n        string categoryId FK\n        string seriesId FK\n        string title\n        string slug\n        text content\n        string excerpt\n        array tags\n        date publishedDate\n        date updatedDate\n        string status\n        int readingTime\n        string featuredImage\n    }\n    \n    Category {\n        string categoryId PK\n        string name\n        string slug\n        string description\n        int postCount\n    }\n    \n    Tag {\n        string tagId PK\n        string name\n        string slug\n        int usageCount\n    }\n    \n    Series {\n        string seriesId PK\n        string title\n        string description\n        int postCount\n        array postOrder\n    }\n    \n    Comment {\n        string commentId PK\n        string postId FK\n        string authorName\n        string authorEmail\n        text content\n        date postedDate\n        string status\n    }\n```\n\n---",
            "hydration_source_header": "Content Model Prompt Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "user-flow-prompt",
            "title": "User Flow Generation Prompt",
            "taskType": "generation",
            "lines": "335-380",
            "standalone": true,
            "content": "**Basic user flow:**\n\n```text\nCreate a user flow diagram showing how users [accomplish specific goal].\n\nStarting point: [Where user begins]\nGoal: [What user wants to accomplish]\nKey decision points: [Major choices user makes]\nPossible paths: [Different routes to success]\nFailure points: [Where users might get stuck]\n\nUse Mermaid flowchart with:\n- Diamond shapes {} for decision points (e.g., \"Has API key?\")\n- Rectangle shapes [] for action steps (e.g., \"Read authentication guide\")\n- Different colors for successful vs. error paths\n- Specify error handling paths explicitly\n- Annotations for pain points\n\nOutput valid Mermaid syntax.\n```\n\n**Example: API Documentation User Flow**\n\n**Your Prompt:**\n\n```\nCreate a user flow diagram for a developer using API documentation to integrate authentication.\n\nStarting point: Documentation homepage\nGoal: Successfully implement OAuth 2.0 authentication\nKey decision points:\n- New to APIs vs. experienced\n- OAuth vs. API keys\n- Language/framework choice\n\nShow both successful and error paths.\n```\n\n**AI Output:**\n\n```mermaid\nflowchart TD\n    Start([Developer arrives at<br/>docs homepage])\n    Start --> Q1{New to our API?}\n    \n    Q1 -->|Yes| GetStarted[Get Started Guide]\n    Q1 -->|No| GoToAuth[Navigate to Authentication]\n    \n    GetStarted --> LearnBasics[Learn API Basics]\n    LearnBasics --> Q2{Ready for auth?}\n    Q2 -->|Yes| GoToAuth\n    Q2 -->|No| Confused1[\ud83d\ude15 Still confused]\n    \n    GoToAuth --> AuthOverview[Authentication Overview]\n    AuthOverview --> Q3{Which method?}\n    \n    Q3 -->|OAuth 2.0| OAuthGuide[OAuth 2.0 Guide]\n    Q3 -->|API Keys| APIKeyGuide[API Keys Guide]\n    Q3 -->|Not sure| Confused2[\ud83d\ude15 Which should I use?]\n    \n    OAuthGuide --> Q4{Has OAuth<br/>experience?}\n    Q4 -->|Yes| QuickStart[OAuth Quickstart]\n    Q4 -->|No| Tutorial[OAuth Tutorial]\n    \n    Tutorial --> CodeExample[Copy code example]\n    QuickStart --> CodeExample\n    \n    CodeExample --> Q5{Choose language}\n    Q5 -->|Python| PythonSDK[Python SDK Guide]\n    Q5 -->|JavaScript| JSSDK[JavaScript SDK Guide]\n    Q5 -->|Other| OtherSDK[Other Languages]\n    \n    PythonSDK --> Implement[Implement in app]\n    JSSDK --> Implement\n    OtherSDK --> Implement\n    \n    Implement --> Q6{Working?}\n    Q6 -->|Yes| Success([\u2705 Successfully authenticated])\n    Q6 -->|No| Troubleshoot[Troubleshooting Guide]\n    \n    Troubleshoot --> Q7{Found solution?}\n    Q7 -->|Yes| Implement\n    Q7 -->|No| Support[Contact Support]\n    \n    APIKeyGuide --> APIQuickStart[API Key Setup]\n    APIQuickStart --> CodeExample\n    \n    Confused1 -.->|Needs help| GetStarted\n    Confused2 -.->|Needs guidance| CompareAuth[Compare Auth Methods]\n    CompareAuth --> Q3\n    \n    classDef successPath fill:#c8e6c9,stroke:#2e7d32\n    classDef errorPath fill:#ffccbc,stroke:#d84315\n    classDef decisionPath fill:#fff9c4,stroke:#f57f17\n    classDef painPoint fill:#ffcdd2,stroke:#c62828\n    \n    class Success successPath\n    class Confused1,Confused2,Troubleshoot,Support errorPath\n    class Q1,Q2,Q3,Q4,Q5,Q6,Q7 decisionPath\n    class Confused1,Confused2 painPoint\n```\n\n**Flow analysis annotation:**\n\n```\nUSER FLOW ANALYSIS:\n\nSUCCESS PATHS:\n1. Experienced \u2192 Auth Overview \u2192 OAuth Guide \u2192 Quickstart \u2192 Implement\n   Estimated time: 10-15 minutes\n   \n2. New \u2192 Get Started \u2192 Learn Basics \u2192 Auth Guide \u2192 Tutorial \u2192 Implement\n   Estimated time: 30-45 minutes\n\nPAIN POINTS IDENTIFIED:\n\u26a0\ufe0f Confusion Point 1: New users unsure if they're ready for auth\n   Solution: Add \"Prerequisites\" checklist in Get Started\n\n\u26a0\ufe0f Confusion Point 2: Users don't know which auth method to choose\n   Solution: Add comparison table or decision tree in Auth Overview\n\n\u26a0\ufe0f Drop-off risk: Between code example and implementation\n   Solution: Add \"Test your authentication\" interactive validator\n\nMETRICS TO TRACK:\n- % taking successful path without troubleshooting\n- Average time from Start to Success\n- Most common exit points (abandonment)\n- % needing support after troubleshooting\n```\n\n---",
            "hydration_source_header": "User Flow Diagram Prompt Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "adr-generation-prompt",
            "title": "ADR Generation Prompt",
            "taskType": "generation",
            "lines": "810-870",
            "standalone": true,
            "retrievalQuestions": [
              "Give me a prompt to generate an ADR"
            ],
            "content": "**Basic content model diagram:**\n\n```text\nCreate a content model diagram in Mermaid syntax for [content domain].\n\nContent types:\n[List content types with brief descriptions]\n\nRelationships:\n[Describe key relationships, or let AI infer them]\n\nRequirements:\n- Use Mermaid entity-relationship diagram (erDiagram) syntax\n- Limit to 5-7 main entities to maintain diagram readability\n- Show cardinality (the relationship multiplicity: one-to-one, one-to-many, many-to-many)\n- Include key attributes for each content type\n- Use proper relationship labels\n\nOutput valid Mermaid syntax ready for rendering.\n```\n\n**Example: Blog Content Model**\n\n**Your Prompt:**\n\n```\nCreate a content model diagram in Mermaid syntax for a technical blog.\n\nContent types:\n1. BlogPost - Main article content\n2. Author - Person who writes posts\n3. Category - Topic classification\n4. Tag - Keyword metadata\n5. Series - Related posts grouped together\n6. Comment - Reader feedback\n\nRelationships to show:\n- Authors write BlogPosts (one author per post, authors can write many posts)\n- BlogPosts belong to one Category, Categories contain many posts\n- BlogPosts have many Tags, Tags can be on many posts\n- BlogPosts can belong to one Series (optional), Series contain many posts\n- BlogPosts have many Comments, Comments belong to one post\n\nInclude key attributes for each type.\n```\n\n**AI Output:**\n\n```mermaid\nerDiagram\n    Author ||--o{ BlogPost : writes\n    BlogPost }o--|| Category : \"belongs to\"\n    BlogPost }o--o{ Tag : \"tagged with\"\n    BlogPost }o--o| Series : \"part of\"\n    BlogPost ||--o{ Comment : receives\n    \n    Author {\n        string authorId PK\n        string name\n        string email\n        string bio\n        string avatarUrl\n        date joinedDate\n        array socialLinks\n    }\n    \n    BlogPost {\n        string postId PK\n        string authorId FK\n        string categoryId FK\n        string seriesId FK\n        string title\n        string slug\n        text content\n        string excerpt\n        array tags\n        date publishedDate\n        date updatedDate\n        string status\n        int readingTime\n        string featuredImage\n    }\n    \n    Category {\n        string categoryId PK\n        string name\n        string slug\n        string description\n        int postCount\n    }\n    \n    Tag {\n        string tagId PK\n        string name\n        string slug\n        int usageCount\n    }\n    \n    Series {\n        string seriesId PK\n        string title\n        string description\n        int postCount\n        array postOrder\n    }\n    \n    Comment {\n        string commentId PK\n        string postId FK\n        string authorName\n        string authorEmail\n        text content\n        date postedDate\n        string status\n    }\n```\n\n---",
            "hydration_source_header": "Content Model Prompt Pattern",
            "hydration_method": "line_proximity"
          },
          {
            "id": "adr-options-prompt",
            "title": "ADR Options Analysis Prompt",
            "taskType": "analysis",
            "lines": "875-920",
            "standalone": true,
            "hydration_status": "failed"
          },
          {
            "id": "adr-consequences-prompt",
            "title": "ADR Consequences Prompt",
            "taskType": "analysis",
            "lines": "925-970",
            "standalone": true,
            "content": "**Positive:**\n- Clearer entry points for common tasks\n- Faster time-to-find for developers\n- Reduced cognitive load (no need to learn internal architecture)\n\n**Negative:**\n- Some internal teams may find structure doesn't match how they think\n- Migration effort required to reorganize content\n\n**Neutral:**\n- Will need to maintain mapping documentation for internal team reference",
            "hydration_source_header": "Consequences",
            "hydration_method": "title_match"
          },
          {
            "id": "mermaid-conversion-prompt",
            "title": "Mermaid Diagram Conversion Prompt",
            "taskType": "generation",
            "lines": "1515-1560",
            "standalone": true,
            "retrievalQuestions": [
              "How do I prompt AI to create Mermaid diagrams?"
            ],
            "content": "Current: v1.0 (2024-04-15)\nStatus: Approved for implementation",
            "hydration_source_header": "Version",
            "hydration_method": "title_match"
          },
          {
            "id": "documentation-suite-prompt",
            "title": "Complete Documentation Suite Prompt",
            "taskType": "generation",
            "lines": "1585-1650",
            "standalone": true,
            "content": "**Essential deliverables:**\n\n1. **IA Overview Document**\n   - Executive summary\n   - Key decisions and rationale\n   - Success metrics\n\n2. **Sitemap Diagram**\n   - Full hierarchical structure\n   - Page counts and distribution\n   - Implementation status\n\n3. **Content Model**\n   - Content types and relationships\n   - Metadata schemas\n   - Validation rules\n\n4. **Navigation Specification**\n   - Top navigation\n   - Sidebar/secondary navigation\n   - Breadcrumbs\n   - Footer navigation\n\n5. **Taxonomy Documentation**\n   - Classification system\n   - Tagging schema\n   - Governance rules\n\n6. **User Flows**\n   - Primary user journeys\n   - Decision points\n   - Pain points and solutions\n\n7. **Implementation Guide**\n   - Technical requirements\n   - CMS configuration\n   - Content migration plan\n   - Rollout phases\n\n---",
            "hydration_source_header": "The Complete Documentation Set",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "adrComponents": [
          {
            "id": "adr-title",
            "component": "Title",
            "purpose": "Descriptive decision name",
            "format": "ADR-XXX: [Decision Name]",
            "lines": "910-920",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "adr-status",
            "component": "Status",
            "purpose": "Decision lifecycle state",
            "options": [
              "Proposed",
              "Accepted",
              "Deprecated",
              "Superseded"
            ],
            "lines": "920-935",
            "retrievalQuestions": [
              "What are ADR status options?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "adr-context",
            "component": "Context",
            "purpose": "Situation that led to decision",
            "includes": [
              "constraints",
              "requirements",
              "forces"
            ],
            "lines": "935-960",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "adr-decision",
            "component": "Decision",
            "purpose": "What was decided",
            "format": "Clear statement of choice",
            "lines": "960-980",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "adr-options",
            "component": "Options Considered",
            "purpose": "Alternatives evaluated",
            "includes": [
              "pros",
              "cons",
              "why-not"
            ],
            "lines": "980-1010",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "adr-consequences",
            "component": "Consequences",
            "purpose": "Impact of decision",
            "includes": [
              "positive",
              "negative",
              "risks"
            ],
            "lines": "1010-1040",
            "retrievalQuestions": [
              "What goes in an ADR?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "adr-related",
            "component": "Related Decisions",
            "purpose": "Connected ADRs",
            "format": "Links to related ADRs",
            "lines": "1040-1060",
            "hydration_status": "skipped_unknown"
          }
        ],
        "adrExamples": [
          {
            "id": "adr-taxonomy-hierarchy",
            "title": "ADR: Taxonomy Hierarchy Depth",
            "decision": "Limit to 3 levels",
            "lines": "1065-1140",
            "retrievalQuestions": [
              "Show me an ADR example"
            ],
            "content": "**Your Turn:** Create a simple content model for a blog.\n\n**Scenario:** A technical blog needs a content model with:\n- BlogPost (the main content)\n- Author (person who writes)\n- Category (topic classification - max 1 per post)\n- Tag (keywords - multiple per post)\n\n**Task:**\n1. Write a prompt to generate an erDiagram\n2. Include cardinality relationships\n3. Add 3-4 key attributes for BlogPost\n4. Test in Mermaid Live Editor\n\n<details>\n<summary>Sample Solution</summary>\n\n**Prompt:**\n```text\nCreate a content model diagram in Mermaid erDiagram syntax for a technical blog.\n\nContent types:\n1. BlogPost - Main article\n2. Author - Writer\n3. Category - Topic (one per post)\n4. Tag - Keywords (many per post)\n\nRelationships:\n- One Author writes many BlogPosts\n- One BlogPost belongs to one Category\n- BlogPosts have many Tags (many-to-many)\n\nInclude key attributes for BlogPost: title, slug, publishedDate, status\nUse proper cardinality notation.\n\nOutput valid Mermaid syntax.\n```\n\n**Expected Output:**\n```mermaid\nerDiagram\n    Author ||--o{ BlogPost : writes\n    BlogPost }o--|| Category : \"belongs to\"\n    BlogPost }o--o{ Tag : \"tagged with\"\n\n    Author {\n        string authorId PK\n        string name\n        string email\n    }\n\n    BlogPost {\n        string postId PK\n        string authorId FK\n        string categoryId FK\n        string title\n        string slug\n        date publishedDate\n        string status\n    }\n\n    Category {\n        string categoryId PK\n        string name\n    }\n\n    Tag {\n        string tagId PK\n        string name\n    }\n```\n\n**Self-check:**\n- [ ] Diagram renders in Mermaid Live Editor\n- [ ] Cardinality notation is correct (||--o{} for one-to-many)\n- [ ] All entities have at least 2-3 attributes\n- [ ] Primary/Foreign keys identified\n</details>\n\n---",
            "hydration_source_header": "Quick Practice Exercise (7 minutes)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "adr-navigation-pattern",
            "title": "ADR: Primary Navigation Pattern",
            "decision": "Mega-menu for products",
            "lines": "1145-1220",
            "content": "Taxonomies can be visualized in multiple ways depending on complexity and purpose.\n\n### Simple Taxonomy Diagram Prompt\n\n**For hierarchical taxonomies:**\n\n```text\nVisualize this taxonomy as a Mermaid flowchart:\n\nTAXONOMY:\n[Paste your taxonomy structure]\n\nRequirements:\n- Use flowchart TD (top-down) layout\n- Show all levels of hierarchy (maximum 4 levels deep to prevent diagram complexity)\n- Include item counts at each node\n- Use colors to distinguish levels\n- Add a legend explaining the structure\n\nOutput valid Mermaid syntax.\n```\n\n**Example Output:**\n\n```mermaid\nflowchart TD\n    Root[Documentation Taxonomy<br/>150 pages]\n    \n    Root --> L1A[Get Started<br/>25 pages]\n    Root --> L1B[Build Features<br/>60 pages]\n    Root --> L1C[Deploy & Monitor<br/>35 pages]\n    Root --> L1D[Reference<br/>30 pages]\n    \n    L1A --> L2A1[Installation<br/>8 pages]\n    L1A --> L2A2[Quickstart<br/>12 pages]\n    L1A --> L2A3[Core Concepts<br/>5 pages]\n    \n    L1B --> L2B1[Authentication<br/>15 pages]\n    L1B --> L2B2[Data Management<br/>25 pages]\n    L1B --> L2B3[APIs<br/>20 pages]\n    \n    L1C --> L2C1[Configuration<br/>10 pages]\n    L1C --> L2C2[Deployment<br/>15 pages]\n    L1C --> L2C3[Monitoring<br/>10 pages]\n    \n    L1D --> L2D1[API Endpoints<br/>20 pages]\n    L1D --> L2D2[CLI Commands<br/>10 pages]\n    \n    L2A1 --> L3A1A[Linux]\n    L2A1 --> L3A1B[macOS]\n    L2A1 --> L3A1C[Windows]\n    \n    L2B2 --> L3B2A[Create Records]\n    L2B2 --> L3B2B[Update Records]\n    L2B2 --> L3B2C[Delete Records]\n    \n    classDef level1 fill:#e3f2fd,stroke:#1976d2,stroke-width:3px\n    classDef level2 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n    classDef level3 fill:#fff3e0,stroke:#f57c00,stroke-width:1px\n    \n    class L1A,L1B,L1C,L1D level1\n    class L2A1,L2A2,L2A3,L2B1,L2B2,L2B3,L2C1,L2C2,L2C3,L2D1,L2D2 level2\n    class L3A1A,L3A1B,L3A1C,L3B2A,L3B2B,L3B2C level3\n```\n\n---\n\n### Faceted Taxonomy Diagrams\n\nFor faceted classification systems, show multiple dimensions:\n\n**Faceted taxonomy prompt:**\n\n```\nCreate a diagram showing this faceted taxonomy:\n\nFACETS:\n[List each facet and its values]\n\nShow:\n- Each facet as a separate dimension\n- Values within each facet\n- How facets can be combined\n- Example combinations\n\nUse Mermaid mindmap or flowchart syntax.\n```\n\n**Example: Documentation Faceted Classification**\n\n**Your Prompt:**\n\n```\nCreate a diagram showing a faceted taxonomy for documentation.\n\nFacets:\n1. Content Type: Tutorial, How-to, Reference, Explanation\n2. Difficulty: Beginner, Intermediate, Advanced\n3. Product Area: Authentication, Storage, Search, Analytics\n4. Format: Text, Video, Interactive\n\nShow how these facets can be combined.\n```\n\n**AI Output:**\n\n```mermaid\nmindmap\n  root((Documentation<br/>Taxonomy))\n    Content Type\n      Tutorial\n      How-to Guide\n      Reference\n      Explanation\n    Difficulty\n      Beginner\n      Intermediate\n      Advanced\n    Product Area\n      Authentication\n      Storage\n      Search\n      Analytics\n    Format\n      Text Article\n      Video\n      Interactive Demo\n      Code Sample\n      \n```\n\n**With example combinations:**\n\n```\nEXAMPLE FACET COMBINATIONS:\n\n1. Tutorial + Beginner + Authentication + Video\n   = \"Video tutorial: Your first OAuth login (beginner)\"\n\n2. How-to + Intermediate + Storage + Text\n   = \"How to optimize file uploads (intermediate)\"\n\n3. Reference + Advanced + Analytics + Code Sample\n   = \"Analytics API reference with code samples (advanced)\"\n\n4. Explanation + Beginner + Search + Text\n   = \"How search indexing works (beginner explanation)\"\n\nFACET RULES:\n- Content Type: Required (exactly one)\n- Difficulty: Required (exactly one)\n- Product Area: Required (one or more)\n- Format: Optional (one or more)\n\nTOTAL COMBINATIONS: 4 \u00d7 3 \u00d7 4 \u00d7 4 = 192 possible combinations\n```\n\n---",
            "hydration_source_header": "IV. Taxonomy Visualizations (10 minutes)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "adr-content-reuse",
            "title": "ADR: Content Reuse Strategy",
            "decision": "Component-based reuse",
            "lines": "1225-1300",
            "content": "**Di\u00c3\u00a1taxis Distribution:**\n- Tutorials (18%): Concentrated in \"Get Started\" for onboarding\n- How-to Guides (38%): Distributed across feature sections\n- Reference (33%): Primarily in \"API Reference\" but also in feature sections\n- Explanations (12%): Primarily in \"Get Started\" and \"Authenticate\"\n\n**Rationale:**\n- High How-to percentage serves developers solving specific problems\n- Sufficient Reference for lookup needs\n- Adequate Tutorial content for learning path\n- Explanations provide necessary context without overwhelming",
            "hydration_source_header": "Content Type Strategy",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "adr-metadata-schema",
            "title": "ADR: Metadata Schema Design",
            "decision": "Dublin Core + custom fields",
            "lines": "1305-1380",
            "retrievalQuestions": [
              "Examples of IA ADRs"
            ],
            "content": "[Detailed schema for each content type]\n\n---",
            "hydration_source_header": "Metadata Schema",
            "hydration_method": "title_match"
          }
        ],
        "mermaidPatterns": [
          {
            "id": "mermaid-flowchart",
            "title": "Mermaid Flowchart Pattern",
            "syntax": "graph TD/LR",
            "bestFor": "User flows, processes",
            "lines": "1510-1530",
            "content": "**Basic user flow:**\n\n```text\nCreate a user flow diagram showing how users [accomplish specific goal].\n\nStarting point: [Where user begins]\nGoal: [What user wants to accomplish]\nKey decision points: [Major choices user makes]\nPossible paths: [Different routes to success]\nFailure points: [Where users might get stuck]\n\nUse Mermaid flowchart with:\n- Diamond shapes {} for decision points (e.g., \"Has API key?\")\n- Rectangle shapes [] for action steps (e.g., \"Read authentication guide\")\n- Different colors for successful vs. error paths\n- Specify error handling paths explicitly\n- Annotations for pain points\n\nOutput valid Mermaid syntax.\n```\n\n**Example: API Documentation User Flow**\n\n**Your Prompt:**\n\n```\nCreate a user flow diagram for a developer using API documentation to integrate authentication.\n\nStarting point: Documentation homepage\nGoal: Successfully implement OAuth 2.0 authentication\nKey decision points:\n- New to APIs vs. experienced\n- OAuth vs. API keys\n- Language/framework choice\n\nShow both successful and error paths.\n```\n\n**AI Output:**\n\n```mermaid\nflowchart TD\n    Start([Developer arrives at<br/>docs homepage])\n    Start --> Q1{New to our API?}\n    \n    Q1 -->|Yes| GetStarted[Get Started Guide]\n    Q1 -->|No| GoToAuth[Navigate to Authentication]\n    \n    GetStarted --> LearnBasics[Learn API Basics]\n    LearnBasics --> Q2{Ready for auth?}\n    Q2 -->|Yes| GoToAuth\n    Q2 -->|No| Confused1[\ud83d\ude15 Still confused]\n    \n    GoToAuth --> AuthOverview[Authentication Overview]\n    AuthOverview --> Q3{Which method?}\n    \n    Q3 -->|OAuth 2.0| OAuthGuide[OAuth 2.0 Guide]\n    Q3 -->|API Keys| APIKeyGuide[API Keys Guide]\n    Q3 -->|Not sure| Confused2[\ud83d\ude15 Which should I use?]\n    \n    OAuthGuide --> Q4{Has OAuth<br/>experience?}\n    Q4 -->|Yes| QuickStart[OAuth Quickstart]\n    Q4 -->|No| Tutorial[OAuth Tutorial]\n    \n    Tutorial --> CodeExample[Copy code example]\n    QuickStart --> CodeExample\n    \n    CodeExample --> Q5{Choose language}\n    Q5 -->|Python| PythonSDK[Python SDK Guide]\n    Q5 -->|JavaScript| JSSDK[JavaScript SDK Guide]\n    Q5 -->|Other| OtherSDK[Other Languages]\n    \n    PythonSDK --> Implement[Implement in app]\n    JSSDK --> Implement\n    OtherSDK --> Implement\n    \n    Implement --> Q6{Working?}\n    Q6 -->|Yes| Success([\u2705 Successfully authenticated])\n    Q6 -->|No| Troubleshoot[Troubleshooting Guide]\n    \n    Troubleshoot --> Q7{Found solution?}\n    Q7 -->|Yes| Implement\n    Q7 -->|No| Support[Contact Support]\n    \n    APIKeyGuide --> APIQuickStart[API Key Setup]\n    APIQuickStart --> CodeExample\n    \n    Confused1 -.->|Needs help| GetStarted\n    Confused2 -.->|Needs guidance| CompareAuth[Compare Auth Methods]\n    CompareAuth --> Q3\n    \n    classDef successPath fill:#c8e6c9,stroke:#2e7d32\n    classDef errorPath fill:#ffccbc,stroke:#d84315\n    classDef decisionPath fill:#fff9c4,stroke:#f57f17\n    classDef painPoint fill:#ffcdd2,stroke:#c62828\n    \n    class Success successPath\n    class Confused1,Confused2,Troubleshoot,Support errorPath\n    class Q1,Q2,Q3,Q4,Q5,Q6,Q7 decisionPath\n    class Confused1,Confused2 painPoint\n```\n\n**Flow analysis annotation:**\n\n```\nUSER FLOW ANALYSIS:\n\nSUCCESS PATHS:\n1. Experienced \u2192 Auth Overview \u2192 OAuth Guide \u2192 Quickstart \u2192 Implement\n   Estimated time: 10-15 minutes\n   \n2. New \u2192 Get Started \u2192 Learn Basics \u2192 Auth Guide \u2192 Tutorial \u2192 Implement\n   Estimated time: 30-45 minutes\n\nPAIN POINTS IDENTIFIED:\n\u26a0\ufe0f Confusion Point 1: New users unsure if they're ready for auth\n   Solution: Add \"Prerequisites\" checklist in Get Started\n\n\u26a0\ufe0f Confusion Point 2: Users don't know which auth method to choose\n   Solution: Add comparison table or decision tree in Auth Overview\n\n\u26a0\ufe0f Drop-off risk: Between code example and implementation\n   Solution: Add \"Test your authentication\" interactive validator\n\nMETRICS TO TRACK:\n- % taking successful path without troubleshooting\n- Average time from Start to Success\n- Most common exit points (abandonment)\n- % needing support after troubleshooting\n```\n\n---",
            "hydration_source_header": "User Flow Diagram Prompt Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "mermaid-mindmap",
            "title": "Mermaid Mindmap Pattern",
            "syntax": "mindmap",
            "bestFor": "Taxonomy visualization",
            "lines": "1530-1550",
            "retrievalQuestions": [
              "How do I create a taxonomy mindmap in Mermaid?"
            ],
            "content": "**Essential deliverables:**\n\n1. **IA Overview Document**\n   - Executive summary\n   - Key decisions and rationale\n   - Success metrics\n\n2. **Sitemap Diagram**\n   - Full hierarchical structure\n   - Page counts and distribution\n   - Implementation status\n\n3. **Content Model**\n   - Content types and relationships\n   - Metadata schemas\n   - Validation rules\n\n4. **Navigation Specification**\n   - Top navigation\n   - Sidebar/secondary navigation\n   - Breadcrumbs\n   - Footer navigation\n\n5. **Taxonomy Documentation**\n   - Classification system\n   - Tagging schema\n   - Governance rules\n\n6. **User Flows**\n   - Primary user journeys\n   - Decision points\n   - Pain points and solutions\n\n7. **Implementation Guide**\n   - Technical requirements\n   - CMS configuration\n   - Content migration plan\n   - Rollout phases\n\n---",
            "hydration_source_header": "The Complete Documentation Set",
            "hydration_method": "line_proximity"
          },
          {
            "id": "mermaid-classDiagram",
            "title": "Mermaid Class Diagram Pattern",
            "syntax": "classDiagram",
            "bestFor": "Content models",
            "lines": "1550-1570",
            "content": "**Basic user flow:**\n\n```text\nCreate a user flow diagram showing how users [accomplish specific goal].\n\nStarting point: [Where user begins]\nGoal: [What user wants to accomplish]\nKey decision points: [Major choices user makes]\nPossible paths: [Different routes to success]\nFailure points: [Where users might get stuck]\n\nUse Mermaid flowchart with:\n- Diamond shapes {} for decision points (e.g., \"Has API key?\")\n- Rectangle shapes [] for action steps (e.g., \"Read authentication guide\")\n- Different colors for successful vs. error paths\n- Specify error handling paths explicitly\n- Annotations for pain points\n\nOutput valid Mermaid syntax.\n```\n\n**Example: API Documentation User Flow**\n\n**Your Prompt:**\n\n```\nCreate a user flow diagram for a developer using API documentation to integrate authentication.\n\nStarting point: Documentation homepage\nGoal: Successfully implement OAuth 2.0 authentication\nKey decision points:\n- New to APIs vs. experienced\n- OAuth vs. API keys\n- Language/framework choice\n\nShow both successful and error paths.\n```\n\n**AI Output:**\n\n```mermaid\nflowchart TD\n    Start([Developer arrives at<br/>docs homepage])\n    Start --> Q1{New to our API?}\n    \n    Q1 -->|Yes| GetStarted[Get Started Guide]\n    Q1 -->|No| GoToAuth[Navigate to Authentication]\n    \n    GetStarted --> LearnBasics[Learn API Basics]\n    LearnBasics --> Q2{Ready for auth?}\n    Q2 -->|Yes| GoToAuth\n    Q2 -->|No| Confused1[\ud83d\ude15 Still confused]\n    \n    GoToAuth --> AuthOverview[Authentication Overview]\n    AuthOverview --> Q3{Which method?}\n    \n    Q3 -->|OAuth 2.0| OAuthGuide[OAuth 2.0 Guide]\n    Q3 -->|API Keys| APIKeyGuide[API Keys Guide]\n    Q3 -->|Not sure| Confused2[\ud83d\ude15 Which should I use?]\n    \n    OAuthGuide --> Q4{Has OAuth<br/>experience?}\n    Q4 -->|Yes| QuickStart[OAuth Quickstart]\n    Q4 -->|No| Tutorial[OAuth Tutorial]\n    \n    Tutorial --> CodeExample[Copy code example]\n    QuickStart --> CodeExample\n    \n    CodeExample --> Q5{Choose language}\n    Q5 -->|Python| PythonSDK[Python SDK Guide]\n    Q5 -->|JavaScript| JSSDK[JavaScript SDK Guide]\n    Q5 -->|Other| OtherSDK[Other Languages]\n    \n    PythonSDK --> Implement[Implement in app]\n    JSSDK --> Implement\n    OtherSDK --> Implement\n    \n    Implement --> Q6{Working?}\n    Q6 -->|Yes| Success([\u2705 Successfully authenticated])\n    Q6 -->|No| Troubleshoot[Troubleshooting Guide]\n    \n    Troubleshoot --> Q7{Found solution?}\n    Q7 -->|Yes| Implement\n    Q7 -->|No| Support[Contact Support]\n    \n    APIKeyGuide --> APIQuickStart[API Key Setup]\n    APIQuickStart --> CodeExample\n    \n    Confused1 -.->|Needs help| GetStarted\n    Confused2 -.->|Needs guidance| CompareAuth[Compare Auth Methods]\n    CompareAuth --> Q3\n    \n    classDef successPath fill:#c8e6c9,stroke:#2e7d32\n    classDef errorPath fill:#ffccbc,stroke:#d84315\n    classDef decisionPath fill:#fff9c4,stroke:#f57f17\n    classDef painPoint fill:#ffcdd2,stroke:#c62828\n    \n    class Success successPath\n    class Confused1,Confused2,Troubleshoot,Support errorPath\n    class Q1,Q2,Q3,Q4,Q5,Q6,Q7 decisionPath\n    class Confused1,Confused2 painPoint\n```\n\n**Flow analysis annotation:**\n\n```\nUSER FLOW ANALYSIS:\n\nSUCCESS PATHS:\n1. Experienced \u2192 Auth Overview \u2192 OAuth Guide \u2192 Quickstart \u2192 Implement\n   Estimated time: 10-15 minutes\n   \n2. New \u2192 Get Started \u2192 Learn Basics \u2192 Auth Guide \u2192 Tutorial \u2192 Implement\n   Estimated time: 30-45 minutes\n\nPAIN POINTS IDENTIFIED:\n\u26a0\ufe0f Confusion Point 1: New users unsure if they're ready for auth\n   Solution: Add \"Prerequisites\" checklist in Get Started\n\n\u26a0\ufe0f Confusion Point 2: Users don't know which auth method to choose\n   Solution: Add comparison table or decision tree in Auth Overview\n\n\u26a0\ufe0f Drop-off risk: Between code example and implementation\n   Solution: Add \"Test your authentication\" interactive validator\n\nMETRICS TO TRACK:\n- % taking successful path without troubleshooting\n- Average time from Start to Success\n- Most common exit points (abandonment)\n- % needing support after troubleshooting\n```\n\n---",
            "hydration_source_header": "User Flow Diagram Prompt Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "mermaid-er",
            "title": "Mermaid ER Diagram Pattern",
            "syntax": "erDiagram",
            "bestFor": "Metadata relationships",
            "lines": "1570-1590",
            "retrievalQuestions": [
              "What Mermaid diagram type for metadata?"
            ],
            "content": "**Basic user flow:**\n\n```text\nCreate a user flow diagram showing how users [accomplish specific goal].\n\nStarting point: [Where user begins]\nGoal: [What user wants to accomplish]\nKey decision points: [Major choices user makes]\nPossible paths: [Different routes to success]\nFailure points: [Where users might get stuck]\n\nUse Mermaid flowchart with:\n- Diamond shapes {} for decision points (e.g., \"Has API key?\")\n- Rectangle shapes [] for action steps (e.g., \"Read authentication guide\")\n- Different colors for successful vs. error paths\n- Specify error handling paths explicitly\n- Annotations for pain points\n\nOutput valid Mermaid syntax.\n```\n\n**Example: API Documentation User Flow**\n\n**Your Prompt:**\n\n```\nCreate a user flow diagram for a developer using API documentation to integrate authentication.\n\nStarting point: Documentation homepage\nGoal: Successfully implement OAuth 2.0 authentication\nKey decision points:\n- New to APIs vs. experienced\n- OAuth vs. API keys\n- Language/framework choice\n\nShow both successful and error paths.\n```\n\n**AI Output:**\n\n```mermaid\nflowchart TD\n    Start([Developer arrives at<br/>docs homepage])\n    Start --> Q1{New to our API?}\n    \n    Q1 -->|Yes| GetStarted[Get Started Guide]\n    Q1 -->|No| GoToAuth[Navigate to Authentication]\n    \n    GetStarted --> LearnBasics[Learn API Basics]\n    LearnBasics --> Q2{Ready for auth?}\n    Q2 -->|Yes| GoToAuth\n    Q2 -->|No| Confused1[\ud83d\ude15 Still confused]\n    \n    GoToAuth --> AuthOverview[Authentication Overview]\n    AuthOverview --> Q3{Which method?}\n    \n    Q3 -->|OAuth 2.0| OAuthGuide[OAuth 2.0 Guide]\n    Q3 -->|API Keys| APIKeyGuide[API Keys Guide]\n    Q3 -->|Not sure| Confused2[\ud83d\ude15 Which should I use?]\n    \n    OAuthGuide --> Q4{Has OAuth<br/>experience?}\n    Q4 -->|Yes| QuickStart[OAuth Quickstart]\n    Q4 -->|No| Tutorial[OAuth Tutorial]\n    \n    Tutorial --> CodeExample[Copy code example]\n    QuickStart --> CodeExample\n    \n    CodeExample --> Q5{Choose language}\n    Q5 -->|Python| PythonSDK[Python SDK Guide]\n    Q5 -->|JavaScript| JSSDK[JavaScript SDK Guide]\n    Q5 -->|Other| OtherSDK[Other Languages]\n    \n    PythonSDK --> Implement[Implement in app]\n    JSSDK --> Implement\n    OtherSDK --> Implement\n    \n    Implement --> Q6{Working?}\n    Q6 -->|Yes| Success([\u2705 Successfully authenticated])\n    Q6 -->|No| Troubleshoot[Troubleshooting Guide]\n    \n    Troubleshoot --> Q7{Found solution?}\n    Q7 -->|Yes| Implement\n    Q7 -->|No| Support[Contact Support]\n    \n    APIKeyGuide --> APIQuickStart[API Key Setup]\n    APIQuickStart --> CodeExample\n    \n    Confused1 -.->|Needs help| GetStarted\n    Confused2 -.->|Needs guidance| CompareAuth[Compare Auth Methods]\n    CompareAuth --> Q3\n    \n    classDef successPath fill:#c8e6c9,stroke:#2e7d32\n    classDef errorPath fill:#ffccbc,stroke:#d84315\n    classDef decisionPath fill:#fff9c4,stroke:#f57f17\n    classDef painPoint fill:#ffcdd2,stroke:#c62828\n    \n    class Success successPath\n    class Confused1,Confused2,Troubleshoot,Support errorPath\n    class Q1,Q2,Q3,Q4,Q5,Q6,Q7 decisionPath\n    class Confused1,Confused2 painPoint\n```\n\n**Flow analysis annotation:**\n\n```\nUSER FLOW ANALYSIS:\n\nSUCCESS PATHS:\n1. Experienced \u2192 Auth Overview \u2192 OAuth Guide \u2192 Quickstart \u2192 Implement\n   Estimated time: 10-15 minutes\n   \n2. New \u2192 Get Started \u2192 Learn Basics \u2192 Auth Guide \u2192 Tutorial \u2192 Implement\n   Estimated time: 30-45 minutes\n\nPAIN POINTS IDENTIFIED:\n\u26a0\ufe0f Confusion Point 1: New users unsure if they're ready for auth\n   Solution: Add \"Prerequisites\" checklist in Get Started\n\n\u26a0\ufe0f Confusion Point 2: Users don't know which auth method to choose\n   Solution: Add comparison table or decision tree in Auth Overview\n\n\u26a0\ufe0f Drop-off risk: Between code example and implementation\n   Solution: Add \"Test your authentication\" interactive validator\n\nMETRICS TO TRACK:\n- % taking successful path without troubleshooting\n- Average time from Start to Success\n- Most common exit points (abandonment)\n- % needing support after troubleshooting\n```\n\n---",
            "hydration_source_header": "User Flow Diagram Prompt Pattern",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "concepts": [
          {
            "id": "architecture-decision-record",
            "term": "Architecture Decision Record (ADR)",
            "definition": "Document that captures an important decision with its context and consequences",
            "lines": "790-810",
            "retrievalQuestions": [
              "What is an ADR?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "ia-documentation",
            "term": "IA Documentation",
            "definition": "Artifacts that communicate information architecture",
            "lines": "45-55",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "notation-system",
            "term": "Notation System",
            "definition": "Standardized symbols and conventions for diagrams",
            "lines": "725-735",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "text-based-diagrams",
            "term": "Text-Based Diagrams",
            "definition": "Diagrams written as code, version-controlled",
            "lines": "735-745",
            "retrievalQuestions": [
              "What are text-based diagrams?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "living-documentation",
            "term": "Living Documentation",
            "definition": "Documentation that stays current with the system",
            "lines": "1915-1920",
            "hydration_status": "skipped_unknown"
          }
        ],
        "examples": [
          {
            "id": "site-map-output",
            "title": "Generated Site Map Example",
            "demonstrates": "site-map-prompt",
            "lines": "120-140",
            "content": "Not sure which diagram to use? Follow this decision flow:\n\n<AccordionGroup>\n<Accordion title=\"Start Here: What are you trying to communicate?\">\n\n**Question 1: What's your primary goal?**\n\n**A. \"Show what content exists and how it's organized\"**\n\u2192 Use **Sitemap/Hierarchy Diagram**\n- Best for: Stakeholder presentations, developer handoff, content planning\n- Example: \"Show all 85 pages in our docs and their structure\"\n\n**B. \"Show how different content types relate to each other\"**\n\u2192 Use **Content Model Diagram**\n- Best for: CMS planning, database design, metadata strategy\n- Example: \"Explain how BlogPosts, Authors, and Tags connect\"\n\n**C. \"Show how we classify and categorize things\"**\n\u2192 Use **Taxonomy Diagram**\n- Best for: Filtering systems, tag hierarchies, navigation facets\n- Example: \"Illustrate our product categorization with 3 facets\"\n\n**D. \"Show how users navigate to accomplish a goal\"**\n\u2192 Use **User Flow Diagram**\n- Best for: Journey mapping, identifying friction points, testing navigation\n- Example: \"Map the path from homepage to first successful API call\"\n\n**E. \"Show the full picture with page layouts\"**\n\u2192 Use **Wireflow Diagram**\n- Best for: Detailed interaction design, prototype documentation\n- Example: \"Combine navigation + page structure for checkout flow\"\n\n</Accordion>\n\n<Accordion title=\"Audience Considerations\">\n\n**Who will use this diagram?**\n\n**Executive Stakeholders:**\n- Keep it simple: **Sitemap** (high-level structure only)\n- Avoid: Detailed content models, technical notation\n\n**Developers/Engineers:**\n- Technical detail welcome: **Content Model** with full attributes\n- Include: Implementation notes, CMS mappings, data types\n\n**Design Team:**\n- Visual emphasis: **User Flow** with decision points\n- Include: Screen states, interaction patterns\n\n**Content Team:**\n- Practical organization: **Sitemap** or **Taxonomy**\n- Include: Content type labels, page counts, workflow notes\n\n**Mixed Audience:**\n- Start simple: **Sitemap** for overview\n- Layer detail: Add content model and flows as appendices\n\n</Accordion>\n\n  <Accordion title=\"When to Use Multiple Diagrams\">\n\n**Comprehensive Documentation Package:**\n\nUse 3-4 complementary diagrams:\n\n1. **Sitemap** \u2192 Shows overall structure\n2. **Content Model** \u2192 Shows data relationships\n3. **User Flow** \u2192 Shows 1-2 primary journeys\n4. (Optional) **Taxonomy** \u2192 Shows classification logic\n\n**Example: API Documentation Package**\n\n```\n\u251c\u2500\u2500 1-sitemap.md (85 pages, 6 top-level sections)\n\u251c\u2500\u2500 2-content-model.md (Tutorial, Guide, Reference relationships)\n\u251c\u2500\u2500 3-user-flow-onboarding.md (New user \u2192 First API call)\n\u2514\u2500\u2500 4-user-flow-troubleshooting.md (Error \u2192 Solution path)\n```\n\n**When One Diagram Isn't Enough:**\n\n- Complex site (>50 pages) \u2192 Break sitemap into sections\n- Multiple user types \u2192 Create flow per persona\n- Evolving IA \u2192 Show current vs. proposed side-by-side\n\n</Accordion>\n\n<Accordion title=\"Common Mistakes to Avoid\">\n\n\u274c **Wrong:** Using sitemap when you need to show relationships\n- **Problem:** Sitemaps only show hierarchy, not cross-links or connections\n- **Fix:** Use content model with relationship lines\n\n\u274c **Wrong:** Using content model when you need to show user paths\n- **Problem:** Content models are static, not sequential\n- **Fix:** Use user flow diagram with decision points\n\n\u274c **Wrong:** Creating one massive diagram for everything\n- **Problem:** Overwhelms viewers, hard to maintain\n- **Fix:** Break into focused diagrams, each with single purpose\n\n\u274c **Wrong:** Choosing diagram type before understanding goal\n- **Problem:** Diagram doesn't answer the actual question\n- **Fix:** Start with \"What decision will this diagram inform?\"\n\n\u2705 **Right:** Match diagram type to communication goal\n\n</Accordion>\n\n<Accordion title=\"Quick Reference Table\">\n\n| Diagram Type | Primary Use | Key Question It Answers | Complexity Level |\n|--------------|-------------|------------------------|------------------|\n| **Sitemap** | Structure overview | \"What pages exist and where?\" | Simple |\n| **Content Model** | Data relationships | \"How do content types connect?\" | Medium |\n| **Taxonomy** | Classification | \"How do we categorize things?\" | Medium |\n| **User Flow** | Navigation paths | \"How do users accomplish goals?\" | Medium-Complex |\n| **Wireflow** | Detailed interaction | \"What does user see at each step?\" | Complex |\n\n**Complexity Guide:**\n- **Simple:** Can explain in under 5 minutes, few elements\n- **Medium:** Takes 10-15 minutes to explain, moderate detail\n- **Complex:** Requires 20+ minutes, many elements, best for technical audiences\n\n</Accordion>\n\n</AccordionGroup>\n\n---",
            "hydration_source_header": "Decision Guide: Choosing the Right Diagram Type",
            "hydration_method": "line_proximity"
          },
          {
            "id": "taxonomy-viz-output",
            "title": "Taxonomy Visualization Output",
            "demonstrates": "taxonomy-viz-prompt",
            "lines": "200-220",
            "content": "Taxonomies can be visualized in multiple ways depending on complexity and purpose.\n\n### Simple Taxonomy Diagram Prompt\n\n**For hierarchical taxonomies:**\n\n```text\nVisualize this taxonomy as a Mermaid flowchart:\n\nTAXONOMY:\n[Paste your taxonomy structure]\n\nRequirements:\n- Use flowchart TD (top-down) layout\n- Show all levels of hierarchy (maximum 4 levels deep to prevent diagram complexity)\n- Include item counts at each node\n- Use colors to distinguish levels\n- Add a legend explaining the structure\n\nOutput valid Mermaid syntax.\n```\n\n**Example Output:**\n\n```mermaid\nflowchart TD\n    Root[Documentation Taxonomy<br/>150 pages]\n    \n    Root --> L1A[Get Started<br/>25 pages]\n    Root --> L1B[Build Features<br/>60 pages]\n    Root --> L1C[Deploy & Monitor<br/>35 pages]\n    Root --> L1D[Reference<br/>30 pages]\n    \n    L1A --> L2A1[Installation<br/>8 pages]\n    L1A --> L2A2[Quickstart<br/>12 pages]\n    L1A --> L2A3[Core Concepts<br/>5 pages]\n    \n    L1B --> L2B1[Authentication<br/>15 pages]\n    L1B --> L2B2[Data Management<br/>25 pages]\n    L1B --> L2B3[APIs<br/>20 pages]\n    \n    L1C --> L2C1[Configuration<br/>10 pages]\n    L1C --> L2C2[Deployment<br/>15 pages]\n    L1C --> L2C3[Monitoring<br/>10 pages]\n    \n    L1D --> L2D1[API Endpoints<br/>20 pages]\n    L1D --> L2D2[CLI Commands<br/>10 pages]\n    \n    L2A1 --> L3A1A[Linux]\n    L2A1 --> L3A1B[macOS]\n    L2A1 --> L3A1C[Windows]\n    \n    L2B2 --> L3B2A[Create Records]\n    L2B2 --> L3B2B[Update Records]\n    L2B2 --> L3B2C[Delete Records]\n    \n    classDef level1 fill:#e3f2fd,stroke:#1976d2,stroke-width:3px\n    classDef level2 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n    classDef level3 fill:#fff3e0,stroke:#f57c00,stroke-width:1px\n    \n    class L1A,L1B,L1C,L1D level1\n    class L2A1,L2A2,L2A3,L2B1,L2B2,L2B3,L2C1,L2C2,L2C3,L2D1,L2D2 level2\n    class L3A1A,L3A1B,L3A1C,L3B2A,L3B2B,L3B2C level3\n```\n\n---\n\n### Faceted Taxonomy Diagrams\n\nFor faceted classification systems, show multiple dimensions:\n\n**Faceted taxonomy prompt:**\n\n```\nCreate a diagram showing this faceted taxonomy:\n\nFACETS:\n[List each facet and its values]\n\nShow:\n- Each facet as a separate dimension\n- Values within each facet\n- How facets can be combined\n- Example combinations\n\nUse Mermaid mindmap or flowchart syntax.\n```\n\n**Example: Documentation Faceted Classification**\n\n**Your Prompt:**\n\n```\nCreate a diagram showing a faceted taxonomy for documentation.\n\nFacets:\n1. Content Type: Tutorial, How-to, Reference, Explanation\n2. Difficulty: Beginner, Intermediate, Advanced\n3. Product Area: Authentication, Storage, Search, Analytics\n4. Format: Text, Video, Interactive\n\nShow how these facets can be combined.\n```\n\n**AI Output:**\n\n```mermaid\nmindmap\n  root((Documentation<br/>Taxonomy))\n    Content Type\n      Tutorial\n      How-to Guide\n      Reference\n      Explanation\n    Difficulty\n      Beginner\n      Intermediate\n      Advanced\n    Product Area\n      Authentication\n      Storage\n      Search\n      Analytics\n    Format\n      Text Article\n      Video\n      Interactive Demo\n      Code Sample\n      \n```\n\n**With example combinations:**\n\n```\nEXAMPLE FACET COMBINATIONS:\n\n1. Tutorial + Beginner + Authentication + Video\n   = \"Video tutorial: Your first OAuth login (beginner)\"\n\n2. How-to + Intermediate + Storage + Text\n   = \"How to optimize file uploads (intermediate)\"\n\n3. Reference + Advanced + Analytics + Code Sample\n   = \"Analytics API reference with code samples (advanced)\"\n\n4. Explanation + Beginner + Search + Text\n   = \"How search indexing works (beginner explanation)\"\n\nFACET RULES:\n- Content Type: Required (exactly one)\n- Difficulty: Required (exactly one)\n- Product Area: Required (one or more)\n- Format: Optional (one or more)\n\nTOTAL COMBINATIONS: 4 \u00d7 3 \u00d7 4 \u00d7 4 = 192 possible combinations\n```\n\n---",
            "hydration_source_header": "IV. Taxonomy Visualizations (10 minutes)",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "content-model-output",
            "title": "Content Model Diagram Output",
            "demonstrates": "content-model-prompt",
            "lines": "290-310",
            "retrievalQuestions": [
              "Show me a content model diagram example"
            ],
            "content": "**Basic content model diagram:**\n\n```text\nCreate a content model diagram in Mermaid syntax for [content domain].\n\nContent types:\n[List content types with brief descriptions]\n\nRelationships:\n[Describe key relationships, or let AI infer them]\n\nRequirements:\n- Use Mermaid entity-relationship diagram (erDiagram) syntax\n- Limit to 5-7 main entities to maintain diagram readability\n- Show cardinality (the relationship multiplicity: one-to-one, one-to-many, many-to-many)\n- Include key attributes for each content type\n- Use proper relationship labels\n\nOutput valid Mermaid syntax ready for rendering.\n```\n\n**Example: Blog Content Model**\n\n**Your Prompt:**\n\n```\nCreate a content model diagram in Mermaid syntax for a technical blog.\n\nContent types:\n1. BlogPost - Main article content\n2. Author - Person who writes posts\n3. Category - Topic classification\n4. Tag - Keyword metadata\n5. Series - Related posts grouped together\n6. Comment - Reader feedback\n\nRelationships to show:\n- Authors write BlogPosts (one author per post, authors can write many posts)\n- BlogPosts belong to one Category, Categories contain many posts\n- BlogPosts have many Tags, Tags can be on many posts\n- BlogPosts can belong to one Series (optional), Series contain many posts\n- BlogPosts have many Comments, Comments belong to one post\n\nInclude key attributes for each type.\n```\n\n**AI Output:**\n\n```mermaid\nerDiagram\n    Author ||--o{ BlogPost : writes\n    BlogPost }o--|| Category : \"belongs to\"\n    BlogPost }o--o{ Tag : \"tagged with\"\n    BlogPost }o--o| Series : \"part of\"\n    BlogPost ||--o{ Comment : receives\n    \n    Author {\n        string authorId PK\n        string name\n        string email\n        string bio\n        string avatarUrl\n        date joinedDate\n        array socialLinks\n    }\n    \n    BlogPost {\n        string postId PK\n        string authorId FK\n        string categoryId FK\n        string seriesId FK\n        string title\n        string slug\n        text content\n        string excerpt\n        array tags\n        date publishedDate\n        date updatedDate\n        string status\n        int readingTime\n        string featuredImage\n    }\n    \n    Category {\n        string categoryId PK\n        string name\n        string slug\n        string description\n        int postCount\n    }\n    \n    Tag {\n        string tagId PK\n        string name\n        string slug\n        int usageCount\n    }\n    \n    Series {\n        string seriesId PK\n        string title\n        string description\n        int postCount\n        array postOrder\n    }\n    \n    Comment {\n        string commentId PK\n        string postId FK\n        string authorName\n        string authorEmail\n        text content\n        date postedDate\n        string status\n    }\n```\n\n---",
            "hydration_source_header": "Content Model Prompt Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "user-flow-output",
            "title": "User Flow Diagram Output",
            "demonstrates": "user-flow-prompt",
            "lines": "380-400",
            "content": "**Basic user flow:**\n\n```text\nCreate a user flow diagram showing how users [accomplish specific goal].\n\nStarting point: [Where user begins]\nGoal: [What user wants to accomplish]\nKey decision points: [Major choices user makes]\nPossible paths: [Different routes to success]\nFailure points: [Where users might get stuck]\n\nUse Mermaid flowchart with:\n- Diamond shapes {} for decision points (e.g., \"Has API key?\")\n- Rectangle shapes [] for action steps (e.g., \"Read authentication guide\")\n- Different colors for successful vs. error paths\n- Specify error handling paths explicitly\n- Annotations for pain points\n\nOutput valid Mermaid syntax.\n```\n\n**Example: API Documentation User Flow**\n\n**Your Prompt:**\n\n```\nCreate a user flow diagram for a developer using API documentation to integrate authentication.\n\nStarting point: Documentation homepage\nGoal: Successfully implement OAuth 2.0 authentication\nKey decision points:\n- New to APIs vs. experienced\n- OAuth vs. API keys\n- Language/framework choice\n\nShow both successful and error paths.\n```\n\n**AI Output:**\n\n```mermaid\nflowchart TD\n    Start([Developer arrives at<br/>docs homepage])\n    Start --> Q1{New to our API?}\n    \n    Q1 -->|Yes| GetStarted[Get Started Guide]\n    Q1 -->|No| GoToAuth[Navigate to Authentication]\n    \n    GetStarted --> LearnBasics[Learn API Basics]\n    LearnBasics --> Q2{Ready for auth?}\n    Q2 -->|Yes| GoToAuth\n    Q2 -->|No| Confused1[\ud83d\ude15 Still confused]\n    \n    GoToAuth --> AuthOverview[Authentication Overview]\n    AuthOverview --> Q3{Which method?}\n    \n    Q3 -->|OAuth 2.0| OAuthGuide[OAuth 2.0 Guide]\n    Q3 -->|API Keys| APIKeyGuide[API Keys Guide]\n    Q3 -->|Not sure| Confused2[\ud83d\ude15 Which should I use?]\n    \n    OAuthGuide --> Q4{Has OAuth<br/>experience?}\n    Q4 -->|Yes| QuickStart[OAuth Quickstart]\n    Q4 -->|No| Tutorial[OAuth Tutorial]\n    \n    Tutorial --> CodeExample[Copy code example]\n    QuickStart --> CodeExample\n    \n    CodeExample --> Q5{Choose language}\n    Q5 -->|Python| PythonSDK[Python SDK Guide]\n    Q5 -->|JavaScript| JSSDK[JavaScript SDK Guide]\n    Q5 -->|Other| OtherSDK[Other Languages]\n    \n    PythonSDK --> Implement[Implement in app]\n    JSSDK --> Implement\n    OtherSDK --> Implement\n    \n    Implement --> Q6{Working?}\n    Q6 -->|Yes| Success([\u2705 Successfully authenticated])\n    Q6 -->|No| Troubleshoot[Troubleshooting Guide]\n    \n    Troubleshoot --> Q7{Found solution?}\n    Q7 -->|Yes| Implement\n    Q7 -->|No| Support[Contact Support]\n    \n    APIKeyGuide --> APIQuickStart[API Key Setup]\n    APIQuickStart --> CodeExample\n    \n    Confused1 -.->|Needs help| GetStarted\n    Confused2 -.->|Needs guidance| CompareAuth[Compare Auth Methods]\n    CompareAuth --> Q3\n    \n    classDef successPath fill:#c8e6c9,stroke:#2e7d32\n    classDef errorPath fill:#ffccbc,stroke:#d84315\n    classDef decisionPath fill:#fff9c4,stroke:#f57f17\n    classDef painPoint fill:#ffcdd2,stroke:#c62828\n    \n    class Success successPath\n    class Confused1,Confused2,Troubleshoot,Support errorPath\n    class Q1,Q2,Q3,Q4,Q5,Q6,Q7 decisionPath\n    class Confused1,Confused2 painPoint\n```\n\n**Flow analysis annotation:**\n\n```\nUSER FLOW ANALYSIS:\n\nSUCCESS PATHS:\n1. Experienced \u2192 Auth Overview \u2192 OAuth Guide \u2192 Quickstart \u2192 Implement\n   Estimated time: 10-15 minutes\n   \n2. New \u2192 Get Started \u2192 Learn Basics \u2192 Auth Guide \u2192 Tutorial \u2192 Implement\n   Estimated time: 30-45 minutes\n\nPAIN POINTS IDENTIFIED:\n\u26a0\ufe0f Confusion Point 1: New users unsure if they're ready for auth\n   Solution: Add \"Prerequisites\" checklist in Get Started\n\n\u26a0\ufe0f Confusion Point 2: Users don't know which auth method to choose\n   Solution: Add comparison table or decision tree in Auth Overview\n\n\u26a0\ufe0f Drop-off risk: Between code example and implementation\n   Solution: Add \"Test your authentication\" interactive validator\n\nMETRICS TO TRACK:\n- % taking successful path without troubleshooting\n- Average time from Start to Success\n- Most common exit points (abandonment)\n- % needing support after troubleshooting\n```\n\n---",
            "hydration_source_header": "User Flow Diagram Prompt Pattern",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "complete-adr-example",
            "title": "Complete ADR Example",
            "demonstrates": "adr-creation-pattern",
            "lines": "1065-1200",
            "retrievalQuestions": [
              "Give me a complete ADR example"
            ],
            "content": "**Your Turn:** Create a simple content model for a blog.\n\n**Scenario:** A technical blog needs a content model with:\n- BlogPost (the main content)\n- Author (person who writes)\n- Category (topic classification - max 1 per post)\n- Tag (keywords - multiple per post)\n\n**Task:**\n1. Write a prompt to generate an erDiagram\n2. Include cardinality relationships\n3. Add 3-4 key attributes for BlogPost\n4. Test in Mermaid Live Editor\n\n<details>\n<summary>Sample Solution</summary>\n\n**Prompt:**\n```text\nCreate a content model diagram in Mermaid erDiagram syntax for a technical blog.\n\nContent types:\n1. BlogPost - Main article\n2. Author - Writer\n3. Category - Topic (one per post)\n4. Tag - Keywords (many per post)\n\nRelationships:\n- One Author writes many BlogPosts\n- One BlogPost belongs to one Category\n- BlogPosts have many Tags (many-to-many)\n\nInclude key attributes for BlogPost: title, slug, publishedDate, status\nUse proper cardinality notation.\n\nOutput valid Mermaid syntax.\n```\n\n**Expected Output:**\n```mermaid\nerDiagram\n    Author ||--o{ BlogPost : writes\n    BlogPost }o--|| Category : \"belongs to\"\n    BlogPost }o--o{ Tag : \"tagged with\"\n\n    Author {\n        string authorId PK\n        string name\n        string email\n    }\n\n    BlogPost {\n        string postId PK\n        string authorId FK\n        string categoryId FK\n        string title\n        string slug\n        date publishedDate\n        string status\n    }\n\n    Category {\n        string categoryId PK\n        string name\n    }\n\n    Tag {\n        string tagId PK\n        string name\n    }\n```\n\n**Self-check:**\n- [ ] Diagram renders in Mermaid Live Editor\n- [ ] Cardinality notation is correct (||--o{} for one-to-many)\n- [ ] All entities have at least 2-3 attributes\n- [ ] Primary/Foreign keys identified\n</details>\n\n---",
            "hydration_source_header": "Quick Practice Exercise (7 minutes)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "mermaid-site-map-example",
            "title": "Mermaid Site Map Code Example",
            "demonstrates": "mermaid-site-map-pattern",
            "lines": "1560-1580",
            "content": "<Warning>\n**Best Practice:** Don't generate complete IA package in one prompt! Break into 5-prompt chain where each output becomes context for next.\n</Warning>\n\n**Quick overview:**\n1. Prompt 1: Executive Summary (1 page)\n2. Prompt 2: IA Overview (2-3 pages)\n3. Prompt 3: Visual Diagrams (validate in Mermaid Live)\n4. Prompt 4: Navigation Spec (1-2 pages)\n5. Prompt 5: Implementation Guide (1 page)\n\nThen assemble all outputs.",
            "hydration_source_header": "The 5-Prompt Chain Strategy",
            "hydration_method": "line_proximity"
          },
          {
            "id": "documentation-suite-output",
            "title": "Complete Documentation Suite Output",
            "demonstrates": "documentation-suite-prompt",
            "lines": "1650-1750",
            "retrievalQuestions": [
              "What does a complete IA documentation suite include?"
            ],
            "content": "**Essential deliverables:**\n\n1. **IA Overview Document**\n   - Executive summary\n   - Key decisions and rationale\n   - Success metrics\n\n2. **Sitemap Diagram**\n   - Full hierarchical structure\n   - Page counts and distribution\n   - Implementation status\n\n3. **Content Model**\n   - Content types and relationships\n   - Metadata schemas\n   - Validation rules\n\n4. **Navigation Specification**\n   - Top navigation\n   - Sidebar/secondary navigation\n   - Breadcrumbs\n   - Footer navigation\n\n5. **Taxonomy Documentation**\n   - Classification system\n   - Tagging schema\n   - Governance rules\n\n6. **User Flows**\n   - Primary user journeys\n   - Decision points\n   - Pain points and solutions\n\n7. **Implementation Guide**\n   - Technical requirements\n   - CMS configuration\n   - Content migration plan\n   - Rollout phases\n\n---",
            "hydration_source_header": "The Complete Documentation Set",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "workflows": [
          {
            "id": "diagram-selection-workflow",
            "title": "Diagram Selection Workflow",
            "steps": [
              "identify-audience",
              "determine-purpose",
              "choose-type",
              "select-notation"
            ],
            "lines": "1755-1820",
            "retrievalQuestions": [
              "How do I choose which diagram to create?"
            ],
            "content": "| Category | Pages | Percentage | Status |\n|----------|-------|------------|--------|\n| Get Started | 12 | 14% | \u2705 Appropriate |\n| Authenticate & Authorize | 10 | 12% | \u2705 Appropriate |\n| Store & Manage Files | 28 | 33% | \u2705 Acceptable (core feature) |\n| Integrate with Webhooks | 12 | 14% | \u2705 Appropriate |\n| API Reference | 18 | 21% | \u2705 Appropriate |\n| Troubleshooting | 5 | 6% | \u2705 Intentionally lean |\n\n**Analysis:**\n- \"Store & Manage Files\" at 33% is acceptable as it's the core product feature\n- No category exceeds 40% threshold\n- All categories have sufficient content (>5 pages)\n- Good distribution supports multiple entry points",
            "hydration_source_header": "Balance Analysis",
            "hydration_method": "line_proximity"
          },
          {
            "id": "adr-creation-workflow",
            "title": "ADR Creation Workflow",
            "steps": [
              "identify-decision",
              "gather-context",
              "evaluate-options",
              "document-decision",
              "review-approve"
            ],
            "lines": "1825-1890",
            "retrievalQuestions": [
              "What's the process for creating an ADR?"
            ],
            "content": "[Detailed schema for each content type]\n\n---",
            "hydration_source_header": "Metadata Schema",
            "hydration_method": "line_proximity"
          },
          {
            "id": "documentation-suite-workflow",
            "title": "Complete Documentation Workflow",
            "steps": [
              "create-overview",
              "add-diagrams",
              "document-decisions",
              "add-details",
              "review-iterate"
            ],
            "lines": "1895-1960",
            "content": "**Essential deliverables:**\n\n1. **IA Overview Document**\n   - Executive summary\n   - Key decisions and rationale\n   - Success metrics\n\n2. **Sitemap Diagram**\n   - Full hierarchical structure\n   - Page counts and distribution\n   - Implementation status\n\n3. **Content Model**\n   - Content types and relationships\n   - Metadata schemas\n   - Validation rules\n\n4. **Navigation Specification**\n   - Top navigation\n   - Sidebar/secondary navigation\n   - Breadcrumbs\n   - Footer navigation\n\n5. **Taxonomy Documentation**\n   - Classification system\n   - Tagging schema\n   - Governance rules\n\n6. **User Flows**\n   - Primary user journeys\n   - Decision points\n   - Pain points and solutions\n\n7. **Implementation Guide**\n   - Technical requirements\n   - CMS configuration\n   - Content migration plan\n   - Rollout phases\n\n---",
            "hydration_source_header": "The Complete Documentation Set",
            "hydration_method": "fuzzy_title_match"
          }
        ],
        "checklists": [
          {
            "id": "diagram-quality-checklist",
            "title": "Diagram Quality Checklist",
            "validates": "diagram-system-framework",
            "items": 8,
            "lines": "1965-2000",
            "retrievalQuestions": [
              "How do I validate my IA diagrams?"
            ],
            "content": "| Level | Score | Criteria |\n|-------|-------|----------|\n| **Exemplary** | 23-25 | All diagrams render perfectly in Mermaid Live Editor. Visually polished with appropriate complexity. Notation choices well-justified. Diagrams tell clear story without text. |\n| **Proficient** | 18-22 | All diagrams render correctly. Clear and readable. Appropriate types chosen. Minor notation inconsistencies that don't affect understanding. |\n| **Developing** | 12-17 | Most diagrams render but may have syntax issues. Some clarity problems or inconsistent notation. May use wrong diagram type for use case. |\n| **Incomplete** | 0-11 | Diagrams have rendering errors. Hard to read or understand. Inconsistent notation. Wrong diagram types chosen. |\n\n**Self-check:**\n- [ ] Tested ALL diagrams in Mermaid Live Editor\n- [ ] Entity/node count within recommended limits (5-7 entities, max 4 levels)\n- [ ] Used correct diagram type per decision guide\n- [ ] Notation consistent across all diagrams",
            "hydration_source_header": "1. Diagram Quality (25 points)",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "adr-completeness-checklist",
            "title": "ADR Completeness Checklist",
            "validates": "adr-framework",
            "items": 10,
            "lines": "2005-2045",
            "content": "- Card sort analysis report (2024-03-15)\n- User interview synthesis (2024-03-20)\n- Analytics report Q1 2024\n```\n\n---",
            "hydration_source_header": "References",
            "hydration_method": "line_proximity"
          },
          {
            "id": "notation-consistency-checklist",
            "title": "Notation Consistency Checklist",
            "validates": "notation-systems",
            "items": 6,
            "lines": "2050-2080",
            "hydration_status": "failed"
          },
          {
            "id": "documentation-suite-checklist",
            "title": "Documentation Suite Checklist",
            "validates": "ia-notation-framework",
            "items": 12,
            "lines": "2085-2130",
            "retrievalQuestions": [
              "What should complete IA documentation include?"
            ],
            "content": "Modern IA documentation uses a **Docs-as-Code** approach:\n\n```\nTEXT-BASED SOURCE FILES (version controlled)\n           \u2193\n    MARKDOWN + MERMAID\n           \u2193\n    RENDERED DIAGRAMS\n           \u2193\n    PUBLISHED DOCUMENTATION\n```\n\n**Why Docs-as-Code?**\n\n**Traditional approach (Visio, Lucidchart, etc.):**\n- \u274c Binary files, can't diff changes\n- \u274c Hard to collaborate (file locking)\n- \u274c Version control is manual\n- \u274c Requires specialized software\n- \u274c Diagrams separate from documentation\n\n**Docs-as-Code approach (Markdown + Mermaid):**\n- \u2705 Plain text, easy to diff\n- \u2705 Multiple people can edit simultaneously\n- \u2705 Git tracks every change\n- \u2705 Any text editor works\n- \u2705 Diagrams live with documentation\n- \u2705 Automated rendering in CI/CD\n\n---",
            "hydration_source_header": "The IA Documentation Stack",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "success-criteria-checklist",
            "title": "Success Criteria Checklist",
            "validates": "ia-notation-framework",
            "items": 8,
            "lines": "2135-2170",
            "content": "**Scenario: DevCLI Documentation**\n\n```\nPROJECT BRIEF\n\nProduct: DevCLI\nDescription: Command-line tool for cloud infrastructure management\nContent: 60 documentation pages covering:\n  - Getting started & installation\n  - Core commands (create, deploy, monitor, destroy)\n  - Configuration & settings\n  - Plugins & extensions\n  - Troubleshooting\n\nAudience: DevOps engineers, varying experience levels\nCurrent problem: Documentation is alphabetically organized by command,\nmaking it hard to learn workflow\nGoal: Create task-based documentation supporting both learning and reference\n```\n\n---",
            "hydration_source_header": "Step 1: Define Your Project (5 minutes)",
            "hydration_method": "line_proximity"
          }
        ],
        "warnings": [
          {
            "id": "over-documentation",
            "title": "Over-Documentation",
            "prevents": "Creating more docs than needed",
            "lines": "2000",
            "content": "Information architecture specification and documentation for DevCLI command-line tool docs.\n\n## Contents\n\n- [IA Specification](specifications/ia-specification.md) - Complete IA design doc\n- [Diagrams](diagrams/) - Visual representations\n- [Decisions](decisions/) - Architectural Decision Records\n\n## Quick Links\n\n- [Sitemap](diagrams/sitemap.md)\n- [Content Model](diagrams/content-model.md)\n- [User Flow](diagrams/user-flow.md)\n\n## Version\n\nCurrent: v1.0 (2024-04-15)\nStatus: Approved for implementation\n\n## Stakeholders\n\n- IA Lead: [Your name]\n- Engineering Lead: [Name]\n- Product Manager: [Name]\n```\n\n**Commit your work:**\n\n```bash\ngit add .\ngit commit -m \"docs(spec): Add complete IA specification v1.0\n\n- Task-based organization with 6 top-level categories\n- Content model with 4 content types\n- Primary user flow for first deployment\n- 4-week implementation plan\"\n```\n\n---\n\n## IX. Self-Assessment Project: Create IA Deliverables for Sample Project (5 minutes)\n\n**Project Brief**\n\nCreate a complete, professional IA documentation package for a documentation project of your choice.\n\n### Deliverables\n\n**1. Complete IA Specification Document (5-7 pages)**\n\nMust include:\n- Executive summary with goals, decisions, and success metrics\n- IA overview with organizational principle and rationale\n- Balance analysis with percentages\n- Content type strategy\n- Design trade-offs explanation\n- Visual sitemap (Mermaid format)\n- Content model diagram (Mermaid format)\n- At least one user flow diagram (Mermaid format)\n- Navigation specification\n- Implementation plan with phases and timeline\n\n**2. Standalone Diagram Files**\n\nSeparate markdown files for:\n- `sitemap.md` - Complete sitemap with Mermaid diagram\n- `content-model.md` - Content types and relationships\n- `user-flow-primary.md` - Primary user journey\n- Optional: Additional user flows or taxonomy diagrams\n\n**3. Architectural Decision Records (2-3 ADRs)**\n\nDocument major IA decisions:\n- Why task-based vs. feature-based organization?\n- Why this specific content type strategy?\n- Why this hierarchy depth?\n\nEach ADR must include:\n- Context\n- Decision\n- Rationale with evidence\n- Alternatives considered\n- Consequences\n- Implementation approach\n\n**4. Version-Controlled Repository**\n\n- Organized directory structure\n- README with project overview\n- Meaningful commit messages\n- Professional formatting\n\n### Project Options\n\n**Option A: Your own project**\n- Most valuable for immediate application\n- Use real content and constraints\n- Leverage actual user research if available\n\n**Option B: Open-source documentation redesign**\n- Choose: React, Vue, Django, PostgreSQL, or similar\n- Analyze existing structure\n- Propose improvements with rationale\n\n**Option C: Provided scenario**\n- E-commerce platform documentation\n- SaaS product documentation\n- Developer tool documentation\n[Detailed scenarios can be provided if needed]\n\n### Requirements\n\n**Scope:**\n- Minimum 50 pages of content\n- At least 4 content types\n- 3-level hierarchy maximum\n- 5-7 top-level categories\n\n**Quality Standards:**\n- All Mermaid diagrams must render correctly\n- Notation must be consistent throughout\n- Professional formatting and presentation\n- Clear rationale for all major decisions\n- Evidence-based (not just opinions)\n\n**Documentation Standards:**\n- Proper markdown formatting\n- Table of contents for main document\n- All diagrams have explanatory text\n- Cross-references between sections work\n- No spelling or grammar errors\n\n### Self-Evaluation Rubric\n\nUse this 4-level rubric to assess your work honestly. A strong portfolio piece should score Proficient or Exemplary in all categories.\n\n#### 1. Diagram Quality (25 points)\n\n| Level | Score | Criteria |\n|-------|-------|----------|\n| **Exemplary** | 23-25 | All diagrams render perfectly in Mermaid Live Editor. Visually polished with appropriate complexity. Notation choices well-justified. Diagrams tell clear story without text. |\n| **Proficient** | 18-22 | All diagrams render correctly. Clear and readable. Appropriate types chosen. Minor notation inconsistencies that don't affect understanding. |\n| **Developing** | 12-17 | Most diagrams render but may have syntax issues. Some clarity problems or inconsistent notation. May use wrong diagram type for use case. |\n| **Incomplete** | 0-11 | Diagrams have rendering errors. Hard to read or understand. Inconsistent notation. Wrong diagram types chosen. |\n\n**Self-check:**\n- [ ] Tested ALL diagrams in Mermaid Live Editor\n- [ ] Entity/node count within recommended limits (5-7 entities, max 4 levels)\n- [ ] Used correct diagram type per decision guide\n- [ ] Notation consistent across all diagrams\n\n#### 2. Documentation Completeness (25 points)\n\n| Level | Score | Criteria |\n|-------|-------|----------|\n| **Exemplary** | 23-25 | All 8+ required sections present with rich detail. Every decision backed by evidence. Implementation plan is actionable with realistic timelines. Anticipates stakeholder questions. |\n| **Proficient** | 18-22 | All required sections present. Good depth in most areas. Clear explanations. Some evidence-based rationale. Implementation plan is realistic. |\n| **Developing** | 12-17 | Most sections present but some lack depth. Explanations present but may lack evidence. Implementation plan vague. Missing some required elements. |\n| **Incomplete** | 0-11 | Major sections missing. Shallow treatment. Little rationale provided. No clear implementation guidance. |\n\n**Self-check:**\n- [ ] Executive summary covers goals, decisions, metrics\n- [ ] IA overview explains organizational principle\n- [ ] Balance analysis shows percentages\n- [ ] All required diagrams included\n- [ ] Implementation plan has phases and timeline\n\n#### 3. IA Quality (25 points)\n\n| Level | Score | Criteria |\n|-------|-------|----------|\n| **Exemplary** | 23-25 | Organizational principle clearly serves user needs with evidence. Perfect balance (no category >35%). Depth appropriate for content volume. Content types well-defined with clear boundaries. Scalable design. |\n| **Proficient** | 18-22 | Sound organizational principle. Good balance (no category >40%). Appropriate depth. Content types make sense. Could scale reasonably. |\n| **Developing** | 12-17 | Organizational principle present but not well-justified. Some balance issues. Depth inconsistent. Content types overlap. Scaling concerns. |\n| **Incomplete** | 0-11 | Unclear organizational principle. Poor balance (>40% in one category). Wrong depth for volume. Content types poorly defined. Won't scale. |\n\n**Self-check:**\n- [ ] Ran balance analysis - no category >35%\n- [ ] Applied 5-check validation (completeness, consistency, balance, clarity, scalability)\n- [ ] User-centered organization (not company-structure based)\n- [ ] Content types have clear purposes and boundaries\n\n#### 4. Professional Presentation (15 points)\n\n| Level | Score | Criteria |\n|-------|-------|----------|\n| **Exemplary** | 14-15 | Flawless formatting. Perfect markdown. Scannable with clear hierarchy. Zero errors. Git history tells story. Ready to share with stakeholders today. |\n| **Proficient** | 11-13 | Clean, consistent formatting. Proper markdown. Mostly scannable. 1-2 minor errors. Good git commits. Nearly stakeholder-ready. |\n| **Developing** | 7-10 | Inconsistent formatting. Some markdown issues. Hard to scan in places. Several errors. Weak commit messages. Needs polish. |\n| **Incomplete** | 0-6 | Poor formatting. Markdown errors. Difficult to read. Many spelling/grammar errors. No git discipline. Not professional. |\n\n**Self-check:**\n- [ ] Ran spell check\n- [ ] Used markdown linter or previewed rendered output\n- [ ] Meaningful commit messages following convention\n- [ ] README provides clear project overview\n\n#### 5. Decision Documentation (10 points)\n\n| Level | Score | Criteria |\n|-------|-------|----------|\n| **Exemplary** | 9-10 | 2-3 ADRs covering major decisions. Each explores 3+ alternatives with pros/cons. Clear rationale with evidence. Acknowledges trade-offs and consequences. |\n| **Proficient** | 7-8 | 2-3 ADRs present. Alternatives mentioned. Rationale clear. Some trade-offs acknowledged. |\n| **Developing** | 4-6 | 1-2 ADRs. Limited alternatives explored. Rationale weak. Few trade-offs acknowledged. |\n| **Incomplete** | 0-3 | ADRs missing or incomplete. No alternatives. No clear rationale. No trade-off discussion. |\n\n**Self-check:**\n- [ ] At least 2 ADRs covering major decisions\n- [ ] Each ADR has context, decision, rationale, alternatives, consequences\n- [ ] Compared 2-3 alternatives per decision with evidence\n\n---\n\n### Scoring Guide\n\n- **90-100 points (Exemplary):** Portfolio-ready work. Demonstrates professional IA skills. Share with confidence.\n- **75-89 points (Proficient):** Solid work. Minor improvements needed before sharing externally.\n- **60-74 points (Developing):** Core competencies present but needs significant revision. Review module content.\n- **Below 60 (Incomplete):** Major gaps. Revisit module sections and redo project.\n- Evidence-based rationale\n- Consequences considered\n\n### Success Indicators\n\nRate your IA documentation package using this progressive scale. **Aim for Level 4-5 performance.**\n\n#### Level 5: Portfolio-Ready (Outstanding)\n```\n\u2705 Implementation-ready: Developer could build with ZERO clarification questions\n\u2705 Stakeholder-approved: Executives understand trade-offs and approve confidently\n\u2705 Technical excellence: All diagrams render perfectly, validated in target platform\n\u2705 Evidence-rich: Every decision backed by data, user research, or competitive analysis\n\u2705 Future-proof: Documentation includes version control, change rationale, evolution path\n\u2705 Onboarding-ready: New team member becomes productive within 30 minutes\n\u2705 Professional presentation: Publication-quality formatting, consistent notation, no errors\n```\n**Score: 90-100%** | **Time investment: 10-12 hours** | **Portfolio quality work**\n\n#### Level 4: Professional Standard (Strong)\n```\n\u2705 Implementable: Developer needs <3 clarification questions\n\u2705 Stakeholder-ready: Executives understand main decisions, minor questions only\n\u2705 Diagrams validated: All render correctly, tested in Mermaid Live Editor\n\u2705 Decisions justified: Clear rationale with supporting evidence for major choices\n\u2705 Maintainable: Documentation useful 6+ months later, includes ADRs\n\u2705 Understandable: New team member grasps IA within 1 hour\n\u2705 Polished: Clean formatting, consistent notation, minimal typos\n```\n**Score: 75-89%** | **Time investment: 8-10 hours** | **Meets professional standards**\n\n#### Level 3: Functional (Adequate)\n```\n\u26a0\ufe0f Mostly implementable: Developer needs 5-7 clarification questions\n\u26a0\ufe0f Stakeholder review possible: Some sections need explanation\n\u26a0\ufe0f Diagrams mostly work: 1-2 minor rendering issues or platform compatibility questions\n\u26a0\ufe0f Some rationale provided: Major decisions explained, evidence sometimes missing\n\u26a0\ufe0f Somewhat maintainable: Core decisions documented, some context missing\n\u26a0\ufe0f Requires orientation: New team member needs 2-3 hours + questions\n\u26a0\ufe0f Acceptable presentation: Some formatting inconsistencies or notation errors\n```\n**Score: 60-74%** | **Time investment: 6-8 hours** | **Needs revision for professional use**\n\n#### Level 2: Incomplete (Developing)\n```\n\u274c Missing key details: Developer needs extensive clarification (10+ questions)\n\u274c Stakeholder confusion: Major decisions lack explanation or rationale\n\u274c Diagram errors: Multiple syntax errors, untested outputs\n\u274c Weak justification: Decisions stated without supporting evidence\n\u274c Poor documentation: No ADRs, unclear why choices were made\n\u274c Hard to understand: Takes 4+ hours for new team member, many questions\n\u274c Rough presentation: Multiple formatting errors, inconsistent notation\n```\n**Score: 40-59%** | **Time investment: 4-6 hours** | **Requires substantial rework**\n\n#### Level 1: Insufficient (Needs Major Revision)\n```\n\u274c Not implementable: Missing critical sections (sitemap/content model/flows)\n\u274c No stakeholder value: Can't review or approve without complete rewrite\n\u274c Diagrams missing/broken: Most don't render or aren't included\n\u274c No rationale: Decisions unexplained, no evidence provided\n\u274c No documentation trail: No version control, ADRs, or decision history\n\u274c Incomprehensible: Can't understand IA without significant external help\n\u274c Unprofessional: Severe formatting issues, incomplete sections\n```\n**Score: 0-39%** | **Time investment: under 4 hours** | **Start over with better planning**\n\n---\n\n**Self-Diagnosis Questions:**\n\n1. **Implementation Test:** Could a developer unfamiliar with your project build the site structure from your sitemap alone? (If no \u2192 Level 3 or below)\n\n2. **Stakeholder Test:** Could an executive approve your IA after reading only the executive summary and ADRs? (If no \u2192 Level 3 or below)\n\n3. **Technical Test:** Have you validated ALL Mermaid diagrams in your target platform (GitHub/GitLab/Docusaurus)? (If no \u2192 Level 3 or below)\n\n4. **Evidence Test:** Can you cite specific data/research for your top 3 decisions? (If no \u2192 Level 2 or below)\n\n5. **Time Test:** Is your documentation useful 6 months from now without you present to explain? (If no \u2192 Level 3 or below)\n\n6. **Onboarding Test:** Track how long it takes a peer to understand your IA. Under 1 hour = Level 4+, 2-3 hours = Level 3, 4+ hours = Level 2 or below\n\n7. **Professional Test:** Would you include this in your portfolio without hesitation? (If no \u2192 Level 3 or below)\n\n### Common Pitfalls to Avoid\n\n```\n\u274c Mermaid syntax errors (test all diagrams!)\n\u274c Vague rationale (\"it feels better\")\n\u274c Missing evidence for decisions\n\u274c Inconsistent notation between diagrams\n\u274c No consideration of alternatives\n\u274c Unrealistic implementation timeline\n\u274c Forgetting to document trade-offs\n\u274c Poor formatting or presentation\n\u274c No version control or change tracking\n```\n\n---\n\n### Troubleshooting Mermaid Diagrams\n\nWhen your Mermaid diagrams don't render correctly, follow this systematic debugging approach:\n\n<AccordionGroup>\n  <Accordion title=\"Common Syntax Errors and Fixes\">\n\n**1. Unclosed Brackets/Parentheses**\n\n\u274c **Error:**\n```mermaid\nflowchart TD\n    Start[Get Started\n    Start --> Next\n```\n\n\u2705 **Fix:** Close all brackets\n```mermaid\nflowchart TD\n    Start[Get Started]\n    Start --> Next[Next Step]\n```\n\n**2. Special Characters in Labels**\n\n\u274c **Error:**\n```mermaid\nflowchart TD\n    A[User's Guide] --> B\n```\n\n\u2705 **Fix:** Use quotes for special characters\n```mermaid\nflowchart TD\n    A[\"User's Guide\"] --> B[Next]\n```\n\n**3. Invalid Relationship Syntax**\n\n\u274c **Error:**\n```mermaid\nerDiagram\n    Author -> BlogPost : writes\n```\n\n\u2705 **Fix:** Use correct cardinality notation\n```mermaid\nerDiagram\n    Author ||--o{ BlogPost : writes\n```\n\n**4. Missing Node Definitions**\n\n\u274c **Error:**\n```mermaid\nflowchart TD\n    Start --> End\n    Start --> Middle\n```\n\n\u2705 **Fix:** Define all nodes (or use implicit)\n```mermaid\nflowchart TD\n    Start[Start] --> End[End]\n    Start --> Middle[Middle Step]\n```\n\n  </Accordion>\n\n  <Accordion title=\"Debugging Workflow\">\n\n**Step 1: Isolate the Problem**\n\n1. Copy your diagram code\n2. Go to [Mermaid Live Editor](https://mermaid.live/)\n3. Paste and check if it renders\n\n**Step 2: Binary Search for Error**\n\nIf diagram is long and won't render:\n\n1. Comment out half the diagram\n2. Test which half has the error\n3. Repeat until you find the problematic line\n\n**Step 3: Check Common Issues**\n\n- \u2610 All brackets closed? `[ ]` `( )` `{ }`\n- \u2610 Quotes around special characters? `'` or `\"`\n- \u2610 Correct relationship syntax for diagram type?\n- \u2610 Node IDs are unique (no duplicates)?\n- \u2610 Direction specified? (`TD`, `LR`, etc.)\n\n**Step 4: Validate Incrementally**\n\nBuild complex diagrams in steps:\n\n1. Create basic structure \u2192 Test\n2. Add first level details \u2192 Test\n3. Add styling \u2192 Test\n4. Add remaining content \u2192 Test\n\n<Tip>\n**Pro tip:** Keep a \"known good\" version. When adding complexity, save each working state so you can revert if something breaks.\n</Tip>\n\n  </Accordion>\n\n  <Accordion title=\"Platform-Specific Issues\">\n\n**GitHub/GitLab:**\n- Use triple backticks with `mermaid` language identifier\n- Some advanced features may not be supported\n- Test in platform's preview mode\n\n**Docusaurus/MkDocs:**\n- Ensure Mermaid plugin is installed and configured\n- Check plugin version compatibility\n- Some syntax variations may be required\n\n**Notion:**\n- Use `/code` block and select Mermaid\n- Limited diagram type support\n- Test before committing to complex diagrams\n\n**VS Code:**\n- Install \"Markdown Preview Mermaid Support\" extension\n- Restart VS Code after installation\n- Preview with `Ctrl+Shift+V` (Windows) or `Cmd+Shift+V` (Mac)\n\n</Accordion>\n\n<Accordion title=\"When to Ask for Help\">\n\n**Mermaid Documentation:**\n- [Official Docs](https://mermaid.js.org/)\n- [Syntax Reference](https://mermaid.js.org/intro/syntax-reference.html)\n- [Examples Gallery](https://mermaid.js.org/ecosystem/tutorials.html)\n\n**Community Resources:**\n- [Mermaid GitHub Discussions](https://github.com/mermaid-js/mermaid/discussions)\n- [Stack Overflow](https://stackoverflow.com/questions/tagged/mermaid)\n- Search error message + \"mermaid\"\n\n**Red Flags (Time to Simplify):**\n- Diagram has >20 nodes\n- 4+ levels of nesting\n- Syntax works in Live Editor but not in your platform\n- Taking >30 minutes to debug\n\n**Solution:** Break into multiple simpler diagrams\n\n</Accordion>\n\n</AccordionGroup>\n\n---\n\n### Submission Format\n\nSubmit as:\n1. Git repository (GitHub, GitLab, or zip file)\n2. README with project overview\n3. All required files in organized structure\n4. Brief reflection document (1 page):\n   - What you learned\n   - What was challenging\n   - How you'd improve with more time\n   - What AI helped with vs. what required human judgment\n\n### Time Budget\n\n- Project planning: 1 hour\n- Sitemap generation: 1 hour\n- Content model creation: 1 hour\n- User flow documentation: 1 hour\n- Complete spec writing: 2-3 hours\n- ADR documentation: 1-2 hours\n- Formatting and polish: 1 hour\n- Version control setup: 30 minutes\n- **Total: 8.5-11.5 hours**\n\n---\n\n## Module Summary\n\nIn this module, you've learned how to create professional IA documentation using AI assistance and modern Docs-as-Code practices:\n\n```\n\u2705 Generate sitemaps in multiple formats (ASCII, Mermaid)\n\u2705 Create content model diagrams showing types and relationships\n\u2705 Visualize taxonomies for different classification systems\n\u2705 Document user flows with decision points and error paths\n\u2705 Apply standard IA notation consistently\n\u2705 Build complete IA specification packages\n\u2705 Version control IA artifacts with Git\n\u2705 Write Architectural Decision Records for major choices\n\u2705 Choose appropriate diagram types for communication needs\n```\n\n**Key takeaways:**\n\n**1. Documentation enables implementation**\nWell-documented IA is the bridge between design and implementation. Without it, great IA stays in your head.\n\n**2. Docs-as-Code scales better**\nText-based documentation (Markdown + Mermaid) version controls better, collaborates easier, and maintains longer than binary diagram files.\n\n**3. Mermaid is your friend**\nLearning Mermaid syntax pays dividends. AI can generate it, humans can read it, Git can diff it, and pipelines can render it.\n\n**4. Decisions need documentation**\nADRs capture not just what you decided, but why\u2014preserving context that's invaluable months later.\n\n**5. Multiple views serve multiple stakeholders**\nThe same IA needs different representations: executives need high-level, developers need details, writers need content types.\n\n**6. AI accelerates but doesn't replace judgment**\nAI quickly generates diagrams and documentation, but humans must validate accuracy, choose emphasis, and ensure clarity.\n\nThe self-assessment project gives you experience creating a complete, professional IA documentation package\u2014the kind of deliverable that gets approved, guides implementation accurately, and serves as institutional knowledge.\n\n---\n\n**Congratulations on completing Module 4.2!** You now have the skills to document your information architecture work professionally and effectively.",
            "hydration_source_header": "DevCLI IA Documentation",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "stale-documentation",
            "title": "Stale Documentation",
            "prevents": "Diagrams that don't match reality",
            "lines": "2005",
            "retrievalQuestions": [
              "How do I prevent stale IA documentation?"
            ],
            "content": "## Information Architecture Specification\n\n**Version:** 1.0  \n**Date:** 2024-04-15  \n**Author:** [Your name]  \n**Status:** Approved for implementation\n\n---\n\n## Table of Contents\n\n1. [Executive Summary](#executive-summary)\n2. [IA Overview](#ia-overview)\n3. [Sitemap](#sitemap)\n4. [Content Model](#content-model)\n5. [Navigation Specification](#navigation-specification)\n6. [User Flows](#user-flows)\n7. [Implementation Guide](#implementation-guide)\n8. [Appendices](#appendices)\n\n---\n\n## 1. Executive Summary\n\n### Project Goals\nCloudStore API documentation currently receives low satisfaction scores (6.2/10) and generates high support volume due to findability issues. This redesign aims to:\n\n- Improve documentation satisfaction to 8.5+/10\n- Reduce \"how-to\" support tickets by 40%\n- Decrease time-to-first-successful-API-call from 45min to <15min\n\n### Key Decisions\n\n**Organizational Principle: Task-Based**\nReorganized from internal service structure to user-task structure, allowing developers to find content by \"what they want to accomplish\" rather than understanding CloudStore's internal architecture.\n\n**Di\u00c3\u00a1taxis Integration**\nApplied Di\u00c3\u00a1taxis framework to clearly separate:\n- Tutorials (learning-oriented): 15 pages (18%)\n- How-to Guides (task-oriented): 32 pages (38%)\n- Reference (information-oriented): 28 pages (33%)\n- Explanations (understanding-oriented): 10 pages (12%)\n\n**Balance & Accessibility**\n- Top-level categories: 6 (optimal for scanning)\n- Maximum depth: 3 levels\n- No single category exceeds 35% of content\n- Progressive disclosure from simple to complex\n\n### Expected Impact\n\n**Quantitative:**\n- 40% reduction in documentation-related support tickets\n- 35% faster time-to-first-API-call\n- 30% increase in API adoption among new users\n\n**Qualitative:**\n- Clearer learning path for new developers\n- Faster lookup for experienced developers\n- Reduced frustration and abandonment\n\n### Success Metrics\n\n**Track Monthly:**\n- Documentation satisfaction (target: 8.5/10)\n- Time-to-find-content (target: <2 min)\n- Support ticket volume (target: -40%)\n- Search success rate (target: >80%)\n\n---\n\n## 2. IA Overview\n\n### Organizational Principle\n\n**Previous Structure: Service-Based** \u274c\n```\n\u251c\u2500\u2500 Identity Service\n\u251c\u2500\u2500 Storage Service  \n\u251c\u2500\u2500 Event Service\n\u2514\u2500\u2500 Analytics Service\n```\nProblem: Required users to understand CloudStore's internal architecture\n\n**New Structure: Task-Based** \u2705\n```\n\u251c\u2500\u2500 Get Started\n\u251c\u2500\u2500 Authenticate & Authorize\n\u251c\u2500\u2500 Store & Manage Files\n\u251c\u2500\u2500 Integrate with Webhooks\n\u251c\u2500\u2500 API Reference\n\u2514\u2500\u2500 Troubleshooting\n```\nBenefit: Users navigate by what they want to accomplish\n\n### Hierarchy Structure\n\n**Level 1: User Tasks (6 categories)**\n- Purpose: High-level user goals\n- Labels: Action-oriented, clear intent\n- Balance: 10-35% each, well-distributed\n\n**Level 2: Specific Features/Tasks (2-6 per L1)**\n- Purpose: Break down tasks into components\n- Labels: Specific, parallel granularity\n- Organization: Follows typical workflow order\n\n**Level 3: Content Types (Di\u00c3\u00a1taxis)**\n- Purpose: Organize by how content is used\n- Labels: Tutorial, How-to, Reference, Explanation\n- Organization: Learning progression\n\n### Balance Analysis\n\n| Category | Pages | Percentage | Status |\n|----------|-------|------------|--------|\n| Get Started | 12 | 14% | \u2705 Appropriate |\n| Authenticate & Authorize | 10 | 12% | \u2705 Appropriate |\n| Store & Manage Files | 28 | 33% | \u2705 Acceptable (core feature) |\n| Integrate with Webhooks | 12 | 14% | \u2705 Appropriate |\n| API Reference | 18 | 21% | \u2705 Appropriate |\n| Troubleshooting | 5 | 6% | \u2705 Intentionally lean |\n\n**Analysis:**\n- \"Store & Manage Files\" at 33% is acceptable as it's the core product feature\n- No category exceeds 40% threshold\n- All categories have sufficient content (>5 pages)\n- Good distribution supports multiple entry points\n\n### Content Type Strategy\n\n**Di\u00c3\u00a1taxis Distribution:**\n- Tutorials (18%): Concentrated in \"Get Started\" for onboarding\n- How-to Guides (38%): Distributed across feature sections\n- Reference (33%): Primarily in \"API Reference\" but also in feature sections\n- Explanations (12%): Primarily in \"Get Started\" and \"Authenticate\"\n\n**Rationale:**\n- High How-to percentage serves developers solving specific problems\n- Sufficient Reference for lookup needs\n- Adequate Tutorial content for learning path\n- Explanations provide necessary context without overwhelming\n\n### Design Trade-offs\n\n**Trade-off 1: Depth vs. Simplicity**\n- **Decision:** 3 levels maximum\n- **Reason:** Balances comprehensive organization with navigability\n- **Alternative considered:** 2 levels (too flat for 85 pages)\n\n**Trade-off 2: Feature-based vs. Workflow-based**\n- **Decision:** Hybrid\u2014features at L2, workflows within features\n- **Reason:** Matches how developers think about APIs\n- **Alternative considered:** Pure workflow (doesn't scale well)\n\n**Trade-off 3: Centralized vs. Distributed Reference**\n- **Decision:** Distributed\u2014reference content in features + standalone section\n- **Reason:** Supports both browse and lookup patterns\n- **Alternative considered:** All reference in one place (harder to discover)\n\n---\n\n## 3. Sitemap\n\n### Visual Structure\n\n```mermaid\n[Complete sitemap diagram from earlier example]\n```\n\n### Page Inventory\n\n[Detailed listing with implementation status]\n\n---\n\n## 4. Content Model\n\n### Content Types\n\n```mermaid\n[Content model diagram from earlier]\n```\n\n### Metadata Schema\n\n[Detailed schema for each content type]\n\n---\n\n## 5. Navigation Specification\n\n### Top Navigation\n\n| Item | Destination | Purpose |\n|------|-------------|---------|\n| Get Started | /get-started | Entry point for new users |\n| Guides | /guides | Task-based how-to content |\n| API Reference | /api-reference | Complete endpoint documentation |\n| SDKs | /sdks | Language-specific libraries |\n\n### Sidebar Navigation Logic\n\n[Detailed sidebar spec with expansion behavior]\n\n---\n\n## 6. User Flows\n\n### Primary Flow: Implement Authentication\n\n```mermaid\n[User flow diagram from earlier]\n```\n\n[Additional flows as needed]\n\n---\n\n## 7. Implementation Guide\n\n### Phase 1: Infrastructure (Week 1)\n- [ ] Configure Docusaurus\n- [ ] Set up navigation structure\n- [ ] Implement content type templates\n\n### Phase 2: Content Migration (Weeks 2-3)\n- [ ] Add frontmatter metadata\n- [ ] Reorganize into new structure\n- [ ] Update all cross-links\n\n### Phase 3: Enhancement (Week 4)\n- [ ] Add related content components\n- [ ] Implement search\n- [ ] Create interactive examples\n\n### Phase 4: Launch (Week 5)\n- [ ] QA testing\n- [ ] Soft launch to internal team\n- [ ] Full launch with announcement\n\n---\n\n## 8. Appendices\n\n### A. Notation Key\n[Legend for all symbols used]\n\n### B. Stakeholder Approvals\n- [x] Engineering Lead: Approved 2024-04-10\n- [x] Product Manager: Approved 2024-04-12\n- [x] Technical Writing Lead: Approved 2024-04-14\n\n### C. Version History\n- v1.0 (2024-04-15): Initial specification\n```\n\n---\n\n## VII. Version Control for IA Artifacts (5 minutes)\n\nIA documentation should be version controlled just like code.\n\n### Git Workflow for IA Documentation\n\n**Repository structure:**\n\n```\nia-documentation/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 diagrams/\n\u2502   \u251c\u2500\u2500 sitemap.md (with Mermaid)\n\u2502   \u251c\u2500\u2500 content-model.md\n\u2502   \u251c\u2500\u2500 user-flows.md\n\u2502   \u2514\u2500\u2500 taxonomy.md\n\u251c\u2500\u2500 specifications/\n\u2502   \u251c\u2500\u2500 navigation-spec.md\n\u2502   \u251c\u2500\u2500 metadata-schema.md\n\u2502   \u2514\u2500\u2500 content-types.md\n\u251c\u2500\u2500 decisions/\n\u2502   \u251c\u2500\u2500 001-task-based-organization.md\n\u2502   \u251c\u2500\u2500 002-diataxis-integration.md\n\u2502   \u2514\u2500\u2500 003-three-level-hierarchy.md\n\u2514\u2500\u2500 archive/\n    \u2514\u2500\u2500 v1-initial/\n```\n\n**Commit message conventions:**\n\n```\nfeat(sitemap): Add webhooks section\nfix(taxonomy): Correct balance in Core Resources category\ndocs(flows): Update authentication user flow\nrefactor(model): Simplify content type relationships\n```\n\n---\n\n### Architectural Decision Records (ADRs)\n\n**ADR** (Architectural Decision Record) is a document that captures an important architectural decision along with its context and consequences.\n\nDocument major IA decisions using ADR format:\n\n**Template:**\n\n```markdown",
            "hydration_source_header": "CloudStore API Documentation",
            "hydration_method": "fuzzy_title_match"
          },
          {
            "id": "wrong-audience",
            "title": "Wrong Audience Focus",
            "prevents": "Technical docs for executives",
            "lines": "2010",
            "content": "Let's create a complete, professional IA documentation package from start to finish.\n\n### Step 0: Warmup Exercise (10 minutes)\n\nBefore tackling the full 60-page project, let's practice with a simpler scenario to build confidence.\n\n**Mini-Scenario:** Personal portfolio website documentation (10 pages total)\n\n**Your Simple Project:**\n```\nPortfolio Site Docs\n- About (1 page)\n- Projects (5 pages - 5 case studies)\n- Blog (3 posts)\n- Contact (1 page)\n\nGoal: Create sitemap + simple content model\n```\n\n**Warmup Tasks:**\n\n1. **Generate ASCII sitemap** (3 min)\n   - Write prompt for 10-page portfolio site\n   - Generate with AI\n   - Verify structure makes sense\n\n2. **Create simple content model** (4 min)\n   - Content types: Project, BlogPost\n   - Minimal attributes (3-4 each)\n   - No relationships needed yet\n\n3. **Convert sitemap to Mermaid** (3 min)\n   - Test in Mermaid Live Editor\n   - Verify it renders\n\n<details>\n<summary>Warmup Solution (Try on your own first!)</summary>\n\n**Sitemap Prompt:**\n```text\nGenerate a sitemap for a portfolio website with 10 pages.\n\nStructure:\n- Home\n- About (1 page)\n- Projects (5 case studies)\n- Blog (3 posts)\n- Contact\n\nFormat as ASCII tree with page counts.\n```\n\n**Expected Sitemap:**\n```text\nHome\n\u251c\u2500\u2500 About\n\u251c\u2500\u2500 Projects (5 pages, 50%)\n\u2502   \u251c\u2500\u2500 E-commerce Redesign\n\u2502   \u251c\u2500\u2500 Mobile App IA\n\u2502   \u251c\u2500\u2500 Documentation Site\n\u2502   \u251c\u2500\u2500 Search UX Improvement\n\u2502   \u2514\u2500\u2500 Content Migration\n\u251c\u2500\u2500 Blog (3 pages, 30%)\n\u2502   \u251c\u2500\u2500 How I Approach IA\n\u2502   \u251c\u2500\u2500 Tools I Use\n\u2502   \u2514\u2500\u2500 Common IA Mistakes\n\u2514\u2500\u2500 Contact\n```\n\n**Simple Content Model:**\n```mermaid\nerDiagram\n    Project {\n        string title\n        string description\n        date completedDate\n        string clientType\n    }\n\n    BlogPost {\n        string title\n        text content\n        date publishedDate\n        array tags\n    }\n```\n\n**Key Learning:** Even a simple 10-page site benefits from structured IA documentation!\n</details>\n\n---\n\n### Tutorial Overview\n\n**What You'll Create:**\nComplete IA documentation for a CLI tool documentation site\n\n**Time:** 25-30 minutes\n\n**Deliverables:**\n- IA specification document with embedded Mermaid diagrams\n- Sitemap visualization\n- Content model\n- User flow diagram\n- Implementation plan\n\n---\n\n### Step 1: Define Your Project (5 minutes)\n\n**Scenario: DevCLI Documentation**\n\n```\nPROJECT BRIEF\n\nProduct: DevCLI\nDescription: Command-line tool for cloud infrastructure management\nContent: 60 documentation pages covering:\n  - Getting started & installation\n  - Core commands (create, deploy, monitor, destroy)\n  - Configuration & settings\n  - Plugins & extensions\n  - Troubleshooting\n\nAudience: DevOps engineers, varying experience levels\nCurrent problem: Documentation is alphabetically organized by command,\nmaking it hard to learn workflow\nGoal: Create task-based documentation supporting both learning and reference\n```\n\n---\n\n### Step 2: Generate Sitemap (5 minutes)\n\n**Your Prompt:**\n\n```\nGenerate a sitemap for CLI tool documentation.\n\nProduct: DevCLI (cloud infrastructure management)\nContent: 60 pages\n- Installation & setup (8 pages)\n- Core workflow commands (25 pages)\n- Configuration (12 pages)\n- Advanced features (10 pages)\n- Troubleshooting (5 pages)\n\nAudience: DevOps engineers (beginner to advanced)\nApproach: Task-based with Di\u00c3\u00a1taxis content types\n\nStructure:\n- 3 levels maximum\n- 5-7 top-level categories\n- Include page counts and percentages\n- Mark content types where relevant\n\nFormat as ASCII tree with Mermaid conversion.\n```\n\n**Expected output:** Complete sitemap in both ASCII and Mermaid format\n\n---\n\n### Step 3: Create Content Model (5 minutes)\n\n**Your Prompt:**\n\n```\nCreate a content model diagram for CLI tool documentation.\n\nContent types:\n1. Command Reference - Technical specs for each command\n2. Tutorial - Step-by-step learning content\n3. How-to Guide - Task-focused solutions\n4. Explanation - Conceptual content\n\nRelationships:\n- Tutorials reference Commands\n- How-to Guides reference Commands\n- Explanations provide context for Commands\n- Content can link to related content of any type\n\nShow in Mermaid erDiagram format with key attributes for each type.\n```\n\n**Expected output:** Content model diagram with relationships and metadata\n\n---\n\n### Step 4: Document User Flow (5 minutes)\n\n**Your Prompt:**\n\n```\nCreate a user flow diagram for a DevOps engineer learning to deploy infrastructure.\n\nStarting point: Documentation homepage\nGoal: Successfully deploy first application\nKey steps:\n- Installation\n- Configuration\n- First deployment\n- Monitoring\n- Troubleshooting (if errors)\n\nShow decision points and potential error paths.\nUse Mermaid flowchart format.\n```\n\n**Expected output:** Complete user flow with success and error paths\n\n---\n\n### Step 5: Generate Complete Documentation Package (10 minutes)\n\n**Your Prompt:**\n\n```\nGenerate a complete IA specification document for DevCLI documentation.\n\nInclude:\n1. Executive Summary\n   - Goals: Improve learning path, reduce time-to-first-deploy\n   - Key decisions: Task-based organization, Di\u00c3\u00a1taxis integration\n   - Success metrics\n\n2. IA Overview\n   - Organizational principle and rationale\n   - Hierarchy explanation\n   - Balance analysis\n   - Content type strategy\n   - Design trade-offs\n\n3. Embed the sitemap diagram (Mermaid)\n\n4. Embed the content model (Mermaid)\n\n5. Embed the user flow (Mermaid)\n\n6. Navigation specification\n   - Top nav items\n   - Sidebar logic\n   - Cross-linking strategy\n\n7. Implementation plan\n   - 4-week rollout\n   - Phases and milestones\n   - Success metrics\n\nFormat as professional markdown document with table of contents.\nUse the CloudStore example as a template for structure and depth.\n\nPROJECT CONTEXT:\n[Paste project brief from Step 1]\n[Include sitemaps, models, and flows from Steps 2-4]\n```\n\n**Expected output:** \n\nComplete markdown document (5-7 pages) with:\n- Professional formatting\n- Embedded Mermaid diagrams\n- Clear sections and headers\n- Implementation guidance\n- Ready for stakeholder review\n\n---\n\n### Step 6: Version Control Setup (5 minutes)\n\n**Create your repository structure:**\n\n```bash",
            "hydration_source_header": "VIII. Hands-on Tutorial: Generate Complete IA Documentation Set (25 minutes)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "inconsistent-notation",
            "title": "Inconsistent Notation",
            "prevents": "Mixed symbols and conventions",
            "lines": "2015",
            "content": "Let's create a complete, professional IA documentation package from start to finish.\n\n### Step 0: Warmup Exercise (10 minutes)\n\nBefore tackling the full 60-page project, let's practice with a simpler scenario to build confidence.\n\n**Mini-Scenario:** Personal portfolio website documentation (10 pages total)\n\n**Your Simple Project:**\n```\nPortfolio Site Docs\n- About (1 page)\n- Projects (5 pages - 5 case studies)\n- Blog (3 posts)\n- Contact (1 page)\n\nGoal: Create sitemap + simple content model\n```\n\n**Warmup Tasks:**\n\n1. **Generate ASCII sitemap** (3 min)\n   - Write prompt for 10-page portfolio site\n   - Generate with AI\n   - Verify structure makes sense\n\n2. **Create simple content model** (4 min)\n   - Content types: Project, BlogPost\n   - Minimal attributes (3-4 each)\n   - No relationships needed yet\n\n3. **Convert sitemap to Mermaid** (3 min)\n   - Test in Mermaid Live Editor\n   - Verify it renders\n\n<details>\n<summary>Warmup Solution (Try on your own first!)</summary>\n\n**Sitemap Prompt:**\n```text\nGenerate a sitemap for a portfolio website with 10 pages.\n\nStructure:\n- Home\n- About (1 page)\n- Projects (5 case studies)\n- Blog (3 posts)\n- Contact\n\nFormat as ASCII tree with page counts.\n```\n\n**Expected Sitemap:**\n```text\nHome\n\u251c\u2500\u2500 About\n\u251c\u2500\u2500 Projects (5 pages, 50%)\n\u2502   \u251c\u2500\u2500 E-commerce Redesign\n\u2502   \u251c\u2500\u2500 Mobile App IA\n\u2502   \u251c\u2500\u2500 Documentation Site\n\u2502   \u251c\u2500\u2500 Search UX Improvement\n\u2502   \u2514\u2500\u2500 Content Migration\n\u251c\u2500\u2500 Blog (3 pages, 30%)\n\u2502   \u251c\u2500\u2500 How I Approach IA\n\u2502   \u251c\u2500\u2500 Tools I Use\n\u2502   \u2514\u2500\u2500 Common IA Mistakes\n\u2514\u2500\u2500 Contact\n```\n\n**Simple Content Model:**\n```mermaid\nerDiagram\n    Project {\n        string title\n        string description\n        date completedDate\n        string clientType\n    }\n\n    BlogPost {\n        string title\n        text content\n        date publishedDate\n        array tags\n    }\n```\n\n**Key Learning:** Even a simple 10-page site benefits from structured IA documentation!\n</details>\n\n---\n\n### Tutorial Overview\n\n**What You'll Create:**\nComplete IA documentation for a CLI tool documentation site\n\n**Time:** 25-30 minutes\n\n**Deliverables:**\n- IA specification document with embedded Mermaid diagrams\n- Sitemap visualization\n- Content model\n- User flow diagram\n- Implementation plan\n\n---\n\n### Step 1: Define Your Project (5 minutes)\n\n**Scenario: DevCLI Documentation**\n\n```\nPROJECT BRIEF\n\nProduct: DevCLI\nDescription: Command-line tool for cloud infrastructure management\nContent: 60 documentation pages covering:\n  - Getting started & installation\n  - Core commands (create, deploy, monitor, destroy)\n  - Configuration & settings\n  - Plugins & extensions\n  - Troubleshooting\n\nAudience: DevOps engineers, varying experience levels\nCurrent problem: Documentation is alphabetically organized by command,\nmaking it hard to learn workflow\nGoal: Create task-based documentation supporting both learning and reference\n```\n\n---\n\n### Step 2: Generate Sitemap (5 minutes)\n\n**Your Prompt:**\n\n```\nGenerate a sitemap for CLI tool documentation.\n\nProduct: DevCLI (cloud infrastructure management)\nContent: 60 pages\n- Installation & setup (8 pages)\n- Core workflow commands (25 pages)\n- Configuration (12 pages)\n- Advanced features (10 pages)\n- Troubleshooting (5 pages)\n\nAudience: DevOps engineers (beginner to advanced)\nApproach: Task-based with Di\u00c3\u00a1taxis content types\n\nStructure:\n- 3 levels maximum\n- 5-7 top-level categories\n- Include page counts and percentages\n- Mark content types where relevant\n\nFormat as ASCII tree with Mermaid conversion.\n```\n\n**Expected output:** Complete sitemap in both ASCII and Mermaid format\n\n---\n\n### Step 3: Create Content Model (5 minutes)\n\n**Your Prompt:**\n\n```\nCreate a content model diagram for CLI tool documentation.\n\nContent types:\n1. Command Reference - Technical specs for each command\n2. Tutorial - Step-by-step learning content\n3. How-to Guide - Task-focused solutions\n4. Explanation - Conceptual content\n\nRelationships:\n- Tutorials reference Commands\n- How-to Guides reference Commands\n- Explanations provide context for Commands\n- Content can link to related content of any type\n\nShow in Mermaid erDiagram format with key attributes for each type.\n```\n\n**Expected output:** Content model diagram with relationships and metadata\n\n---\n\n### Step 4: Document User Flow (5 minutes)\n\n**Your Prompt:**\n\n```\nCreate a user flow diagram for a DevOps engineer learning to deploy infrastructure.\n\nStarting point: Documentation homepage\nGoal: Successfully deploy first application\nKey steps:\n- Installation\n- Configuration\n- First deployment\n- Monitoring\n- Troubleshooting (if errors)\n\nShow decision points and potential error paths.\nUse Mermaid flowchart format.\n```\n\n**Expected output:** Complete user flow with success and error paths\n\n---\n\n### Step 5: Generate Complete Documentation Package (10 minutes)\n\n**Your Prompt:**\n\n```\nGenerate a complete IA specification document for DevCLI documentation.\n\nInclude:\n1. Executive Summary\n   - Goals: Improve learning path, reduce time-to-first-deploy\n   - Key decisions: Task-based organization, Di\u00c3\u00a1taxis integration\n   - Success metrics\n\n2. IA Overview\n   - Organizational principle and rationale\n   - Hierarchy explanation\n   - Balance analysis\n   - Content type strategy\n   - Design trade-offs\n\n3. Embed the sitemap diagram (Mermaid)\n\n4. Embed the content model (Mermaid)\n\n5. Embed the user flow (Mermaid)\n\n6. Navigation specification\n   - Top nav items\n   - Sidebar logic\n   - Cross-linking strategy\n\n7. Implementation plan\n   - 4-week rollout\n   - Phases and milestones\n   - Success metrics\n\nFormat as professional markdown document with table of contents.\nUse the CloudStore example as a template for structure and depth.\n\nPROJECT CONTEXT:\n[Paste project brief from Step 1]\n[Include sitemaps, models, and flows from Steps 2-4]\n```\n\n**Expected output:** \n\nComplete markdown document (5-7 pages) with:\n- Professional formatting\n- Embedded Mermaid diagrams\n- Clear sections and headers\n- Implementation guidance\n- Ready for stakeholder review\n\n---\n\n### Step 6: Version Control Setup (5 minutes)\n\n**Create your repository structure:**\n\n```bash",
            "hydration_source_header": "VIII. Hands-on Tutorial: Generate Complete IA Documentation Set (25 minutes)",
            "hydration_method": "line_proximity"
          },
          {
            "id": "no-decision-rationale",
            "title": "Missing Decision Rationale",
            "prevents": "ADRs without 'why'",
            "lines": "2020",
            "retrievalQuestions": [
              "What mistakes should I avoid in IA documentation?"
            ],
            "content": "Reorganize documentation using task-based architecture where top-level categories represent user goals (\"Authenticate & Authorize\", \"Store & Manage Files\") rather than internal services.",
            "hydration_source_header": "Decision",
            "hydration_method": "title_match"
          }
        ],
        "tools": [
          {
            "id": "mermaid-live",
            "tool": "Mermaid Live Editor",
            "purpose": "Create/preview Mermaid diagrams",
            "lines": "implicit",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "draw-io",
            "tool": "Draw.io / Diagrams.net",
            "purpose": "Visual diagram creation",
            "lines": "implicit",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "whimsical",
            "tool": "Whimsical",
            "purpose": "Flowcharts and wireframes",
            "lines": "implicit",
            "retrievalQuestions": [
              "What tools for IA diagrams?"
            ],
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "figma-figjam",
            "tool": "Figma/FigJam",
            "purpose": "Collaborative diagramming",
            "lines": "implicit",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "lucidchart",
            "tool": "Lucidchart",
            "purpose": "Professional diagrams",
            "lines": "implicit",
            "hydration_status": "skipped_unknown"
          }
        ],
        "timeMetrics": [
          {
            "id": "site-map-time",
            "activity": "Site Map Creation",
            "traditionalTime": "2-4 hours",
            "aiAssistedTime": "30-60 min",
            "savings": "70%+",
            "lines": "2175",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "adr-time",
            "activity": "ADR Creation",
            "traditionalTime": "1-2 hours",
            "aiAssistedTime": "20-30 min",
            "savings": "70%+",
            "lines": "2180",
            "hydration_status": "skipped_unknown"
          },
          {
            "id": "documentation-suite-time",
            "activity": "Complete Documentation Suite",
            "traditionalTime": "8-16 hours",
            "aiAssistedTime": "2-4 hours",
            "savings": "75%+",
            "lines": "2185",
            "retrievalQuestions": [
              "How long does IA documentation take with AI?"
            ],
            "hydration_status": "skipped_unknown"
          }
        ]
      }
    }
  }
}